{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAryclxsQJ5"
      },
      "source": [
        "# **3D Semantic Segmentation pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook, we show how to apply a [BiaPy](https://biapyx.github.io/) pipeline for **3D semantic segmentation** of microscopy data.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://biapy.readthedocs.io/en/latest/_images/lucchi_test_0.png' width='300px'/>\n",
        "<img src='https://biapy.readthedocs.io/en/latest/_images/lucchi_test_0_gt.png' width='300px'/>\n",
        "<figcaption><b>Figure 1</b>: Example of a 3D semantic segmentation problem. From left to right: 3D electron microscopy image and its corresponding mitochondria semantic labels.</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "**Without any coding**, we explain step by step how to:\n",
        "1. **Upload a set of training and test images** along with their corresponding semantic label images.\n",
        "2. **Train a Deep Neural Network (DNN)** model using the training set.\n",
        "3. **Apply the model** to the test images.\n",
        "4. **Download the segmentation results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired by the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus), [Lenka Backov\u00e1](mailto:lenka.backova@ehu.eus), [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org) and [Ane Paniagua](mailto:anepaniagua@gmail.com). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5ClE_HHQaE"
      },
      "source": [
        "## **Expected Inputs and Outputs**\n",
        "___\n",
        "\n",
        "### **Inputs**\n",
        "\n",
        "This notebook anticipates the following five folders as input:\n",
        "\n",
        "- **Training Raw Images**: Contains the unprocessed 3D images used to train the model.\n",
        "- **Training Label Images**: Contains the 3D semantic label images for training. Ensure the number and dimensions match the training raw images.\n",
        "- **Test Raw Images**: Contains the 3D images to evaluate the model's performance.\n",
        "- **Test Label Images**: Contains the 3D semantic label images for testing. Again, ensure their count and sizes align with the test raw images.\n",
        "- **Output Folder**: A designated path to save the segmentation outcomes.\n",
        "\n",
        "### **Outputs**\n",
        "\n",
        "Upon successful execution, a directory will be generated with the segmentation results. Both probability maps and label images will be available for download at the notebook's conclusion.\n",
        "\n",
        "<font color='red'><b>Note:</b></font> For testing purposes, you can utilize the **example datasets provided under 'Manage File(s) Source > Option 3'**.\n",
        "\n",
        "**Data structure**\n",
        "\n",
        "To ensure the proper operation of the library the data directory tree should be something like this:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "\u251c\u2500\u2500 train\n",
        "\u2502   \u251c\u2500\u2500 raw\n",
        "\u2502   \u2502   \u251c\u2500\u2500 training-0001.tif\n",
        "\u2502   \u2502   \u251c\u2500\u2500 training-0002.tif\n",
        "\u2502   \u2502   \u251c\u2500\u2500 . . .\n",
        "\u2502   \u2502   \u2514\u2500\u2500 training-9999.tif\n",
        "\u2502   \u2514\u2500\u2500 label\n",
        "\u2502       \u251c\u2500\u2500 training_groundtruth-0001.tif\n",
        "\u2502       \u251c\u2500\u2500 training_groundtruth-0002.tif\n",
        "\u2502       \u251c\u2500\u2500 . . .\n",
        "\u2502       \u2514\u2500\u2500 training_groundtruth-9999.tif\n",
        "\u2514\u2500\u2500 test\n",
        "    \u251c\u2500\u2500 raw\n",
        "    \u2502   \u251c\u2500\u2500 testing-0001.tif\n",
        "    \u2502   \u251c\u2500\u2500 testing-0002.tif\n",
        "    \u2502   \u251c\u2500\u2500 . . .\n",
        "    \u2502   \u2514\u2500\u2500 testing-9999.tif\n",
        "    \u2514\u2500\u2500 label\n",
        "        \u251c\u2500\u2500 testing_groundtruth-0001.tif\n",
        "        \u251c\u2500\u2500 testing_groundtruth-0002.tif\n",
        "        \u251c\u2500\u2500 . . .\n",
        "        \u2514\u2500\u2500 testing_groundtruth-9999.tif\n",
        "```\n",
        "\n",
        "**\u26a0\ufe0f Warning:** Ensure that images and their corresponding masks are sorted in the same way. A common approach is to fill with zeros the image number added to the filenames (as in the example).\n",
        "\n",
        "**Input Format Support**\n",
        "\n",
        "This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.npy` (every extension for 3D images supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread)).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGSj0DrpUJoY"
      },
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bj_sbDFTiZ7"
      },
      "source": [
        "## **Check for GPU Access**\n",
        "---\n",
        "\n",
        "By default, the session is configured to use Python 3 with GPU acceleration. However, it's a good practice to double-check these settings:\n",
        "\n",
        "1. Navigate to **Runtime** in the top menu and select **Change the Runtime type**.\n",
        "2. Ensure the following settings:\n",
        "   - **Runtime type:** Python 3 (This program is written in the Python 3 programming language.)\n",
        "   - **Accelerator:** GPU (Graphics Processing Unit)\n",
        "\n",
        "This will ensure that you're using Python 3 and taking advantage of GPU acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYG2zlUAEfFU"
      },
      "source": [
        "## **Install BiaPy**\n",
        "---\n",
        "This might take some minutes depending on the current installed libraries in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1742987930340,
          "user_tz": -60,
          "elapsed": 217914,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "4dab9c0f-6c01-4eed-ef98-547d2492a139",
        "cellView": "form",
        "id": "yW7YmO1zEfFa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biapy==3.5.12\n",
            "  Downloading biapy-3.5.12-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.6.1)\n",
            "Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.0.4)\n",
            "Collecting yacs>=0.1.8 (from biapy==3.5.12)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (0.25.2)\n",
            "Collecting edt>=2.3.2 (from biapy==3.5.12)\n",
            "  Downloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting fill-voids>=2.0.6 (from biapy==3.5.12)\n",
            "  Downloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.76 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.2.2)\n",
            "Collecting torchinfo>=1.8.0 (from biapy==3.5.12)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.6.2.2 (from biapy==3.5.12)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: h5py>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.13.0)\n",
            "Requirement already satisfied: zarr>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.18.4)\n",
            "Collecting bioimageio.core==0.7.0 (from biapy==3.5.12)\n",
            "  Downloading bioimageio.core-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting imagecodecs>=2024.1.1 (from biapy==3.5.12)\n",
            "  Downloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.26.4)\n",
            "Collecting imgaug>=0.4.0 (from biapy==3.5.12)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pooch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.8.2)\n",
            "Collecting diplib>=3.5.1 (from biapy==3.5.12)\n",
            "  Downloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting pydantic<2.10,>=2.7.0 (from biapy==3.5.12)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray==2025.1.* in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2025.1.2)\n",
            "Collecting bioimageio.spec==0.5.3.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading bioimageio.spec-0.5.3.5-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: imageio>=2.10 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.37.0)\n",
            "Collecting loguru (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic-settings>=2.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.32.3)\n",
            "Collecting ruyaml (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading ruyaml-0.91.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (4.12.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray==2025.1.*->biapy==3.5.12) (24.2)\n",
            "Requirement already satisfied: annotated-types<1,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.7.0)\n",
            "Collecting email-validator (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.8.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (13.9.4)\n",
            "Requirement already satisfied: tifffile>=2020.7.4 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2025.3.13)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.21.0)\n",
            "Collecting fastremap (from fill-voids>=2.0.6->biapy==3.5.12)\n",
            "  Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (11.1.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (2.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.8.1->biapy==3.5.12) (4.3.7)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<2.10,>=2.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (3.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.5.12) (5.29.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8->biapy==3.5.12) (6.0.2)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.3.3)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.19)\n",
            "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.15.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.2.18)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2025.1.31)\n",
            "Requirement already satisfied: distro>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=39.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (75.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.1.2)\n",
            "Downloading biapy-3.5.12-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.core-0.7.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.spec-0.5.3.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruyaml-0.91.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yacs, torchinfo, tensorboardX, ruyaml, python-dotenv, pydantic-core, loguru, imagecodecs, fastremap, edt, dnspython, diplib, pydantic, fill-voids, email-validator, pydantic-settings, imgaug, bioimageio.spec, bioimageio.core, biapy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "Successfully installed biapy-3.5.12 bioimageio.core-0.7.0 bioimageio.spec-0.5.3.5 diplib-3.5.2 dnspython-2.7.0 edt-3.0.0 email-validator-2.2.0 fastremap-1.15.1 fill-voids-2.0.8 imagecodecs-2024.12.30 imgaug-0.4.0 loguru-0.7.3 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.8.1 python-dotenv-1.1.0 ruyaml-0.91.0 tensorboardX-2.6.2.2 torchinfo-1.8.0 yacs-0.1.8\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting torchmetrics==1.4.* (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (24.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.4.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (0.19.0+cu118)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.86)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-msssim, torch-fidelity\n",
            "Successfully installed lightning-utilities-0.14.2 pytorch-msssim-1.0.0 torch-fidelity-0.3.0 torchmetrics-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "!pip install git+https://www.github.com/BiaPyX/BiaPy.git\n",
        "\n",
        "# Then install Pytorch + CUDA 11.8\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Finally install some packages that rely on the Pytorch installation\n",
        "!pip install timm pytorch-msssim torchmetrics[image]==1.4.*\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "from biapy import BiaPy\n",
        "\n",
        "changed_source = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZmI9c09OhSo"
      },
      "source": [
        "## **Manage File(s) Source**\n",
        "---\n",
        "\n",
        "The input folder can be provided using three different options:\n",
        "1. **Direct Upload**: Directly upload the desired folder.\n",
        "2. **Google Drive**: Use a folder stored in your Google Drive.\n",
        "3. **Sample Data**: Use a sample dataset provided by us.\n",
        "\n",
        "The steps you'll need to follow vary depending on your chosen option. These steps are detailed in the subsequent sections.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPksHcHLO0SU"
      },
      "source": [
        "### **Option 1: Upload Local Files to the Notebook**\n",
        "---\n",
        "You will be prompted to upload your files to Colab and they will be stored under `/content/input/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xGS5LCaHPWR8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train raw images)\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/raw\n",
        "%cd /content/input/train/raw\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qyvRptgjXMMN"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train label images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/label\n",
        "%cd /content/input/train/label\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PafWC0U3XYjd"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (test raw images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test/raw\n",
        "%cd /content/input/test/raw\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Tl1qtfeJXYp1"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (test label images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test/label\n",
        "%cd /content/input/test/label\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXGd55gUYjK"
      },
      "source": [
        "### **Option 2: Mount Your Google Drive**\n",
        "---\n",
        "\n",
        "If you wish to use this notebook with data from your Google Drive, you'll first need to mount the drive to this notebook.\n",
        "\n",
        "Execute the cell below to initiate the Google Drive mounting process. A link will be displayed click on it. In the new browser window that opens, choose your drive and click 'Allow'. Copy the code that appears, return to this notebook, paste the code into the cell, and press 'Enter'. This action grants Colab access to your Google Drive data.\n",
        "\n",
        "After this process, you can access your data via the **Files** tab, located on the top left of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h-yXrZLdUk3Z"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL.\n",
        "\n",
        "#@markdown * Sign in your Google Account.\n",
        "\n",
        "#@markdown * Copy the authorization code.\n",
        "\n",
        "#@markdown * Enter the authorization code.\n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9FcxFB3H7az"
      },
      "source": [
        "### **Option 3: Download an Example Dataset**\n",
        "---\n",
        "Don't have data readily available but still want to test the notebook? No problem! Simply execute the following cell to download a sample dataset.\n",
        "\n",
        "Specifically, we'll use the [Electron Microscopy Dataset (EPFL - CVLAB)](https://www.epfl.ch/labs/cvlab/data/data-em/) which is publicly available online."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 23778,
          "status": "ok",
          "timestamp": 1745318003534,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          },
          "user_tz": -120
        },
        "id": "pD3aoo-ZUtW4",
        "outputId": "4c3c5fe4-c950-4e1b-cea2-a159f7aae7d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "!pip install gdown==5.1.0 --quiet\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "gdown.download(\"https://drive.google.com/uc?id=10Cf11PtERq4pDHCJroekxu_hf10EZzwG\", \"fibsem_epfl.zip\", quiet=True)\n",
        "\n",
        "!unzip -q fibsem_epfl.zip\n",
        "!rm fibsem_epfl.zip\n",
        "\n",
        "print( 'Dataset downloaded and unzipped under /content/data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEv7FBXFQvjv"
      },
      "source": [
        "## **Paths for Input Images and Output Files**\n",
        "___\n",
        "\n",
        "Depending on the option you chose for managing file sources, you'll set your paths differently:\n",
        "\n",
        "- **Option 1 (Upload from Local Machine)**:\n",
        "  - Set `train_data_path` to `/content/input/train/raw`\n",
        "  - Set `train_data_gt_path` to `/content/input/train/label`\n",
        "  - Set `test_data_path` to `/content/input/test/raw`\n",
        "  - Set `test_data_gt_path` to `/content/input/test/label`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "- **Option 2 (Use Google Drive Data)**:\n",
        "  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n",
        "  \n",
        "- **Option 3 (Use Our Sample Data)**:\n",
        "  - Set `train_data_path` to `/content/data/train/raw`\n",
        "  - Set `train_data_gt_path` to `/content/data/train/label`\n",
        "  - Set `test_data_path` to `/content/data/test/raw`\n",
        "  - Set `test_data_gt_path` to `/content/data/test/label`\n",
        "  - Set `output_path` to `/content/out`\n",
        "\n",
        "  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n",
        "\n",
        "**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl4e0UIGYZcx",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745318003581,
          "user_tz": -120,
          "elapsed": 45,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "eb9dea18-e17b-4b9a-d61e-bf05fbd1dfb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training raw images: 1\n",
            "Number of training label images: 1\n",
            "Number of test raw images: 1\n",
            "Number of test label images: 1\n"
          ]
        }
      ],
      "source": [
        "#@markdown #####Path to training input images\n",
        "train_data_path = '/content/data/train/raw' #@param {type:\"string\"}\n",
        "#@markdown #####Path to training label images\n",
        "train_data_gt_path = '/content/data/train/label' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test input images\n",
        "test_data_path = '/content/data/test/raw' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test label images (if available)\n",
        "test_data_gt_path = '/content/data/test/label' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def count_image_files(directory):\n",
        "    if not directory or not os.path.exists(directory):\n",
        "        return 0\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.tif', '.npy', '.tiff', '.h5', '.hd5', '.zarr'}\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in image_extensions:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "num_train_images = count_image_files(train_data_path)\n",
        "num_train_labels = count_image_files(train_data_gt_path)\n",
        "\n",
        "num_test_images = count_image_files(test_data_path)\n",
        "num_test_labels = count_image_files(test_data_gt_path)\n",
        "\n",
        "print(f\"Number of training raw images: {num_train_images}\")\n",
        "print(f\"Number of training label images: {num_train_labels}\")\n",
        "print(f\"Number of test raw images: {num_test_images}\")\n",
        "if test_data_gt_path != \"\":\n",
        "    print(f\"Number of test label images: {num_test_labels}\")\n",
        "\n",
        "if num_train_images != num_train_labels:\n",
        "    print(\"Error: The number of training raw images does not match the number of training label images.\")\n",
        "if test_data_gt_path != \"\" and num_test_images != num_test_labels:\n",
        "    print(\"Error: The number of test raw images does not match the number of test label images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "SQRFra4_fk0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## Play to visualize some data samples\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread\n",
        "import os\n",
        "from ipywidgets import interact, IntSlider, Layout, Dropdown, VBox, Output\n",
        "\n",
        "# Initialize global attributes\n",
        "input_path = train_data_path\n",
        "gt_path = train_data_gt_path\n",
        "\n",
        "instance_id = 0\n",
        "\n",
        "ids_input = sorted(next(os.walk(input_path))[2])\n",
        "input_img = imread(os.path.join(input_path, ids_input[0]))\n",
        "\n",
        "ids_gt = sorted(next(os.walk(gt_path))[2])\n",
        "gt_img = imread(os.path.join(gt_path, ids_gt[0])).astype(np.uint16)\n",
        "\n",
        "# Initialize widgets\n",
        "\n",
        "# Dropdown widget to choose training or test set\n",
        "dropdown = Dropdown(\n",
        "    options=['training-set', 'test-set'],\n",
        "    value='training-set',\n",
        "    description='Set:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Slider widget to choose instance\n",
        "slider= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(ids_input),\n",
        "    step=1,\n",
        "    description='Image index:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "slider.style.description_width = 'initial'\n",
        "slider.style.handle_color='blue'\n",
        "\n",
        "# Slider widget to choose Z value\n",
        "sliderZ= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(input_img),\n",
        "    step=1,\n",
        "    description='Z value:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "sliderZ.style.description_width = 'initial'\n",
        "sliderZ.style.handle_color='blue'\n",
        "\n",
        "# Initialize Output instance to handle code output cell\n",
        "output = Output()\n",
        "\n",
        "# Function to update paths (input_path, gt_path) and image IDs (ids_input, ids_gt) depending on dropdown\n",
        "def update_paths(change):\n",
        "    global input_path, gt_path\n",
        "    if change.new == 'test-set':\n",
        "        input_path = test_data_path\n",
        "        gt_path = test_data_gt_path\n",
        "    else:\n",
        "        input_path = train_data_path\n",
        "        gt_path = train_data_gt_path\n",
        "\n",
        "    global ids_input, ids_gt\n",
        "    ids_input = sorted(next(os.walk(input_path))[2])\n",
        "    try:\n",
        "        ids_gt = sorted(next(os.walk(gt_path))[2])\n",
        "    except StopIteration:\n",
        "        ids_gt = []\n",
        "\n",
        "    # Reset instance slider value to 1 when dropdown changes\n",
        "    slider.value = 1\n",
        "    slider.max = len(ids_input)\n",
        "    update_id({'new': 1})\n",
        "\n",
        "# Function to update image and label set (input_img, gt_img, instance_id) depending on slider value\n",
        "def update_id(change):\n",
        "    index = change['new']\n",
        "\n",
        "    global instance_id\n",
        "    instance_id = index - 1\n",
        "\n",
        "    global input_path, ids_input, input_img, gt_path, ids_gt, gt_img\n",
        "    input_img_path = os.path.join(input_path, ids_input[instance_id])\n",
        "    input_img = imread(input_img_path)\n",
        "\n",
        "    if ids_gt != []: # If StopIteration exception was not thrown\n",
        "        gt_img_path = os.path.join(gt_path, ids_gt[instance_id])\n",
        "        gt_img = imread(gt_img_path).astype(np.uint16)\n",
        "    else:\n",
        "        gt_img = None\n",
        "\n",
        "    sliderZ.value = 1\n",
        "    sliderZ.max = len(input_img)\n",
        "    display_images({'new': 1})\n",
        "\n",
        "# Function to display images depending on sliderZ value\n",
        "def display_images(change):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "        index = change['new']\n",
        "\n",
        "        global input_img, gt_img, instance_id\n",
        "\n",
        "        # Display images\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f\"Input image: {instance_id+1}, Z: {index}\")\n",
        "        plt.imshow(input_img[index-1], cmap='gray')\n",
        "        # plt.axis('off')\n",
        "\n",
        "        # # Print sample path to ensure the image displayed is correct\n",
        "        # global input_path, ids_input\n",
        "        # print(os.path.join(input_path, ids_input[instance_id]))\n",
        "\n",
        "        if gt_img is not None: # If StopIteration exception was not thrown\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.title(\"Label\")\n",
        "            plt.imshow(np.squeeze(gt_img[index-1]), cmap='gray', interpolation='nearest')\n",
        "            # plt.axis('off')\n",
        "\n",
        "            # # Print label path to ensure the image displayed is correct\n",
        "            # global gt_path, ids_gt\n",
        "            # print(os.path.join(gt_path, ids_gt[instance_id]))\n",
        "\n",
        "        else:\n",
        "            print(\"No labels for this set.\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create an VBox to hold the dropdown and slider\n",
        "controls = VBox([dropdown, slider, sliderZ])\n",
        "display(controls, output)\n",
        "\n",
        "# Link widgets to functions\n",
        "dropdown.observe(update_paths, names='value')\n",
        "slider.observe(update_id, names='value')\n",
        "sliderZ.observe(display_images, names='value')\n",
        "\n",
        "# Initial display\n",
        "display_images({'new': slider.value})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488,
          "referenced_widgets": [
            "af956665f4c841bcb3a4b8b935a66b80",
            "a867393a3d614c0897dfee88e7946ded",
            "c7f3dc36bda34ba59ca36b1d1fabbf88",
            "183dff2073624539b3002494c2bd23c6",
            "703929bca8304ffaaa1fe2df2769da0e",
            "2c77a0af0d7d47d390e9fc1197a88e6f",
            "ef8c8d003c834056a31468f7266a1e1f",
            "e5fff3a4221149478196d168bbc23062",
            "9b225767403646928729fcbae1787dd1",
            "e87c1d9d777a414baf8e5ac1c4dea264",
            "8ce070b9606147d8a318134e0945e96a",
            "3bfe089e17cf4e93a05c0641a2fec2fe",
            "87741be779c64cf59d7b7854650fc252"
          ]
        },
        "id": "HA7kAfXIOzz2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1734435960574,
          "user_tz": -60,
          "elapsed": 1433,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "d62221d8-3584-456c-e9ff-0591000eacba",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Set:', options=('training-set', 'test-set'), value='training-set'), IntSl\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af956665f4c841bcb3a4b8b935a66b80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3bfe089e17cf4e93a05c0641a2fec2fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZwoZC20rK42"
      },
      "source": [
        "## **Configure and train the DNN model**\n",
        "[BiaPy](https://biapy.readthedocs.io/en/latest/) contains a large list of deep learning models to perform semantic segmentation.\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1727165041562,
          "user_tz": -120,
          "elapsed": 45382,
          "user": {
            "displayName": "Daniel Franco-Barranco",
            "userId": "13463799105703234009"
          }
        },
        "outputId": "bfa098a1-e705-4137-fe0f-d805aadf5451",
        "id": "daGtIo-V_Ydt",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>List of models that can be used in BiaPy:</h1><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table style='width:100%''><tr><td style='width:33%'><p style='color:#2196f3'>3D UNet Mouse Embryo Live</p><p>Nickname: powerful-fish (\ud83d\udc1f)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/powerful-fish/1/files/raw.png' height='220'></td><td style='width:33%'><p style='color:#2196f3'>3D UNet Mouse Embryo Fixed</p><p>Nickname: loyal-squid (\ud83e\udd91)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/loyal-squid/1/files/raw.png' height='220'></td><td style='width:33%'><p style='color:#2196f3'>3D UNet Lateral Root Primordia Cells</p><p>Nickname: thoughtful-turtle (\ud83d\udc22)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/thoughtful-turtle/1/files/raw.png' height='220'></td></tr><tr><td style='width:33%'><p style='color:#2196f3'>3D UNet Arabidopsis Ovules</p><p>Nickname: passionate-t-rex (\ud83e\udd96)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/passionate-t-rex/1/files/ilastik_raw.png' height='220'></td><td style='width:33%'><p style='color:#2196f3'>CebraNET Cellular Membranes in Volume SEM</p><p>Nickname: joyful-deer (\ud83e\udd8c)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/joyful-deer/1/files/coverimage.jpg' height='220'></td><td style='width:33%'><p style='color:#2196f3'>3D UNet Arabidopsis Ovules Nuclei</p><p>Nickname: noisy-fish (\ud83d\udc1f)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/noisy-fish/1/files/raw.png' height='220'></td></tr><tr><td style='width:33%'><p style='color:#2196f3'>3D UNet Arabidopsis Apical Stem Cells</p><p>Nickname: emotional-cricket (\ud83e\udd97)</p><p>number_of_classes: 2</p><img src='https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/emotional-cricket/1.1/files/raw.png' height='220'></td></table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ###OPTIONAL: Check BioImage Model Zoo (BMZ) models compatible with BiaPy\n",
        "# @markdown Use this option to generate a full list of the available BiaPy-compatible models in the BMZ.\n",
        "\n",
        "# @markdown **Important:** To select one of the listed models (if any), you will have to run the next cell and select \"BioImage Model Zoo\" as the source of the model. Then, paste the corresponding model's nickname into the created field.\n",
        "# @markdown <div><img src=\"https://bioimage.io/static/img/bioimage-io-logo.svg\" width=\"600\"/></div>\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pooch\n",
        "import yaml\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "from biapy.models import check_bmz_model_compatibility\n",
        "from packaging.version import Version\n",
        "from typing import Optional, Dict, Tuple, List, Literal\n",
        "\n",
        "# Change pooch verbosity\n",
        "logger = pooch.get_logger()\n",
        "logger.setLevel(\"WARNING\")\n",
        "\n",
        "# Extracted from BiaPy-GUI.\n",
        "# Adapted from BiaPy commit: 284ec3838766392c9a333ac9d27b55816a267bb9 (3.5.2)\n",
        "def check_model_restrictions(\n",
        "    model_rdf,\n",
        "    workflow_specs,\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks model restrictions to be applied into the current configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_rdf : dict\n",
        "        BMZ model RDF that contains all the information of the model.\n",
        "\n",
        "    workflow_specs : dict\n",
        "        Specifications of the workflow. If not provided all possible models will be considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    option_list: dict\n",
        "        Variables and values to change in current configuration. These changes\n",
        "        are imposed by the selected model.\n",
        "    \"\"\"\n",
        "    specific_workflow = workflow_specs[\"workflow_type\"]\n",
        "\n",
        "    # Version of the model\n",
        "    model_version = Version(model_rdf[\"format_version\"])\n",
        "    opts = {}\n",
        "\n",
        "    # 1) Change PATCH_SIZE with the one stored in the model description. This differs from the code of BiaPy where\n",
        "    # get_test_inputs() is simply used as there a ModelDescr is build out of the RDF. Here we try to do it manually\n",
        "    # to avoid fetching files using the network as it may be slow.\n",
        "    input_image_shape = []\n",
        "    if \"shape\" in model_rdf[\"inputs\"][0]:\n",
        "        input_image_shape = model_rdf[\"inputs\"][0][\"shape\"]\n",
        "        # \"CebraNET Cellular Membranes in Volume SEM\" ('format_version': '0.4.10')\n",
        "        #   have: {'min': [1, 1, 64, 64, 64], 'step': [0, 0, 16, 16, 16]}\n",
        "        if isinstance(input_image_shape, dict) and \"min\" in input_image_shape:\n",
        "            input_image_shape = input_image_shape[\"min\"]\n",
        "    else:\n",
        "        # Check axes and dimension\n",
        "        input_image_shape = []\n",
        "        for axis in model_rdf[\"inputs\"][0][\"axes\"]:\n",
        "            if 'type' in axis:\n",
        "                if axis['type'] == \"batch\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif axis['type'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif 'id' in axis and 'size' in axis:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "            elif 'id' in axis:\n",
        "                if axis['id'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                else:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "    if len(input_image_shape) == 0:\n",
        "        raise ValueError(\"Couldn't load input info from BMZ model's RDF: {}\".format(model_rdf[\"inputs\"][0]))\n",
        "    opts[\"DATA.PATCH_SIZE\"] = tuple(input_image_shape[2:]) + (input_image_shape[1],)\n",
        "\n",
        "    # Capture model kwargs\n",
        "    if \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]:\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"kwargs\"]\n",
        "    elif (\n",
        "        \"architecture\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]\n",
        "        and \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"]\n",
        "    ):\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"][\"kwargs\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Couldn't extract kwargs from model description.\")\n",
        "\n",
        "    # 2) Workflow specific restrictions\n",
        "    # Classes in semantic segmentation\n",
        "    if specific_workflow in [\"SEMANTIC_SEG\"]:\n",
        "        # Check number of classes\n",
        "        classes = -1\n",
        "        if \"n_classes\" in model_kwargs: # BiaPy\n",
        "            classes = model_kwargs[\"n_classes\"]\n",
        "        elif \"out_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"out_channels\"]\n",
        "        elif \"classes\" in model_kwargs:\n",
        "            classes = model_kwargs[\"classes\"]\n",
        "\n",
        "        if isinstance(classes, list):\n",
        "            classes = classes[0]\n",
        "        if not isinstance(classes, int):\n",
        "            raise ValueError(f\"Classes not extracted correctly. Obtained {classes}\")\n",
        "\n",
        "        if specific_workflow == \"SEMANTIC_SEG\" and classes == -1:\n",
        "            raise ValueError(\"Classes not found for semantic segmentation dir. \")\n",
        "        opts[\"MODEL.N_CLASSES\"] = max(2,classes)\n",
        "    elif specific_workflow in [\"INSTANCE_SEG\"]:\n",
        "        # Assumed it's BC. This needs a more elaborated process. Still deciding this:\n",
        "        # https://github.com/bioimage-io/spec-bioimage-io/issues/621\n",
        "        channels = 2\n",
        "        if \"out_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"out_channels\"]\n",
        "        if channels == 1:\n",
        "            channel_code = \"C\"\n",
        "        elif channels == 2:\n",
        "            channel_code = \"BC\"\n",
        "        elif channels == 3:\n",
        "            channel_code = \"BCM\"\n",
        "        if channels > 3:\n",
        "            raise ValueError(f\"Not recognized number of channels for instance segmentation. Obtained {channels}\")\n",
        "\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\"] = channel_code\n",
        "\n",
        "    if \"preprocessing\" not in model_rdf[\"inputs\"][0]:\n",
        "        return opts\n",
        "\n",
        "    preproc_info = model_rdf[\"inputs\"][0][\"preprocessing\"]\n",
        "    if len(preproc_info) == 0:\n",
        "        return opts\n",
        "    preproc_info = preproc_info[0]\n",
        "\n",
        "    # 3) Change preprocessing to the one stablished by BMZ by translate BMZ keywords into BiaPy's\n",
        "    # 'zero_mean_unit_variance' and 'fixed_zero_mean_unit_variance' norms of BMZ can be translated to our 'custom' norm\n",
        "    # providing mean and std\n",
        "    key_to_find = \"id\" if model_version > Version(\"0.5.0\") else \"name\"\n",
        "    if key_to_find in preproc_info:\n",
        "        if preproc_info[key_to_find] in [\"fixed_zero_mean_unit_variance\", \"zero_mean_unit_variance\"]:\n",
        "            if (\n",
        "                \"kwargs\" in preproc_info\n",
        "                and \"mean\" in preproc_info[\"kwargs\"]\n",
        "            ):\n",
        "                mean = preproc_info[\"kwargs\"][\"mean\"]\n",
        "                std = preproc_info[\"kwargs\"][\"std\"]\n",
        "            elif \"mean\" in preproc_info:\n",
        "                mean = preproc_info[\"mean\"]\n",
        "                std = preproc_info[\"std\"]\n",
        "            else:\n",
        "                mean, std = -1., -1.\n",
        "\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"custom\"\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_MEAN\"] = mean\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_STD\"] = std\n",
        "\n",
        "        # 'scale_linear' norm of BMZ is close to our 'div' norm (TODO: we need to control the \"gain\" arg)\n",
        "        elif preproc_info[key_to_find] == \"scale_linear\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"div\"\n",
        "\n",
        "        # 'scale_range' norm of BMZ is as our PERC_CLIP + 'scale_range' norm\n",
        "        elif preproc_info[key_to_find] == \"scale_range\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"scale_range\"\n",
        "            if (\n",
        "                float(preproc_info[\"kwargs\"][\"min_percentile\"]) != 0\n",
        "                or float(preproc_info[\"kwargs\"][\"max_percentile\"]) != 100\n",
        "            ):\n",
        "                opts[\"DATA.NORMALIZATION.PERC_CLIP\"] = True\n",
        "                opts[\"DATA.NORMALIZATION.PERC_LOWER\"] = float(preproc_info[\"kwargs\"][\"min_percentile\"])\n",
        "                opts[\"DATA.NORMALIZATION.PERC_UPPER\"] = float(preproc_info[\"kwargs\"][\"max_percentile\"])\n",
        "\n",
        "    return opts\n",
        "\n",
        "# Check the models that BiaPy can consume\n",
        "COLLECTION_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/collection.json\"\n",
        "collection_path = Path(pooch.retrieve(COLLECTION_URL, known_hash=None))\n",
        "with collection_path.open() as f:\n",
        "    collection = json.load(f)\n",
        "\n",
        "model_urls = [entry[\"rdf_source\"] for entry in collection[\"collection\"] if entry[\"type\"] == \"model\"]\n",
        "\n",
        "model_rdfs = []\n",
        "for mu in model_urls:\n",
        "    with open(Path(pooch.retrieve(mu, known_hash=None)), 'rt', encoding='utf8') as stream:\n",
        "        try:\n",
        "            model_rdfs.append(yaml.safe_load(stream))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "\n",
        "# Check axes, preprocessing functions used and postprocessing.\n",
        "pytorch_models = []\n",
        "imposed_vars = []\n",
        "\n",
        "workflow_specs = {\n",
        "    \"workflow_type\": \"SEMANTIC_SEG\",\n",
        "    \"ndim\": \"3D\",\n",
        "    \"nclasses\": \"all\",\n",
        "}\n",
        "for model_rdf in model_rdfs:\n",
        "    try:\n",
        "        (\n",
        "            preproc_info,\n",
        "            error,\n",
        "            error_message\n",
        "        ) = check_bmz_model_compatibility(model_rdf, workflow_specs=workflow_specs)\n",
        "    except:\n",
        "        error = True\n",
        "\n",
        "    if not error:\n",
        "        model_imposed_vars = check_model_restrictions(model_rdf, workflow_specs=workflow_specs)\n",
        "        imposed_vars.append(model_imposed_vars)\n",
        "        pytorch_models.append(model_rdf)\n",
        "\n",
        "# Print the possible models\n",
        "html = \"<table style='width:100%''>\"\n",
        "c = 0\n",
        "for i, model in enumerate(pytorch_models):\n",
        "\n",
        "    if 'nickname' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['nickname']\n",
        "        nickname_icon = model['config']['bioimageio']['nickname_icon']\n",
        "    elif 'id' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['id']\n",
        "        nickname_icon = model['config']['bioimageio']['id_emoji']\n",
        "    else:\n",
        "        doi = \"/\".join(model['id'].split(\"/\")[:2])\n",
        "        nickname = doi\n",
        "        nickname_icon = doi\n",
        "    cover_url = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/\"+nickname+\"/\"+str(model[\"version\"])+\"/files/\"+model['covers'][0]\n",
        "    restrictions = \"\"\n",
        "    for key, val in imposed_vars[i].items():\n",
        "        if key == 'MODEL.N_CLASSES':\n",
        "            restrictions += \"<p>number_of_classes: {}</p>\".format(val)\n",
        "        elif key == \"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\":\n",
        "            problem_channels = 'Binary mask + Contours'\n",
        "            if val == \"BC\":\n",
        "                problem_channels = \"Binary mask + Contours\"\n",
        "            elif val == 'BP':\n",
        "                problem_channels = \"Binary mask + Central points\"\n",
        "            elif val == 'BD':\n",
        "                problem_channels = \"Binary mask + Distance map\"\n",
        "            elif val == 'BCM':\n",
        "                problem_channels = \"Binary mask + Contours + Foreground mask\"\n",
        "            elif val == 'BCD':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map\"\n",
        "            elif val == 'BCDv2':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map with background\"\n",
        "            elif val == 'Dv2':\n",
        "                problem_channels = \"Distance map with background\"\n",
        "            restrictions += \"<p>problem_representation: {}</p>\".format(problem_channels)\n",
        "    if c == 0:\n",
        "        html += \"<tr>\"\n",
        "    html += \"<td style='width:33%'>\"\n",
        "    html += \"<p style='color:#2196f3'>%s</p><p>Nickname: %s (%s)</p>%s<img src='%s' height='200'></td>\"%(\n",
        "        model['name'],\n",
        "        nickname,\n",
        "        nickname_icon,\n",
        "        restrictions,\n",
        "        cover_url,\n",
        "    )\n",
        "    c +=1\n",
        "    if c == 3:\n",
        "        html += \"</tr>\"\n",
        "        c=0\n",
        "html += \"</table>\"\n",
        "if len( pytorch_models ) == 0:\n",
        "    display(HTML('<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>'))\n",
        "else:\n",
        "    display(HTML('<h1>List of models that can be used in BiaPy:</h1><br>'))\n",
        "    display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b89f729adb604671b0087d7c54040fb2",
            "0a33d54376a547e3bbc4f99aebf21c01",
            "25e197065dbd42b6bc26234aacbe2ba8",
            "e553a4014f4a4d6082cef8294588d4bb",
            "eb5403d4d1924b08a2feca4b4fa7924a",
            "47f42641a4234f449a35d9a974c8a102",
            "b23822c4887a4092a3f75dc1e2aa3753",
            "80da20535a6b4223acce206afaffe036"
          ]
        },
        "executionInfo": {
          "elapsed": 6,
          "status": "ok",
          "timestamp": 1707294611268,
          "user": {
            "displayName": "Lenka Backov\u00e1",
            "userId": "06932584979084724145"
          },
          "user_tz": -60
        },
        "id": "bTQfoFf1mlw8",
        "outputId": "978e5b79-68a2-4bfb-8673-b8da1d9c1780"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b89f729adb604671b0087d7c54040fb2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ToggleButtons(description='Source:', options=('BiaPy', 'BioImage Model Zoo'), tooltips=('Models created during\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e553a4014f4a4d6082cef8294588d4bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='', description='DOI:', layout=Layout(display='flex'), placeholder='DOI of BMZ model')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b23822c4887a4092a3f75dc1e2aa3753",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output(outputs=({'output_type': 'display_data', 'data': {}, 'metadata': {}},))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to select the source to build the model (BiaPy or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown **BiaPy**: to use the models implemented in BiaPy.\n",
        "\n",
        "#@markdown **Bioimage Model Zoo (BMZ)**: to use models from the [BMZ repository](https://bioimage.io/#/). You can run the above cell to generate an updated list of the models that can be used with BiaPy. Copy the nickname from the model and paste it below.\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "\n",
        "changed_source = True\n",
        "exists_bmz = False\n",
        "# create widgets\n",
        "source = widgets.ToggleButtons(\n",
        "    options=['BiaPy', 'BioImage Model Zoo'],\n",
        "    description='Source:',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltips=['Models created during this workflow', 'BioImage Model Zoo model'],\n",
        "#     icons=['check'] * 3\n",
        ")\n",
        "\n",
        "bmz = widgets.Text(\n",
        "    # value='10.5281/zenodo.5764892',\n",
        "    placeholder='Nickname of BMZ model',\n",
        "    description='ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# display the first widget\n",
        "display(source)\n",
        "\n",
        "# intialize the output - second widget\n",
        "out = Output()\n",
        "\n",
        "def changed(change):\n",
        "    '''\n",
        "    Monitor change in the first widget\n",
        "    '''\n",
        "    global out\n",
        "    global exists_bmz\n",
        "    if source.value == 'BiaPy':\n",
        "        bmz.layout.display = 'none'\n",
        "        out.clear_output() #clear output\n",
        "        out = Output() # redefine output\n",
        "    else:\n",
        "        bmz.layout.display = 'none'\n",
        "        bmz.layout.display = 'flex'\n",
        "        if not exists_bmz:\n",
        "          out.append_display_data(bmz)\n",
        "          display(out)\n",
        "        exists_bmz = True\n",
        "\n",
        "# monitor the source widget for changes\n",
        "source.observe(changed, 'value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfUyeHEP4vY3"
      },
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "* **`test_ground_truth`:** Select to use test data ground truth to measure the performance of the model's result. If selected, **test_data_gt_path** variable path set above will be used. **Default value: True**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`number_of_classes`:** Input number of segmentation classes/labels (number of different classes + background) **Default value: 2**\n",
        "\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 1**\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. For the example dataset, reasonable results can already be observed after 100 epochs. **Default value: 30**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 30**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: U-Net, Residual U-Net, Attention U-Net, SEUNet, MultiResUNet, ResUNet++ (see [Franco-Barranco et al., 2021](https://link.springer.com/article/10.1007/s12021-021-09556-1)), UNETR-Mini, UNETR-Small, UNETR-Base and U-NeXt V1. **Default value: Residual U-Net**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 4**\n",
        "\n",
        "* **`patch_size_xy`:** Input the XY size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 80**\n",
        "\n",
        "* **`patch_size_z`:** Input the Z size of the patches use to train your model (length in pixels in Z). The value should be smaller or equal to the dimensions of the image. **Default value: 80**\n",
        "\n",
        "* **`anisotropic_data`:** Select if your image data is anisotropic (lower resolution in Z with respect to XY). The model downsampling step size will be set accordingly. **Default value: False**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization. **Default value: ADAMW**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.001**\n",
        "\n",
        "* **`learning_rate_scheduler`:** Select to adjust the learning rate between epochs. Options: \"None\", \"Reduce on plateau\", \"One cycle\", \"Warm-up cosine decay\". **Default value: One cycle**\n",
        "\n",
        "* **`aggressive_data_augmentation`:** Select to apply more aggressive data augmentation (CutBlur, CutNoise, GridMask, etc.) during training. Otherwise, simple flips and rotations will be applied. **Default value: False**\n",
        "\n",
        "* **`test_time_augmentation`:** Select to apply augmentation (flips and rotations) at test time. It usually provides more robust results but uses more time to produce each result. **Default value: False**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RLdMygZVT5aH"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_3d_semantic_segmentation\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Data management:\n",
        "test_ground_truth = True #@param {type:\"boolean\"}\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "number_of_classes =  2#@param {type:\"number\"}\n",
        "input_channels = 1 #@param {type:\"number\"}\n",
        "number_of_epochs =  30#@param {type:\"number\"}\n",
        "patience =  30#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "model_architecture = \"Residual U-Net\" #@param [\"U-Net\", \"Residual U-Net\", \"Attention U-Net\", 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\",\"UNETR-Small\", \"UNETR-Base\", \"U-NeXt V1\"]\n",
        "\n",
        "batch_size =  4#@param {type:\"number\"}\n",
        "patch_size_xy = 80 #@param {type:\"number\"}\n",
        "patch_size_z = 80 #@param {type:\"number\"}\n",
        "anisotropic_data = False #@param {type:\"boolean\"}\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}\n",
        "learning_rate_scheduler = \"One cycle\" #@param [\"None\", \"Reduce on plateau\",\"One cycle\", \"Warm-up cosine decay\"]\n",
        "\n",
        "\n",
        "aggressive_data_augmentation = False #@param {type:\"boolean\"}\n",
        "test_time_augmentation = False #@param {type:\"boolean\"}\n",
        "\n",
        "checkpoint_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "frjrkkM1Wm6k"
      },
      "outputs": [],
      "source": [
        "#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n",
        "#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n",
        "\n",
        "#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n",
        "from google.colab import files\n",
        "\n",
        "#s.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "checkpoint_path = '/content/' + list(uploaded.keys())[0]\n",
        "\n",
        "# open previously configured file, if exists\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# edit previous configuration file if it exists to load the checkpoint model\n",
        "if os.path.exists( yaml_file ):\n",
        "    import yaml\n",
        "    with open( yaml_file, 'r') as stream:\n",
        "        try:\n",
        "            biapy_config = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "    # save file\n",
        "    with open( yaml_file, 'w') as outfile:\n",
        "        yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Pre-trained model loaded and ready to re-train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNWZYlu4zSG"
      },
      "source": [
        "### **Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CZKK9EoVmH-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725256344527,
          "user_tz": -120,
          "elapsed": 1050858,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "d29872e8-016e-47a5-d30d-16f80dd90cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:34:53.743693] Training configuration finished.\n",
            "[05:34:53.754385] Date: 2024-09-02 05:34:53\n",
            "[05:34:53.754505] Arguments: Namespace(config='/content/my_3d_semantic_segmentation.yaml', result_dir='/content/output', name='my_3d_semantic_segmentation', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "[05:34:53.754588] Job: my_3d_semantic_segmentation_1\n",
            "[05:34:53.754638] Python       : 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "[05:34:53.754683] PyTorch:  2.4.0+cu121\n",
            "[05:34:53.756057] Not using distributed mode\n",
            "[05:34:53.763708] Configuration details:\n",
            "[05:34:53.764367] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: True\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: True\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    APPLICATION_MODE: image\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    PERC_CLIP: False\n",
            "    PERC_LOWER: -1.0\n",
            "    PERC_UPPER: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (80, 80, 80, 1)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/test/x/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/test/y_detection_masks\n",
            "    GT_PATH: /content/data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/test/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/test/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: True\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (10, 10, 10)\n",
            "    PATH: /content/data/test/x\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/test/x_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/train/y_detection_masks\n",
            "    GT_PATH: /content/data/train/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: 0.01\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: /content/data/train/x\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    DIST_EVAL: True\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_3d_semantic_segmentation/train_logs\n",
            "  LOG_FILE_PREFIX: my_3d_semantic_segmentation_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: False\n",
            "  TYPE: CE\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: ELU\n",
            "  ARCHITECTURE: resunet\n",
            "  BMZ:\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [16, 32, 64, 128, 256]\n",
            "  ISOTROPY: [True, True, True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 2\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: pre\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [2, 2, 2, 2]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/charts\n",
            "  CHECKPOINT: /content/output/my_3d_semantic_segmentation/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/aug\n",
            "  GEN_CHECKS: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/gen_mask_check\n",
            "  LWR_X_FILE: /content/output/my_3d_semantic_segmentation/checkpoints/lower_bound_X_perc.npy\n",
            "  LWR_Y_FILE: /content/output/my_3d_semantic_segmentation/checkpoints/lower_bound_Y_perc.npy\n",
            "  MAE_OUT_DIR: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/MAE_checks\n",
            "  MEAN_INFO_FILE: /content/output/my_3d_semantic_segmentation/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_3d_semantic_segmentation/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/instance_associations\n",
            "    PATH: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1\n",
            "    PER_IMAGE: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_3d_semantic_segmentation/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: /content/data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/train_BC_instance_channels\n",
            "  UPR_X_FILE: /content/output/my_3d_semantic_segmentation/checkpoints/upper_bound_X_perc.npy\n",
            "  UPR_Y_FILE: /content/output/my_3d_semantic_segmentation/checkpoints/upper_bound_Y_perc.npy\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [2]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 3D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1, 1)\n",
            "  TYPE: SEMANTIC_SEG\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: 5\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    FORMAT: H5\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['iou']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGN: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: True\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 4\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 30\n",
            "  LR: 0.001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: onecycle\n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "  METRICS: ['iou']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 30\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[05:34:53.766199] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[05:34:53.766848] Initializing Semantic_Segmentation_Workflow\n",
            "[05:34:53.767386] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[05:34:53.769744] Checking ground truth classes in /content/data/train/y . . .\n",
            "[05:34:58.316574] Checking ground truth classes in /content/data/test/y . . .\n",
            "[05:35:01.749474] ##########################\n",
            "[05:35:01.749635] #   LOAD TRAINING DATA   #\n",
            "[05:35:01.749678] ##########################\n",
            "[05:35:01.749798] ### LOAD ###\n",
            "[05:35:01.752607] 0) Loading train images . . .\n",
            "[05:35:01.752684] Loading data from /content/data/train/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:02.245308] *** Loaded data shape is (390, 80, 80, 80, 1)\n",
            "[05:35:02.258520] 1) Loading train GT . . .\n",
            "[05:35:02.259361] Loading data from /content/data/train/y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:02.769868] *** Loaded data shape is (390, 80, 80, 80, 1)\n",
            "[05:35:02.781952] Data that do not have 0.01% of foreground is discarded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:06.000209] 205 samples discarded!\n",
            "[05:35:06.000386] *** Remaining data shape is (185, 80, 80, 80, 1)\n",
            "[05:35:06.000429] Creating validation data\n",
            "[05:35:06.061514] Not all samples seem to have the same shape. Number of samples: 166\n",
            "[05:35:06.061670] *** Loaded train data shape is: (166, 80, 80, 80, 1)\n",
            "[05:35:06.062983] *** Loaded train GT shape is: (166, 80, 80, 80, 1)\n",
            "[05:35:06.063040] *** Loaded validation data shape is: (19, 80, 80, 80, 1)\n",
            "[05:35:06.063084] *** Loaded validation GT shape is: (19, 80, 80, 80, 1)\n",
            "[05:35:06.063128] ### END LOAD ###\n",
            "[05:35:06.063217] ###############\n",
            "[05:35:06.063978] # Build model #\n",
            "[05:35:06.064044] ###############\n",
            "[05:35:06.215967] ##############################\n",
            "[05:35:06.216063] #  PREPARE TRAIN GENERATORS  #\n",
            "[05:35:06.216103] ##############################\n",
            "[05:35:06.216392] Initializing train data generator . . .\n",
            "[05:35:06.222639] Checking which channel of the mask needs normalization . . .\n",
            "[05:35:06.562099] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('uint8'), 'div': 1}\n",
            "[05:35:06.563273] Normalization config used for Y: as_mask\n",
            "[05:35:06.563876] Initializing val data generator . . .\n",
            "[05:35:06.566571] Checking which channel of the mask needs normalization . . .\n",
            "[05:35:06.609438] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('uint8'), 'div': 1}\n",
            "[05:35:06.609593] Normalization config used for Y: as_mask\n",
            "[05:35:06.609958] Creating generator samples . . .\n",
            "[05:35:06.610044] 0) Creating samples of data augmentation . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|\u2588         | 1/10 [00:00<00:01,  5.56it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 2/10 [00:00<00:01,  6.07it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 3/10 [00:00<00:01,  6.26it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:00,  6.32it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:01,  4.81it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:01<00:01,  3.84it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  3.38it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  3.91it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:02<00:00,  3.97it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:02<00:00,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:08.957201] Number of workers: 5\n",
            "[05:35:08.959454] Accumulate grad iterations: 1\n",
            "[05:35:08.959502] Effective batch size: 4\n",
            "[05:35:08.959573] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7d131b3ee2f0>\n",
            "[05:35:08.959818] #######################\n",
            "[05:35:08.959859] # Prepare logging tool #\n",
            "[05:35:08.959887] #######################\n",
            "[05:35:08.967559] AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.02\n",
            ")\n",
            "[05:35:08.967946] #####################\n",
            "[05:35:08.968004] #  TRAIN THE MODEL  #\n",
            "[05:35:08.968034] #####################\n",
            "[05:35:08.968072] Start training in epoch 1 - Total: 30\n",
            "[05:35:08.968125] ~~~ Epoch 1/30 ~~~\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:35:12.073622] Epoch: [1]  [ 0/42]  eta: 0:02:10  loss: 0.9073 (0.9073)  IoU: 0.2099 (0.2099)  lr: 0.000040  iter-time: 3.0990\n",
            "[05:35:18.748218] Epoch: [1]  [10/42]  eta: 0:00:28  loss: 0.8727 (0.8674)  IoU: 0.1449 (0.1541)  lr: 0.000042  iter-time: 0.8881\n",
            "[05:35:25.281351] Epoch: [1]  [20/42]  eta: 0:00:17  loss: 0.7700 (0.7833)  IoU: 0.1574 (0.1791)  lr: 0.000047  iter-time: 0.6600\n",
            "[05:35:31.892456] Epoch: [1]  [30/42]  eta: 0:00:08  loss: 0.6057 (0.7089)  IoU: 0.1944 (0.1959)  lr: 0.000056  iter-time: 0.6570\n",
            "[05:35:38.505947] Epoch: [1]  [40/42]  eta: 0:00:01  loss: 0.4943 (0.6397)  IoU: 0.2530 (0.2323)  lr: 0.000068  iter-time: 0.6611\n",
            "[05:36:43.588754] Epoch: [1]  [41/42]  eta: 0:00:02  loss: 0.4873 (0.6340)  IoU: 0.2530 (0.2298)  lr: 0.000069  iter-time: 3.8823\n",
            "[05:36:43.756636] Epoch: [1] Total time: 0:01:34 (2.2567 s / it)\n",
            "[05:36:43.756840] [Train] averaged stats: loss: 0.4873 (0.6340)  IoU: 0.2530 (0.2298)  lr: 0.000069\n",
            "[05:36:44.353670] Epoch: [1]  [0/5]  eta: 0:00:02  loss: 1.0671 (1.0671)  IoU: 0.1973 (0.1973)  iter-time: 0.5943\n",
            "[05:36:45.127247] Epoch: [1]  [4/5]  eta: 0:00:00  loss: 1.2560 (1.2258)  IoU: 0.1281 (0.1313)  iter-time: 0.2734\n",
            "[05:36:45.215362] Epoch: [1] Total time: 0:00:01 (0.2913 s / it)\n",
            "[05:36:45.217041] [Val] averaged stats: loss: 1.2560 (1.2258)  IoU: 0.1281 (0.1313)\n",
            "[05:36:45.218930] Val loss improved from inf to 1.225768232345581, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:36:45.446752] [Val] best loss: 1.2258 best  IoU: 0.1313 \n",
            "[05:36:45.449558] [Time] 1.6m 1.6m/49.8m\n",
            "\n",
            "[05:36:45.449662] ~~~ Epoch 2/30 ~~~\n",
            "\n",
            "[05:36:47.969259] Epoch: [2]  [ 0/42]  eta: 0:01:45  loss: 0.3192 (0.3192)  IoU: 0.6351 (0.6351)  lr: 0.000070  iter-time: 2.5100\n",
            "[05:36:54.504896] Epoch: [2]  [10/42]  eta: 0:00:26  loss: 0.3007 (0.3004)  IoU: 0.5068 (0.4886)  lr: 0.000086  iter-time: 0.8215\n",
            "[05:37:01.150369] Epoch: [2]  [20/42]  eta: 0:00:16  loss: 0.2726 (0.2758)  IoU: 0.5068 (0.4930)  lr: 0.000105  iter-time: 0.6585\n",
            "[05:37:07.711259] Epoch: [2]  [30/42]  eta: 0:00:08  loss: 0.2160 (0.2498)  IoU: 0.5041 (0.4985)  lr: 0.000126  iter-time: 0.6601\n",
            "[05:37:14.214089] Epoch: [2]  [40/42]  eta: 0:00:01  loss: 0.1741 (0.2288)  IoU: 0.5366 (0.5075)  lr: 0.000150  iter-time: 0.6530\n",
            "[05:37:14.571772] Epoch: [2]  [41/42]  eta: 0:00:00  loss: 0.1741 (0.2285)  IoU: 0.5062 (0.4991)  lr: 0.000153  iter-time: 0.6372\n",
            "[05:37:14.720141] Epoch: [2] Total time: 0:00:29 (0.6969 s / it)\n",
            "[05:37:14.720357] [Train] averaged stats: loss: 0.1741 (0.2285)  IoU: 0.5062 (0.4991)  lr: 0.000153\n",
            "[05:37:15.339265] Epoch: [2]  [0/5]  eta: 0:00:03  loss: 0.1558 (0.1558)  IoU: 0.7446 (0.7446)  iter-time: 0.6163\n",
            "[05:37:16.100572] Epoch: [2]  [4/5]  eta: 0:00:00  loss: 0.2187 (0.2331)  IoU: 0.4878 (0.4963)  iter-time: 0.2750\n",
            "[05:37:16.231900] Epoch: [2] Total time: 0:00:01 (0.3019 s / it)\n",
            "[05:37:16.232035] [Val] averaged stats: loss: 0.2187 (0.2331)  IoU: 0.4878 (0.4963)\n",
            "[05:37:16.232749] Val loss improved from 1.225768232345581 to 0.23313161730766296, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:37:16.521162] [Val] best loss: 0.2331 best  IoU: 0.4963 \n",
            "[05:37:16.527427] [Time] 31.1s 2.1m/17.1m\n",
            "\n",
            "[05:37:16.528324] ~~~ Epoch 3/30 ~~~\n",
            "\n",
            "[05:37:18.376202] Epoch: [3]  [ 0/42]  eta: 0:01:17  loss: 0.1720 (0.1720)  IoU: 0.6157 (0.6157)  lr: 0.000155  iter-time: 1.8433\n",
            "[05:37:24.869169] Epoch: [3]  [10/42]  eta: 0:00:24  loss: 0.1232 (0.1364)  IoU: 0.5940 (0.5720)  lr: 0.000183  iter-time: 0.7577\n",
            "[05:37:31.385286] Epoch: [3]  [20/42]  eta: 0:00:15  loss: 0.1242 (0.1474)  IoU: 0.5743 (0.5621)  lr: 0.000212  iter-time: 0.6503\n",
            "[05:37:37.860173] Epoch: [3]  [30/42]  eta: 0:00:08  loss: 0.1425 (0.1453)  IoU: 0.5553 (0.5580)  lr: 0.000244  iter-time: 0.6493\n",
            "[05:37:44.309102] Epoch: [3]  [40/42]  eta: 0:00:01  loss: 0.1168 (0.1402)  IoU: 0.5856 (0.5699)  lr: 0.000278  iter-time: 0.6459\n",
            "[05:37:44.662026] Epoch: [3]  [41/42]  eta: 0:00:00  loss: 0.1209 (0.1402)  IoU: 0.5674 (0.5629)  lr: 0.000281  iter-time: 0.6305\n",
            "[05:37:44.813327] Epoch: [3] Total time: 0:00:28 (0.6734 s / it)\n",
            "[05:37:44.814372] [Train] averaged stats: loss: 0.1209 (0.1402)  IoU: 0.5674 (0.5629)  lr: 0.000281\n",
            "[05:37:45.538549] Epoch: [3]  [0/5]  eta: 0:00:03  loss: 0.1034 (0.1034)  IoU: 0.7785 (0.7785)  iter-time: 0.7190\n",
            "[05:37:46.306018] Epoch: [3]  [4/5]  eta: 0:00:00  loss: 0.1538 (0.1664)  IoU: 0.4977 (0.4927)  iter-time: 0.2963\n",
            "[05:37:46.437709] Epoch: [3] Total time: 0:00:01 (0.3238 s / it)\n",
            "[05:37:46.437851] [Val] averaged stats: loss: 0.1538 (0.1664)  IoU: 0.4977 (0.4927)\n",
            "[05:37:46.438664] Val loss improved from 0.23313161730766296 to 0.16638855040073394, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:37:46.746473] [Val] best loss: 0.1664 best  IoU: 0.4927 \n",
            "[05:37:46.749896] [Time] 30.2s 2.6m/16.7m\n",
            "\n",
            "[05:37:46.750952] ~~~ Epoch 4/30 ~~~\n",
            "\n",
            "[05:37:48.236038] Epoch: [4]  [ 0/42]  eta: 0:01:01  loss: 0.1904 (0.1904)  IoU: 0.5674 (0.5674)  lr: 0.000285  iter-time: 1.4677\n",
            "[05:37:55.343005] Epoch: [4]  [10/42]  eta: 0:00:24  loss: 0.0992 (0.1177)  IoU: 0.6161 (0.6156)  lr: 0.000320  iter-time: 0.7791\n",
            "[05:38:01.875365] Epoch: [4]  [20/42]  eta: 0:00:15  loss: 0.1067 (0.1246)  IoU: 0.6395 (0.6122)  lr: 0.000357  iter-time: 0.6817\n",
            "[05:38:08.425872] Epoch: [4]  [30/42]  eta: 0:00:08  loss: 0.1189 (0.1345)  IoU: 0.5660 (0.5731)  lr: 0.000395  iter-time: 0.6536\n",
            "[05:38:14.903890] Epoch: [4]  [40/42]  eta: 0:00:01  loss: 0.1079 (0.1289)  IoU: 0.6235 (0.5949)  lr: 0.000434  iter-time: 0.6508\n",
            "[05:38:15.261558] Epoch: [4]  [41/42]  eta: 0:00:00  loss: 0.1017 (0.1274)  IoU: 0.5814 (0.5918)  lr: 0.000438  iter-time: 0.6355\n",
            "[05:38:15.430482] Epoch: [4] Total time: 0:00:28 (0.6828 s / it)\n",
            "[05:38:15.431588] [Train] averaged stats: loss: 0.1017 (0.1274)  IoU: 0.5814 (0.5918)  lr: 0.000438\n",
            "[05:38:16.100132] Epoch: [4]  [0/5]  eta: 0:00:03  loss: 0.4320 (0.4320)  IoU: 0.1287 (0.1287)  iter-time: 0.6648\n",
            "[05:38:16.866159] Epoch: [4]  [4/5]  eta: 0:00:00  loss: 0.3511 (0.3387)  IoU: 0.0533 (0.0806)  iter-time: 0.2857\n",
            "[05:38:17.020878] Epoch: [4] Total time: 0:00:01 (0.3172 s / it)\n",
            "[05:38:17.021059] [Val] averaged stats: loss: 0.3511 (0.3387)  IoU: 0.0533 (0.0806)\n",
            "[05:38:17.023279] [Val] best loss: 0.1664 best  IoU: 0.4927 \n",
            "EarlyStopping counter: 1 out of 30\n",
            "[05:38:17.026851] [Time] 30.3s 3.1m/16.8m\n",
            "\n",
            "[05:38:17.026900] ~~~ Epoch 5/30 ~~~\n",
            "\n",
            "[05:38:19.860166] Epoch: [5]  [ 0/42]  eta: 0:01:58  loss: 0.2991 (0.2991)  IoU: 0.3862 (0.3862)  lr: 0.000442  iter-time: 2.8260\n",
            "[05:38:26.320219] Epoch: [5]  [10/42]  eta: 0:00:27  loss: 0.1082 (0.1316)  IoU: 0.6363 (0.6051)  lr: 0.000482  iter-time: 0.8439\n",
            "[05:38:32.847135] Epoch: [5]  [20/42]  eta: 0:00:16  loss: 0.1075 (0.1199)  IoU: 0.6792 (0.6414)  lr: 0.000522  iter-time: 0.6491\n",
            "[05:38:39.374960] Epoch: [5]  [30/42]  eta: 0:00:08  loss: 0.1161 (0.1317)  IoU: 0.5974 (0.5878)  lr: 0.000562  iter-time: 0.6525\n",
            "[05:38:45.856020] Epoch: [5]  [40/42]  eta: 0:00:01  loss: 0.1491 (0.1358)  IoU: 0.5141 (0.5708)  lr: 0.000602  iter-time: 0.6502\n",
            "[05:38:46.211520] Epoch: [5]  [41/42]  eta: 0:00:00  loss: 0.1535 (0.1369)  IoU: 0.5051 (0.5626)  lr: 0.000606  iter-time: 0.6349\n",
            "[05:38:46.331166] Epoch: [5] Total time: 0:00:29 (0.6977 s / it)\n",
            "[05:38:46.332260] [Train] averaged stats: loss: 0.1535 (0.1369)  IoU: 0.5051 (0.5626)  lr: 0.000606\n",
            "[05:38:47.038586] Epoch: [5]  [0/5]  eta: 0:00:03  loss: 0.0943 (0.0943)  IoU: 0.7921 (0.7921)  iter-time: 0.7026\n",
            "[05:38:47.804188] Epoch: [5]  [4/5]  eta: 0:00:00  loss: 0.1096 (0.1195)  IoU: 0.6214 (0.6077)  iter-time: 0.2935\n",
            "[05:38:47.935143] Epoch: [5] Total time: 0:00:01 (0.3199 s / it)\n",
            "[05:38:47.935268] [Val] averaged stats: loss: 0.1096 (0.1195)  IoU: 0.6214 (0.6077)\n",
            "[05:38:47.935903] Val loss improved from 0.16638855040073394 to 0.11954100504517555, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:38:48.279424] [Val] best loss: 0.1195 best  IoU: 0.6077 \n",
            "[05:38:48.282672] Creating training plots . . .\n",
            "[05:38:48.814958] [Time] 31.8s 3.7m/17.4m\n",
            "\n",
            "[05:38:48.816366] ~~~ Epoch 6/30 ~~~\n",
            "\n",
            "[05:38:51.526838] Epoch: [6]  [ 0/42]  eta: 0:01:53  loss: 0.1581 (0.1581)  IoU: 0.6613 (0.6613)  lr: 0.000609  iter-time: 2.7062\n",
            "[05:38:57.975864] Epoch: [6]  [10/42]  eta: 0:00:26  loss: 0.0962 (0.1115)  IoU: 0.6593 (0.6491)  lr: 0.000648  iter-time: 0.8321\n",
            "[05:39:04.486503] Epoch: [6]  [20/42]  eta: 0:00:16  loss: 0.0962 (0.1179)  IoU: 0.6593 (0.6432)  lr: 0.000686  iter-time: 0.6478\n",
            "[05:39:11.053943] Epoch: [6]  [30/42]  eta: 0:00:08  loss: 0.1179 (0.1293)  IoU: 0.6285 (0.6079)  lr: 0.000723  iter-time: 0.6536\n",
            "[05:39:17.535457] Epoch: [6]  [40/42]  eta: 0:00:01  loss: 0.1207 (0.1280)  IoU: 0.5823 (0.6060)  lr: 0.000759  iter-time: 0.6522\n",
            "[05:39:17.890764] Epoch: [6]  [41/42]  eta: 0:00:00  loss: 0.1207 (0.1275)  IoU: 0.5772 (0.6011)  lr: 0.000762  iter-time: 0.6364\n",
            "[05:39:17.994977] Epoch: [6] Total time: 0:00:29 (0.6947 s / it)\n",
            "[05:39:17.995161] [Train] averaged stats: loss: 0.1207 (0.1275)  IoU: 0.5772 (0.6011)  lr: 0.000762\n",
            "[05:39:18.495231] Epoch: [6]  [0/5]  eta: 0:00:02  loss: 0.3496 (0.3496)  IoU: 0.0496 (0.0496)  iter-time: 0.4975\n",
            "[05:39:19.259462] Epoch: [6]  [4/5]  eta: 0:00:00  loss: 0.3496 (0.3278)  IoU: 0.0385 (0.0549)  iter-time: 0.2522\n",
            "[05:39:19.417126] Epoch: [6] Total time: 0:00:01 (0.2840 s / it)\n",
            "[05:39:19.417269] [Val] averaged stats: loss: 0.3496 (0.3278)  IoU: 0.0385 (0.0549)\n",
            "[05:39:19.417877] [Val] best loss: 0.1195 best  IoU: 0.6077 \n",
            "EarlyStopping counter: 1 out of 30\n",
            "[05:39:19.422237] [Time] 30.6s 4.2m/16.9m\n",
            "\n",
            "[05:39:19.422281] ~~~ Epoch 7/30 ~~~\n",
            "\n",
            "[05:39:24.099145] Epoch: [7]  [ 0/42]  eta: 0:03:16  loss: 0.1713 (0.1713)  IoU: 0.6085 (0.6085)  lr: 0.000766  iter-time: 4.6747\n",
            "[05:39:31.066357] Epoch: [7]  [10/42]  eta: 0:00:33  loss: 0.1062 (0.1141)  IoU: 0.6445 (0.6448)  lr: 0.000799  iter-time: 1.0572\n",
            "[05:39:37.530543] Epoch: [7]  [20/42]  eta: 0:00:18  loss: 0.1062 (0.1186)  IoU: 0.6527 (0.6508)  lr: 0.000831  iter-time: 0.6709\n",
            "[05:39:44.094225] Epoch: [7]  [30/42]  eta: 0:00:09  loss: 0.1174 (0.1250)  IoU: 0.6492 (0.6222)  lr: 0.000860  iter-time: 0.6513\n",
            "[05:39:50.580050] Epoch: [7]  [40/42]  eta: 0:00:01  loss: 0.1322 (0.1300)  IoU: 0.6063 (0.6077)  lr: 0.000887  iter-time: 0.6523\n",
            "[05:39:50.935733] Epoch: [7]  [41/42]  eta: 0:00:00  loss: 0.1329 (0.1315)  IoU: 0.6029 (0.5994)  lr: 0.000890  iter-time: 0.6375\n",
            "[05:39:51.043386] Epoch: [7] Total time: 0:00:31 (0.7528 s / it)\n",
            "[05:39:51.044363] [Train] averaged stats: loss: 0.1329 (0.1315)  IoU: 0.6029 (0.5994)  lr: 0.000890\n",
            "[05:39:51.563960] Epoch: [7]  [0/5]  eta: 0:00:02  loss: 0.1712 (0.1712)  IoU: 0.5123 (0.5123)  iter-time: 0.5147\n",
            "[05:39:52.331929] Epoch: [7]  [4/5]  eta: 0:00:00  loss: 0.1976 (0.2030)  IoU: 0.3134 (0.3005)  iter-time: 0.2561\n",
            "[05:39:52.421200] Epoch: [7] Total time: 0:00:01 (0.2745 s / it)\n",
            "[05:39:52.422223] [Val] averaged stats: loss: 0.1976 (0.2030)  IoU: 0.3134 (0.3005)\n",
            "[05:39:52.423928] [Val] best loss: 0.1195 best  IoU: 0.6077 \n",
            "EarlyStopping counter: 2 out of 30\n",
            "[05:39:52.425984] [Time] 33.0s 4.7m/17.9m\n",
            "\n",
            "[05:39:52.426027] ~~~ Epoch 8/30 ~~~\n",
            "\n",
            "[05:39:54.322622] Epoch: [8]  [ 0/42]  eta: 0:01:19  loss: 0.1230 (0.1230)  IoU: 0.7066 (0.7066)  lr: 0.000892  iter-time: 1.8930\n",
            "[05:40:01.027929] Epoch: [8]  [10/42]  eta: 0:00:25  loss: 0.1061 (0.1330)  IoU: 0.6699 (0.6243)  lr: 0.000916  iter-time: 0.7816\n",
            "[05:40:07.547138] Epoch: [8]  [20/42]  eta: 0:00:15  loss: 0.1367 (0.1430)  IoU: 0.5798 (0.5779)  lr: 0.000937  iter-time: 0.6605\n",
            "[05:40:14.019959] Epoch: [8]  [30/42]  eta: 0:00:08  loss: 0.1239 (0.1473)  IoU: 0.5724 (0.5787)  lr: 0.000956  iter-time: 0.6488\n",
            "[05:40:20.490489] Epoch: [8]  [40/42]  eta: 0:00:01  loss: 0.1213 (0.1522)  IoU: 0.6346 (0.5571)  lr: 0.000971  iter-time: 0.6470\n",
            "[05:40:20.846228] Epoch: [8]  [41/42]  eta: 0:00:00  loss: 0.1239 (0.1520)  IoU: 0.5724 (0.5540)  lr: 0.000972  iter-time: 0.6321\n",
            "[05:40:21.019195] Epoch: [8] Total time: 0:00:28 (0.6808 s / it)\n",
            "[05:40:21.020974] [Train] averaged stats: loss: 0.1239 (0.1520)  IoU: 0.5724 (0.5540)  lr: 0.000972\n",
            "[05:40:21.620095] Epoch: [8]  [0/5]  eta: 0:00:02  loss: 0.1390 (0.1390)  IoU: 0.6513 (0.6513)  iter-time: 0.5950\n",
            "[05:40:22.383361] Epoch: [8]  [4/5]  eta: 0:00:00  loss: 0.1659 (0.1691)  IoU: 0.3513 (0.4027)  iter-time: 0.2715\n",
            "[05:40:22.474269] Epoch: [8] Total time: 0:00:01 (0.2899 s / it)\n",
            "[05:40:22.474975] [Val] averaged stats: loss: 0.1659 (0.1691)  IoU: 0.3513 (0.4027)\n",
            "[05:40:22.477186] [Val] best loss: 0.1195 best  IoU: 0.6077 \n",
            "EarlyStopping counter: 3 out of 30\n",
            "[05:40:22.479853] [Time] 30.1s 5.2m/16.7m\n",
            "\n",
            "[05:40:22.480672] ~~~ Epoch 9/30 ~~~\n",
            "\n",
            "[05:40:24.758727] Epoch: [9]  [ 0/42]  eta: 0:01:35  loss: 0.1750 (0.1750)  IoU: 0.5475 (0.5475)  lr: 0.000974  iter-time: 2.2700\n",
            "[05:40:31.212742] Epoch: [9]  [10/42]  eta: 0:00:25  loss: 0.1126 (0.1284)  IoU: 0.6039 (0.6175)  lr: 0.000985  iter-time: 0.7928\n",
            "[05:40:37.745517] Epoch: [9]  [20/42]  eta: 0:00:15  loss: 0.1121 (0.1291)  IoU: 0.6288 (0.6263)  lr: 0.000993  iter-time: 0.6491\n",
            "[05:40:44.257669] Epoch: [9]  [30/42]  eta: 0:00:08  loss: 0.1343 (0.1445)  IoU: 0.6073 (0.5850)  lr: 0.000998  iter-time: 0.6520\n",
            "[05:40:50.714378] Epoch: [9]  [40/42]  eta: 0:00:01  loss: 0.1464 (0.1475)  IoU: 0.4907 (0.5715)  lr: 0.001000  iter-time: 0.6482\n",
            "[05:40:51.069230] Epoch: [9]  [41/42]  eta: 0:00:00  loss: 0.1492 (0.1500)  IoU: 0.4893 (0.5628)  lr: 0.001000  iter-time: 0.6327\n",
            "[05:40:51.237494] Epoch: [9] Total time: 0:00:28 (0.6847 s / it)\n",
            "[05:40:51.238642] [Train] averaged stats: loss: 0.1492 (0.1500)  IoU: 0.4893 (0.5628)  lr: 0.001000\n",
            "[05:40:51.919672] Epoch: [9]  [0/5]  eta: 0:00:03  loss: 0.0905 (0.0905)  IoU: 0.7973 (0.7973)  iter-time: 0.6774\n",
            "[05:40:52.685761] Epoch: [9]  [4/5]  eta: 0:00:00  loss: 0.0905 (0.0950)  IoU: 0.7382 (0.6560)  iter-time: 0.2885\n",
            "[05:40:52.830933] Epoch: [9] Total time: 0:00:01 (0.3179 s / it)\n",
            "[05:40:52.831064] [Val] averaged stats: loss: 0.0905 (0.0950)  IoU: 0.7382 (0.6560)\n",
            "[05:40:52.831748] Val loss improved from 0.11954100504517555 to 0.0949821949005127, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:40:53.175925] [Val] best loss: 0.0950 best  IoU: 0.6560 \n",
            "[05:40:53.179105] [Time] 30.7s 5.7m/17.0m\n",
            "\n",
            "[05:40:53.179193] ~~~ Epoch 10/30 ~~~\n",
            "\n",
            "[05:40:56.272915] Epoch: [10]  [ 0/42]  eta: 0:02:09  loss: 0.1242 (0.1242)  IoU: 0.7247 (0.7247)  lr: 0.001000  iter-time: 3.0910\n",
            "[05:41:02.734349] Epoch: [10]  [10/42]  eta: 0:00:27  loss: 0.0869 (0.0943)  IoU: 0.7142 (0.7051)  lr: 0.001000  iter-time: 0.8683\n",
            "[05:41:09.240870] Epoch: [10]  [20/42]  eta: 0:00:16  loss: 0.0861 (0.0992)  IoU: 0.7129 (0.6982)  lr: 0.000998  iter-time: 0.6483\n",
            "[05:41:15.758817] Epoch: [10]  [30/42]  eta: 0:00:08  loss: 0.0950 (0.1059)  IoU: 0.6591 (0.6790)  lr: 0.000997  iter-time: 0.6511\n",
            "[05:41:22.236958] Epoch: [10]  [40/42]  eta: 0:00:01  loss: 0.0840 (0.1009)  IoU: 0.6736 (0.6892)  lr: 0.000994  iter-time: 0.6497\n",
            "[05:41:22.593925] Epoch: [10]  [41/42]  eta: 0:00:00  loss: 0.0840 (0.1010)  IoU: 0.6679 (0.6815)  lr: 0.000994  iter-time: 0.6344\n",
            "[05:41:22.741110] Epoch: [10] Total time: 0:00:29 (0.7038 s / it)\n",
            "[05:41:22.741315] [Train] averaged stats: loss: 0.0840 (0.1010)  IoU: 0.6679 (0.6815)  lr: 0.000994\n",
            "[05:41:23.452687] Epoch: [10]  [0/5]  eta: 0:00:03  loss: 0.0727 (0.0727)  IoU: 0.8388 (0.8388)  iter-time: 0.7087\n",
            "[05:41:24.218593] Epoch: [10]  [4/5]  eta: 0:00:00  loss: 0.0741 (0.0863)  IoU: 0.7376 (0.7055)  iter-time: 0.2945\n",
            "[05:41:24.378414] Epoch: [10] Total time: 0:00:01 (0.3270 s / it)\n",
            "[05:41:24.378628] [Val] averaged stats: loss: 0.0741 (0.0863)  IoU: 0.7376 (0.7055)\n",
            "[05:41:24.379296] Val loss improved from 0.0949821949005127 to 0.0862903505563736, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:41:24.724585] [Val] best loss: 0.0863 best  IoU: 0.7055 \n",
            "[05:41:24.727717] Creating training plots . . .\n",
            "[05:41:25.032668] [Time] 31.9s 6.3m/17.4m\n",
            "\n",
            "[05:41:25.032796] ~~~ Epoch 11/30 ~~~\n",
            "\n",
            "[05:41:26.939047] Epoch: [11]  [ 0/42]  eta: 0:01:19  loss: 0.1087 (0.1087)  IoU: 0.7563 (0.7563)  lr: 0.000994  iter-time: 1.8983\n",
            "[05:41:33.437837] Epoch: [11]  [10/42]  eta: 0:00:24  loss: 0.0816 (0.0825)  IoU: 0.7563 (0.7343)  lr: 0.000991  iter-time: 0.7631\n",
            "[05:41:39.990476] Epoch: [11]  [20/42]  eta: 0:00:15  loss: 0.0816 (0.0865)  IoU: 0.7560 (0.7313)  lr: 0.000987  iter-time: 0.6524\n",
            "[05:41:46.530686] Epoch: [11]  [30/42]  eta: 0:00:08  loss: 0.0841 (0.0897)  IoU: 0.7408 (0.7203)  lr: 0.000983  iter-time: 0.6545\n",
            "[05:41:53.004625] Epoch: [11]  [40/42]  eta: 0:00:01  loss: 0.0815 (0.0907)  IoU: 0.7148 (0.7128)  lr: 0.000978  iter-time: 0.6504\n",
            "[05:41:53.361703] Epoch: [11]  [41/42]  eta: 0:00:00  loss: 0.0907 (0.0919)  IoU: 0.6820 (0.7046)  lr: 0.000977  iter-time: 0.6352\n",
            "[05:41:53.505284] Epoch: [11] Total time: 0:00:28 (0.6779 s / it)\n",
            "[05:41:53.506311] [Train] averaged stats: loss: 0.0907 (0.0919)  IoU: 0.6820 (0.7046)  lr: 0.000977\n",
            "[05:41:54.191320] Epoch: [11]  [0/5]  eta: 0:00:03  loss: 0.0664 (0.0664)  IoU: 0.8530 (0.8530)  iter-time: 0.6814\n",
            "[05:41:54.952137] Epoch: [11]  [4/5]  eta: 0:00:00  loss: 0.0745 (0.0795)  IoU: 0.7613 (0.7266)  iter-time: 0.2883\n",
            "[05:41:55.090082] Epoch: [11] Total time: 0:00:01 (0.3160 s / it)\n",
            "[05:41:55.090257] [Val] averaged stats: loss: 0.0745 (0.0795)  IoU: 0.7613 (0.7266)\n",
            "[05:41:55.090918] Val loss improved from 0.0862903505563736 to 0.07950651720166206, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:41:55.449220] [Val] best loss: 0.0795 best  IoU: 0.7266 \n",
            "[05:41:55.452214] [Time] 30.4s 6.8m/16.9m\n",
            "\n",
            "[05:41:55.453108] ~~~ Epoch 12/30 ~~~\n",
            "\n",
            "[05:41:57.589864] Epoch: [12]  [ 0/42]  eta: 0:01:29  loss: 0.0728 (0.0728)  IoU: 0.8332 (0.8332)  lr: 0.000977  iter-time: 2.1335\n",
            "[05:42:04.092227] Epoch: [12]  [10/42]  eta: 0:00:25  loss: 0.0649 (0.0726)  IoU: 0.7785 (0.7635)  lr: 0.000971  iter-time: 0.7849\n",
            "[05:42:10.650025] Epoch: [12]  [20/42]  eta: 0:00:15  loss: 0.0654 (0.0781)  IoU: 0.7528 (0.7547)  lr: 0.000965  iter-time: 0.6526\n",
            "[05:42:17.260648] Epoch: [12]  [30/42]  eta: 0:00:08  loss: 0.0795 (0.0793)  IoU: 0.7528 (0.7511)  lr: 0.000958  iter-time: 0.6578\n",
            "[05:42:23.734979] Epoch: [12]  [40/42]  eta: 0:00:01  loss: 0.0630 (0.0776)  IoU: 0.7459 (0.7525)  lr: 0.000950  iter-time: 0.6539\n",
            "[05:42:24.092005] Epoch: [12]  [41/42]  eta: 0:00:00  loss: 0.0705 (0.0785)  IoU: 0.7417 (0.7435)  lr: 0.000950  iter-time: 0.6382\n",
            "[05:42:24.196360] Epoch: [12] Total time: 0:00:28 (0.6843 s / it)\n",
            "[05:42:24.197394] [Train] averaged stats: loss: 0.0705 (0.0785)  IoU: 0.7417 (0.7435)  lr: 0.000950\n",
            "[05:42:24.613756] Epoch: [12]  [0/5]  eta: 0:00:02  loss: 0.0772 (0.0772)  IoU: 0.8351 (0.8351)  iter-time: 0.4129\n",
            "[05:42:25.377743] Epoch: [12]  [4/5]  eta: 0:00:00  loss: 0.0993 (0.0946)  IoU: 0.7118 (0.7039)  iter-time: 0.2352\n",
            "[05:42:25.499752] Epoch: [12] Total time: 0:00:01 (0.2599 s / it)\n",
            "[05:42:25.499887] [Val] averaged stats: loss: 0.0993 (0.0946)  IoU: 0.7118 (0.7039)\n",
            "[05:42:25.500485] [Val] best loss: 0.0795 best  IoU: 0.7266 \n",
            "EarlyStopping counter: 1 out of 30\n",
            "[05:42:25.504302] [Time] 30.1s 7.3m/16.8m\n",
            "\n",
            "[05:42:25.504349] ~~~ Epoch 13/30 ~~~\n",
            "\n",
            "[05:42:28.999870] Epoch: [13]  [ 0/42]  eta: 0:02:26  loss: 0.0874 (0.0874)  IoU: 0.8028 (0.8028)  lr: 0.000949  iter-time: 3.4926\n",
            "[05:42:35.602250] Epoch: [13]  [10/42]  eta: 0:00:29  loss: 0.0628 (0.0697)  IoU: 0.7676 (0.7661)  lr: 0.000941  iter-time: 0.9174\n",
            "[05:42:42.062165] Epoch: [13]  [20/42]  eta: 0:00:17  loss: 0.0620 (0.0716)  IoU: 0.7668 (0.7678)  lr: 0.000932  iter-time: 0.6528\n",
            "[05:42:48.568845] Epoch: [13]  [30/42]  eta: 0:00:08  loss: 0.0725 (0.0741)  IoU: 0.7668 (0.7598)  lr: 0.000923  iter-time: 0.6478\n",
            "[05:42:55.051032] Epoch: [13]  [40/42]  eta: 0:00:01  loss: 0.0706 (0.0722)  IoU: 0.7844 (0.7617)  lr: 0.000913  iter-time: 0.6487\n",
            "[05:42:55.408114] Epoch: [13]  [41/42]  eta: 0:00:00  loss: 0.0706 (0.0720)  IoU: 0.7744 (0.7561)  lr: 0.000912  iter-time: 0.6340\n",
            "[05:42:55.515168] Epoch: [13] Total time: 0:00:30 (0.7145 s / it)\n",
            "[05:42:55.515351] [Train] averaged stats: loss: 0.0706 (0.0720)  IoU: 0.7744 (0.7561)  lr: 0.000912\n",
            "[05:42:56.043995] Epoch: [13]  [0/5]  eta: 0:00:02  loss: 0.0552 (0.0552)  IoU: 0.8790 (0.8790)  iter-time: 0.5263\n",
            "[05:42:56.813026] Epoch: [13]  [4/5]  eta: 0:00:00  loss: 0.0576 (0.0872)  IoU: 0.7774 (0.7172)  iter-time: 0.2589\n",
            "[05:42:56.900595] Epoch: [13] Total time: 0:00:01 (0.2767 s / it)\n",
            "[05:42:56.900732] [Val] averaged stats: loss: 0.0576 (0.0872)  IoU: 0.7774 (0.7172)\n",
            "[05:42:56.903372] [Val] best loss: 0.0795 best  IoU: 0.7266 \n",
            "EarlyStopping counter: 2 out of 30\n",
            "[05:42:56.905599] [Time] 31.4s 7.8m/17.2m\n",
            "\n",
            "[05:42:56.905653] ~~~ Epoch 14/30 ~~~\n",
            "\n",
            "[05:42:59.817880] Epoch: [14]  [ 0/42]  eta: 0:02:02  loss: 0.0916 (0.0916)  IoU: 0.7823 (0.7823)  lr: 0.000911  iter-time: 2.9080\n",
            "[05:43:06.331040] Epoch: [14]  [10/42]  eta: 0:00:27  loss: 0.0591 (0.0657)  IoU: 0.7781 (0.7756)  lr: 0.000901  iter-time: 0.8562\n",
            "[05:43:12.896447] Epoch: [14]  [20/42]  eta: 0:00:16  loss: 0.0572 (0.0673)  IoU: 0.7885 (0.7817)  lr: 0.000890  iter-time: 0.6536\n",
            "[05:43:19.370161] Epoch: [14]  [30/42]  eta: 0:00:08  loss: 0.0577 (0.0644)  IoU: 0.7933 (0.7886)  lr: 0.000878  iter-time: 0.6517\n",
            "[05:43:25.845187] Epoch: [14]  [40/42]  eta: 0:00:01  loss: 0.0570 (0.0627)  IoU: 0.8012 (0.7914)  lr: 0.000867  iter-time: 0.6472\n",
            "[05:43:26.199069] Epoch: [14]  [41/42]  eta: 0:00:00  loss: 0.0577 (0.0631)  IoU: 0.7905 (0.7842)  lr: 0.000865  iter-time: 0.6326\n",
            "[05:43:26.367710] Epoch: [14] Total time: 0:00:29 (0.7014 s / it)\n",
            "[05:43:26.370974] [Train] averaged stats: loss: 0.0577 (0.0631)  IoU: 0.7905 (0.7842)  lr: 0.000865\n",
            "[05:43:26.997843] Epoch: [14]  [0/5]  eta: 0:00:03  loss: 0.0501 (0.0501)  IoU: 0.8877 (0.8877)  iter-time: 0.6223\n",
            "[05:43:27.763810] Epoch: [14]  [4/5]  eta: 0:00:00  loss: 0.0593 (0.0692)  IoU: 0.6985 (0.7552)  iter-time: 0.2775\n",
            "[05:43:27.852340] Epoch: [14] Total time: 0:00:01 (0.2955 s / it)\n",
            "[05:43:27.852472] [Val] averaged stats: loss: 0.0593 (0.0692)  IoU: 0.6985 (0.7552)\n",
            "[05:43:27.854887] Val loss improved from 0.07950651720166206 to 0.06915312781929969, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:43:28.078689] [Val] best loss: 0.0692 best  IoU: 0.7552 \n",
            "[05:43:28.082032] [Time] 31.2s 8.3m/17.2m\n",
            "\n",
            "[05:43:28.083013] ~~~ Epoch 15/30 ~~~\n",
            "\n",
            "[05:43:30.631580] Epoch: [15]  [ 0/42]  eta: 0:01:46  loss: 0.0680 (0.0680)  IoU: 0.8564 (0.8564)  lr: 0.000864  iter-time: 2.5452\n",
            "[05:43:37.081057] Epoch: [15]  [10/42]  eta: 0:00:26  loss: 0.0526 (0.0557)  IoU: 0.8066 (0.8023)  lr: 0.000852  iter-time: 0.8175\n",
            "[05:43:43.618051] Epoch: [15]  [20/42]  eta: 0:00:16  loss: 0.0526 (0.0616)  IoU: 0.7965 (0.7978)  lr: 0.000839  iter-time: 0.6491\n",
            "[05:43:50.100723] Epoch: [15]  [30/42]  eta: 0:00:08  loss: 0.0699 (0.0635)  IoU: 0.7930 (0.7888)  lr: 0.000825  iter-time: 0.6507\n",
            "[05:43:56.574390] Epoch: [15]  [40/42]  eta: 0:00:01  loss: 0.0557 (0.0619)  IoU: 0.7872 (0.7907)  lr: 0.000812  iter-time: 0.6476\n",
            "[05:43:56.933356] Epoch: [15]  [41/42]  eta: 0:00:00  loss: 0.0581 (0.0623)  IoU: 0.7809 (0.7842)  lr: 0.000810  iter-time: 0.6325\n",
            "[05:43:57.147916] Epoch: [15] Total time: 0:00:29 (0.6920 s / it)\n",
            "[05:43:57.149128] [Train] averaged stats: loss: 0.0581 (0.0623)  IoU: 0.7809 (0.7842)  lr: 0.000810\n",
            "[05:43:57.810858] Epoch: [15]  [0/5]  eta: 0:00:03  loss: 0.0436 (0.0436)  IoU: 0.8991 (0.8991)  iter-time: 0.6578\n",
            "[05:43:58.575433] Epoch: [15]  [4/5]  eta: 0:00:00  loss: 0.0604 (0.0639)  IoU: 0.7386 (0.7637)  iter-time: 0.2843\n",
            "[05:43:58.663042] Epoch: [15] Total time: 0:00:01 (0.3021 s / it)\n",
            "[05:43:58.663167] [Val] averaged stats: loss: 0.0604 (0.0639)  IoU: 0.7386 (0.7637)\n",
            "[05:43:58.665698] Val loss improved from 0.06915312781929969 to 0.06385702677071095, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:43:58.901231] [Val] best loss: 0.0639 best  IoU: 0.7637 \n",
            "[05:43:58.904335] Creating training plots . . .\n",
            "[05:43:59.215424] [Time] 31.1s 8.8m/17.1m\n",
            "\n",
            "[05:43:59.216028] ~~~ Epoch 16/30 ~~~\n",
            "\n",
            "[05:44:00.726094] Epoch: [16]  [ 0/42]  eta: 0:01:03  loss: 0.0619 (0.0619)  IoU: 0.8607 (0.8607)  lr: 0.000809  iter-time: 1.5051\n",
            "[05:44:07.227481] Epoch: [16]  [10/42]  eta: 0:00:23  loss: 0.0518 (0.0539)  IoU: 0.8158 (0.8090)  lr: 0.000795  iter-time: 0.7271\n",
            "[05:44:13.754351] Epoch: [16]  [20/42]  eta: 0:00:15  loss: 0.0560 (0.0607)  IoU: 0.8043 (0.8003)  lr: 0.000780  iter-time: 0.6510\n",
            "[05:44:20.261979] Epoch: [16]  [30/42]  eta: 0:00:08  loss: 0.0647 (0.0614)  IoU: 0.7880 (0.7977)  lr: 0.000765  iter-time: 0.6515\n",
            "[05:44:26.738744] Epoch: [16]  [40/42]  eta: 0:00:01  loss: 0.0494 (0.0586)  IoU: 0.8148 (0.8044)  lr: 0.000750  iter-time: 0.6489\n",
            "[05:44:27.096237] Epoch: [16]  [41/42]  eta: 0:00:00  loss: 0.0518 (0.0590)  IoU: 0.7913 (0.7970)  lr: 0.000748  iter-time: 0.6335\n",
            "[05:44:27.285273] Epoch: [16] Total time: 0:00:28 (0.6683 s / it)\n",
            "[05:44:27.286366] [Train] averaged stats: loss: 0.0518 (0.0590)  IoU: 0.7913 (0.7970)  lr: 0.000748\n",
            "[05:44:27.905263] Epoch: [16]  [0/5]  eta: 0:00:03  loss: 0.0363 (0.0363)  IoU: 0.9161 (0.9161)  iter-time: 0.6152\n",
            "[05:44:28.669847] Epoch: [16]  [4/5]  eta: 0:00:00  loss: 0.0441 (0.0567)  IoU: 0.7615 (0.7977)  iter-time: 0.2758\n",
            "[05:44:28.811460] Epoch: [16] Total time: 0:00:01 (0.3044 s / it)\n",
            "[05:44:28.811649] [Val] averaged stats: loss: 0.0441 (0.0567)  IoU: 0.7615 (0.7977)\n",
            "[05:44:28.812261] Val loss improved from 0.06385702677071095 to 0.0567388229072094, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:44:29.162192] [Val] best loss: 0.0567 best  IoU: 0.7977 \n",
            "[05:44:29.165321] [Time] 29.9s 9.3m/16.8m\n",
            "\n",
            "[05:44:29.165990] ~~~ Epoch 17/30 ~~~\n",
            "\n",
            "[05:44:31.503308] Epoch: [17]  [ 0/42]  eta: 0:01:38  loss: 0.0562 (0.0562)  IoU: 0.8806 (0.8806)  lr: 0.000747  iter-time: 2.3351\n",
            "[05:44:37.975067] Epoch: [17]  [10/42]  eta: 0:00:25  loss: 0.0469 (0.0520)  IoU: 0.8414 (0.8264)  lr: 0.000731  iter-time: 0.7999\n",
            "[05:44:44.504159] Epoch: [17]  [20/42]  eta: 0:00:16  loss: 0.0500 (0.0561)  IoU: 0.8195 (0.8200)  lr: 0.000715  iter-time: 0.6496\n",
            "[05:44:51.018456] Epoch: [17]  [30/42]  eta: 0:00:08  loss: 0.0518 (0.0563)  IoU: 0.8195 (0.8174)  lr: 0.000699  iter-time: 0.6519\n",
            "[05:44:57.494277] Epoch: [17]  [40/42]  eta: 0:00:01  loss: 0.0484 (0.0553)  IoU: 0.8239 (0.8164)  lr: 0.000683  iter-time: 0.6492\n",
            "[05:44:57.855327] Epoch: [17]  [41/42]  eta: 0:00:00  loss: 0.0518 (0.0552)  IoU: 0.8219 (0.8101)  lr: 0.000681  iter-time: 0.6344\n",
            "[05:44:58.029913] Epoch: [17] Total time: 0:00:28 (0.6872 s / it)\n",
            "[05:44:58.031916] [Train] averaged stats: loss: 0.0518 (0.0552)  IoU: 0.8219 (0.8101)  lr: 0.000681\n",
            "[05:44:58.698291] Epoch: [17]  [0/5]  eta: 0:00:03  loss: 0.0387 (0.0387)  IoU: 0.9111 (0.9111)  iter-time: 0.6623\n",
            "[05:44:59.462515] Epoch: [17]  [4/5]  eta: 0:00:00  loss: 0.0429 (0.0496)  IoU: 0.8290 (0.8075)  iter-time: 0.2847\n",
            "[05:44:59.632915] Epoch: [17] Total time: 0:00:01 (0.3196 s / it)\n",
            "[05:44:59.633047] [Val] averaged stats: loss: 0.0429 (0.0496)  IoU: 0.8290 (0.8075)\n",
            "[05:44:59.636000] Val loss improved from 0.0567388229072094 to 0.049621086567640305, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:44:59.978992] [Val] best loss: 0.0496 best  IoU: 0.8075 \n",
            "[05:44:59.982002] [Time] 30.8s 9.9m/17.0m\n",
            "\n",
            "[05:44:59.982956] ~~~ Epoch 18/30 ~~~\n",
            "\n",
            "[05:45:03.030072] Epoch: [18]  [ 0/42]  eta: 0:02:07  loss: 0.0514 (0.0514)  IoU: 0.8881 (0.8881)  lr: 0.000679  iter-time: 3.0416\n",
            "[05:45:09.471467] Epoch: [18]  [10/42]  eta: 0:00:27  loss: 0.0474 (0.0502)  IoU: 0.8272 (0.8197)  lr: 0.000663  iter-time: 0.8618\n",
            "[05:45:16.044602] Epoch: [18]  [20/42]  eta: 0:00:16  loss: 0.0485 (0.0539)  IoU: 0.8202 (0.8184)  lr: 0.000646  iter-time: 0.6502\n",
            "[05:45:22.600380] Epoch: [18]  [30/42]  eta: 0:00:08  loss: 0.0502 (0.0526)  IoU: 0.8202 (0.8201)  lr: 0.000629  iter-time: 0.6559\n",
            "[05:45:29.070564] Epoch: [18]  [40/42]  eta: 0:00:01  loss: 0.0470 (0.0516)  IoU: 0.8307 (0.8216)  lr: 0.000611  iter-time: 0.6511\n",
            "[05:45:29.426802] Epoch: [18]  [41/42]  eta: 0:00:00  loss: 0.0472 (0.0521)  IoU: 0.8269 (0.8160)  lr: 0.000610  iter-time: 0.6361\n",
            "[05:45:29.582941] Epoch: [18] Total time: 0:00:29 (0.7047 s / it)\n",
            "[05:45:29.586335] [Train] averaged stats: loss: 0.0472 (0.0521)  IoU: 0.8269 (0.8160)  lr: 0.000610\n",
            "[05:45:30.221919] Epoch: [18]  [0/5]  eta: 0:00:03  loss: 0.0448 (0.0448)  IoU: 0.8957 (0.8957)  iter-time: 0.6308\n",
            "[05:45:30.991426] Epoch: [18]  [4/5]  eta: 0:00:00  loss: 0.0448 (0.0523)  IoU: 0.8138 (0.8089)  iter-time: 0.2796\n",
            "[05:45:31.127139] Epoch: [18] Total time: 0:00:01 (0.3073 s / it)\n",
            "[05:45:31.127291] [Val] averaged stats: loss: 0.0448 (0.0523)  IoU: 0.8138 (0.8089)\n",
            "[05:45:31.130012] [Val] best loss: 0.0496 best  IoU: 0.8075 \n",
            "EarlyStopping counter: 1 out of 30\n",
            "[05:45:31.131028] [Time] 31.1s 10.4m/17.1m\n",
            "\n",
            "[05:45:31.131078] ~~~ Epoch 19/30 ~~~\n",
            "\n",
            "[05:45:34.437421] Epoch: [19]  [ 0/42]  eta: 0:02:18  loss: 0.0542 (0.0542)  IoU: 0.8871 (0.8871)  lr: 0.000608  iter-time: 3.2997\n",
            "[05:45:41.000983] Epoch: [19]  [10/42]  eta: 0:00:28  loss: 0.0445 (0.0483)  IoU: 0.8406 (0.8289)  lr: 0.000590  iter-time: 0.8965\n",
            "[05:45:47.460350] Epoch: [19]  [20/42]  eta: 0:00:17  loss: 0.0462 (0.0525)  IoU: 0.8255 (0.8226)  lr: 0.000573  iter-time: 0.6510\n",
            "[05:45:54.036237] Epoch: [19]  [30/42]  eta: 0:00:08  loss: 0.0532 (0.0512)  IoU: 0.8363 (0.8281)  lr: 0.000555  iter-time: 0.6516\n",
            "[05:46:00.526657] Epoch: [19]  [40/42]  eta: 0:00:01  loss: 0.0429 (0.0505)  IoU: 0.8445 (0.8287)  lr: 0.000537  iter-time: 0.6530\n",
            "[05:46:00.881666] Epoch: [19]  [41/42]  eta: 0:00:00  loss: 0.0435 (0.0506)  IoU: 0.8444 (0.8214)  lr: 0.000536  iter-time: 0.6376\n",
            "[05:46:00.985227] Epoch: [19] Total time: 0:00:29 (0.7107 s / it)\n",
            "[05:46:00.988862] [Train] averaged stats: loss: 0.0435 (0.0506)  IoU: 0.8444 (0.8214)  lr: 0.000536\n",
            "[05:46:01.426436] Epoch: [19]  [0/5]  eta: 0:00:02  loss: 0.0386 (0.0386)  IoU: 0.9127 (0.9127)  iter-time: 0.4338\n",
            "[05:46:02.190067] Epoch: [19]  [4/5]  eta: 0:00:00  loss: 0.0386 (0.0438)  IoU: 0.8649 (0.8389)  iter-time: 0.2394\n",
            "[05:46:02.277871] Epoch: [19] Total time: 0:00:01 (0.2572 s / it)\n",
            "[05:46:02.278065] [Val] averaged stats: loss: 0.0386 (0.0438)  IoU: 0.8649 (0.8389)\n",
            "[05:46:02.280747] Val loss improved from 0.049621086567640305 to 0.043784158676862715, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:46:02.513942] [Val] best loss: 0.0438 best  IoU: 0.8389 \n",
            "[05:46:02.517093] [Time] 31.4s 10.9m/17.2m\n",
            "\n",
            "[05:46:02.517175] ~~~ Epoch 20/30 ~~~\n",
            "\n",
            "[05:46:03.489252] Epoch: [20]  [ 0/42]  eta: 0:00:40  loss: 0.0521 (0.0521)  IoU: 0.8892 (0.8892)  lr: 0.000534  iter-time: 0.9692\n",
            "[05:46:10.162653] Epoch: [20]  [10/42]  eta: 0:00:22  loss: 0.0428 (0.0482)  IoU: 0.8471 (0.8300)  lr: 0.000516  iter-time: 0.6945\n",
            "[05:46:16.709286] Epoch: [20]  [20/42]  eta: 0:00:14  loss: 0.0428 (0.0511)  IoU: 0.8297 (0.8300)  lr: 0.000498  iter-time: 0.6607\n",
            "[05:46:23.186960] Epoch: [20]  [30/42]  eta: 0:00:07  loss: 0.0464 (0.0494)  IoU: 0.8436 (0.8350)  lr: 0.000480  iter-time: 0.6510\n",
            "[05:46:29.660855] Epoch: [20]  [40/42]  eta: 0:00:01  loss: 0.0413 (0.0486)  IoU: 0.8471 (0.8355)  lr: 0.000463  iter-time: 0.6474\n",
            "[05:46:30.013268] Epoch: [20]  [41/42]  eta: 0:00:00  loss: 0.0413 (0.0485)  IoU: 0.8389 (0.8303)  lr: 0.000461  iter-time: 0.6325\n",
            "[05:46:30.207222] Epoch: [20] Total time: 0:00:27 (0.6593 s / it)\n",
            "[05:46:30.208371] [Train] averaged stats: loss: 0.0413 (0.0485)  IoU: 0.8389 (0.8303)  lr: 0.000461\n",
            "[05:46:30.835327] Epoch: [20]  [0/5]  eta: 0:00:03  loss: 0.0337 (0.0337)  IoU: 0.9249 (0.9249)  iter-time: 0.6232\n",
            "[05:46:31.600300] Epoch: [20]  [4/5]  eta: 0:00:00  loss: 0.0392 (0.0402)  IoU: 0.8473 (0.8434)  iter-time: 0.2775\n",
            "[05:46:31.691166] Epoch: [20] Total time: 0:00:01 (0.2959 s / it)\n",
            "[05:46:31.692065] [Val] averaged stats: loss: 0.0392 (0.0402)  IoU: 0.8473 (0.8434)\n",
            "[05:46:31.694030] Val loss improved from 0.043784158676862715 to 0.04022934399545193, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:46:31.908408] [Val] best loss: 0.0402 best  IoU: 0.8434 \n",
            "[05:46:31.910903] Creating training plots . . .\n",
            "[05:46:32.237652] [Time] 29.7s 11.4m/16.8m\n",
            "\n",
            "[05:46:32.237774] ~~~ Epoch 21/30 ~~~\n",
            "\n",
            "[05:46:34.170053] Epoch: [21]  [ 0/42]  eta: 0:01:20  loss: 0.0511 (0.0511)  IoU: 0.8930 (0.8930)  lr: 0.000459  iter-time: 1.9261\n",
            "[05:46:40.638275] Epoch: [21]  [10/42]  eta: 0:00:24  loss: 0.0430 (0.0444)  IoU: 0.8394 (0.8395)  lr: 0.000441  iter-time: 0.7629\n",
            "[05:46:47.179683] Epoch: [21]  [20/42]  eta: 0:00:15  loss: 0.0442 (0.0476)  IoU: 0.8393 (0.8371)  lr: 0.000424  iter-time: 0.6503\n",
            "[05:46:53.674991] Epoch: [21]  [30/42]  eta: 0:00:08  loss: 0.0463 (0.0468)  IoU: 0.8404 (0.8408)  lr: 0.000406  iter-time: 0.6515\n",
            "[05:47:00.159640] Epoch: [21]  [40/42]  eta: 0:00:01  loss: 0.0412 (0.0461)  IoU: 0.8361 (0.8398)  lr: 0.000389  iter-time: 0.6480\n",
            "[05:47:00.514998] Epoch: [21]  [41/42]  eta: 0:00:00  loss: 0.0412 (0.0465)  IoU: 0.8340 (0.8311)  lr: 0.000387  iter-time: 0.6326\n",
            "[05:47:00.704502] Epoch: [21] Total time: 0:00:28 (0.6777 s / it)\n",
            "[05:47:00.706310] [Train] averaged stats: loss: 0.0412 (0.0465)  IoU: 0.8340 (0.8311)  lr: 0.000387\n",
            "[05:47:01.386215] Epoch: [21]  [0/5]  eta: 0:00:03  loss: 0.0343 (0.0343)  IoU: 0.9206 (0.9206)  iter-time: 0.6761\n",
            "[05:47:02.146481] Epoch: [21]  [4/5]  eta: 0:00:00  loss: 0.0343 (0.0391)  IoU: 0.8717 (0.8512)  iter-time: 0.2871\n",
            "[05:47:02.233124] Epoch: [21] Total time: 0:00:01 (0.3047 s / it)\n",
            "[05:47:02.234074] [Val] averaged stats: loss: 0.0343 (0.0391)  IoU: 0.8717 (0.8512)\n",
            "[05:47:02.235996] Val loss improved from 0.04022934399545193 to 0.039065994694828986, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:47:02.465212] [Val] best loss: 0.0391 best  IoU: 0.8512 \n",
            "[05:47:02.467933] [Time] 30.2s 11.9m/16.9m\n",
            "\n",
            "[05:47:02.468018] ~~~ Epoch 22/30 ~~~\n",
            "\n",
            "[05:47:04.066814] Epoch: [22]  [ 0/42]  eta: 0:01:06  loss: 0.0470 (0.0470)  IoU: 0.8987 (0.8987)  lr: 0.000385  iter-time: 1.5951\n",
            "[05:47:10.607163] Epoch: [22]  [10/42]  eta: 0:00:23  loss: 0.0415 (0.0424)  IoU: 0.8592 (0.8470)  lr: 0.000368  iter-time: 0.7393\n",
            "[05:47:17.181842] Epoch: [22]  [20/42]  eta: 0:00:15  loss: 0.0422 (0.0458)  IoU: 0.8532 (0.8461)  lr: 0.000351  iter-time: 0.6555\n",
            "[05:47:23.659990] Epoch: [22]  [30/42]  eta: 0:00:08  loss: 0.0478 (0.0446)  IoU: 0.8572 (0.8506)  lr: 0.000334  iter-time: 0.6524\n",
            "[05:47:30.137971] Epoch: [22]  [40/42]  eta: 0:00:01  loss: 0.0373 (0.0447)  IoU: 0.8563 (0.8472)  lr: 0.000317  iter-time: 0.6476\n",
            "[05:47:30.492935] Epoch: [22]  [41/42]  eta: 0:00:00  loss: 0.0415 (0.0453)  IoU: 0.8498 (0.8387)  lr: 0.000316  iter-time: 0.6326\n",
            "[05:47:30.674091] Epoch: [22] Total time: 0:00:28 (0.6715 s / it)\n",
            "[05:47:30.675329] [Train] averaged stats: loss: 0.0415 (0.0453)  IoU: 0.8498 (0.8387)  lr: 0.000316\n",
            "[05:47:31.304592] Epoch: [22]  [0/5]  eta: 0:00:03  loss: 0.0322 (0.0322)  IoU: 0.9269 (0.9269)  iter-time: 0.6255\n",
            "[05:47:32.067862] Epoch: [22]  [4/5]  eta: 0:00:00  loss: 0.0325 (0.0379)  IoU: 0.8667 (0.8608)  iter-time: 0.2776\n",
            "[05:47:32.157575] Epoch: [22] Total time: 0:00:01 (0.2958 s / it)\n",
            "[05:47:32.158081] [Val] averaged stats: loss: 0.0325 (0.0379)  IoU: 0.8667 (0.8608)\n",
            "[05:47:32.160421] Val loss improved from 0.039065994694828986 to 0.03793212808668613, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:47:32.382621] [Val] best loss: 0.0379 best  IoU: 0.8608 \n",
            "[05:47:32.385825] [Time] 29.9s 12.4m/16.9m\n",
            "\n",
            "[05:47:32.386659] ~~~ Epoch 23/30 ~~~\n",
            "\n",
            "[05:47:34.158972] Epoch: [23]  [ 0/42]  eta: 0:01:14  loss: 0.0443 (0.0443)  IoU: 0.9039 (0.9039)  lr: 0.000314  iter-time: 1.7683\n",
            "[05:47:40.653389] Epoch: [23]  [10/42]  eta: 0:00:24  loss: 0.0403 (0.0433)  IoU: 0.8552 (0.8466)  lr: 0.000298  iter-time: 0.7508\n",
            "[05:47:47.210387] Epoch: [23]  [20/42]  eta: 0:00:15  loss: 0.0412 (0.0455)  IoU: 0.8552 (0.8477)  lr: 0.000281  iter-time: 0.6523\n",
            "[05:47:53.715153] Epoch: [23]  [30/42]  eta: 0:00:08  loss: 0.0446 (0.0448)  IoU: 0.8569 (0.8489)  lr: 0.000266  iter-time: 0.6528\n",
            "[05:48:00.191176] Epoch: [23]  [40/42]  eta: 0:00:01  loss: 0.0386 (0.0448)  IoU: 0.8561 (0.8485)  lr: 0.000250  iter-time: 0.6488\n",
            "[05:48:00.544844] Epoch: [23]  [41/42]  eta: 0:00:00  loss: 0.0386 (0.0449)  IoU: 0.8476 (0.8408)  lr: 0.000248  iter-time: 0.6333\n",
            "[05:48:00.767728] Epoch: [23] Total time: 0:00:28 (0.6757 s / it)\n",
            "[05:48:00.769225] [Train] averaged stats: loss: 0.0386 (0.0449)  IoU: 0.8476 (0.8408)  lr: 0.000248\n",
            "[05:48:01.416547] Epoch: [23]  [0/5]  eta: 0:00:03  loss: 0.0333 (0.0333)  IoU: 0.9243 (0.9243)  iter-time: 0.6420\n",
            "[05:48:02.179548] Epoch: [23]  [4/5]  eta: 0:00:00  loss: 0.0333 (0.0374)  IoU: 0.8638 (0.8523)  iter-time: 0.2806\n",
            "[05:48:02.267888] Epoch: [23] Total time: 0:00:01 (0.2991 s / it)\n",
            "[05:48:02.268018] [Val] averaged stats: loss: 0.0333 (0.0374)  IoU: 0.8638 (0.8523)\n",
            "[05:48:02.270986] Val loss improved from 0.03793212808668613 to 0.03744871988892555, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:48:02.489945] [Val] best loss: 0.0374 best  IoU: 0.8523 \n",
            "[05:48:02.492825] [Time] 30.1s 12.9m/16.9m\n",
            "\n",
            "[05:48:02.492911] ~~~ Epoch 24/30 ~~~\n",
            "\n",
            "[05:48:03.951152] Epoch: [24]  [ 0/42]  eta: 0:01:01  loss: 0.0481 (0.0481)  IoU: 0.8989 (0.8989)  lr: 0.000247  iter-time: 1.4537\n",
            "[05:48:10.855485] Epoch: [24]  [10/42]  eta: 0:00:24  loss: 0.0383 (0.0411)  IoU: 0.8532 (0.8497)  lr: 0.000232  iter-time: 0.7595\n",
            "[05:48:17.377713] Epoch: [24]  [20/42]  eta: 0:00:15  loss: 0.0404 (0.0430)  IoU: 0.8532 (0.8528)  lr: 0.000217  iter-time: 0.6709\n",
            "[05:48:23.893818] Epoch: [24]  [30/42]  eta: 0:00:08  loss: 0.0429 (0.0417)  IoU: 0.8527 (0.8545)  lr: 0.000202  iter-time: 0.6516\n",
            "[05:48:30.351469] Epoch: [24]  [40/42]  eta: 0:00:01  loss: 0.0371 (0.0408)  IoU: 0.8527 (0.8564)  lr: 0.000188  iter-time: 0.6485\n",
            "[05:48:30.709119] Epoch: [24]  [41/42]  eta: 0:00:00  loss: 0.0371 (0.0411)  IoU: 0.8527 (0.8502)  lr: 0.000187  iter-time: 0.6335\n",
            "[05:48:30.883679] Epoch: [24] Total time: 0:00:28 (0.6759 s / it)\n",
            "[05:48:30.885474] [Train] averaged stats: loss: 0.0371 (0.0411)  IoU: 0.8527 (0.8502)  lr: 0.000187\n",
            "[05:48:31.566788] Epoch: [24]  [0/5]  eta: 0:00:03  loss: 0.0325 (0.0325)  IoU: 0.9255 (0.9255)  iter-time: 0.6769\n",
            "[05:48:32.335582] Epoch: [24]  [4/5]  eta: 0:00:00  loss: 0.0325 (0.0367)  IoU: 0.8761 (0.8595)  iter-time: 0.2890\n",
            "[05:48:32.496788] Epoch: [24] Total time: 0:00:01 (0.3215 s / it)\n",
            "[05:48:32.496958] [Val] averaged stats: loss: 0.0325 (0.0367)  IoU: 0.8761 (0.8595)\n",
            "[05:48:32.501763] Val loss improved from 0.03744871988892555 to 0.03672179728746414, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:48:32.847130] [Val] best loss: 0.0367 best  IoU: 0.8595 \n",
            "[05:48:32.850180] [Time] 30.4s 13.4m/16.9m\n",
            "\n",
            "[05:48:32.850303] ~~~ Epoch 25/30 ~~~\n",
            "\n",
            "[05:48:35.239018] Epoch: [25]  [ 0/42]  eta: 0:01:39  loss: 0.0515 (0.0515)  IoU: 0.8899 (0.8899)  lr: 0.000185  iter-time: 2.3792\n",
            "[05:48:41.682827] Epoch: [25]  [10/42]  eta: 0:00:25  loss: 0.0350 (0.0403)  IoU: 0.8582 (0.8551)  lr: 0.000172  iter-time: 0.8020\n",
            "[05:48:48.194195] Epoch: [25]  [20/42]  eta: 0:00:16  loss: 0.0372 (0.0417)  IoU: 0.8558 (0.8574)  lr: 0.000159  iter-time: 0.6476\n",
            "[05:48:54.762801] Epoch: [25]  [30/42]  eta: 0:00:08  loss: 0.0382 (0.0407)  IoU: 0.8603 (0.8596)  lr: 0.000146  iter-time: 0.6538\n",
            "[05:49:01.238870] Epoch: [25]  [40/42]  eta: 0:00:01  loss: 0.0355 (0.0404)  IoU: 0.8603 (0.8600)  lr: 0.000133  iter-time: 0.6520\n",
            "[05:49:01.598093] Epoch: [25]  [41/42]  eta: 0:00:00  loss: 0.0355 (0.0408)  IoU: 0.8561 (0.8510)  lr: 0.000132  iter-time: 0.6370\n",
            "[05:49:01.704897] Epoch: [25] Total time: 0:00:28 (0.6869 s / it)\n",
            "[05:49:01.706391] [Train] averaged stats: loss: 0.0355 (0.0408)  IoU: 0.8561 (0.8510)  lr: 0.000132\n",
            "[05:49:02.207198] Epoch: [25]  [0/5]  eta: 0:00:02  loss: 0.0316 (0.0316)  IoU: 0.9273 (0.9273)  iter-time: 0.4974\n",
            "[05:49:02.974233] Epoch: [25]  [4/5]  eta: 0:00:00  loss: 0.0329 (0.0357)  IoU: 0.8733 (0.8611)  iter-time: 0.2524\n",
            "[05:49:03.121162] Epoch: [25] Total time: 0:00:01 (0.2824 s / it)\n",
            "[05:49:03.121317] [Val] averaged stats: loss: 0.0329 (0.0357)  IoU: 0.8733 (0.8611)\n",
            "[05:49:03.122026] Val loss improved from 0.03672179728746414 to 0.03572345711290836, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:49:03.455909] [Val] best loss: 0.0357 best  IoU: 0.8611 \n",
            "[05:49:03.458702] Creating training plots . . .\n",
            "[05:49:03.900640] [Time] 31.1s 13.9m/17.0m\n",
            "\n",
            "[05:49:03.902038] ~~~ Epoch 26/30 ~~~\n",
            "\n",
            "[05:49:05.258928] Epoch: [26]  [ 0/42]  eta: 0:00:56  loss: 0.0507 (0.0507)  IoU: 0.8880 (0.8880)  lr: 0.000131  iter-time: 1.3470\n",
            "[05:49:13.206948] Epoch: [26]  [10/42]  eta: 0:00:27  loss: 0.0382 (0.0401)  IoU: 0.8580 (0.8524)  lr: 0.000119  iter-time: 0.8449\n",
            "[05:49:19.672132] Epoch: [26]  [20/42]  eta: 0:00:16  loss: 0.0384 (0.0414)  IoU: 0.8572 (0.8570)  lr: 0.000108  iter-time: 0.7205\n",
            "[05:49:26.196103] Epoch: [26]  [30/42]  eta: 0:00:08  loss: 0.0393 (0.0403)  IoU: 0.8640 (0.8600)  lr: 0.000097  iter-time: 0.6493\n",
            "[05:49:32.681777] Epoch: [26]  [40/42]  eta: 0:00:01  loss: 0.0378 (0.0406)  IoU: 0.8602 (0.8569)  lr: 0.000087  iter-time: 0.6503\n",
            "[05:49:33.037602] Epoch: [26]  [41/42]  eta: 0:00:00  loss: 0.0378 (0.0408)  IoU: 0.8549 (0.8507)  lr: 0.000086  iter-time: 0.6356\n",
            "[05:49:33.143419] Epoch: [26] Total time: 0:00:29 (0.6962 s / it)\n",
            "[05:49:33.143633] [Train] averaged stats: loss: 0.0378 (0.0408)  IoU: 0.8549 (0.8507)  lr: 0.000086\n",
            "[05:49:33.617335] Epoch: [26]  [0/5]  eta: 0:00:02  loss: 0.0320 (0.0320)  IoU: 0.9263 (0.9263)  iter-time: 0.4714\n",
            "[05:49:34.379143] Epoch: [26]  [4/5]  eta: 0:00:00  loss: 0.0320 (0.0361)  IoU: 0.8803 (0.8593)  iter-time: 0.2465\n",
            "[05:49:34.472251] Epoch: [26] Total time: 0:00:01 (0.2654 s / it)\n",
            "[05:49:34.472385] [Val] averaged stats: loss: 0.0320 (0.0361)  IoU: 0.8803 (0.8593)\n",
            "[05:49:34.474999] [Val] best loss: 0.0357 best  IoU: 0.8611 \n",
            "EarlyStopping counter: 1 out of 30\n",
            "[05:49:34.477264] [Time] 30.6s 14.4m/17.0m\n",
            "\n",
            "[05:49:34.478224] ~~~ Epoch 27/30 ~~~\n",
            "\n",
            "[05:49:36.999972] Epoch: [27]  [ 0/42]  eta: 0:01:45  loss: 0.0523 (0.0523)  IoU: 0.8888 (0.8888)  lr: 0.000085  iter-time: 2.5191\n",
            "[05:49:43.492040] Epoch: [27]  [10/42]  eta: 0:00:26  loss: 0.0369 (0.0383)  IoU: 0.8722 (0.8619)  lr: 0.000075  iter-time: 0.8191\n",
            "[05:49:49.995558] Epoch: [27]  [20/42]  eta: 0:00:16  loss: 0.0370 (0.0404)  IoU: 0.8609 (0.8633)  lr: 0.000066  iter-time: 0.6496\n",
            "[05:49:56.458878] Epoch: [27]  [30/42]  eta: 0:00:08  loss: 0.0412 (0.0403)  IoU: 0.8614 (0.8628)  lr: 0.000058  iter-time: 0.6482\n",
            "[05:50:02.919245] Epoch: [27]  [40/42]  eta: 0:00:01  loss: 0.0342 (0.0398)  IoU: 0.8660 (0.8639)  lr: 0.000050  iter-time: 0.6460\n",
            "[05:50:03.274341] Epoch: [27]  [41/42]  eta: 0:00:00  loss: 0.0328 (0.0397)  IoU: 0.8660 (0.8588)  lr: 0.000049  iter-time: 0.6314\n",
            "[05:50:03.448093] Epoch: [27] Total time: 0:00:28 (0.6897 s / it)\n",
            "[05:50:03.449205] [Train] averaged stats: loss: 0.0328 (0.0397)  IoU: 0.8660 (0.8588)  lr: 0.000049\n",
            "[05:50:04.070080] Epoch: [27]  [0/5]  eta: 0:00:03  loss: 0.0314 (0.0314)  IoU: 0.9282 (0.9282)  iter-time: 0.6170\n",
            "[05:50:04.832707] Epoch: [27]  [4/5]  eta: 0:00:00  loss: 0.0319 (0.0363)  IoU: 0.8772 (0.8630)  iter-time: 0.2758\n",
            "[05:50:04.924560] Epoch: [27] Total time: 0:00:01 (0.2944 s / it)\n",
            "[05:50:04.924703] [Val] averaged stats: loss: 0.0319 (0.0363)  IoU: 0.8772 (0.8630)\n",
            "[05:50:04.927304] [Val] best loss: 0.0357 best  IoU: 0.8611 \n",
            "EarlyStopping counter: 2 out of 30\n",
            "[05:50:04.929606] [Time] 30.5s 14.9m/17.0m\n",
            "\n",
            "[05:50:04.930658] ~~~ Epoch 28/30 ~~~\n",
            "\n",
            "[05:50:07.475171] Epoch: [28]  [ 0/42]  eta: 0:01:46  loss: 0.0436 (0.0436)  IoU: 0.9023 (0.9023)  lr: 0.000048  iter-time: 2.5416\n",
            "[05:50:13.923500] Epoch: [28]  [10/42]  eta: 0:00:26  loss: 0.0356 (0.0371)  IoU: 0.8747 (0.8632)  lr: 0.000041  iter-time: 0.8170\n",
            "[05:50:20.484062] Epoch: [28]  [20/42]  eta: 0:00:16  loss: 0.0387 (0.0395)  IoU: 0.8692 (0.8633)  lr: 0.000034  iter-time: 0.6501\n",
            "[05:50:26.950799] Epoch: [28]  [30/42]  eta: 0:00:08  loss: 0.0394 (0.0388)  IoU: 0.8656 (0.8632)  lr: 0.000028  iter-time: 0.6511\n",
            "[05:50:33.424208] Epoch: [28]  [40/42]  eta: 0:00:01  loss: 0.0351 (0.0384)  IoU: 0.8564 (0.8631)  lr: 0.000022  iter-time: 0.6468\n",
            "[05:50:33.780468] Epoch: [28]  [41/42]  eta: 0:00:00  loss: 0.0344 (0.0382)  IoU: 0.8455 (0.8582)  lr: 0.000022  iter-time: 0.6317\n",
            "[05:50:33.957818] Epoch: [28] Total time: 0:00:29 (0.6911 s / it)\n",
            "[05:50:33.959397] [Train] averaged stats: loss: 0.0344 (0.0382)  IoU: 0.8455 (0.8582)  lr: 0.000022\n",
            "[05:50:34.568414] Epoch: [28]  [0/5]  eta: 0:00:03  loss: 0.0310 (0.0310)  IoU: 0.9293 (0.9293)  iter-time: 0.6050\n",
            "[05:50:35.332540] Epoch: [28]  [4/5]  eta: 0:00:00  loss: 0.0312 (0.0352)  IoU: 0.8815 (0.8657)  iter-time: 0.2737\n",
            "[05:50:35.422748] Epoch: [28] Total time: 0:00:01 (0.2920 s / it)\n",
            "[05:50:35.422879] [Val] averaged stats: loss: 0.0312 (0.0352)  IoU: 0.8815 (0.8657)\n",
            "[05:50:35.425668] Val loss improved from 0.03572345711290836 to 0.03520941771566868, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:50:35.650078] [Val] best loss: 0.0352 best  IoU: 0.8657 \n",
            "[05:50:35.653276] [Time] 30.7s 15.4m/17.0m\n",
            "\n",
            "[05:50:35.653357] ~~~ Epoch 29/30 ~~~\n",
            "\n",
            "[05:50:37.953477] Epoch: [29]  [ 0/42]  eta: 0:01:36  loss: 0.0475 (0.0475)  IoU: 0.9041 (0.9041)  lr: 0.000021  iter-time: 2.2953\n",
            "[05:50:44.426019] Epoch: [29]  [10/42]  eta: 0:00:25  loss: 0.0342 (0.0374)  IoU: 0.8732 (0.8632)  lr: 0.000016  iter-time: 0.7968\n",
            "[05:50:50.985765] Epoch: [29]  [20/42]  eta: 0:00:16  loss: 0.0378 (0.0398)  IoU: 0.8715 (0.8633)  lr: 0.000012  iter-time: 0.6513\n",
            "[05:50:57.475778] Epoch: [29]  [30/42]  eta: 0:00:08  loss: 0.0384 (0.0392)  IoU: 0.8577 (0.8633)  lr: 0.000009  iter-time: 0.6522\n",
            "[05:51:03.956605] Epoch: [29]  [40/42]  eta: 0:00:01  loss: 0.0348 (0.0386)  IoU: 0.8678 (0.8631)  lr: 0.000006  iter-time: 0.6483\n",
            "[05:51:04.314821] Epoch: [29]  [41/42]  eta: 0:00:00  loss: 0.0313 (0.0385)  IoU: 0.8678 (0.8585)  lr: 0.000005  iter-time: 0.6334\n",
            "[05:51:04.497764] Epoch: [29] Total time: 0:00:28 (0.6867 s / it)\n",
            "[05:51:04.498937] [Train] averaged stats: loss: 0.0313 (0.0385)  IoU: 0.8678 (0.8585)  lr: 0.000005\n",
            "[05:51:05.186547] Epoch: [29]  [0/5]  eta: 0:00:03  loss: 0.0308 (0.0308)  IoU: 0.9297 (0.9297)  iter-time: 0.6837\n",
            "[05:51:05.952497] Epoch: [29]  [4/5]  eta: 0:00:00  loss: 0.0314 (0.0353)  IoU: 0.8805 (0.8660)  iter-time: 0.2898\n",
            "[05:51:06.043304] Epoch: [29] Total time: 0:00:01 (0.3082 s / it)\n",
            "[05:51:06.044509] [Val] averaged stats: loss: 0.0314 (0.0353)  IoU: 0.8805 (0.8660)\n",
            "[05:51:06.046350] [Val] best loss: 0.0352 best  IoU: 0.8657 \n",
            "EarlyStopping counter: 1 out of 30\n",
            "[05:51:06.048483] [Time] 30.4s 16.0m/17.0m\n",
            "\n",
            "[05:51:06.049625] ~~~ Epoch 30/30 ~~~\n",
            "\n",
            "[05:51:08.184944] Epoch: [30]  [ 0/42]  eta: 0:01:29  loss: 0.0486 (0.0486)  IoU: 0.8958 (0.8958)  lr: 0.000005  iter-time: 2.1327\n",
            "[05:51:14.650300] Epoch: [30]  [10/42]  eta: 0:00:25  loss: 0.0397 (0.0391)  IoU: 0.8710 (0.8601)  lr: 0.000003  iter-time: 0.7813\n",
            "[05:51:21.190159] Epoch: [30]  [20/42]  eta: 0:00:15  loss: 0.0394 (0.0410)  IoU: 0.8656 (0.8596)  lr: 0.000001  iter-time: 0.6500\n",
            "[05:51:27.677708] Epoch: [30]  [30/42]  eta: 0:00:08  loss: 0.0391 (0.0401)  IoU: 0.8656 (0.8603)  lr: 0.000000  iter-time: 0.6512\n",
            "[05:51:34.134182] Epoch: [30]  [40/42]  eta: 0:00:01  loss: 0.0326 (0.0392)  IoU: 0.8706 (0.8622)  lr: 0.000000  iter-time: 0.6469\n",
            "[05:51:34.488135] Epoch: [30]  [41/42]  eta: 0:00:00  loss: 0.0326 (0.0396)  IoU: 0.8699 (0.8552)  lr: 0.000000  iter-time: 0.6318\n",
            "[05:51:34.665615] Epoch: [30] Total time: 0:00:28 (0.6813 s / it)\n",
            "[05:51:34.666692] [Train] averaged stats: loss: 0.0326 (0.0396)  IoU: 0.8699 (0.8552)  lr: 0.000000\n",
            "[05:51:35.335853] Epoch: [30]  [0/5]  eta: 0:00:03  loss: 0.0308 (0.0308)  IoU: 0.9299 (0.9299)  iter-time: 0.6655\n",
            "[05:51:36.098073] Epoch: [30]  [4/5]  eta: 0:00:00  loss: 0.0311 (0.0351)  IoU: 0.8816 (0.8663)  iter-time: 0.2850\n",
            "[05:51:36.241702] Epoch: [30] Total time: 0:00:01 (0.3144 s / it)\n",
            "[05:51:36.241839] [Val] averaged stats: loss: 0.0311 (0.0351)  IoU: 0.8816 (0.8663)\n",
            "[05:51:36.242474] Val loss improved from 0.03520941771566868 to 0.03509102873504162, saving model to /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:51:36.570563] [Val] best loss: 0.0351 best  IoU: 0.8663 \n",
            "[05:51:36.573804] Creating training plots . . .\n",
            "[05:51:36.906732] [Time] 30.9s 16.5m/17.0m\n",
            "\n",
            "[05:51:36.907977] Training time: 0:16:27\n",
            "[05:51:36.908054] Train loss: 0.039591001391056035\n",
            "[05:51:36.909314] Train IoU: 0.8551971287954421\n",
            "[05:51:36.909371] Validation loss: 0.03509102873504162\n",
            "[05:51:36.909421] Validation IoU: 0.8663197755813599\n",
            "[05:51:36.909463] Finished Training\n",
            "[05:51:38.671586] Releasing memory . . .\n",
            "[05:51:38.671952] ######################\n",
            "[05:51:38.672114] #   LOAD TEST DATA   #\n",
            "[05:51:38.672161] ######################\n",
            "[05:51:38.674962] 2) Loading test images . . .\n",
            "[05:51:38.675066] Loading data from /content/data/test/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:51:39.735170] *** Loaded data shape is (1, 165, 768, 1024, 1)\n",
            "[05:51:39.744952] 3) Loading test masks . . .\n",
            "[05:51:39.745040] Loading data from /content/data/test/y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  6.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:51:40.112416] *** Loaded data shape is (1, 165, 768, 1024, 1)\n",
            "[05:51:40.121909] ############################\n",
            "[05:51:40.121989] #  PREPARE TEST GENERATOR  #\n",
            "[05:51:40.122031] ############################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:51:42.877162] Loading checkpoint from file /content/output/my_3d_semantic_segmentation/checkpoints/my_3d_semantic_segmentation_1-checkpoint-best.pth\n",
            "[05:51:43.011103] Model weights loaded!\n",
            "[05:51:43.013061] ###############\n",
            "[05:51:43.013158] #  INFERENCE  #\n",
            "[05:51:43.014506] ###############\n",
            "[05:51:43.015128] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:51:46.411898] Processing image: testing.tif\n",
            "[05:51:46.412129] ### 3D-OV-CROP ###\n",
            "[05:51:46.412193] Cropping (165, 768, 1024, 1) images into (80, 80, 80, 1) with overlapping . . .\n",
            "[05:51:46.412238] Minimum overlap selected: (0, 0, 0)\n",
            "[05:51:46.412275] Padding: (10, 10, 10)\n",
            "[05:51:46.538775] Real overlapping (%): (0.11666666666666667, 0.016666666666666666, 0.05)\n",
            "[05:51:46.538909] Real overlapping (pixels): (7.0, 1.0, 3.0)\n",
            "[05:51:46.538953] (3, 18, 13) patches per (z,y,x) axis\n",
            "[05:51:47.380873] **** New data shape is: (702, 80, 80, 80, 1)\n",
            "[05:51:47.381048] ### END 3D-OV-CROP ###\n",
            "[05:51:47.382080] ### 3D-OV-CROP ###\n",
            "[05:51:47.382191] Cropping (165, 768, 1024, 1) images into (80, 80, 80, 1) with overlapping . . .\n",
            "[05:51:47.382241] Minimum overlap selected: (0, 0, 0)\n",
            "[05:51:47.382290] Padding: (10, 10, 10)\n",
            "[05:51:47.470317] Real overlapping (%): (0.11666666666666667, 0.016666666666666666, 0.05)\n",
            "[05:51:47.470484] Real overlapping (pixels): (7.0, 1.0, 3.0)\n",
            "[05:51:47.470555] (3, 18, 13) patches per (z,y,x) axis\n",
            "[05:51:47.962607] **** New data shape is: (702, 80, 80, 80, 1)\n",
            "[05:51:47.963926] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/176 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  1%|          | 1/176 [00:01<04:48,  1.65s/it]\u001b[A\n",
            "  2%|\u258f         | 3/176 [00:01<01:22,  2.09it/s]\u001b[A\n",
            "  3%|\u258e         | 5/176 [00:01<00:45,  3.74it/s]\u001b[A\n",
            "  4%|\u258d         | 7/176 [00:02<00:30,  5.47it/s]\u001b[A\n",
            "  5%|\u258c         | 9/176 [00:02<00:23,  7.20it/s]\u001b[A\n",
            "  6%|\u258b         | 11/176 [00:02<00:18,  8.81it/s]\u001b[A\n",
            "  7%|\u258b         | 13/176 [00:02<00:15, 10.27it/s]\u001b[A\n",
            "  9%|\u258a         | 15/176 [00:02<00:14, 11.40it/s]\u001b[A\n",
            " 10%|\u2589         | 17/176 [00:02<00:12, 12.27it/s]\u001b[A\n",
            " 11%|\u2588         | 19/176 [00:02<00:12, 13.04it/s]\u001b[A\n",
            " 12%|\u2588\u258f        | 21/176 [00:02<00:11, 13.59it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 23/176 [00:03<00:10, 14.00it/s]\u001b[A\n",
            " 14%|\u2588\u258d        | 25/176 [00:03<00:10, 14.06it/s]\u001b[A\n",
            " 15%|\u2588\u258c        | 27/176 [00:03<00:10, 14.23it/s]\u001b[A\n",
            " 16%|\u2588\u258b        | 29/176 [00:03<00:10, 14.50it/s]\u001b[A\n",
            " 18%|\u2588\u258a        | 31/176 [00:03<00:10, 14.43it/s]\u001b[A\n",
            " 19%|\u2588\u2589        | 33/176 [00:03<00:09, 14.55it/s]\u001b[A\n",
            " 20%|\u2588\u2589        | 35/176 [00:03<00:09, 14.59it/s]\u001b[A\n",
            " 21%|\u2588\u2588        | 37/176 [00:04<00:09, 14.69it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 39/176 [00:04<00:09, 14.76it/s]\u001b[A\n",
            " 23%|\u2588\u2588\u258e       | 41/176 [00:04<00:09, 14.79it/s]\u001b[A\n",
            " 24%|\u2588\u2588\u258d       | 43/176 [00:04<00:08, 14.85it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 45/176 [00:04<00:08, 14.85it/s]\u001b[A\n",
            " 27%|\u2588\u2588\u258b       | 47/176 [00:04<00:08, 14.76it/s]\u001b[A\n",
            " 28%|\u2588\u2588\u258a       | 49/176 [00:04<00:08, 14.83it/s]\u001b[A\n",
            " 29%|\u2588\u2588\u2589       | 51/176 [00:05<00:08, 14.87it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 53/176 [00:05<00:08, 14.95it/s]\u001b[A\n",
            " 31%|\u2588\u2588\u2588\u258f      | 55/176 [00:05<00:08, 14.86it/s]\u001b[A\n",
            " 32%|\u2588\u2588\u2588\u258f      | 57/176 [00:05<00:07, 14.88it/s]\u001b[A\n",
            " 34%|\u2588\u2588\u2588\u258e      | 59/176 [00:05<00:07, 14.89it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 61/176 [00:05<00:07, 14.79it/s]\u001b[A\n",
            " 36%|\u2588\u2588\u2588\u258c      | 63/176 [00:05<00:07, 14.73it/s]\u001b[A\n",
            " 37%|\u2588\u2588\u2588\u258b      | 65/176 [00:05<00:07, 14.82it/s]\u001b[A\n",
            " 38%|\u2588\u2588\u2588\u258a      | 67/176 [00:06<00:07, 14.88it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 69/176 [00:06<00:07, 14.83it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2588      | 71/176 [00:06<00:07, 14.58it/s]\u001b[A\n",
            " 41%|\u2588\u2588\u2588\u2588\u258f     | 73/176 [00:06<00:07, 14.62it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 75/176 [00:06<00:06, 14.72it/s]\u001b[A\n",
            " 44%|\u2588\u2588\u2588\u2588\u258d     | 77/176 [00:06<00:06, 14.68it/s]\u001b[A\n",
            " 45%|\u2588\u2588\u2588\u2588\u258d     | 79/176 [00:06<00:06, 14.83it/s]\u001b[A\n",
            " 46%|\u2588\u2588\u2588\u2588\u258c     | 81/176 [00:07<00:06, 14.86it/s]\u001b[A\n",
            " 47%|\u2588\u2588\u2588\u2588\u258b     | 83/176 [00:07<00:06, 14.67it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 85/176 [00:07<00:06, 14.66it/s]\u001b[A\n",
            " 49%|\u2588\u2588\u2588\u2588\u2589     | 87/176 [00:07<00:06, 14.53it/s]\u001b[A\n",
            " 51%|\u2588\u2588\u2588\u2588\u2588     | 89/176 [00:07<00:05, 14.70it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 91/176 [00:07<00:05, 14.79it/s]\u001b[A\n",
            " 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 93/176 [00:07<00:05, 14.81it/s]\u001b[A\n",
            " 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 95/176 [00:08<00:05, 14.79it/s]\u001b[A\n",
            " 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 97/176 [00:08<00:05, 14.83it/s]\u001b[A\n",
            " 56%|\u2588\u2588\u2588\u2588\u2588\u258b    | 99/176 [00:08<00:05, 14.96it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 101/176 [00:08<00:05, 14.80it/s]\u001b[A\n",
            " 59%|\u2588\u2588\u2588\u2588\u2588\u258a    | 103/176 [00:08<00:04, 14.99it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2589    | 105/176 [00:08<00:04, 14.87it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 107/176 [00:08<00:04, 14.79it/s]\u001b[A\n",
            " 62%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 109/176 [00:08<00:04, 14.87it/s]\u001b[A\n",
            " 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 111/176 [00:09<00:04, 14.92it/s]\u001b[A\n",
            " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 113/176 [00:09<00:04, 14.97it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 115/176 [00:09<00:04, 14.98it/s]\u001b[A\n",
            " 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 117/176 [00:09<00:03, 14.93it/s]\u001b[A\n",
            " 68%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 119/176 [00:09<00:03, 14.93it/s]\u001b[A\n",
            " 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 121/176 [00:09<00:03, 14.83it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 123/176 [00:09<00:03, 14.73it/s]\u001b[A\n",
            " 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 125/176 [00:10<00:03, 14.78it/s]\u001b[A\n",
            " 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 127/176 [00:10<00:03, 14.89it/s]\u001b[A\n",
            " 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 129/176 [00:10<00:03, 14.95it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 131/176 [00:10<00:03, 14.99it/s]\u001b[A\n",
            " 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 133/176 [00:10<00:02, 14.47it/s]\u001b[A\n",
            " 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 135/176 [00:10<00:02, 14.46it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 137/176 [00:10<00:02, 14.54it/s]\u001b[A\n",
            " 79%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 139/176 [00:10<00:02, 14.61it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 141/176 [00:11<00:02, 14.50it/s]\u001b[A\n",
            " 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 143/176 [00:11<00:02, 14.37it/s]\u001b[A\n",
            " 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 145/176 [00:11<00:02, 14.10it/s]\u001b[A\n",
            " 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 147/176 [00:11<00:02, 13.97it/s]\u001b[A\n",
            " 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 149/176 [00:11<00:02, 13.34it/s]\u001b[A\n",
            " 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 151/176 [00:11<00:01, 13.33it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 153/176 [00:12<00:01, 13.64it/s]\u001b[A\n",
            " 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 155/176 [00:12<00:01, 13.62it/s]\u001b[A\n",
            " 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 157/176 [00:12<00:01, 13.64it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 159/176 [00:12<00:01, 13.45it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 161/176 [00:12<00:01, 13.42it/s]\u001b[A\n",
            " 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 163/176 [00:12<00:00, 13.01it/s]\u001b[A\n",
            " 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 165/176 [00:12<00:00, 12.81it/s]\u001b[A\n",
            " 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 167/176 [00:13<00:00, 13.08it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 169/176 [00:13<00:00, 13.22it/s]\u001b[A\n",
            " 97%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 171/176 [00:13<00:00, 13.09it/s]\u001b[A\n",
            " 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 173/176 [00:13<00:00, 13.05it/s]\u001b[A\n",
            " 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 175/176 [00:13<00:00, 12.74it/s]\u001b[A\n",
            "                                                 \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:02.385672] ### MERGE-3D-OV-CROP ###\n",
            "[05:52:02.386490] Merging (702, 80, 80, 80, 1) images into (165, 768, 1024, 1) with overlapping . . .\n",
            "[05:52:02.386570] Minimum overlap selected: (0, 0, 0)\n",
            "[05:52:02.386618] Padding: (10, 10, 10)\n",
            "[05:52:02.388876] Real overlapping (%): (0.11666666666666667, 0.016666666666666666, 0.05)\n",
            "[05:52:02.388950] Real overlapping (pixels): (7.0, 1.0, 3.0)\n",
            "[05:52:02.388996] (3, 18, 13) patches per (z,y,x) axis\n",
            "[05:52:06.220542] **** New data shape is: (165, 768, 1024, 1)\n",
            "[05:52:06.220701] ### END MERGE-3D-OV-CROP ###\n",
            "[05:52:06.239088] ### MERGE-3D-OV-CROP ###\n",
            "[05:52:06.239187] Merging (702, 80, 80, 80, 1) images into (165, 768, 1024, 1) with overlapping . . .\n",
            "[05:52:06.239230] Minimum overlap selected: (0, 0, 0)\n",
            "[05:52:06.239279] Padding: (10, 10, 10)\n",
            "[05:52:06.241925] Real overlapping (%): (0.11666666666666667, 0.016666666666666666, 0.05)\n",
            "[05:52:06.242012] Real overlapping (pixels): (7.0, 1.0, 3.0)\n",
            "[05:52:06.242057] (3, 18, 13) patches per (z,y,x) axis\n",
            "[05:52:08.376620] **** New data shape is: (165, 768, 1024, 1)\n",
            "[05:52:08.376757] ### END MERGE-3D-OV-CROP ###\n",
            "[05:52:08.415998] Saving (1, 165, 768, 1024, 1) data as .tif in folder: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:13<00:00, 13.53s/it]\u001b[A\n",
            "                                             \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:23.490002] Saving (1, 165, 768, 1024, 1) data as .tif in folder: /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image_binarized\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.33it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:40<00:00, 40.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:24.015361] Releasing memory . . .\n",
            "[05:52:24.017001] #############\n",
            "[05:52:24.017062] #  RESULTS  #\n",
            "[05:52:24.017107] #############\n",
            "[05:52:24.017167] Epoch number: 30\n",
            "[05:52:24.017205] Train time (s): 0:16:27\n",
            "[05:52:24.017339] Train loss: 0.03821218262116114\n",
            "[05:52:24.017445] Train Foreground IoU: 0.8587936758995056\n",
            "[05:52:24.017491] Validation loss: 0.03509102873504162\n",
            "[05:52:24.017578] Validation Foreground IoU: 0.8663197755813599\n",
            "[05:52:24.017665] Test Foreground IoU (per patch): 0.5922103551780641\n",
            "[05:52:24.017715] Test Foreground IoU (merge patches): 0.8476091623306274\n",
            "[05:52:24.017758]  \n",
            "[05:52:24.017838] FINISHED JOB my_3d_semantic_segmentation_1 !!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play to train the model\n",
        "\n",
        "import os\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# remove template file it is exists\n",
        "template_file = '3d_semantic_segmentation.yaml'\n",
        "if os.path.exists( template_file ):\n",
        "    os.remove( template_file )\n",
        "\n",
        "# Download template file\n",
        "!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/semantic_segmentation/3d_semantic_segmentation.yaml &> /dev/null\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No images found in dir {}\".format(train_data_path))\n",
        "if not os.path.exists(train_data_gt_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_gt_path)\n",
        "ids = sorted(next(os.walk(train_data_gt_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No images found in dir {}\".format(train_data_gt_path))\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No images found in dir {}\".format(test_data_path))\n",
        "if test_ground_truth:\n",
        "    if not os.path.exists(test_data_gt_path):\n",
        "        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_gt_path)\n",
        "    ids = sorted(next(os.walk(test_data_gt_path))[2])\n",
        "    if len(ids) == 0:\n",
        "        raise ValueError(\"No images found in dir {}\".format(test_data_gt_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( template_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['TRAIN']['GT_PATH'] = train_data_gt_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "biapy_config['DATA']['TEST']['GT_PATH'] = test_data_gt_path\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size_z)+', '+str(patch_size_xy)+', '+ str(patch_size_xy)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding_xy = patch_size_xy // 8\n",
        "padding_z = patch_size_z // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding_z)+', '+ str(padding_xy)+', '+ str(padding_xy)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# Data augmentation\n",
        "if aggressive_data_augmentation == True:\n",
        "    biapy_config['AUGMENTOR']['DROPOUT'] = True\n",
        "    biapy_config['AUGMENTOR']['GRIDMASK'] = True\n",
        "    biapy_config['AUGMENTOR']['CUTBLUR'] = True\n",
        "    biapy_config['AUGMENTOR']['CUTNOISE'] = True\n",
        "    biapy_config['AUGMENTOR']['MOTION_BLUR'] = True\n",
        "    #biapy_config['AUGMENTOR']['ELASTIC'] = True\n",
        "    #biapy_config['AUGMENTOR']['CUTOUT'] = True\n",
        "    #biapy_config['AUGMENTOR']['BRIGHTNESS'] = True\n",
        "    #biapy_config['AUGMENTOR']['CONTRAST'] = True\n",
        "\n",
        "# number of segmentation classes\n",
        "biapy_config['MODEL']['N_CLASSES'] = number_of_classes\n",
        "\n",
        "# change source to build model - biapy, torchvision or bmz\n",
        "if changed_source:\n",
        "    if source.value == \"BiaPy\":\n",
        "        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "    elif source.value == 'Torchvision':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"torchvision\"\n",
        "        biapy_config['MODEL']['TORCHVISION_MODEL_NAME'] = t_vision.value\n",
        "    elif source.value == 'BioImage Model Zoo':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n",
        "        biapy_config['MODEL']['BMZ'] = {}\n",
        "        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_ID'] = str(bmz.value).strip()\n",
        "else:\n",
        "    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"U-Net\", \"Residual U-Net\", \"Attention U-Net\",\n",
        "# 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\",\"UNETR-Small\"\n",
        "# \"UNETR-Base\"\n",
        "architecture = 'unet'\n",
        "if model_architecture == \"U-Net\":\n",
        "    architecture = 'unet'\n",
        "elif model_architecture == \"Residual U-Net\":\n",
        "    architecture = 'resunet'\n",
        "elif model_architecture == \"Attention U-Net\":\n",
        "    architecture = 'attention_unet'\n",
        "elif model_architecture == \"MultiResUNet\":\n",
        "    architecture = 'multiresunet'\n",
        "elif model_architecture == \"SEUNet\":\n",
        "    architecture = 'seunet'\n",
        "elif model_architecture == \"ResUNet++\":\n",
        "    architecture = 'resunet++'\n",
        "elif model_architecture == \"UNETR-Mini\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 64\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 4\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4.\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 4\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 1\n",
        "    biapy_config['MODEL']['UNETR_VIT_NUM_FILTERS'] = 32\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "elif model_architecture == \"UNETR-Small\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 128\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 8\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4.\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 8\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 2\n",
        "    biapy_config['MODEL']['UNETR_VIT_NUM_FILTERS'] = 32\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "elif model_architecture == \"UNETR-Base\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 384\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 12\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4.\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 12\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 3\n",
        "    biapy_config['MODEL']['UNETR_VIT_NUM_FILTERS'] = 32\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "else: # U-NeXt V1\n",
        "    architecture = 'unext_v1'\n",
        "    biapy_config['MODEL']['FEATURE_MAPS'] = \"[16, 32, 64, 128]\"\n",
        "    biapy_config['MODEL']['CONVNEXT_LAYERS'] = \"[1, 1, 1, 1]\"\n",
        "    biapy_config['MODEL']['CONVNEXT_STEM_K_SIZE'] = 1\n",
        "\n",
        "\n",
        "# learning rate scheduler\n",
        "if learning_rate_scheduler == 'One cycle':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'onecycle'\n",
        "elif learning_rate_scheduler == 'Warm-up cosine decay':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'warmupcosine'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.0\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['WARMUP_COSINE_DECAY_EPOCHS'] = 0\n",
        "elif learning_rate_scheduler == 'Reduce on plateau':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'reduceonplateau'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_FACTOR'] = 0.5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_PATIENCE'] = 5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.00001\n",
        "\n",
        "\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "if anisotropic_data == True:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [1 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "else:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [2 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "\n",
        "# update test parameters\n",
        "biapy_config['TEST']['FULL_IMG'] = False\n",
        "biapy_config['TEST']['AUGMENTATION'] = test_time_augmentation\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "biapy_config['TEST']['ENABLE'] = True\n",
        "biapy_config['TEST']['REDUCE_MEMORY'] = True\n",
        "\n",
        "# model weights\n",
        "if checkpoint_path != '':\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4i0N2vOWUes"
      },
      "source": [
        "## **Inspection of the Loss Function and the Intersection over Union (IoU)**\n",
        "---\n",
        "\n",
        "Before proceeding with interpretations, it's pivotal to gauge the training evolution by juxtaposing the training loss against the validation loss. The validation loss casts light on the model's efficacy over a reserved subset of data unseen during training. A deeper understanding can be garnered from [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n",
        "\n",
        "- **Training Loss**: This captures the discrepancy between the model's predictions and the actual ground-truth after each epoch.\n",
        "\n",
        "- **Validation Loss**: This signifies the error between the model's estimates on validation images and their actual counterparts.\n",
        "\n",
        "As training unfurls, these metrics are expected to wane, eventually plateauing at an optimal, minimal value. Contrasting the trajectories of these losses can yield vital information about the model's adaptability.\n",
        "\n",
        "- **Decreasing Training and Validation Losses**: This trend is indicative of potential model improvements with further training. Elevating the `number_of_epochs` is advised in such scenarios. Notably, even if the loss curves seem to stabilize towards the tail end, it might be a mere visual effect due to y-axis scaling. The model is considered convergent once the curves genuinely flatten, marking the end of required training.\n",
        "\n",
        "- **Divergent Losses**: An upward tick in validation loss while training loss gravitates towards zero hints at overfitting. It suggests that the model is intricately memorizing training patterns at the cost of broader applicability. A more substantial training dataset can alleviate this.\n",
        "\n",
        "The **Jaccard Index, also known as the Intersection over Union (IoU)**, offers a means to evaluate the overlap between the target mask and prediction. **A score inching towards 1 denotes optimal performance.** It's a handy metric to gauge the precision of your model in predicting cellular structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ur21krhZVwX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725256345482,
          "user_tz": -120,
          "elapsed": 963,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "90e5954e-59fb-4687-8623-dbcbc0cb49e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play the cell to show a plot of training error vs. epoch number and IoU vs epoch number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n",
        "\n",
        "iou_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_IoU.png' )\n",
        "\n",
        "fig = plt.figure( figsize = (20,10))\n",
        "ax1 = plt.subplot( 1, 2, 1 )\n",
        "_ = plt.imshow( loss_plot )\n",
        "_ = plt.axis('off')\n",
        "ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n",
        "\n",
        "ax2 = plt.subplot( 1, 2, 2 )\n",
        "_ = plt.imshow( iou_plot )\n",
        "_ = plt.axis('off')\n",
        "_= ax2.set_title( 'Intersection over Union (IoU) vs epoch number', fontdict = {'fontsize':22})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30kYCWjYI9W1"
      },
      "source": [
        "## **Visualize semantic segmentation results (from the test set)**\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326,
          "referenced_widgets": [
            "54eebc86280149aa93776c3e5c629773",
            "c918feb625a848bda59f11fcf38c228f",
            "ae948c2f8d4c4052995ee93c622edf9d",
            "68a82e39ce2c4c75bb777b00bb287083",
            "0d5516a2dede4a8d8d1fec370caf3c12",
            "abd2f630146d404c86f2a26d4b4bc31f",
            "5773f0f58b0c45d3872c3287c9524c10"
          ]
        },
        "executionInfo": {
          "elapsed": 2037,
          "status": "ok",
          "timestamp": 1725257504601,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          },
          "user_tz": -120
        },
        "id": "DFPUsjCUNgNl",
        "outputId": "399dd2a8-d60f-47ff-a331-bca7c7d32fe7",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=82, description='z', max=165, min=1), Output()), _dom_classes=('widget-i\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54eebc86280149aa93776c3e5c629773"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "#@markdown ###Play to visualize results from the test set\n",
        "#@markdown The results will be shown as browsable 2D stacks displaying:\n",
        "#@markdown 1. The original **Source** image.\n",
        "#@markdown 2. Its corresponding **Ground truth** image.\n",
        "#@markdown 3. The **Prediction** masks of the model.\n",
        "#@markdown 4. An **Overlay** of the ground truth and the predicted masks.\n",
        "\n",
        "#@markdown Move the Z-scroll to navigate among slices.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from numpy.random import randint, seed\n",
        "from matplotlib import pyplot as plt\n",
        "from ipywidgets import interact, fixed\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "semantic_results = os.path.join(final_results, \"per_image_binarized\")\n",
        "\n",
        "# Show a few examples to check that they have been stored correctly\n",
        "\n",
        "try:\n",
        "    ids_pred = sorted(next(os.walk(semantic_results))[2])\n",
        "except StopIteration:\n",
        "    print(f\"No files found in directory: {semantic_results}\")\n",
        "    ids_pred = []\n",
        "\n",
        "ids_input = sorted(next(os.walk(test_data_path))[2])\n",
        "ids_gt = sorted(next(os.walk(test_data_gt_path))[2])\n",
        "\n",
        "samples_to_show = min(len(ids_input), 3)\n",
        "\n",
        "chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n",
        "seed(1)\n",
        "\n",
        "test_samples = []\n",
        "test_sample_preds = []\n",
        "test_sample_gt = []\n",
        "\n",
        "# read 3D images again\n",
        "for i in range(len(chosen_images)):\n",
        "    aux = imread(os.path.join(test_data_path, ids_input[chosen_images[i]]))\n",
        "    test_samples.append(aux)\n",
        "\n",
        "    if ids_pred:  # Check if ids_pred is not empty\n",
        "        aux = imread(os.path.join(semantic_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n",
        "        test_sample_preds.append(aux)\n",
        "    else:\n",
        "        print(\"ids_pred list is empty. Can't read image.\")\n",
        "\n",
        "    aux = imread(os.path.join(test_data_gt_path, ids_gt[chosen_images[i]])).astype(np.uint16)\n",
        "    test_sample_gt.append(aux)\n",
        "\n",
        "# function to show results in 3D within a widget\n",
        "def scroll_in_z(z, j):\n",
        "    plt.figure(figsize=(25,5))\n",
        "    # Source\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_samples[j][z-1], cmap='gray')\n",
        "    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Target (Ground-truth)\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_sample_gt[j][z-1], interpolation='nearest')\n",
        "    plt.title('Ground truth (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Only plot prediction and overlay if there is a prediction\n",
        "    if test_sample_preds:  # if list is not empty\n",
        "        # Prediction\n",
        "        plt.subplot(1,4,3)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_preds[j][z-1],  interpolation='nearest')\n",
        "        plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        # Overlay\n",
        "        plt.subplot(1,4,4)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_gt[j][z-1], cmap='Greens')\n",
        "        plt.imshow(test_sample_preds[j][z-1], alpha=0.5, cmap='Purples')\n",
        "        plt.title('Overlay (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No predictions available.\")\n",
        "\n",
        "\n",
        "for s in range(samples_to_show):\n",
        "    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_sample_gt[s].shape[0], step=1, value=test_sample_gt[s].shape[0]//2), j=fixed(s));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mlQnAH6uAawl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725256347052,
          "user_tz": -120,
          "elapsed": 6,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "6721773f-e42f-4ad2-a059-53407c9927a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[05:52:25.923547] Output paths:\n",
            "[05:52:25.925856]     Semantic segmentation files are in /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image_binarized\n",
            "[05:52:25.926891]     Semantic probability files are in /content/output/my_3d_semantic_segmentation/results/my_3d_semantic_segmentation_1/per_image\n"
          ]
        }
      ],
      "source": [
        "#@markdown ###Play to display the paths to the output files (one 3D TIFF label image for each input image).\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "if biapy_config['TEST']['FULL_IMG'] == True:\n",
        "    semantic_results = os.path.join(final_results, \"full_image_binarized\")\n",
        "    prob_results = os.path.join(final_results, \"full_image\")\n",
        "else:\n",
        "    semantic_results = os.path.join(final_results, \"per_image_binarized\")\n",
        "    prob_results = os.path.join(final_results, \"per_image\")\n",
        "print(\"Output paths:\")\n",
        "print(\"    Semantic segmentation files are in {}\".format(semantic_results))\n",
        "print(\"    Semantic probability files are in {}\".format(prob_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdCIYo4ohcAw"
      },
      "source": [
        "## **Download semantic segmentation results**\n",
        "___"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gnRa9DOUP0FM",
        "outputId": "25f5ba0b-43eb-4e54-ef53-a269d525af71"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4e6f365c-5af5-45c3-ab1e-cc246d80fdf1\", \"semantic_segmentation_results.zip\", 1666844)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download a zip file with all semantic segmentation results in test.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!zip -q -j /content/semantic_segmentation_results.zip $semantic_results/*.tif\n",
        "\n",
        "files.download(\"/content/semantic_segmentation_results.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwt72WYddVgl"
      },
      "source": [
        "## **Download train model (weights and configuration file)**\n",
        "___\n",
        "If you want to **reuse the train model in the future**, you can download both the model weights and its configuration file (.YAML) by running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XoFclBfEduZC"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "#@markdown ###Play to download the model weights\n",
        "\n",
        "checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n",
        "\n",
        "weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n",
        "\n",
        "files.download( os.path.join( checkpoints_path, weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "raDdSsz1dujE",
        "outputId": "2ca2e938-cf0b-499f-8872-21a50a471b08",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1719322208092,
          "user_tz": -120,
          "elapsed": 522,
          "user": {
            "displayName": "Ane Paniagua",
            "userId": "02091107795241666186"
          }
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be5d1861-ba2e-459e-8840-6dd73d6100c7\", \"my_3d_semantic_segmentation.yaml\", 876)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ###Play to download the model configuration file (.YAML)\n",
        "from google.colab import files\n",
        "config_path = os.path.join(output_path, job_name, 'config_files')\n",
        "\n",
        "files.download( os.path.join( config_path, yaml_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB681CtYmlw-"
      },
      "source": [
        "## **Export your model to BioImage Model Zoo format**\n",
        "___\n",
        "If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWHr_sQK_-qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##Construct model's metadata to export it to the BioImage Model Zoo format. Choose just one option:\n",
        "\n",
        "#@markdown **Option 1: Reuse previous BioImage Model Zoo model configuration**\n",
        "\n",
        "#@markdown With this option, if you were using a model from BioImage Model Zoo you can select this option to reuse its configuration instead of provide all fields manually. If that's not the case and you try to use this option an error will be thrown.\n",
        "reuse_previous_BMZ_model_config = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Option 2: Manual export fields**\n",
        "\n",
        "#@markdown With this option you need to introduce manually the metadata of the model.\n",
        "\n",
        "# ------------- User input ------------\n",
        "# information about the model\n",
        "trained_model_name    = \"\" #@param {type:\"string\"}\n",
        "trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n",
        "trained_model_authors_github_user =  \"[First Author Github User, Second Author Github User, Third Author Github User]\" #@param {type:\"string\"}\n",
        "trained_model_description = \"\" #@param {type:\"string\"}\n",
        "trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n",
        "trained_model_references = [\"Ronneberger et al. arXiv in 2015\", \"Franco-Barranco, Daniel, et al. ISBI in 2023\"] #@param {type:\"string\"}\n",
        "trained_model_references_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n",
        "trained_model_tags = \"[\\\"tag-1\\\", \\\"tag-2\\\"]\" #@param {type:\"string\"}\n",
        "trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KH8UuC_CgpH2"
      },
      "outputs": [],
      "source": [
        "# @markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "bmz_results = os.path.join(final_results, \"bmz_model\")\n",
        "\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "\n",
        "    # create the author spec input\n",
        "    auth_names = trained_model_authors[1:-1].split(\",\")\n",
        "    auth_githubusers = trained_model_authors_github_user[1:-1].split(\",\")\n",
        "    assert len(auth_names) == len(auth_githubusers)\n",
        "    authors = [{\"name\": auth_name, \"github_user\": auth_guser} for auth_name, auth_guser in zip(auth_names, auth_githubusers)]\n",
        "\n",
        "    # create the citation input spec\n",
        "    assert len(trained_model_references_DOI) == len(trained_model_references)\n",
        "    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_references_DOI)]\n",
        "\n",
        "    tags = [t for t in trained_model_tags.split(\",\")]\n",
        "\n",
        "    with open(trained_model_documentation, \"w\") as f:\n",
        "        f.write(\"### **Description**\\n\")\n",
        "        f.write(f\"{trained_model_description}\\n\\n\")\n",
        "        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n",
        "\n",
        "    bmz_cfg = {}\n",
        "    # Description of the model\n",
        "    bmz_cfg['description'] = trained_model_description\n",
        "    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Daniel\", \"github_user\": \"danifranco\"}]\n",
        "    bmz_cfg['authors'] = authors\n",
        "    # License of the model. E.g. \"CC-BY-4.0\"\n",
        "    bmz_cfg['license'] = trained_model_license\n",
        "    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n",
        "    bmz_cfg['tags'] = tags\n",
        "    # Tags to make models more findable on the website, e.g. tags=[\"electron-microscopy\", \"mitochondria\"]\n",
        "    bmz_cfg['cite'] = citations\n",
        "    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n",
        "    bmz_cfg['doc'] = trained_model_documentation\n",
        "    # Name of the model\n",
        "    bmz_cfg[\"model_name\"] = trained_model_name\n",
        "    biapy.export_model_to_bmz(bmz_results, bmz_cfg)\n",
        "else:\n",
        "    try:\n",
        "        biapy.export_model_to_bmz(bmz_results, reuse_original_bmz_config=True)\n",
        "    except:\n",
        "        print(\"Seems that the was a problem reusing BMZ model specs. Please uncheck 'reuse_previous_BMZ_model_config' and do it manually\")\n",
        "\n",
        "download = True\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "    bmz_zip_path = f\"/{bmz_results}/{trained_model_name}.zip\"\n",
        "else:\n",
        "    ids = sorted(next(os.walk(bmz_results))[2])\n",
        "    ids = [x for x in ids if x.endswith(\".zip\")]\n",
        "    if len(ids) > 1:\n",
        "        print(f\"There are more than one ZIP files in {bmz_results} folder. Please check which one you want you want to download and do it manually.\")\n",
        "        download = False\n",
        "    elif len(ids) == 0:\n",
        "        print(f\"BMZ zip file could not be found.\")\n",
        "        download = False\n",
        "    else: # only one zip\n",
        "        ids = ids[0]\n",
        "    bmz_zip_path = f\"/{bmz_results}/{ids}\"\n",
        "\n",
        "if download and os.path.exists(bmz_zip_path):\n",
        "    files.download(bmz_zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How to use the trained model with new data**\n",
        "---\n",
        "To directly infer new data to the trained model, you can use [this notebook](https://github.com/BiaPyX/BiaPy/blob/master/notebooks/BiaPy_Inference.ipynb). It will be necessary to upload the downloaded YAML configuration file and model weights to that notebook."
      ],
      "metadata": {
        "id": "PFVjWbF8GZ2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjSgLwe0x-P0"
      },
      "source": [
        "## **Acknowledgments**\n",
        "___\n",
        "We extend our gratitude to the [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki) for their invaluable inspiration. Notably, we have adopted some of their descriptions concerning metrics and parameters."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "https://github.com/BiaPyX/BiaPy/blob/master/notebooks/semantic_segmentation/BiaPy_3D_Semantic_Segmentation.ipynb",
          "timestamp": 1718359716189
        }
      ],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}