{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAryclxsQJ5"
      },
      "source": [
        "# **3D Self supervision pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook we show how to apply a [BiaPy](https://biapyx.github.io/) pipeline for **3D self supervision** of microscopy data.\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "    <table>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/1.png' width='100px'/>\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/2.png' width='100px'/>\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/3.png' width='100px'/>\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/4.png' width='100px'/>\n",
        "        </td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/1m.png' width='100px'/>\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/2m.png' width='100px'/>\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/3m.png' width='100px'/>\n",
        "        </td>\n",
        "        <td>\n",
        "            <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/self-supervised/4m.png' width='100px'/>\n",
        "        </td>\n",
        "    </table>\n",
        "    <figcaption>Illustrative demonstration of a 3D Self-supervised problem. The images presented in the first row correspond to different slices of the 3D electron microscopy image. In the second row each masked version using 'masking' pretext task.</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "**Without any coding**, we explain step by step how to\n",
        "1. **upload a set of training and test images** without any label, as this is unsupervised,\n",
        "2. **train a deep neural network (DNN)** model on the training set,\n",
        "3. **apply the model** to the test images, and\n",
        "4. **download the model's weigths** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired in the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus), [Lenka Backov\u00e1](mailto:lenka.backova@ehu.eus), [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org) and [Ane Paniagua](mailto:anepaniagua@gmail.com). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5ClE_HHQaE"
      },
      "source": [
        "## **Expected inputs and outputs**\n",
        "___\n",
        "**Inputs**\n",
        "\n",
        "This notebook expects two folders as input:\n",
        "* **Training raw images**: with the raw 3D images to train the model.\n",
        "* **Output folder**: a path to store the workflow results.\n",
        "\n",
        "**Outputs**\n",
        "\n",
        "If the execution is successful, a folder will be created containing the workflow results.\n",
        "\n",
        "<font color='red'><b>Note</b></font>: for testing purposes, you can also run this notebook with the **example datasets provided in 'Manage file(s) source > Option 3'**.\n",
        "\n",
        "**Data structure**\n",
        "\n",
        "To ensure the proper operation of the library the data directory tree should be something like this:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "\u2514\u2500\u2500 train\n",
        "    \u251c\u2500\u2500 training-0001.tif\n",
        "    \u251c\u2500\u2500 training-0002.tif\n",
        "    \u251c\u2500\u2500 . . .\n",
        "    \u2514\u2500\u2500 training-9999.tif\n",
        "\n",
        "```\n",
        "\n",
        "**Input Format Support**\n",
        "\n",
        "This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.npy` (every extension for 3D images supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGSj0DrpUJoY"
      },
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bj_sbDFTiZ7"
      },
      "source": [
        "\n",
        "## **Check for GPU access**\n",
        "---\n",
        "\n",
        "By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n",
        "\n",
        "Go to **Runtime -> Change the Runtime type**\n",
        "\n",
        "**Runtime type: Python 3** *(Python 3 is programming language in which this program is written)*\n",
        "\n",
        "**Accelerator: GPU** *(Graphics processing unit)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW5hZPtfDmN-"
      },
      "source": [
        "## **Install BiaPy**\n",
        "---\n",
        "This might take some minutes depending on the current installed libraries in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1742987930340,
          "user_tz": -60,
          "elapsed": 217914,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "4dab9c0f-6c01-4eed-ef98-547d2492a139",
        "cellView": "form",
        "id": "ydf_LplrDmOC"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biapy==3.5.12\n",
            "  Downloading biapy-3.5.12-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.6.1)\n",
            "Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.0.4)\n",
            "Collecting yacs>=0.1.8 (from biapy==3.5.12)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (0.25.2)\n",
            "Collecting edt>=2.3.2 (from biapy==3.5.12)\n",
            "  Downloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting fill-voids>=2.0.6 (from biapy==3.5.12)\n",
            "  Downloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.76 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.2.2)\n",
            "Collecting torchinfo>=1.8.0 (from biapy==3.5.12)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.6.2.2 (from biapy==3.5.12)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: h5py>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.13.0)\n",
            "Requirement already satisfied: zarr>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.18.4)\n",
            "Collecting bioimageio.core==0.7.0 (from biapy==3.5.12)\n",
            "  Downloading bioimageio.core-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting imagecodecs>=2024.1.1 (from biapy==3.5.12)\n",
            "  Downloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.26.4)\n",
            "Collecting imgaug>=0.4.0 (from biapy==3.5.12)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pooch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.8.2)\n",
            "Collecting diplib>=3.5.1 (from biapy==3.5.12)\n",
            "  Downloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting pydantic<2.10,>=2.7.0 (from biapy==3.5.12)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray==2025.1.* in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2025.1.2)\n",
            "Collecting bioimageio.spec==0.5.3.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading bioimageio.spec-0.5.3.5-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: imageio>=2.10 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.37.0)\n",
            "Collecting loguru (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic-settings>=2.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.32.3)\n",
            "Collecting ruyaml (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading ruyaml-0.91.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (4.12.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray==2025.1.*->biapy==3.5.12) (24.2)\n",
            "Requirement already satisfied: annotated-types<1,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.7.0)\n",
            "Collecting email-validator (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.8.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (13.9.4)\n",
            "Requirement already satisfied: tifffile>=2020.7.4 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2025.3.13)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.21.0)\n",
            "Collecting fastremap (from fill-voids>=2.0.6->biapy==3.5.12)\n",
            "  Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (11.1.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (2.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.8.1->biapy==3.5.12) (4.3.7)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<2.10,>=2.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (3.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.5.12) (5.29.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8->biapy==3.5.12) (6.0.2)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.3.3)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.19)\n",
            "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.15.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.2.18)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2025.1.31)\n",
            "Requirement already satisfied: distro>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=39.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (75.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.1.2)\n",
            "Downloading biapy-3.5.12-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.core-0.7.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.spec-0.5.3.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruyaml-0.91.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yacs, torchinfo, tensorboardX, ruyaml, python-dotenv, pydantic-core, loguru, imagecodecs, fastremap, edt, dnspython, diplib, pydantic, fill-voids, email-validator, pydantic-settings, imgaug, bioimageio.spec, bioimageio.core, biapy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "Successfully installed biapy-3.5.12 bioimageio.core-0.7.0 bioimageio.spec-0.5.3.5 diplib-3.5.2 dnspython-2.7.0 edt-3.0.0 email-validator-2.2.0 fastremap-1.15.1 fill-voids-2.0.8 imagecodecs-2024.12.30 imgaug-0.4.0 loguru-0.7.3 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.8.1 python-dotenv-1.1.0 ruyaml-0.91.0 tensorboardX-2.6.2.2 torchinfo-1.8.0 yacs-0.1.8\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting torchmetrics==1.4.* (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (24.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.4.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (0.19.0+cu118)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.86)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-msssim, torch-fidelity\n",
            "Successfully installed lightning-utilities-0.14.2 pytorch-msssim-1.0.0 torch-fidelity-0.3.0 torchmetrics-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "!pip install git+https://www.github.com/BiaPyX/BiaPy.git\n",
        "\n",
        "# Then install Pytorch + CUDA 11.8\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Finally install some packages that rely on the Pytorch installation\n",
        "!pip install timm pytorch-msssim torchmetrics[image]==1.4.*\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "from biapy import BiaPy\n",
        "\n",
        "changed_source = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZmI9c09OhSo"
      },
      "source": [
        "## **Manage file(s) source**\n",
        "---\n",
        "The input folder can be provided using three different options: by directly uploading the folder (option 1), by using a folder stored in Google Drive (option 2) or by using a few samples of our data (option 3).\n",
        "\n",
        "Depending on the option chosen, different steps will have to be taken, as explained in the following cells.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPksHcHLO0SU"
      },
      "source": [
        "### **Option 1: Upload Local Files to the Notebook**\n",
        "---\n",
        "You will be prompted to upload your files to Colab and they will be stored under `/content/input/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xGS5LCaHPWR8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train raw images)\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/x\n",
        "%cd /content/input/train/x\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXGd55gUYjK"
      },
      "source": [
        "### **Option 2: Mount Your Google Drive**\n",
        "---\n",
        "To use this notebook on your own data from Google Drive, you need to mount Google Drive first.\n",
        "\n",
        "Play the cell below to mount your Google Drive and follow the link that will be shown. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive.\n",
        "\n",
        "Once this is done, your data are available in the **Files** tab on the top left of notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h-yXrZLdUk3Z"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL.\n",
        "\n",
        "#@markdown * Sign in your Google Account.\n",
        "\n",
        "#@markdown * Copy the authorization code.\n",
        "\n",
        "#@markdown * Enter the authorization code.\n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9FcxFB3H7az"
      },
      "source": [
        "### **Option 3: Download an Example Dataset**\n",
        "---\n",
        "If you do not have data at hand but would like to test the notebook, no worries! You can run the following cell to download an example dataset.\n",
        "\n",
        "In particular, we will use the [Electron Microscopy Dataset (EPFL - CVLAB)](https://www.epfl.ch/labs/cvlab/data/data-em/) publicly available online."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 21640,
          "status": "ok",
          "timestamp": 1745844506811,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          },
          "user_tz": -120
        },
        "id": "pD3aoo-ZUtW4",
        "outputId": "6a576eb3-6a56-46d0-8b7b-57979576a211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "!pip install gdown==5.1.0 --quiet\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "gdown.download(\"https://drive.google.com/uc?id=10Cf11PtERq4pDHCJroekxu_hf10EZzwG\", \"fibsem_epfl.zip\", quiet=True)\n",
        "\n",
        "!unzip -q fibsem_epfl.zip\n",
        "!rm fibsem_epfl.zip\n",
        "\n",
        "print( 'Dataset downloaded and unzipped under /content/data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEv7FBXFQvjv"
      },
      "source": [
        "## **Paths for Input Images and Output Files**\n",
        "___\n",
        "\n",
        "Depending on the option you chose for managing file sources, you'll set your paths differently:\n",
        "\n",
        "- **Option 1 (Upload from Local Machine)**:\n",
        "  - Set `train_data_path` to `/content/input/train`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "- **Option 2 (Use Google Drive Data)**:\n",
        "  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n",
        "  \n",
        "- **Option 3 (Use Our Sample Data)**:\n",
        "  - Set `train_data_path` to `/content/data/train/raw`\n",
        "  - Set `output_path` to `/content/out`\n",
        "\n",
        "  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n",
        "\n",
        "**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vl4e0UIGYZcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1745844506850,
          "user_tz": -120,
          "elapsed": 30,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "ae409485-4e0f-4762-d395-1e249e1b0c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 1\n"
          ]
        }
      ],
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train/raw' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def count_image_files(directory):\n",
        "    if not directory or not os.path.exists(directory):\n",
        "        return 0\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.tif', '.npy', '.tiff', '.h5', '.hd5', '.zarr'}\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in image_extensions:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "num_train_images = count_image_files(train_data_path)\n",
        "print(f\"Number of training images: {num_train_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "3ZhghE6YjhPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## Play to visualize some data samples\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread\n",
        "import os\n",
        "from ipywidgets import interact, IntSlider, Layout, Dropdown, HBox, Output\n",
        "\n",
        "# Initialize global attributes\n",
        "input_path = train_data_path\n",
        "\n",
        "instance_id = 0\n",
        "\n",
        "ids_input = sorted(next(os.walk(input_path))[2])\n",
        "input_img = imread(os.path.join(input_path, ids_input[0]))\n",
        "\n",
        "# Initialize widgets\n",
        "\n",
        "# Slider widget to choose instance\n",
        "slider= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(ids_input),\n",
        "    step=1,\n",
        "    description='Image index:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "slider.style.description_width = 'initial'\n",
        "slider.style.handle_color='blue'\n",
        "\n",
        "# Slider widget to choose Z value\n",
        "sliderZ= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(input_img),\n",
        "    step=1,\n",
        "    description='Z value:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "sliderZ.style.description_width = 'initial'\n",
        "sliderZ.style.handle_color='blue'\n",
        "\n",
        "# Initialize Output instance to handle code output cell\n",
        "output = Output()\n",
        "\n",
        "# Function to update image (input_img, instance_id) depending on slider value\n",
        "def update_id(change):\n",
        "    index = change['new']\n",
        "\n",
        "    global instance_id\n",
        "    instance_id = index - 1\n",
        "\n",
        "    global input_path, ids_input\n",
        "    input_img_path = os.path.join(input_path, ids_input[instance_id])\n",
        "\n",
        "    global input_img\n",
        "    input_img = imread(input_img_path)\n",
        "\n",
        "    sliderZ.value = 1\n",
        "    sliderZ.max = len(input_img)\n",
        "    display_images({'new': 1})\n",
        "\n",
        "# Function to display images depending on sliderZ value\n",
        "def display_images(change):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "        index = change['new']\n",
        "\n",
        "        global input_img, gt_img, instance_id\n",
        "\n",
        "        # # Print sample path to ensure the image displayed is correct\n",
        "        # global input_path, ids_input\n",
        "        # print(\"Image path:\")\n",
        "        # print(os.path.join(input_path, ids_input[instance_id]))\n",
        "\n",
        "        # Display images\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f\"Input image: {instance_id+1}, Z: {index}\")\n",
        "        plt.imshow(input_img[index-1], cmap='gray')\n",
        "        # plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Create an HBox to hold the dropdown and slider\n",
        "controls = HBox([slider, sliderZ])\n",
        "display(controls, output)\n",
        "\n",
        "# Link widgets to functions\n",
        "slider.observe(update_id, names='value')\n",
        "sliderZ.observe(display_images, names='value')\n",
        "\n",
        "# Initial display\n",
        "display_images({'new': slider.value})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428,
          "referenced_widgets": [
            "a89a0efcd81f4136a4d8e46f9cc4b8b9",
            "1f46a3d0b686417aa11f0bc67aef5285",
            "33630e6485054a0a8ef69b3916cd40ac",
            "80b732a795c74f22a5a39b28cc5888b0",
            "766dfed68b7e462ba46b8c31c7f0c692",
            "dbb0c0ca6a0b4c2a8c8d7b81665c3373",
            "917b3547ca3644e5b57ce7167c1d763d",
            "0b6ac80e4c024d2da94346a5763ca5b4",
            "6acb84cb35af471ab10be11c11437fb5",
            "ecb248e15be845ce96b2f2d62407a7a3"
          ]
        },
        "cellView": "form",
        "id": "F77xEy4l64Yn",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724746459047,
          "user_tz": -120,
          "elapsed": 2175,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "79c0d11c-933b-40bf-9000-eb2a96b00ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntSlider(value=1, continuous_update=False, description='Image index:', layout=Layout(margin='0\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a89a0efcd81f4136a4d8e46f9cc4b8b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6acb84cb35af471ab10be11c11437fb5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZwoZC20rK42"
      },
      "source": [
        "## **Configure and train the DNN model**\n",
        "___\n",
        "In this workflow, any of the models implemented in [BiaPy](https://biapy.readthedocs.io/en/latest/) can be used. In this notebook we configure the networks of semantic/instance segmentation.\n",
        "\n",
        "The idea of this workflow is to pretrain the backbone model by solving a so-called pretext task without labels. This way, the model learns a representation that can be later transferred to solve a downstream task in a labeled (but smaller) dataset. In BiaPy we adopt two pretext tasks that you will need to choose with **pretext_task** variable below. The pretext tasks implemented in BiaPy are these:\n",
        "\n",
        "* 'crappify': To recover a worstened version of the input image as in (see [Franco-Barranco et al., 2022](https://www.sciencedirect.com/science/article/pii/S0169260722003315)).\n",
        "* 'masking': Random patches of the input image are masked and the network needs to reconstruct the missing pixels (see [He et al., 2022](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf)).\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1727170079019,
          "user_tz": -120,
          "elapsed": 48903,
          "user": {
            "displayName": "Daniel Franco-Barranco",
            "userId": "13463799105703234009"
          }
        },
        "outputId": "1c5686aa-d97c-4c3a-e476-9783994e0517",
        "cellView": "form",
        "id": "daGtIo-V_Ydt"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ###OPTIONAL: Check BioImage Model Zoo (BMZ) models compatible with BiaPy\n",
        "# @markdown Use this option to generate a full list of the available BiaPy-compatible models in the BMZ.\n",
        "\n",
        "# @markdown **Important:** To select one of the listed models (if any), you will have to run the next cell and select \"BioImage Model Zoo\" as the source of the model. Then, paste the corresponding model's nickname into the created field.\n",
        "# @markdown <div><img src=\"https://bioimage.io/static/img/bioimage-io-logo.svg\" width=\"600\"/></div>\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pooch\n",
        "import yaml\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "from biapy.models import check_bmz_model_compatibility\n",
        "from packaging.version import Version\n",
        "from typing import Optional, Dict, Tuple, List, Literal\n",
        "\n",
        "# Change pooch verbosity\n",
        "logger = pooch.get_logger()\n",
        "logger.setLevel(\"WARNING\")\n",
        "\n",
        "# Extracted from BiaPy-GUI.\n",
        "# Adapted from BiaPy commit: 284ec3838766392c9a333ac9d27b55816a267bb9 (3.5.2)\n",
        "def check_model_restrictions(\n",
        "    model_rdf,\n",
        "    workflow_specs,\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks model restrictions to be applied into the current configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_rdf : dict\n",
        "        BMZ model RDF that contains all the information of the model.\n",
        "\n",
        "    workflow_specs : dict\n",
        "        Specifications of the workflow. If not provided all possible models will be considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    option_list: dict\n",
        "        Variables and values to change in current configuration. These changes\n",
        "        are imposed by the selected model.\n",
        "    \"\"\"\n",
        "    specific_workflow = workflow_specs[\"workflow_type\"]\n",
        "\n",
        "    # Version of the model\n",
        "    model_version = Version(model_rdf[\"format_version\"])\n",
        "    opts = {}\n",
        "\n",
        "    # 1) Change PATCH_SIZE with the one stored in the model description. This differs from the code of BiaPy where\n",
        "    # get_test_inputs() is simply used as there a ModelDescr is build out of the RDF. Here we try to do it manually\n",
        "    # to avoid fetching files using the network as it may be slow.\n",
        "    input_image_shape = []\n",
        "    if \"shape\" in model_rdf[\"inputs\"][0]:\n",
        "        input_image_shape = model_rdf[\"inputs\"][0][\"shape\"]\n",
        "        # \"CebraNET Cellular Membranes in Volume SEM\" ('format_version': '0.4.10')\n",
        "        #   have: {'min': [1, 1, 64, 64, 64], 'step': [0, 0, 16, 16, 16]}\n",
        "        if isinstance(input_image_shape, dict) and \"min\" in input_image_shape:\n",
        "            input_image_shape = input_image_shape[\"min\"]\n",
        "    else:\n",
        "        # Check axes and dimension\n",
        "        input_image_shape = []\n",
        "        for axis in model_rdf[\"inputs\"][0][\"axes\"]:\n",
        "            if 'type' in axis:\n",
        "                if axis['type'] == \"batch\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif axis['type'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif 'id' in axis and 'size' in axis:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "            elif 'id' in axis:\n",
        "                if axis['id'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                else:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "    if len(input_image_shape) == 0:\n",
        "        raise ValueError(\"Couldn't load input info from BMZ model's RDF: {}\".format(model_rdf[\"inputs\"][0]))\n",
        "    opts[\"DATA.PATCH_SIZE\"] = tuple(input_image_shape[2:]) + (input_image_shape[1],)\n",
        "\n",
        "    # Capture model kwargs\n",
        "    if \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]:\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"kwargs\"]\n",
        "    elif (\n",
        "        \"architecture\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]\n",
        "        and \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"]\n",
        "    ):\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"][\"kwargs\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Couldn't extract kwargs from model description.\")\n",
        "\n",
        "    # 2) Workflow specific restrictions\n",
        "    # Classes in semantic segmentation\n",
        "    if specific_workflow in [\"SEMANTIC_SEG\"]:\n",
        "        # Check number of classes\n",
        "        classes = -1\n",
        "        if \"n_classes\" in model_kwargs: # BiaPy\n",
        "            classes = model_kwargs[\"n_classes\"]\n",
        "        elif \"out_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"out_channels\"]\n",
        "        elif \"classes\" in model_kwargs:\n",
        "            classes = model_kwargs[\"classes\"]\n",
        "\n",
        "        if isinstance(classes, list):\n",
        "            classes = classes[0]\n",
        "        if not isinstance(classes, int):\n",
        "            raise ValueError(f\"Classes not extracted correctly. Obtained {classes}\")\n",
        "\n",
        "        if specific_workflow == \"SEMANTIC_SEG\" and classes == -1:\n",
        "            raise ValueError(\"Classes not found for semantic segmentation dir. \")\n",
        "        opts[\"MODEL.N_CLASSES\"] = max(2,classes)\n",
        "    elif specific_workflow in [\"INSTANCE_SEG\"]:\n",
        "        # Assumed it's BC. This needs a more elaborated process. Still deciding this:\n",
        "        # https://github.com/bioimage-io/spec-bioimage-io/issues/621\n",
        "        channels = 2\n",
        "        if \"out_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"out_channels\"]\n",
        "        if channels == 1:\n",
        "            channel_code = \"C\"\n",
        "        elif channels == 2:\n",
        "            channel_code = \"BC\"\n",
        "        elif channels == 3:\n",
        "            channel_code = \"BCM\"\n",
        "        if channels > 3:\n",
        "            raise ValueError(f\"Not recognized number of channels for instance segmentation. Obtained {channels}\")\n",
        "\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\"] = channel_code\n",
        "\n",
        "    if \"preprocessing\" not in model_rdf[\"inputs\"][0]:\n",
        "        return opts\n",
        "\n",
        "    preproc_info = model_rdf[\"inputs\"][0][\"preprocessing\"]\n",
        "    if len(preproc_info) == 0:\n",
        "        return opts\n",
        "    preproc_info = preproc_info[0]\n",
        "\n",
        "    # 3) Change preprocessing to the one stablished by BMZ by translate BMZ keywords into BiaPy's\n",
        "    # 'zero_mean_unit_variance' and 'fixed_zero_mean_unit_variance' norms of BMZ can be translated to our 'custom' norm\n",
        "    # providing mean and std\n",
        "    key_to_find = \"id\" if model_version > Version(\"0.5.0\") else \"name\"\n",
        "    if key_to_find in preproc_info:\n",
        "        if preproc_info[key_to_find] in [\"fixed_zero_mean_unit_variance\", \"zero_mean_unit_variance\"]:\n",
        "            if (\n",
        "                \"kwargs\" in preproc_info\n",
        "                and \"mean\" in preproc_info[\"kwargs\"]\n",
        "            ):\n",
        "                mean = preproc_info[\"kwargs\"][\"mean\"]\n",
        "                std = preproc_info[\"kwargs\"][\"std\"]\n",
        "            elif \"mean\" in preproc_info:\n",
        "                mean = preproc_info[\"mean\"]\n",
        "                std = preproc_info[\"std\"]\n",
        "            else:\n",
        "                mean, std = -1., -1.\n",
        "\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"custom\"\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_MEAN\"] = mean\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_STD\"] = std\n",
        "\n",
        "        # 'scale_linear' norm of BMZ is close to our 'div' norm (TODO: we need to control the \"gain\" arg)\n",
        "        elif preproc_info[key_to_find] == \"scale_linear\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"div\"\n",
        "\n",
        "        # 'scale_range' norm of BMZ is as our PERC_CLIP + 'scale_range' norm\n",
        "        elif preproc_info[key_to_find] == \"scale_range\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"scale_range\"\n",
        "            if (\n",
        "                float(preproc_info[\"kwargs\"][\"min_percentile\"]) != 0\n",
        "                or float(preproc_info[\"kwargs\"][\"max_percentile\"]) != 100\n",
        "            ):\n",
        "                opts[\"DATA.NORMALIZATION.PERC_CLIP\"] = True\n",
        "                opts[\"DATA.NORMALIZATION.PERC_LOWER\"] = float(preproc_info[\"kwargs\"][\"min_percentile\"])\n",
        "                opts[\"DATA.NORMALIZATION.PERC_UPPER\"] = float(preproc_info[\"kwargs\"][\"max_percentile\"])\n",
        "\n",
        "    return opts\n",
        "\n",
        "# Check the models that BiaPy can consume\n",
        "COLLECTION_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/collection.json\"\n",
        "collection_path = Path(pooch.retrieve(COLLECTION_URL, known_hash=None))\n",
        "with collection_path.open() as f:\n",
        "    collection = json.load(f)\n",
        "\n",
        "model_urls = [entry[\"rdf_source\"] for entry in collection[\"collection\"] if entry[\"type\"] == \"model\"]\n",
        "\n",
        "model_rdfs = []\n",
        "for mu in model_urls:\n",
        "    with open(Path(pooch.retrieve(mu, known_hash=None)), 'rt', encoding='utf8') as stream:\n",
        "        try:\n",
        "            model_rdfs.append(yaml.safe_load(stream))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "\n",
        "# Check axes, preprocessing functions used and postprocessing.\n",
        "pytorch_models = []\n",
        "imposed_vars = []\n",
        "\n",
        "workflow_specs = {\n",
        "    \"workflow_type\": \"SELF_SUPERVISED\",\n",
        "    \"ndim\": \"3D\",\n",
        "    \"nclasses\": \"all\",\n",
        "}\n",
        "for model_rdf in model_rdfs:\n",
        "    try:\n",
        "        (\n",
        "            preproc_info,\n",
        "            error,\n",
        "            error_message\n",
        "        ) = check_bmz_model_compatibility(model_rdf, workflow_specs=workflow_specs)\n",
        "    except:\n",
        "        error = True\n",
        "\n",
        "    if not error:\n",
        "        model_imposed_vars = check_model_restrictions(model_rdf, workflow_specs=workflow_specs)\n",
        "        imposed_vars.append(model_imposed_vars)\n",
        "        pytorch_models.append(model_rdf)\n",
        "\n",
        "# Print the possible models\n",
        "html = \"<table style='width:100%''>\"\n",
        "c = 0\n",
        "for i, model in enumerate(pytorch_models):\n",
        "\n",
        "    if 'nickname' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['nickname']\n",
        "        nickname_icon = model['config']['bioimageio']['nickname_icon']\n",
        "    elif 'id' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['id']\n",
        "        nickname_icon = model['config']['bioimageio']['id_emoji']\n",
        "    else:\n",
        "        doi = \"/\".join(model['id'].split(\"/\")[:2])\n",
        "        nickname = doi\n",
        "        nickname_icon = doi\n",
        "    cover_url = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/\"+nickname+\"/\"+str(model[\"version\"])+\"/files/\"+model['covers'][0]\n",
        "    restrictions = \"\"\n",
        "    for key, val in imposed_vars[i].items():\n",
        "        if key == 'MODEL.N_CLASSES':\n",
        "            restrictions += \"<p>number_of_classes: {}</p>\".format(val)\n",
        "        elif key == \"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\":\n",
        "            problem_channels = 'Binary mask + Contours'\n",
        "            if val == \"BC\":\n",
        "                problem_channels = \"Binary mask + Contours\"\n",
        "            elif val == 'BP':\n",
        "                problem_channels = \"Binary mask + Central points\"\n",
        "            elif val == 'BD':\n",
        "                problem_channels = \"Binary mask + Distance map\"\n",
        "            elif val == 'BCM':\n",
        "                problem_channels = \"Binary mask + Contours + Foreground mask\"\n",
        "            elif val == 'BCD':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map\"\n",
        "            elif val == 'BCDv2':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map with background\"\n",
        "            elif val == 'Dv2':\n",
        "                problem_channels = \"Distance map with background\"\n",
        "            restrictions += \"<p>problem_representation: {}</p>\".format(problem_channels)\n",
        "    if c == 0:\n",
        "        html += \"<tr>\"\n",
        "    html += \"<td style='width:33%'>\"\n",
        "    html += \"<p style='color:#2196f3'>%s</p><p>Nickname: %s (%s)</p>%s<img src='%s' height='200'></td>\"%(\n",
        "        model['name'],\n",
        "        nickname,\n",
        "        nickname_icon,\n",
        "        restrictions,\n",
        "        cover_url,\n",
        "    )\n",
        "    c +=1\n",
        "    if c == 3:\n",
        "        html += \"</tr>\"\n",
        "        c=0\n",
        "html += \"</table>\"\n",
        "if len( pytorch_models ) == 0:\n",
        "    display(HTML('<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>'))\n",
        "else:\n",
        "    display(HTML('<h1>List of models that can be used in BiaPy:</h1><br>'))\n",
        "    display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "262377b8ee2444b49c012c25a5d6b662",
            "55a57fb8f9824e6096a40cae7cb8af7a",
            "2cf5e8fa45a343988b14a84a8b886f2d"
          ]
        },
        "executionInfo": {
          "elapsed": 13,
          "status": "ok",
          "timestamp": 1708338404079,
          "user": {
            "displayName": "Daniel Franco-Barranco",
            "userId": "13463799105703234009"
          },
          "user_tz": -60
        },
        "id": "5QD9gwhsrtJJ",
        "outputId": "ead112a8-56d8-4681-8e58-96867316a117"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "262377b8ee2444b49c012c25a5d6b662",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ToggleButtons(description='Source:', options=('BiaPy', 'BioImage Model Zoo'), tooltips=('Models created during\u2026"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to select the source to build the model (BiaPy or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown **BiaPy**: to use the models implemented in BiaPy.\n",
        "\n",
        "#@markdown **Bioimage Model Zoo (BMZ)**: to use models from the [BMZ repository](https://bioimage.io/#/). You can run the above cell to generate an updated list of the models that can be used with BiaPy. Copy the nickname from the model and paste it below.\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "\n",
        "changed_source = True\n",
        "exists_bmz = False\n",
        "# create widgets\n",
        "source = widgets.ToggleButtons(\n",
        "    options=['BiaPy', 'BioImage Model Zoo'],\n",
        "    description='Source:',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltips=['Models created during this workflow', 'BioImage Model Zoo model'],\n",
        "#     icons=['check'] * 3\n",
        ")\n",
        "\n",
        "bmz = widgets.Text(\n",
        "    # value='10.5281/zenodo.5764892',\n",
        "    placeholder='Nickname of BMZ model',\n",
        "    description='ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# display the first widget\n",
        "display(source)\n",
        "\n",
        "# intialize the output - second widget\n",
        "out = Output()\n",
        "\n",
        "def changed(change):\n",
        "    '''\n",
        "    Monitor change in the first widget\n",
        "    '''\n",
        "    global out\n",
        "    global exists_bmz\n",
        "    if source.value == 'BiaPy':\n",
        "        bmz.layout.display = 'none'\n",
        "        out.clear_output() #clear output\n",
        "        out = Output() # redefine output\n",
        "    else:\n",
        "        bmz.layout.display = 'none'\n",
        "        bmz.layout.display = 'flex'\n",
        "        if not exists_bmz:\n",
        "          out.append_display_data(bmz)\n",
        "          display(out)\n",
        "        exists_bmz = True\n",
        "\n",
        "# monitor the source widget for changes\n",
        "source.observe(changed, 'value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfUyeHEP4vY3"
      },
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`pretext_task`:** Pretext task to use to train the model. Options: 'crappify' to recover a worstened version of the input image as in (see [Franco-Barranco et al., 2022](https://www.sciencedirect.com/science/article/pii/S0169260722003315)) and 'masking', where random patches of the input image are masked and the network needs to reconstruct the missing pixels (see [He et al., 2022](https://openaccess.thecvf.com/content/CVPR2022/papers/He_Masked_Autoencoders_Are_Scalable_Vision_Learners_CVPR_2022_paper.pdf)). **Default value: 'masking'**\n",
        "\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 1**\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. In this example we only use 100 epochs, but if 'masking' pretext task as selected thousand epochs are necessary to obtain good data representations.The MAE method represents a cutting-edge technique in the realm of semi-supervised learning (SSL), albeit with the trade-off of increased computational requirements and time constraints. With 'crappify' less better representations can be obtained but require less epochs too. **Default value: 100**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 20**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: MAE, EDSR, RCAN, WDSR, DFCAN, U-Net, Residual U-Net, Attention U-Net, SEUNet, MultiResUNet, ResUNet++ (see [Franco-Barranco et al., 2021](https://link.springer.com/article/10.1007/s12021-021-09556-1)), UNETR-Mini, UNETR-Small and UNETR-Base. **Default value: MAE**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 6**\n",
        "\n",
        "* **`patch_size`:** Input the size of the patches use to train your model (length in pixels in X, Y and Z). The value should be smaller or equal to the dimensions of the image. **Default value: 96**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization. **Default value: ADAMW**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.0001**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RLdMygZVT5aH"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_3d_self_supervision\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Data management:\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "pretext_task = \"masking\" #@param [\"crappify\", \"masking\"]\n",
        "input_channels = 1 #@param {type:\"number\"}\n",
        "number_of_epochs =  100#@param {type:\"number\"}\n",
        "patience =  20#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "\n",
        "model_architecture = \"MAE\" #@param [\"MAE\", \"U-Net\", \"Residual U-Net\", \"Attention U-Net\", 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\", \"UNETR-Small\", \"UNETR-Base\", \"EDSR\", \"RCAN\", \"WDSR\", \"DFCAN\"]\n",
        "\n",
        "batch_size = 6 #@param {type:\"number\"}\n",
        "patch_size = 96 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n",
        "initial_learning_rate = 0.0001 #@param {type:\"number\"}\n",
        "\n",
        "checkpoint_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AOMhRLgsVyKk"
      },
      "outputs": [],
      "source": [
        "#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n",
        "#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n",
        "\n",
        "#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n",
        "from google.colab import files\n",
        "\n",
        "#s.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "checkpoint_path = '/content/' + list(uploaded.keys())[0]\n",
        "\n",
        "# open previously configured file, if exists\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# edit previous configuration file if it exists to load the checkpoint model\n",
        "if os.path.exists( yaml_file ):\n",
        "    import yaml\n",
        "    with open( yaml_file, 'r') as stream:\n",
        "        try:\n",
        "            biapy_config = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "    # save file\n",
        "    with open( yaml_file, 'w') as outfile:\n",
        "        yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Pre-trained model loaded and ready to re-train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNWZYlu4zSG"
      },
      "source": [
        "### **Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CZKK9EoVmH-Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724748490349,
          "user_tz": -120,
          "elapsed": 1962467,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "d5d436ff-d2a1-4827-dce5-b8f7b8a10a3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration finished.\n",
            "Date: 2024-08-27 08:15:28\n",
            "Arguments: Namespace(config='/content/my_3d_self_supervision.yaml', result_dir='/content/output', name='my_3d_self_supervision', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "Job: my_3d_self_supervision_1\n",
            "Python       : 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "PyTorch:  2.4.0+cu121\n",
            "Not using distributed mode\n",
            "[08:15:28.216377] Configuration details:\n",
            "[08:15:28.216537] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: True\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: True\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    APPLICATION_MODE: image\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    PERC_CLIP: False\n",
            "    PERC_LOWER: -1.0\n",
            "    PERC_UPPER: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (96, 96, 96, 1)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/train/x/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/test/y_detection_masks\n",
            "    GT_PATH: user_data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/test/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: False\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (12, 12, 12)\n",
            "    PATH: /content/data/train/x\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/train/y_detection_masks\n",
            "    GT_PATH: user_data/train/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: -1.0\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: /content/data/train/x\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    DIST_EVAL: True\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_3d_self_supervision/train_logs\n",
            "  LOG_FILE_PREFIX: my_3d_self_supervision_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: False\n",
            "  TYPE: MAE\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: ELU\n",
            "  ARCHITECTURE: mae\n",
            "  BMZ:\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0.0]\n",
            "  FEATURE_MAPS: [16, 32, 64, 128, 256]\n",
            "  ISOTROPY: [True, True, True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 2\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: pre\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [1, 1, 1, 1]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/charts\n",
            "  CHECKPOINT: /content/output/my_3d_self_supervision/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/aug\n",
            "  GEN_CHECKS: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/gen_mask_check\n",
            "  LWR_X_FILE: /content/output/my_3d_self_supervision/checkpoints/lower_bound_X_perc.npy\n",
            "  LWR_Y_FILE: /content/output/my_3d_self_supervision/checkpoints/lower_bound_Y_perc.npy\n",
            "  MAE_OUT_DIR: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/MAE_checks\n",
            "  MEAN_INFO_FILE: /content/output/my_3d_self_supervision/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_3d_self_supervision/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/instance_associations\n",
            "    PATH: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1\n",
            "    PER_IMAGE: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_3d_self_supervision/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: user_data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/train_BC_instance_channels\n",
            "  UPR_X_FILE: /content/output/my_3d_self_supervision/checkpoints/upper_bound_X_perc.npy\n",
            "  UPR_Y_FILE: /content/output/my_3d_self_supervision/checkpoints/upper_bound_Y_perc.npy\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [2]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 3D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: masking\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1, 1)\n",
            "  TYPE: SELF_SUPERVISED\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: 5\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    FORMAT: H5\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['psnr', 'mae', 'mse', 'ssim']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGN: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: False\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 6\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 100\n",
            "  LR: 0.0001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: \n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "  METRICS: ['psnr', 'mae', 'mse', 'ssim']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 20\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[08:15:30.172979] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[08:15:30.173151] Initializing Self_supervised_Workflow\n",
            "[08:15:30.175040] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[08:15:30.539798] Overriding 'LOSS.TYPE' to set it to MSE loss (masking patches)\n",
            "[08:15:30.541202] No SSL data needs to be prepared for masking, as it will be generated on the fly\n",
            "[08:15:30.542433] ##########################\n",
            "[08:15:30.543271] #   LOAD TRAINING DATA   #\n",
            "[08:15:30.544005] ##########################\n",
            "[08:15:30.544860] ### LOAD ###\n",
            "[08:15:30.545863] 0) Loading train images . . .\n",
            "[08:15:30.551574] Loading data from /content/data/train/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:15:31.209369] *** Loaded data shape is (176, 96, 96, 96, 1)\n",
            "[08:15:31.238108] Creating validation data\n",
            "[08:15:31.323803] Not all samples seem to have the same shape. Number of samples: 158\n",
            "[08:15:31.324959] *** Loaded train data shape is: (158, 96, 96, 96, 1)\n",
            "[08:15:31.325787] *** Loaded validation data shape is: (18, 96, 96, 96, 1)\n",
            "[08:15:31.326554] ### END LOAD ###\n",
            "[08:15:31.327443] ###############\n",
            "[08:15:31.328338] # Build model #\n",
            "[08:15:31.329176] ###############\n",
            "[08:15:36.791899] ##############################\n",
            "[08:15:36.792040] #  PREPARE TRAIN GENERATORS  #\n",
            "[08:15:36.794229] ##############################\n",
            "[08:15:36.795318] Initializing train data generator . . .\n",
            "[08:15:36.801213] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('uint8'), 'div': 1}\n",
            "[08:15:36.802773] Initializing val data generator . . .\n",
            "[08:15:36.805012] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('uint8'), 'div': 1}\n",
            "[08:15:36.805267] Creating generator samples . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (96, 96, 96) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
            "  ia.warn(\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  6.83it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.49it/s]\u001b[A\n",
            " 10%|\u2588         | 1/10 [00:00<00:06,  1.31it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 2/10 [00:01<00:03,  2.18it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  3.46it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 3/10 [00:01<00:03,  1.76it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.29it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.41it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:02<00:05,  1.18it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.54it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.69it/s]\u001b[A\n",
            " 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:03<00:04,  1.16it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  4.96it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  6.54it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:04<00:02,  1.36it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  7.73it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  6.03it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:04<00:01,  1.58it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  5.97it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  9.80it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:05<00:01,  1.84it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  5.42it/s]\u001b[A\n",
            "                                             \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  3.22it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:06<00:00,  1.44it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  3.66it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:06<00:00,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:15:43.705055] ### END TR-SAMPLES ###\n",
            "[08:15:43.706958] Number of workers: 5\n",
            "[08:15:43.707014] Accumulate grad iterations: 1\n",
            "[08:15:43.707040] Effective batch size: 6\n",
            "[08:15:43.707081] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f3876247190>\n",
            "[08:15:43.715708] #######################\n",
            "[08:15:43.715751] # Prepare logging tool #\n",
            "[08:15:43.715776] #######################\n",
            "[08:15:43.722045] AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.02\n",
            ")\n",
            "[08:15:43.722440] #####################\n",
            "[08:15:43.722483] #  TRAIN THE MODEL  #\n",
            "[08:15:43.722512] #####################\n",
            "[08:15:43.722549] Start training in epoch 1 - Total: 100\n",
            "[08:15:43.722602] ~~~ Epoch 1/100 ~~~\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:290: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:58: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:16:00.933723] Epoch: [1]  [ 0/27]  eta: 0:07:44  loss: 0.5313 (0.5313)  MSE: 0.5326 (0.5326)  MAE: 0.6076 (0.6076)  PSNR: 13.7916 (13.7916)  SSIM: -0.0030 (-0.0030)  lr: 0.000100  iter-time: 17.2026\n",
            "[08:16:04.650928] Epoch: [1]  [10/27]  eta: 0:00:32  loss: 0.2714 (0.2957)  MSE: 0.2950 (0.3154)  MAE: 0.4422 (0.4495)  PSNR: 14.0392 (13.9914)  SSIM: 0.0307 (0.0301)  lr: 0.000100  iter-time: 1.9016\n",
            "[08:16:08.507073] Epoch: [1]  [20/27]  eta: 0:00:08  loss: 0.1258 (0.1897)  MSE: 0.1446 (0.2078)  MAE: 0.2932 (0.3423)  PSNR: 13.5566 (13.4799)  SSIM: 0.0562 (0.0493)  lr: 0.000100  iter-time: 0.3781\n",
            "[08:16:14.517112] Epoch: [1]  [26/27]  eta: 0:00:01  loss: 0.0584 (0.1538)  MSE: 0.0739 (0.1706)  MAE: 0.2058 (0.3008)  PSNR: 13.3859 (13.4888)  SSIM: 0.0694 (0.0587)  lr: 0.000100  iter-time: 0.5670\n",
            "[08:16:14.683701] Epoch: [1] Total time: 0:00:30 (1.1464 s / it)\n",
            "[08:16:14.684777] [Train] averaged stats: loss: 0.0584 (0.1538)  MSE: 0.0739 (0.1706)  MAE: 0.2058 (0.3008)  PSNR: 13.3859 (13.4888)  SSIM: 0.0694 (0.0587)  lr: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:16:15.252833] Epoch: [1]  [0/3]  eta: 0:00:01  loss: 0.0219 (0.0219)  MSE: 0.0337 (0.0337)  MAE: 0.1440 (0.1440)  PSNR: 14.6897 (14.6897)  SSIM: 0.1011 (0.1011)  iter-time: 0.5615\n",
            "[08:16:15.672075] Epoch: [1]  [2/3]  eta: 0:00:00  loss: 0.0227 (0.0225)  MSE: 0.0344 (0.0344)  MAE: 0.1466 (0.1461)  PSNR: 14.6897 (14.7032)  SSIM: 0.0994 (0.0997)  iter-time: 0.3267\n",
            "[08:16:15.750157] Epoch: [1] Total time: 0:00:01 (0.3532 s / it)\n",
            "[08:16:15.750289] [Val] averaged stats: loss: 0.0227 (0.0225)  MSE: 0.0344 (0.0344)  MAE: 0.1466 (0.1461)  PSNR: 14.6897 (14.7032)  SSIM: 0.0994 (0.0997)\n",
            "[08:16:15.753204] Val loss improved from inf to 0.022539015238483746, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:16:21.898797] [Val] best loss: 0.0225 best  MSE: 0.0344 MAE: 0.1461 PSNR: 14.7032 SSIM: 0.0997 \n",
            "[08:16:21.902393] [Time] 38.2s 38.2s/1.1h\n",
            "\n",
            "[08:16:21.903688] ~~~ Epoch 2/100 ~~~\n",
            "\n",
            "[08:16:24.566471] Epoch: [2]  [ 0/27]  eta: 0:01:11  loss: 0.0222 (0.0222)  MSE: 0.0329 (0.0329)  MAE: 0.1436 (0.1436)  PSNR: 14.3544 (14.3544)  SSIM: 0.1011 (0.1011)  lr: 0.000100  iter-time: 2.6586\n",
            "[08:16:33.426885] Epoch: [2]  [10/27]  eta: 0:00:17  loss: 0.0187 (0.0192)  MSE: 0.0295 (0.0299)  MAE: 0.1368 (0.1376)  PSNR: 14.8453 (14.7975)  SSIM: 0.1042 (0.1044)  lr: 0.000100  iter-time: 1.0467\n",
            "[08:16:39.604809] Epoch: [2]  [20/27]  eta: 0:00:05  loss: 0.0172 (0.0178)  MSE: 0.0279 (0.0284)  MAE: 0.1334 (0.1345)  PSNR: 14.6921 (14.8056)  SSIM: 0.1018 (0.1027)  lr: 0.000100  iter-time: 0.7513\n",
            "[08:16:41.582457] Epoch: [2]  [26/27]  eta: 0:00:00  loss: 0.0157 (0.0172)  MSE: 0.0263 (0.0277)  MAE: 0.1302 (0.1331)  PSNR: 14.7561 (14.8295)  SSIM: 0.1033 (0.1035)  lr: 0.000100  iter-time: 0.6075\n",
            "[08:16:41.690154] Epoch: [2] Total time: 0:00:19 (0.7327 s / it)\n",
            "[08:16:41.691315] [Train] averaged stats: loss: 0.0157 (0.0172)  MSE: 0.0263 (0.0277)  MAE: 0.1302 (0.1331)  PSNR: 14.7561 (14.8295)  SSIM: 0.1033 (0.1035)  lr: 0.000100\n",
            "[08:16:42.192214] Epoch: [2]  [0/3]  eta: 0:00:01  loss: 0.0148 (0.0148)  MSE: 0.0255 (0.0255)  MAE: 0.1282 (0.1282)  PSNR: 14.8706 (14.8706)  SSIM: 0.1096 (0.1096)  iter-time: 0.4949\n",
            "[08:16:42.611509] Epoch: [2]  [2/3]  eta: 0:00:00  loss: 0.0154 (0.0154)  MSE: 0.0260 (0.0261)  MAE: 0.1303 (0.1304)  PSNR: 14.8706 (14.8688)  SSIM: 0.1070 (0.1078)  iter-time: 0.3045\n",
            "[08:16:42.692845] Epoch: [2] Total time: 0:00:00 (0.3321 s / it)\n",
            "[08:16:42.692973] [Val] averaged stats: loss: 0.0154 (0.0154)  MSE: 0.0260 (0.0261)  MAE: 0.1303 (0.1304)  PSNR: 14.8706 (14.8688)  SSIM: 0.1070 (0.1078)\n",
            "[08:16:42.695567] Val loss improved from 0.022539015238483746 to 0.015390721149742603, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:16:49.259247] [Val] best loss: 0.0154 best  MSE: 0.0261 MAE: 0.1304 PSNR: 14.8688 SSIM: 0.1078 \n",
            "[08:16:49.262500] [Time] 27.4s 1.1m/46.2m\n",
            "\n",
            "[08:16:49.262999] ~~~ Epoch 3/100 ~~~\n",
            "\n",
            "[08:16:51.640373] Epoch: [3]  [ 0/27]  eta: 0:01:03  loss: 0.0151 (0.0151)  MSE: 0.0244 (0.0244)  MAE: 0.1255 (0.1255)  PSNR: 14.7645 (14.7645)  SSIM: 0.1093 (0.1093)  lr: 0.000100  iter-time: 2.3694\n",
            "[08:16:55.952105] Epoch: [3]  [10/27]  eta: 0:00:10  loss: 0.0143 (0.0145)  MSE: 0.0248 (0.0249)  MAE: 0.1271 (0.1271)  PSNR: 14.8989 (14.8793)  SSIM: 0.1155 (0.1157)  lr: 0.000100  iter-time: 0.6060\n",
            "[08:17:05.187383] Epoch: [3]  [20/27]  eta: 0:00:05  loss: 0.0143 (0.0144)  MSE: 0.0247 (0.0247)  MAE: 0.1268 (0.1267)  PSNR: 14.8703 (14.9449)  SSIM: 0.1207 (0.1201)  lr: 0.000100  iter-time: 0.6764\n",
            "[08:17:07.520241] Epoch: [3]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0143)  MSE: 0.0245 (0.0246)  MAE: 0.1261 (0.1265)  PSNR: 14.9581 (14.9667)  SSIM: 0.1265 (0.1229)  lr: 0.000100  iter-time: 0.6722\n",
            "[08:17:07.631568] Epoch: [3] Total time: 0:00:18 (0.6802 s / it)\n",
            "[08:17:07.631713] [Train] averaged stats: loss: 0.0141 (0.0143)  MSE: 0.0245 (0.0246)  MAE: 0.1261 (0.1265)  PSNR: 14.9581 (14.9667)  SSIM: 0.1265 (0.1229)  lr: 0.000100\n",
            "[08:17:08.083970] Epoch: [3]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0246 (0.0246)  MAE: 0.1265 (0.1265)  PSNR: 14.9550 (14.9550)  SSIM: 0.1309 (0.1309)  iter-time: 0.4439\n",
            "[08:17:08.508087] Epoch: [3]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0148)  MSE: 0.0251 (0.0252)  MAE: 0.1285 (0.1287)  PSNR: 14.9550 (14.9532)  SSIM: 0.1274 (0.1283)  iter-time: 0.2891\n",
            "[08:17:08.605648] Epoch: [3] Total time: 0:00:00 (0.3221 s / it)\n",
            "[08:17:08.605764] [Val] averaged stats: loss: 0.0147 (0.0148)  MSE: 0.0251 (0.0252)  MAE: 0.1285 (0.1287)  PSNR: 14.9550 (14.9532)  SSIM: 0.1274 (0.1283)\n",
            "[08:17:08.608248] Val loss improved from 0.015390721149742603 to 0.01475215299675862, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:17:15.141186] [Val] best loss: 0.0148 best  MSE: 0.0252 MAE: 0.1287 PSNR: 14.9532 SSIM: 0.1283 \n",
            "[08:17:15.144555] [Time] 25.9s 1.5m/43.8m\n",
            "\n",
            "[08:17:15.145371] ~~~ Epoch 4/100 ~~~\n",
            "\n",
            "[08:17:19.661127] Epoch: [4]  [ 0/27]  eta: 0:02:01  loss: 0.0136 (0.0136)  MSE: 0.0233 (0.0233)  MAE: 0.1230 (0.1230)  PSNR: 14.8299 (14.8299)  SSIM: 0.1321 (0.1321)  lr: 0.000100  iter-time: 4.5113\n",
            "[08:17:27.170396] Epoch: [4]  [10/27]  eta: 0:00:18  loss: 0.0141 (0.0141)  MSE: 0.0241 (0.0242)  MAE: 0.1255 (0.1258)  PSNR: 14.9178 (14.9044)  SSIM: 0.1289 (0.1277)  lr: 0.000100  iter-time: 1.0921\n",
            "[08:17:30.950884] Epoch: [4]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0243 (0.0242)  MAE: 0.1255 (0.1257)  PSNR: 14.9178 (14.9312)  SSIM: 0.1264 (0.1260)  lr: 0.000100  iter-time: 0.5640\n",
            "[08:17:32.949868] Epoch: [4]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0243 (0.0242)  MAE: 0.1255 (0.1256)  PSNR: 14.8643 (14.9381)  SSIM: 0.1252 (0.1262)  lr: 0.000100  iter-time: 0.3677\n",
            "[08:17:33.042227] Epoch: [4] Total time: 0:00:17 (0.6627 s / it)\n",
            "[08:17:33.045872] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0243 (0.0242)  MAE: 0.1255 (0.1256)  PSNR: 14.8643 (14.9381)  SSIM: 0.1252 (0.1262)  lr: 0.000100\n",
            "[08:17:33.519400] Epoch: [4]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0244 (0.0244)  MAE: 0.1259 (0.1259)  PSNR: 14.8144 (14.8144)  SSIM: 0.1253 (0.1253)  iter-time: 0.4688\n",
            "[08:17:33.945652] Epoch: [4]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0249 (0.0250)  MAE: 0.1279 (0.1281)  PSNR: 14.8144 (14.8111)  SSIM: 0.1219 (0.1228)  iter-time: 0.2981\n",
            "[08:17:34.025130] Epoch: [4] Total time: 0:00:00 (0.3251 s / it)\n",
            "[08:17:34.025394] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0249 (0.0250)  MAE: 0.1279 (0.1281)  PSNR: 14.8144 (14.8111)  SSIM: 0.1219 (0.1228)\n",
            "[08:17:34.027948] Val loss improved from 0.01475215299675862 to 0.014701016247272491, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:17:41.947542] [Val] best loss: 0.0147 best  MSE: 0.0250 MAE: 0.1281 PSNR: 14.8111 SSIM: 0.1228 \n",
            "[08:17:41.955755] [Time] 26.8s 2.0m/45.3m\n",
            "\n",
            "[08:17:41.955846] ~~~ Epoch 5/100 ~~~\n",
            "\n",
            "[08:17:44.498016] Epoch: [5]  [ 0/27]  eta: 0:01:08  loss: 0.0140 (0.0140)  MSE: 0.0232 (0.0232)  MAE: 0.1228 (0.1228)  PSNR: 14.6399 (14.6399)  SSIM: 0.1261 (0.1261)  lr: 0.000100  iter-time: 2.5340\n",
            "[08:17:51.725989] Epoch: [5]  [10/27]  eta: 0:00:15  loss: 0.0140 (0.0141)  MSE: 0.0239 (0.0240)  MAE: 0.1252 (0.1251)  PSNR: 14.7791 (14.7578)  SSIM: 0.1256 (0.1255)  lr: 0.000100  iter-time: 0.8873\n",
            "[08:17:57.686091] Epoch: [5]  [20/27]  eta: 0:00:05  loss: 0.0139 (0.0141)  MSE: 0.0240 (0.0240)  MAE: 0.1252 (0.1252)  PSNR: 14.8145 (14.8786)  SSIM: 0.1250 (0.1246)  lr: 0.000100  iter-time: 0.6591\n",
            "[08:17:59.700485] Epoch: [5]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0239 (0.0240)  MAE: 0.1251 (0.1251)  PSNR: 14.8642 (14.9016)  SSIM: 0.1233 (0.1247)  lr: 0.000100  iter-time: 0.5958\n",
            "[08:17:59.804132] Epoch: [5] Total time: 0:00:17 (0.6608 s / it)\n",
            "[08:17:59.805129] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0239 (0.0240)  MAE: 0.1251 (0.1251)  PSNR: 14.8642 (14.9016)  SSIM: 0.1233 (0.1247)  lr: 0.000100\n",
            "[08:18:00.302514] Epoch: [5]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0242 (0.0242)  MAE: 0.1255 (0.1255)  PSNR: 14.8283 (14.8283)  SSIM: 0.1228 (0.1228)  iter-time: 0.4924\n",
            "[08:18:00.731347] Epoch: [5]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0247 (0.0248)  MAE: 0.1275 (0.1277)  PSNR: 14.8283 (14.8247)  SSIM: 0.1193 (0.1203)  iter-time: 0.3068\n",
            "[08:18:00.828619] Epoch: [5] Total time: 0:00:01 (0.3397 s / it)\n",
            "[08:18:00.829584] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0247 (0.0248)  MAE: 0.1275 (0.1277)  PSNR: 14.8283 (14.8247)  SSIM: 0.1193 (0.1203)\n",
            "[08:18:00.831376] [Val] best loss: 0.0147 best  MSE: 0.0250 MAE: 0.1281 PSNR: 14.8111 SSIM: 0.1228 \n",
            "[08:18:00.834120] Creating training plots . . .\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:18:01.691761] [Time] 19.7s 2.3m/33.9m\n",
            "\n",
            "[08:18:01.691830] ~~~ Epoch 6/100 ~~~\n",
            "\n",
            "[08:18:04.621287] Epoch: [6]  [ 0/27]  eta: 0:01:18  loss: 0.0134 (0.0134)  MSE: 0.0228 (0.0228)  MAE: 0.1220 (0.1220)  PSNR: 14.6330 (14.6330)  SSIM: 0.1257 (0.1257)  lr: 0.000100  iter-time: 2.9191\n",
            "[08:18:09.066254] Epoch: [6]  [10/27]  eta: 0:00:11  loss: 0.0139 (0.0141)  MSE: 0.0239 (0.0238)  MAE: 0.1248 (0.1249)  PSNR: 14.8852 (14.8962)  SSIM: 0.1221 (0.1215)  lr: 0.000100  iter-time: 0.6693\n",
            "[08:18:17.280636] Epoch: [6]  [20/27]  eta: 0:00:05  loss: 0.0140 (0.0141)  MSE: 0.0239 (0.0238)  MAE: 0.1248 (0.1249)  PSNR: 14.8926 (14.9848)  SSIM: 0.1222 (0.1224)  lr: 0.000100  iter-time: 0.6326\n",
            "[08:18:19.305385] Epoch: [6]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0140)  MSE: 0.0239 (0.0238)  MAE: 0.1247 (0.1247)  PSNR: 14.8926 (14.9668)  SSIM: 0.1224 (0.1229)  lr: 0.000100  iter-time: 0.6042\n",
            "[08:18:19.402769] Epoch: [6] Total time: 0:00:17 (0.6558 s / it)\n",
            "[08:18:19.404084] [Train] averaged stats: loss: 0.0141 (0.0140)  MSE: 0.0239 (0.0238)  MAE: 0.1247 (0.1247)  PSNR: 14.8926 (14.9668)  SSIM: 0.1224 (0.1229)  lr: 0.000100\n",
            "[08:18:19.922872] Epoch: [6]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0240 (0.0240)  MAE: 0.1250 (0.1250)  PSNR: 14.8263 (14.8263)  SSIM: 0.1225 (0.1225)  iter-time: 0.5128\n",
            "[08:18:20.355040] Epoch: [6]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0245 (0.0246)  MAE: 0.1271 (0.1272)  PSNR: 14.8263 (14.8225)  SSIM: 0.1191 (0.1201)  iter-time: 0.3147\n",
            "[08:18:20.439489] Epoch: [6] Total time: 0:00:01 (0.3434 s / it)\n",
            "[08:18:20.440315] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0245 (0.0246)  MAE: 0.1271 (0.1272)  PSNR: 14.8263 (14.8225)  SSIM: 0.1191 (0.1201)\n",
            "[08:18:20.442288] [Val] best loss: 0.0147 best  MSE: 0.0250 MAE: 0.1281 PSNR: 14.8111 SSIM: 0.1228 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:18:20.445074] [Time] 18.8s 2.6m/32.3m\n",
            "\n",
            "[08:18:20.445994] ~~~ Epoch 7/100 ~~~\n",
            "\n",
            "[08:18:24.228472] Epoch: [7]  [ 0/27]  eta: 0:01:41  loss: 0.0140 (0.0140)  MSE: 0.0226 (0.0226)  MAE: 0.1215 (0.1215)  PSNR: 14.8883 (14.8883)  SSIM: 0.1270 (0.1270)  lr: 0.000100  iter-time: 3.7773\n",
            "[08:18:28.870114] Epoch: [7]  [10/27]  eta: 0:00:13  loss: 0.0141 (0.0141)  MSE: 0.0237 (0.0236)  MAE: 0.1246 (0.1245)  PSNR: 14.8997 (14.8843)  SSIM: 0.1218 (0.1215)  lr: 0.000100  iter-time: 0.7652\n",
            "[08:18:35.541729] Epoch: [7]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0237 (0.0237)  MAE: 0.1246 (0.1246)  PSNR: 14.8962 (14.9360)  SSIM: 0.1213 (0.1213)  lr: 0.000100  iter-time: 0.5651\n",
            "[08:18:37.589913] Epoch: [7]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0237 (0.0236)  MAE: 0.1246 (0.1245)  PSNR: 14.8997 (14.9532)  SSIM: 0.1218 (0.1213)  lr: 0.000100  iter-time: 0.5305\n",
            "[08:18:37.690856] Epoch: [7] Total time: 0:00:17 (0.6386 s / it)\n",
            "[08:18:37.693636] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0237 (0.0236)  MAE: 0.1246 (0.1245)  PSNR: 14.8997 (14.9532)  SSIM: 0.1218 (0.1213)  lr: 0.000100\n",
            "[08:18:38.191552] Epoch: [7]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0238 (0.0238)  MAE: 0.1246 (0.1246)  PSNR: 14.8151 (14.8151)  SSIM: 0.1203 (0.1203)  iter-time: 0.4914\n",
            "[08:18:38.624144] Epoch: [7]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0243 (0.0244)  MAE: 0.1266 (0.1268)  PSNR: 14.8151 (14.8112)  SSIM: 0.1168 (0.1179)  iter-time: 0.3077\n",
            "[08:18:38.708710] Epoch: [7] Total time: 0:00:01 (0.3364 s / it)\n",
            "[08:18:38.708838] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0243 (0.0244)  MAE: 0.1266 (0.1268)  PSNR: 14.8151 (14.8112)  SSIM: 0.1168 (0.1179)\n",
            "[08:18:38.711551] Val loss improved from 0.014701016247272491 to 0.014700518921017647, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:18:47.642386] [Val] best loss: 0.0147 best  MSE: 0.0244 MAE: 0.1268 PSNR: 14.8112 SSIM: 0.1179 \n",
            "[08:18:47.645497] [Time] 27.2s 3.1m/45.7m\n",
            "\n",
            "[08:18:47.645579] ~~~ Epoch 8/100 ~~~\n",
            "\n",
            "[08:18:50.292071] Epoch: [8]  [ 0/27]  eta: 0:01:11  loss: 0.0142 (0.0142)  MSE: 0.0226 (0.0226)  MAE: 0.1218 (0.1218)  PSNR: 14.6054 (14.6054)  SSIM: 0.1216 (0.1216)  lr: 0.000100  iter-time: 2.6409\n",
            "[08:18:54.704182] Epoch: [8]  [10/27]  eta: 0:00:10  loss: 0.0142 (0.0141)  MSE: 0.0234 (0.0234)  MAE: 0.1241 (0.1241)  PSNR: 14.9082 (14.8245)  SSIM: 0.1216 (0.1209)  lr: 0.000100  iter-time: 0.6410\n",
            "[08:19:02.530197] Epoch: [8]  [20/27]  eta: 0:00:04  loss: 0.0142 (0.0141)  MSE: 0.0235 (0.0235)  MAE: 0.1242 (0.1241)  PSNR: 14.9082 (14.8967)  SSIM: 0.1203 (0.1205)  lr: 0.000100  iter-time: 0.6113\n",
            "[08:19:05.201620] Epoch: [8]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0234 (0.0234)  MAE: 0.1241 (0.1240)  PSNR: 14.9704 (14.9381)  SSIM: 0.1189 (0.1200)  lr: 0.000100  iter-time: 0.6083\n",
            "[08:19:05.300357] Epoch: [8] Total time: 0:00:17 (0.6538 s / it)\n",
            "[08:19:05.301354] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0234 (0.0234)  MAE: 0.1241 (0.1240)  PSNR: 14.9704 (14.9381)  SSIM: 0.1189 (0.1200)  lr: 0.000100\n",
            "[08:19:05.804219] Epoch: [8]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0235 (0.0235)  MAE: 0.1239 (0.1239)  PSNR: 14.8020 (14.8020)  SSIM: 0.1182 (0.1182)  iter-time: 0.4920\n",
            "[08:19:06.240743] Epoch: [8]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0240 (0.0241)  MAE: 0.1260 (0.1261)  PSNR: 14.8020 (14.7982)  SSIM: 0.1147 (0.1157)  iter-time: 0.3087\n",
            "[08:19:06.328825] Epoch: [8] Total time: 0:00:01 (0.3391 s / it)\n",
            "[08:19:06.329606] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0240 (0.0241)  MAE: 0.1260 (0.1261)  PSNR: 14.8020 (14.7982)  SSIM: 0.1147 (0.1157)\n",
            "[08:19:06.332094] Val loss improved from 0.014700518921017647 to 0.01467616887142261, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:19:13.384528] [Val] best loss: 0.0147 best  MSE: 0.0241 MAE: 0.1261 PSNR: 14.7982 SSIM: 0.1157 \n",
            "[08:19:13.387992] [Time] 25.7s 3.5m/43.4m\n",
            "\n",
            "[08:19:13.388093] ~~~ Epoch 9/100 ~~~\n",
            "\n",
            "[08:19:17.744661] Epoch: [9]  [ 0/27]  eta: 0:01:57  loss: 0.0140 (0.0140)  MSE: 0.0223 (0.0223)  MAE: 0.1209 (0.1209)  PSNR: 14.7620 (14.7620)  SSIM: 0.1195 (0.1195)  lr: 0.000100  iter-time: 4.3501\n",
            "[08:19:25.851894] Epoch: [9]  [10/27]  eta: 0:00:19  loss: 0.0140 (0.0141)  MSE: 0.0232 (0.0232)  MAE: 0.1235 (0.1236)  PSNR: 14.7578 (14.7690)  SSIM: 0.1205 (0.1193)  lr: 0.000100  iter-time: 1.1310\n",
            "[08:19:29.752513] Epoch: [9]  [20/27]  eta: 0:00:05  loss: 0.0140 (0.0141)  MSE: 0.0232 (0.0233)  MAE: 0.1235 (0.1237)  PSNR: 14.8327 (14.8847)  SSIM: 0.1154 (0.1173)  lr: 0.000100  iter-time: 0.5995\n",
            "[08:19:31.809015] Epoch: [9]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0232 (0.0232)  MAE: 0.1235 (0.1236)  PSNR: 14.8242 (14.8955)  SSIM: 0.1149 (0.1174)  lr: 0.000100  iter-time: 0.4084\n",
            "[08:19:31.893357] Epoch: [9] Total time: 0:00:18 (0.6852 s / it)\n",
            "[08:19:31.893566] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0232 (0.0232)  MAE: 0.1235 (0.1236)  PSNR: 14.8242 (14.8955)  SSIM: 0.1149 (0.1174)  lr: 0.000100\n",
            "[08:19:32.403686] Epoch: [9]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0233 (0.0233)  MAE: 0.1235 (0.1235)  PSNR: 14.8117 (14.8117)  SSIM: 0.1165 (0.1165)  iter-time: 0.5041\n",
            "[08:19:32.846508] Epoch: [9]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0238 (0.0239)  MAE: 0.1256 (0.1257)  PSNR: 14.8117 (14.8084)  SSIM: 0.1133 (0.1142)  iter-time: 0.3153\n",
            "[08:19:32.969892] Epoch: [9] Total time: 0:00:01 (0.3570 s / it)\n",
            "[08:19:32.970021] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0238 (0.0239)  MAE: 0.1256 (0.1257)  PSNR: 14.8117 (14.8084)  SSIM: 0.1133 (0.1142)\n",
            "[08:19:32.970751] Val loss improved from 0.01467616887142261 to 0.01467339942852656, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:19:40.224330] [Val] best loss: 0.0147 best  MSE: 0.0239 MAE: 0.1257 PSNR: 14.8084 SSIM: 0.1142 \n",
            "[08:19:40.227491] [Time] 26.8s 3.9m/45.1m\n",
            "\n",
            "[08:19:40.227584] ~~~ Epoch 10/100 ~~~\n",
            "\n",
            "[08:19:41.208164] Epoch: [10]  [ 0/27]  eta: 0:00:26  loss: 0.0143 (0.0143)  MSE: 0.0225 (0.0225)  MAE: 0.1214 (0.1214)  PSNR: 14.7065 (14.7065)  SSIM: 0.1135 (0.1135)  lr: 0.000100  iter-time: 0.9767\n",
            "[08:19:47.507116] Epoch: [10]  [10/27]  eta: 0:00:11  loss: 0.0140 (0.0142)  MSE: 0.0230 (0.0231)  MAE: 0.1231 (0.1232)  PSNR: 14.8500 (14.8347)  SSIM: 0.1169 (0.1161)  lr: 0.000100  iter-time: 0.6607\n",
            "[08:19:56.388114] Epoch: [10]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0231 (0.0231)  MAE: 0.1232 (0.1233)  PSNR: 14.8790 (14.8876)  SSIM: 0.1159 (0.1161)  lr: 0.000100  iter-time: 0.7585\n",
            "[08:19:58.485933] Epoch: [10]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0230 (0.0230)  MAE: 0.1228 (0.1232)  PSNR: 14.8688 (14.8876)  SSIM: 0.1146 (0.1163)  lr: 0.000100  iter-time: 0.6436\n",
            "[08:19:58.580082] Epoch: [10] Total time: 0:00:18 (0.6796 s / it)\n",
            "[08:19:58.581091] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0230 (0.0230)  MAE: 0.1228 (0.1232)  PSNR: 14.8688 (14.8876)  SSIM: 0.1146 (0.1163)  lr: 0.000100\n",
            "[08:19:59.041336] Epoch: [10]  [0/3]  eta: 0:00:01  loss: 0.0141 (0.0141)  MSE: 0.0231 (0.0231)  MAE: 0.1230 (0.1230)  PSNR: 14.7937 (14.7937)  SSIM: 0.1140 (0.1140)  iter-time: 0.4556\n",
            "[08:19:59.481991] Epoch: [10]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0236 (0.0237)  MAE: 0.1252 (0.1252)  PSNR: 14.7937 (14.7900)  SSIM: 0.1109 (0.1117)  iter-time: 0.2985\n",
            "[08:19:59.565084] Epoch: [10] Total time: 0:00:00 (0.3267 s / it)\n",
            "[08:19:59.565219] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0236 (0.0237)  MAE: 0.1252 (0.1252)  PSNR: 14.7937 (14.7900)  SSIM: 0.1109 (0.1117)\n",
            "[08:19:59.567720] [Val] best loss: 0.0147 best  MSE: 0.0239 MAE: 0.1257 PSNR: 14.8084 SSIM: 0.1142 \n",
            "[08:19:59.570233] Creating training plots . . .\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:20:00.294709] [Time] 20.1s 4.3m/34.7m\n",
            "\n",
            "[08:20:00.294775] ~~~ Epoch 11/100 ~~~\n",
            "\n",
            "[08:20:02.232985] Epoch: [11]  [ 0/27]  eta: 0:00:52  loss: 0.0140 (0.0140)  MSE: 0.0221 (0.0221)  MAE: 0.1205 (0.1205)  PSNR: 14.6926 (14.6926)  SSIM: 0.1139 (0.1139)  lr: 0.000100  iter-time: 1.9298\n",
            "[08:20:07.605634] Epoch: [11]  [10/27]  eta: 0:00:11  loss: 0.0140 (0.0142)  MSE: 0.0228 (0.0229)  MAE: 0.1227 (0.1229)  PSNR: 14.9072 (14.8595)  SSIM: 0.1161 (0.1151)  lr: 0.000100  iter-time: 0.6636\n",
            "[08:20:15.590795] Epoch: [11]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0141)  MSE: 0.0229 (0.0229)  MAE: 0.1229 (0.1229)  PSNR: 14.9072 (14.9343)  SSIM: 0.1137 (0.1141)  lr: 0.000100  iter-time: 0.6674\n",
            "[08:20:17.688492] Epoch: [11]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0228 (0.0228)  MAE: 0.1227 (0.1227)  PSNR: 14.8864 (14.9299)  SSIM: 0.1126 (0.1146)  lr: 0.000100  iter-time: 0.6085\n",
            "[08:20:17.788113] Epoch: [11] Total time: 0:00:17 (0.6478 s / it)\n",
            "[08:20:17.789068] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0228 (0.0228)  MAE: 0.1227 (0.1227)  PSNR: 14.8864 (14.9299)  SSIM: 0.1126 (0.1146)  lr: 0.000100\n",
            "[08:20:18.254582] Epoch: [11]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0229 (0.0229)  MAE: 0.1226 (0.1226)  PSNR: 14.8331 (14.8331)  SSIM: 0.1138 (0.1138)  iter-time: 0.4597\n",
            "[08:20:18.695792] Epoch: [11]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0234 (0.0235)  MAE: 0.1247 (0.1248)  PSNR: 14.8331 (14.8297)  SSIM: 0.1106 (0.1116)  iter-time: 0.2995\n",
            "[08:20:18.782600] Epoch: [11] Total time: 0:00:00 (0.3295 s / it)\n",
            "[08:20:18.783527] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0234 (0.0235)  MAE: 0.1247 (0.1248)  PSNR: 14.8331 (14.8297)  SSIM: 0.1106 (0.1116)\n",
            "[08:20:18.785385] Val loss improved from 0.01467339942852656 to 0.014667867993315062, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:20:24.245329] [Val] best loss: 0.0147 best  MSE: 0.0235 MAE: 0.1248 PSNR: 14.8297 SSIM: 0.1116 \n",
            "[08:20:24.248597] [Time] 24.0s 4.7m/40.6m\n",
            "\n",
            "[08:20:24.248686] ~~~ Epoch 12/100 ~~~\n",
            "\n",
            "[08:20:28.007459] Epoch: [12]  [ 0/27]  eta: 0:01:41  loss: 0.0141 (0.0141)  MSE: 0.0220 (0.0220)  MAE: 0.1203 (0.1203)  PSNR: 14.7182 (14.7182)  SSIM: 0.1135 (0.1135)  lr: 0.000100  iter-time: 3.7508\n",
            "[08:20:35.848682] Epoch: [12]  [10/27]  eta: 0:00:17  loss: 0.0141 (0.0141)  MSE: 0.0226 (0.0227)  MAE: 0.1222 (0.1224)  PSNR: 14.8700 (14.8803)  SSIM: 0.1135 (0.1143)  lr: 0.000100  iter-time: 1.0531\n",
            "[08:20:40.335492] Epoch: [12]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0141)  MSE: 0.0227 (0.0227)  MAE: 0.1223 (0.1225)  PSNR: 14.8771 (14.9391)  SSIM: 0.1115 (0.1127)  lr: 0.000100  iter-time: 0.6159\n",
            "[08:20:42.423349] Epoch: [12]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0226 (0.0226)  MAE: 0.1222 (0.1223)  PSNR: 14.8700 (14.9424)  SSIM: 0.1115 (0.1131)  lr: 0.000100  iter-time: 0.4673\n",
            "[08:20:42.567173] Epoch: [12] Total time: 0:00:18 (0.6783 s / it)\n",
            "[08:20:42.567322] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0226 (0.0226)  MAE: 0.1222 (0.1223)  PSNR: 14.8700 (14.9424)  SSIM: 0.1115 (0.1131)  lr: 0.000100\n",
            "[08:20:43.268326] Epoch: [12]  [0/3]  eta: 0:00:02  loss: 0.0140 (0.0140)  MSE: 0.0227 (0.0227)  MAE: 0.1222 (0.1222)  PSNR: 14.8509 (14.8509)  SSIM: 0.1123 (0.1123)  iter-time: 0.6952\n",
            "[08:20:43.713990] Epoch: [12]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0232 (0.0233)  MAE: 0.1243 (0.1244)  PSNR: 14.8509 (14.8478)  SSIM: 0.1090 (0.1100)  iter-time: 0.3799\n",
            "[08:20:43.848623] Epoch: [12] Total time: 0:00:01 (0.4257 s / it)\n",
            "[08:20:43.848756] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0232 (0.0233)  MAE: 0.1243 (0.1244)  PSNR: 14.8509 (14.8478)  SSIM: 0.1090 (0.1100)\n",
            "[08:20:43.849548] Val loss improved from 0.014667867993315062 to 0.01466278669734796, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:20:51.714771] [Val] best loss: 0.0147 best  MSE: 0.0233 MAE: 0.1244 PSNR: 14.8478 SSIM: 0.1100 \n",
            "[08:20:51.718105] [Time] 27.5s 5.1m/45.9m\n",
            "\n",
            "[08:20:51.718193] ~~~ Epoch 13/100 ~~~\n",
            "\n",
            "[08:20:54.475105] Epoch: [13]  [ 0/27]  eta: 0:01:14  loss: 0.0142 (0.0142)  MSE: 0.0218 (0.0218)  MAE: 0.1199 (0.1199)  PSNR: 14.6885 (14.6885)  SSIM: 0.1132 (0.1132)  lr: 0.000100  iter-time: 2.7539\n",
            "[08:21:01.679610] Epoch: [13]  [10/27]  eta: 0:00:15  loss: 0.0142 (0.0142)  MSE: 0.0226 (0.0226)  MAE: 0.1220 (0.1223)  PSNR: 14.8788 (14.9069)  SSIM: 0.1132 (0.1132)  lr: 0.000100  iter-time: 0.9052\n",
            "[08:21:06.867628] Epoch: [13]  [20/27]  eta: 0:00:05  loss: 0.0142 (0.0142)  MSE: 0.0226 (0.0226)  MAE: 0.1222 (0.1222)  PSNR: 14.8872 (14.9671)  SSIM: 0.1112 (0.1114)  lr: 0.000100  iter-time: 0.6194\n",
            "[08:21:08.959916] Epoch: [13]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0226 (0.0225)  MAE: 0.1222 (0.1220)  PSNR: 14.8884 (14.9732)  SSIM: 0.1104 (0.1114)  lr: 0.000100  iter-time: 0.5141\n",
            "[08:21:09.053861] Epoch: [13] Total time: 0:00:17 (0.6420 s / it)\n",
            "[08:21:09.055634] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0226 (0.0225)  MAE: 0.1222 (0.1220)  PSNR: 14.8884 (14.9732)  SSIM: 0.1104 (0.1114)  lr: 0.000100\n",
            "[08:21:09.536762] Epoch: [13]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0225 (0.0225)  MAE: 0.1217 (0.1217)  PSNR: 14.8322 (14.8322)  SSIM: 0.1112 (0.1112)  iter-time: 0.4751\n",
            "[08:21:09.984238] Epoch: [13]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0230 (0.0231)  MAE: 0.1239 (0.1239)  PSNR: 14.8322 (14.8290)  SSIM: 0.1079 (0.1090)  iter-time: 0.3067\n",
            "[08:21:10.065773] Epoch: [13] Total time: 0:00:01 (0.3350 s / it)\n",
            "[08:21:10.065908] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0230 (0.0231)  MAE: 0.1239 (0.1239)  PSNR: 14.8322 (14.8290)  SSIM: 0.1079 (0.1090)\n",
            "[08:21:10.068442] Val loss improved from 0.01466278669734796 to 0.014649163310726484, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:21:16.697458] [Val] best loss: 0.0146 best  MSE: 0.0231 MAE: 0.1239 PSNR: 14.8290 SSIM: 0.1090 \n",
            "[08:21:16.700558] [Time] 25.0s 5.5m/42.2m\n",
            "\n",
            "[08:21:16.700646] ~~~ Epoch 14/100 ~~~\n",
            "\n",
            "[08:21:19.277386] Epoch: [14]  [ 0/27]  eta: 0:01:09  loss: 0.0143 (0.0143)  MSE: 0.0217 (0.0217)  MAE: 0.1197 (0.1197)  PSNR: 14.7343 (14.7343)  SSIM: 0.1126 (0.1126)  lr: 0.000100  iter-time: 2.5737\n",
            "[08:21:23.995089] Epoch: [14]  [10/27]  eta: 0:00:11  loss: 0.0142 (0.0142)  MSE: 0.0223 (0.0224)  MAE: 0.1217 (0.1218)  PSNR: 14.8116 (14.8131)  SSIM: 0.1126 (0.1132)  lr: 0.000100  iter-time: 0.6627\n",
            "[08:21:32.323953] Epoch: [14]  [20/27]  eta: 0:00:05  loss: 0.0142 (0.0142)  MSE: 0.0224 (0.0224)  MAE: 0.1218 (0.1219)  PSNR: 14.8195 (14.8831)  SSIM: 0.1105 (0.1115)  lr: 0.000100  iter-time: 0.6514\n",
            "[08:21:34.482536] Epoch: [14]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0223 (0.0223)  MAE: 0.1217 (0.1217)  PSNR: 14.8732 (14.9278)  SSIM: 0.1104 (0.1114)  lr: 0.000100  iter-time: 0.6037\n",
            "[08:21:34.580965] Epoch: [14] Total time: 0:00:17 (0.6622 s / it)\n",
            "[08:21:34.582067] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0223 (0.0223)  MAE: 0.1217 (0.1217)  PSNR: 14.8732 (14.9278)  SSIM: 0.1104 (0.1114)  lr: 0.000100\n",
            "[08:21:35.064195] Epoch: [14]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0223 (0.0223)  MAE: 0.1213 (0.1213)  PSNR: 14.8244 (14.8244)  SSIM: 0.1106 (0.1106)  iter-time: 0.4775\n",
            "[08:21:35.510823] Epoch: [14]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0229 (0.0229)  MAE: 0.1236 (0.1236)  PSNR: 14.8244 (14.8207)  SSIM: 0.1073 (0.1083)  iter-time: 0.3072\n",
            "[08:21:35.592504] Epoch: [14] Total time: 0:00:01 (0.3355 s / it)\n",
            "[08:21:35.593294] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0229 (0.0229)  MAE: 0.1236 (0.1236)  PSNR: 14.8244 (14.8207)  SSIM: 0.1073 (0.1083)\n",
            "[08:21:35.595545] [Val] best loss: 0.0146 best  MSE: 0.0231 MAE: 0.1239 PSNR: 14.8290 SSIM: 0.1090 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:21:35.598160] [Time] 18.9s 5.9m/33.3m\n",
            "\n",
            "[08:21:35.598221] ~~~ Epoch 15/100 ~~~\n",
            "\n",
            "[08:21:38.882393] Epoch: [15]  [ 0/27]  eta: 0:01:28  loss: 0.0144 (0.0144)  MSE: 0.0214 (0.0214)  MAE: 0.1189 (0.1189)  PSNR: 14.7385 (14.7385)  SSIM: 0.1129 (0.1129)  lr: 0.000100  iter-time: 3.2799\n",
            "[08:21:42.978335] Epoch: [15]  [10/27]  eta: 0:00:11  loss: 0.0140 (0.0142)  MSE: 0.0221 (0.0222)  MAE: 0.1212 (0.1214)  PSNR: 14.9150 (14.9353)  SSIM: 0.1100 (0.1103)  lr: 0.000100  iter-time: 0.6703\n",
            "[08:21:50.249071] Epoch: [15]  [20/27]  eta: 0:00:04  loss: 0.0139 (0.0141)  MSE: 0.0222 (0.0222)  MAE: 0.1213 (0.1214)  PSNR: 14.8756 (14.9382)  SSIM: 0.1080 (0.1094)  lr: 0.000100  iter-time: 0.5681\n",
            "[08:21:52.835393] Epoch: [15]  [26/27]  eta: 0:00:00  loss: 0.0140 (0.0141)  MSE: 0.0221 (0.0222)  MAE: 0.1212 (0.1213)  PSNR: 14.8850 (14.9645)  SSIM: 0.1075 (0.1093)  lr: 0.000100  iter-time: 0.5733\n",
            "[08:21:52.945351] Epoch: [15] Total time: 0:00:17 (0.6424 s / it)\n",
            "[08:21:52.946317] [Train] averaged stats: loss: 0.0140 (0.0141)  MSE: 0.0221 (0.0222)  MAE: 0.1212 (0.1213)  PSNR: 14.8850 (14.9645)  SSIM: 0.1075 (0.1093)  lr: 0.000100\n",
            "[08:21:53.483858] Epoch: [15]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0222 (0.0222)  MAE: 0.1211 (0.1211)  PSNR: 14.8456 (14.8456)  SSIM: 0.1095 (0.1095)  iter-time: 0.5307\n",
            "[08:21:53.931625] Epoch: [15]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0227 (0.0228)  MAE: 0.1233 (0.1233)  PSNR: 14.8456 (14.8417)  SSIM: 0.1061 (0.1072)  iter-time: 0.3259\n",
            "[08:21:54.017147] Epoch: [15] Total time: 0:00:01 (0.3549 s / it)\n",
            "[08:21:54.018085] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0227 (0.0228)  MAE: 0.1233 (0.1233)  PSNR: 14.8456 (14.8417)  SSIM: 0.1061 (0.1072)\n",
            "[08:21:54.019514] [Val] best loss: 0.0146 best  MSE: 0.0231 MAE: 0.1239 PSNR: 14.8290 SSIM: 0.1090 \n",
            "[08:21:54.020598] Creating training plots . . .\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:21:54.799807] [Time] 19.2s 6.2m/33.7m\n",
            "\n",
            "[08:21:54.799868] ~~~ Epoch 16/100 ~~~\n",
            "\n",
            "[08:21:57.410600] Epoch: [16]  [ 0/27]  eta: 0:01:10  loss: 0.0144 (0.0144)  MSE: 0.0213 (0.0213)  MAE: 0.1189 (0.1189)  PSNR: 14.7692 (14.7692)  SSIM: 0.1109 (0.1109)  lr: 0.000100  iter-time: 2.6068\n",
            "[08:22:02.892137] Epoch: [16]  [10/27]  eta: 0:00:12  loss: 0.0141 (0.0141)  MSE: 0.0220 (0.0220)  MAE: 0.1210 (0.1210)  PSNR: 14.8008 (14.8000)  SSIM: 0.1127 (0.1113)  lr: 0.000100  iter-time: 0.7345\n",
            "[08:22:11.845480] Epoch: [16]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0141)  MSE: 0.0220 (0.0221)  MAE: 0.1210 (0.1211)  PSNR: 14.8008 (14.8769)  SSIM: 0.1067 (0.1093)  lr: 0.000100  iter-time: 0.7210\n",
            "[08:22:14.590557] Epoch: [16]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0140)  MSE: 0.0220 (0.0220)  MAE: 0.1211 (0.1209)  PSNR: 14.8488 (14.8907)  SSIM: 0.1057 (0.1089)  lr: 0.000100  iter-time: 0.6856\n",
            "[08:22:14.694549] Epoch: [16] Total time: 0:00:19 (0.7368 s / it)\n",
            "[08:22:14.694700] [Train] averaged stats: loss: 0.0141 (0.0140)  MSE: 0.0220 (0.0220)  MAE: 0.1211 (0.1209)  PSNR: 14.8488 (14.8907)  SSIM: 0.1057 (0.1089)  lr: 0.000100\n",
            "[08:22:15.238006] Epoch: [16]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0220 (0.0220)  MAE: 0.1206 (0.1206)  PSNR: 14.8264 (14.8264)  SSIM: 0.1067 (0.1067)  iter-time: 0.5352\n",
            "[08:22:15.683175] Epoch: [16]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0226 (0.0226)  MAE: 0.1229 (0.1229)  PSNR: 14.8264 (14.8228)  SSIM: 0.1036 (0.1046)  iter-time: 0.3265\n",
            "[08:22:15.768049] Epoch: [16] Total time: 0:00:01 (0.3554 s / it)\n",
            "[08:22:15.768908] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0226 (0.0226)  MAE: 0.1229 (0.1229)  PSNR: 14.8264 (14.8228)  SSIM: 0.1036 (0.1046)\n",
            "[08:22:15.770855] [Val] best loss: 0.0146 best  MSE: 0.0231 MAE: 0.1239 PSNR: 14.8290 SSIM: 0.1090 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:22:15.773558] [Time] 21.0s 6.5m/36.2m\n",
            "\n",
            "[08:22:15.773614] ~~~ Epoch 17/100 ~~~\n",
            "\n",
            "[08:22:19.442457] Epoch: [17]  [ 0/27]  eta: 0:01:38  loss: 0.0145 (0.0145)  MSE: 0.0213 (0.0213)  MAE: 0.1189 (0.1189)  PSNR: 14.6148 (14.6148)  SSIM: 0.1091 (0.1091)  lr: 0.000100  iter-time: 3.6652\n",
            "[08:22:25.922645] Epoch: [17]  [10/27]  eta: 0:00:15  loss: 0.0143 (0.0142)  MSE: 0.0218 (0.0219)  MAE: 0.1206 (0.1208)  PSNR: 14.7818 (14.8248)  SSIM: 0.1091 (0.1090)  lr: 0.000100  iter-time: 0.9220\n",
            "[08:22:31.736688] Epoch: [17]  [20/27]  eta: 0:00:05  loss: 0.0142 (0.0142)  MSE: 0.0219 (0.0219)  MAE: 0.1207 (0.1208)  PSNR: 14.7962 (14.8858)  SSIM: 0.1060 (0.1072)  lr: 0.000100  iter-time: 0.6144\n",
            "[08:22:33.861128] Epoch: [17]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0218 (0.0219)  MAE: 0.1206 (0.1206)  PSNR: 14.8453 (14.8977)  SSIM: 0.1060 (0.1074)  lr: 0.000100  iter-time: 0.5547\n",
            "[08:22:33.960933] Epoch: [17] Total time: 0:00:18 (0.6735 s / it)\n",
            "[08:22:33.962114] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0218 (0.0219)  MAE: 0.1206 (0.1206)  PSNR: 14.8453 (14.8977)  SSIM: 0.1060 (0.1074)  lr: 0.000100\n",
            "[08:22:34.443296] Epoch: [17]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0219 (0.0219)  MAE: 0.1203 (0.1203)  PSNR: 14.8430 (14.8430)  SSIM: 0.1071 (0.1071)  iter-time: 0.4762\n",
            "[08:22:34.893077] Epoch: [17]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0224 (0.0224)  MAE: 0.1225 (0.1225)  PSNR: 14.8430 (14.8406)  SSIM: 0.1041 (0.1050)  iter-time: 0.3079\n",
            "[08:22:34.979525] Epoch: [17] Total time: 0:00:01 (0.3377 s / it)\n",
            "[08:22:34.979669] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0224 (0.0224)  MAE: 0.1225 (0.1225)  PSNR: 14.8430 (14.8406)  SSIM: 0.1041 (0.1050)\n",
            "[08:22:34.982238] Val loss improved from 0.014649163310726484 to 0.014645199291408062, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:22:43.293065] [Val] best loss: 0.0146 best  MSE: 0.0224 MAE: 0.1225 PSNR: 14.8406 SSIM: 0.1050 \n",
            "[08:22:43.296320] [Time] 27.5s 7.0m/45.5m\n",
            "\n",
            "[08:22:43.296422] ~~~ Epoch 18/100 ~~~\n",
            "\n",
            "[08:22:46.316891] Epoch: [18]  [ 0/27]  eta: 0:01:21  loss: 0.0142 (0.0142)  MSE: 0.0212 (0.0212)  MAE: 0.1186 (0.1186)  PSNR: 14.6217 (14.6217)  SSIM: 0.1078 (0.1078)  lr: 0.000100  iter-time: 3.0163\n",
            "[08:22:52.670130] Epoch: [18]  [10/27]  eta: 0:00:14  loss: 0.0142 (0.0141)  MSE: 0.0216 (0.0217)  MAE: 0.1200 (0.1203)  PSNR: 14.8949 (14.8852)  SSIM: 0.1081 (0.1076)  lr: 0.000100  iter-time: 0.8506\n",
            "[08:22:58.798687] Epoch: [18]  [20/27]  eta: 0:00:05  loss: 0.0139 (0.0141)  MSE: 0.0217 (0.0218)  MAE: 0.1204 (0.1204)  PSNR: 14.8949 (14.9304)  SSIM: 0.1063 (0.1062)  lr: 0.000100  iter-time: 0.6233\n",
            "[08:23:02.189119] Epoch: [18]  [26/27]  eta: 0:00:00  loss: 0.0140 (0.0140)  MSE: 0.0215 (0.0217)  MAE: 0.1200 (0.1202)  PSNR: 14.9408 (14.9351)  SSIM: 0.1057 (0.1064)  lr: 0.000100  iter-time: 0.5608\n",
            "[08:23:02.285846] Epoch: [18] Total time: 0:00:18 (0.7032 s / it)\n",
            "[08:23:02.288987] [Train] averaged stats: loss: 0.0140 (0.0140)  MSE: 0.0215 (0.0217)  MAE: 0.1200 (0.1202)  PSNR: 14.9408 (14.9351)  SSIM: 0.1057 (0.1064)  lr: 0.000100\n",
            "[08:23:02.766132] Epoch: [18]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0218 (0.0218)  MAE: 0.1202 (0.1202)  PSNR: 14.8548 (14.8548)  SSIM: 0.1067 (0.1067)  iter-time: 0.4721\n",
            "[08:23:03.205589] Epoch: [18]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0223 (0.0224)  MAE: 0.1224 (0.1225)  PSNR: 14.8548 (14.8534)  SSIM: 0.1036 (0.1045)  iter-time: 0.3036\n",
            "[08:23:03.289533] Epoch: [18] Total time: 0:00:00 (0.3321 s / it)\n",
            "[08:23:03.289663] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0223 (0.0224)  MAE: 0.1224 (0.1225)  PSNR: 14.8548 (14.8534)  SSIM: 0.1036 (0.1045)\n",
            "[08:23:03.292205] [Val] best loss: 0.0146 best  MSE: 0.0224 MAE: 0.1225 PSNR: 14.8406 SSIM: 0.1050 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:23:03.295477] [Time] 20.0s 7.3m/35.0m\n",
            "\n",
            "[08:23:03.295549] ~~~ Epoch 19/100 ~~~\n",
            "\n",
            "[08:23:06.000784] Epoch: [19]  [ 0/27]  eta: 0:01:12  loss: 0.0144 (0.0144)  MSE: 0.0209 (0.0209)  MAE: 0.1180 (0.1180)  PSNR: 14.7301 (14.7301)  SSIM: 0.1080 (0.1080)  lr: 0.000100  iter-time: 2.7022\n",
            "[08:23:10.977003] Epoch: [19]  [10/27]  eta: 0:00:11  loss: 0.0143 (0.0142)  MSE: 0.0216 (0.0216)  MAE: 0.1201 (0.1202)  PSNR: 14.9018 (14.9286)  SSIM: 0.1061 (0.1062)  lr: 0.000100  iter-time: 0.6978\n",
            "[08:23:19.919339] Epoch: [19]  [20/27]  eta: 0:00:05  loss: 0.0143 (0.0142)  MSE: 0.0216 (0.0217)  MAE: 0.1202 (0.1202)  PSNR: 14.9018 (14.9324)  SSIM: 0.1041 (0.1050)  lr: 0.000100  iter-time: 0.6952\n",
            "[08:23:22.044523] Epoch: [19]  [26/27]  eta: 0:00:00  loss: 0.0143 (0.0141)  MSE: 0.0216 (0.0216)  MAE: 0.1199 (0.1200)  PSNR: 14.9018 (14.9318)  SSIM: 0.1040 (0.1053)  lr: 0.000100  iter-time: 0.6653\n",
            "[08:23:22.143052] Epoch: [19] Total time: 0:00:18 (0.6980 s / it)\n",
            "[08:23:22.143209] [Train] averaged stats: loss: 0.0143 (0.0141)  MSE: 0.0216 (0.0216)  MAE: 0.1199 (0.1200)  PSNR: 14.9018 (14.9318)  SSIM: 0.1040 (0.1053)  lr: 0.000100\n",
            "[08:23:22.685318] Epoch: [19]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0216 (0.0216)  MAE: 0.1196 (0.1196)  PSNR: 14.8456 (14.8456)  SSIM: 0.1037 (0.1037)  iter-time: 0.5358\n",
            "[08:23:23.136693] Epoch: [19]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0222 (0.0222)  MAE: 0.1219 (0.1219)  PSNR: 14.8456 (14.8431)  SSIM: 0.1005 (0.1015)  iter-time: 0.3288\n",
            "[08:23:23.220704] Epoch: [19] Total time: 0:00:01 (0.3573 s / it)\n",
            "[08:23:23.220834] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0222 (0.0222)  MAE: 0.1219 (0.1219)  PSNR: 14.8456 (14.8431)  SSIM: 0.1005 (0.1015)\n",
            "[08:23:23.223352] Val loss improved from 0.014645199291408062 to 0.014634987028936544, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:23:30.209638] [Val] best loss: 0.0146 best  MSE: 0.0222 MAE: 0.1219 PSNR: 14.8431 SSIM: 0.1015 \n",
            "[08:23:30.212601] [Time] 26.9s 7.8m/44.6m\n",
            "\n",
            "[08:23:30.213495] ~~~ Epoch 20/100 ~~~\n",
            "\n",
            "[08:23:32.040743] Epoch: [20]  [ 0/27]  eta: 0:00:49  loss: 0.0146 (0.0146)  MSE: 0.0211 (0.0211)  MAE: 0.1185 (0.1185)  PSNR: 14.7357 (14.7357)  SSIM: 0.1020 (0.1020)  lr: 0.000100  iter-time: 1.8211\n",
            "[08:23:37.747010] Epoch: [20]  [10/27]  eta: 0:00:11  loss: 0.0142 (0.0142)  MSE: 0.0216 (0.0216)  MAE: 0.1199 (0.1200)  PSNR: 14.9318 (14.9426)  SSIM: 0.1051 (0.1047)  lr: 0.000100  iter-time: 0.6841\n",
            "[08:23:42.346276] Epoch: [20]  [20/27]  eta: 0:00:04  loss: 0.0142 (0.0142)  MSE: 0.0216 (0.0216)  MAE: 0.1199 (0.1200)  PSNR: 14.9318 (14.9646)  SSIM: 0.1022 (0.1030)  lr: 0.000100  iter-time: 0.5150\n",
            "[08:23:44.658876] Epoch: [20]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0215 (0.0215)  MAE: 0.1198 (0.1198)  PSNR: 14.9124 (14.9811)  SSIM: 0.1017 (0.1035)  lr: 0.000100  iter-time: 0.4274\n",
            "[08:23:44.808844] Epoch: [20] Total time: 0:00:14 (0.5404 s / it)\n",
            "[08:23:44.809962] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0215 (0.0215)  MAE: 0.1198 (0.1198)  PSNR: 14.9124 (14.9811)  SSIM: 0.1017 (0.1035)  lr: 0.000100\n",
            "[08:23:45.429649] Epoch: [20]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0215 (0.0215)  MAE: 0.1194 (0.1194)  PSNR: 14.8542 (14.8542)  SSIM: 0.1045 (0.1045)  iter-time: 0.6120\n",
            "[08:23:45.879441] Epoch: [20]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0220 (0.0221)  MAE: 0.1217 (0.1217)  PSNR: 14.8542 (14.8526)  SSIM: 0.1014 (0.1024)  iter-time: 0.3536\n",
            "[08:23:45.964022] Epoch: [20] Total time: 0:00:01 (0.3824 s / it)\n",
            "[08:23:45.964154] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0220 (0.0221)  MAE: 0.1217 (0.1217)  PSNR: 14.8542 (14.8526)  SSIM: 0.1014 (0.1024)\n",
            "[08:23:45.966708] [Val] best loss: 0.0146 best  MSE: 0.0222 MAE: 0.1219 PSNR: 14.8431 SSIM: 0.1015 \n",
            "[08:23:45.969427] Creating training plots . . .\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:23:46.818697] [Time] 16.6s 8.1m/30.5m\n",
            "\n",
            "[08:23:46.818758] ~~~ Epoch 21/100 ~~~\n",
            "\n",
            "[08:23:50.813469] Epoch: [21]  [ 0/27]  eta: 0:01:47  loss: 0.0143 (0.0143)  MSE: 0.0207 (0.0207)  MAE: 0.1175 (0.1175)  PSNR: 14.6993 (14.6993)  SSIM: 0.1086 (0.1086)  lr: 0.000100  iter-time: 3.9910\n",
            "[08:23:56.319104] Epoch: [21]  [10/27]  eta: 0:00:14  loss: 0.0143 (0.0141)  MSE: 0.0214 (0.0214)  MAE: 0.1196 (0.1195)  PSNR: 14.9454 (14.9089)  SSIM: 0.1049 (0.1050)  lr: 0.000100  iter-time: 0.8632\n",
            "[08:24:02.465228] Epoch: [21]  [20/27]  eta: 0:00:05  loss: 0.0142 (0.0142)  MSE: 0.0214 (0.0214)  MAE: 0.1196 (0.1197)  PSNR: 14.9454 (14.9240)  SSIM: 0.1001 (0.1028)  lr: 0.000100  iter-time: 0.5821\n",
            "[08:24:04.602911] Epoch: [21]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0214 (0.0214)  MAE: 0.1196 (0.1195)  PSNR: 14.9703 (14.9516)  SSIM: 0.1001 (0.1028)  lr: 0.000100  iter-time: 0.5427\n",
            "[08:24:04.703256] Epoch: [21] Total time: 0:00:17 (0.6623 s / it)\n",
            "[08:24:04.705592] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0214 (0.0214)  MAE: 0.1196 (0.1195)  PSNR: 14.9703 (14.9516)  SSIM: 0.1001 (0.1028)  lr: 0.000100\n",
            "[08:24:05.198292] Epoch: [21]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0213 (0.0213)  MAE: 0.1191 (0.1191)  PSNR: 14.8412 (14.8412)  SSIM: 0.1026 (0.1026)  iter-time: 0.4858\n",
            "[08:24:05.649849] Epoch: [21]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0219 (0.0219)  MAE: 0.1214 (0.1213)  PSNR: 14.8412 (14.8397)  SSIM: 0.0997 (0.1006)  iter-time: 0.3121\n",
            "[08:24:05.734881] Epoch: [21] Total time: 0:00:01 (0.3410 s / it)\n",
            "[08:24:05.735008] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0219 (0.0219)  MAE: 0.1214 (0.1213)  PSNR: 14.8412 (14.8397)  SSIM: 0.0997 (0.1006)\n",
            "[08:24:05.737394] [Val] best loss: 0.0146 best  MSE: 0.0222 MAE: 0.1219 PSNR: 14.8431 SSIM: 0.1015 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:24:05.740155] [Time] 18.9s 8.4m/33.6m\n",
            "\n",
            "[08:24:05.740209] ~~~ Epoch 22/100 ~~~\n",
            "\n",
            "[08:24:08.450114] Epoch: [22]  [ 0/27]  eta: 0:01:13  loss: 0.0144 (0.0144)  MSE: 0.0208 (0.0208)  MAE: 0.1177 (0.1177)  PSNR: 14.6195 (14.6195)  SSIM: 0.1040 (0.1040)  lr: 0.000100  iter-time: 2.7062\n",
            "[08:24:13.187117] Epoch: [22]  [10/27]  eta: 0:00:11  loss: 0.0142 (0.0142)  MSE: 0.0213 (0.0213)  MAE: 0.1193 (0.1194)  PSNR: 14.9819 (14.8955)  SSIM: 0.1024 (0.1027)  lr: 0.000100  iter-time: 0.6763\n",
            "[08:24:21.345162] Epoch: [22]  [20/27]  eta: 0:00:05  loss: 0.0142 (0.0142)  MSE: 0.0213 (0.0213)  MAE: 0.1194 (0.1194)  PSNR: 14.9680 (14.9080)  SSIM: 0.0994 (0.1009)  lr: 0.000100  iter-time: 0.6443\n",
            "[08:24:23.887346] Epoch: [22]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0213 (0.0212)  MAE: 0.1192 (0.1192)  PSNR: 14.8835 (14.9298)  SSIM: 0.1006 (0.1018)  lr: 0.000100  iter-time: 0.6171\n",
            "[08:24:23.987743] Epoch: [22] Total time: 0:00:18 (0.6758 s / it)\n",
            "[08:24:23.989182] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0213 (0.0212)  MAE: 0.1192 (0.1192)  PSNR: 14.8835 (14.9298)  SSIM: 0.1006 (0.1018)  lr: 0.000100\n",
            "[08:24:24.453053] Epoch: [22]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0212 (0.0212)  MAE: 0.1185 (0.1185)  PSNR: 14.8305 (14.8305)  SSIM: 0.0997 (0.0997)  iter-time: 0.4582\n",
            "[08:24:24.897988] Epoch: [22]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0217 (0.0217)  MAE: 0.1209 (0.1208)  PSNR: 14.8305 (14.8291)  SSIM: 0.0968 (0.0977)  iter-time: 0.3001\n",
            "[08:24:24.990792] Epoch: [22] Total time: 0:00:00 (0.3322 s / it)\n",
            "[08:24:24.990950] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0217 (0.0217)  MAE: 0.1209 (0.1208)  PSNR: 14.8305 (14.8291)  SSIM: 0.0968 (0.0977)\n",
            "[08:24:24.991904] Val loss improved from 0.014634987028936544 to 0.014629139254490534, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:24:31.658369] [Val] best loss: 0.0146 best  MSE: 0.0217 MAE: 0.1208 PSNR: 14.8291 SSIM: 0.0977 \n",
            "[08:24:31.661287] [Time] 25.9s 8.8m/42.9m\n",
            "\n",
            "[08:24:31.662207] ~~~ Epoch 23/100 ~~~\n",
            "\n",
            "[08:24:36.219128] Epoch: [23]  [ 0/27]  eta: 0:02:02  loss: 0.0141 (0.0141)  MSE: 0.0206 (0.0206)  MAE: 0.1174 (0.1174)  PSNR: 14.5797 (14.5797)  SSIM: 0.1023 (0.1023)  lr: 0.000100  iter-time: 4.5500\n",
            "[08:24:42.648176] Epoch: [23]  [10/27]  eta: 0:00:16  loss: 0.0141 (0.0141)  MSE: 0.0210 (0.0211)  MAE: 0.1188 (0.1190)  PSNR: 14.9671 (14.9052)  SSIM: 0.1007 (0.1002)  lr: 0.000100  iter-time: 0.9960\n",
            "[08:24:47.352756] Epoch: [23]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0212 (0.0212)  MAE: 0.1190 (0.1192)  PSNR: 14.9671 (14.9562)  SSIM: 0.0999 (0.0998)  lr: 0.000100  iter-time: 0.5554\n",
            "[08:24:49.459076] Epoch: [23]  [26/27]  eta: 0:00:00  loss: 0.0143 (0.0141)  MSE: 0.0211 (0.0211)  MAE: 0.1189 (0.1190)  PSNR: 14.9495 (14.9679)  SSIM: 0.0999 (0.0994)  lr: 0.000100  iter-time: 0.4762\n",
            "[08:24:49.547338] Epoch: [23] Total time: 0:00:17 (0.6622 s / it)\n",
            "[08:24:49.548393] [Train] averaged stats: loss: 0.0143 (0.0141)  MSE: 0.0211 (0.0211)  MAE: 0.1189 (0.1190)  PSNR: 14.9495 (14.9679)  SSIM: 0.0999 (0.0994)  lr: 0.000100\n",
            "[08:24:50.081873] Epoch: [23]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0210 (0.0210)  MAE: 0.1182 (0.1182)  PSNR: 14.8538 (14.8538)  SSIM: 0.0984 (0.0984)  iter-time: 0.5281\n",
            "[08:24:50.529209] Epoch: [23]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0147)  MSE: 0.0216 (0.0216)  MAE: 0.1206 (0.1205)  PSNR: 14.8538 (14.8525)  SSIM: 0.0956 (0.0964)  iter-time: 0.3249\n",
            "[08:24:50.616212] Epoch: [23] Total time: 0:00:01 (0.3544 s / it)\n",
            "[08:24:50.617183] [Val] averaged stats: loss: 0.0147 (0.0147)  MSE: 0.0216 (0.0216)  MAE: 0.1206 (0.1205)  PSNR: 14.8538 (14.8525)  SSIM: 0.0956 (0.0964)\n",
            "[08:24:50.618963] [Val] best loss: 0.0146 best  MSE: 0.0217 MAE: 0.1208 PSNR: 14.8291 SSIM: 0.0977 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:24:50.621661] [Time] 19.0s 9.1m/33.8m\n",
            "\n",
            "[08:24:50.621719] ~~~ Epoch 24/100 ~~~\n",
            "\n",
            "[08:24:53.324386] Epoch: [24]  [ 0/27]  eta: 0:01:12  loss: 0.0143 (0.0143)  MSE: 0.0206 (0.0206)  MAE: 0.1172 (0.1172)  PSNR: 14.6539 (14.6539)  SSIM: 0.0994 (0.0994)  lr: 0.000100  iter-time: 2.6999\n",
            "[08:25:02.686284] Epoch: [24]  [10/27]  eta: 0:00:18  loss: 0.0141 (0.0142)  MSE: 0.0210 (0.0211)  MAE: 0.1188 (0.1189)  PSNR: 14.9035 (14.8878)  SSIM: 0.1002 (0.1010)  lr: 0.000100  iter-time: 1.0946\n",
            "[08:25:07.489270] Epoch: [24]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0211 (0.0211)  MAE: 0.1188 (0.1189)  PSNR: 14.9035 (14.9124)  SSIM: 0.0968 (0.0989)  lr: 0.000100  iter-time: 0.7071\n",
            "[08:25:09.617235] Epoch: [24]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0209 (0.0210)  MAE: 0.1185 (0.1187)  PSNR: 14.9035 (14.9463)  SSIM: 0.0969 (0.0991)  lr: 0.000100  iter-time: 0.5369\n",
            "[08:25:09.721863] Epoch: [24] Total time: 0:00:19 (0.7073 s / it)\n",
            "[08:25:09.722814] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0209 (0.0210)  MAE: 0.1185 (0.1187)  PSNR: 14.9035 (14.9463)  SSIM: 0.0969 (0.0991)  lr: 0.000100\n",
            "[08:25:10.269989] Epoch: [24]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0209 (0.0209)  MAE: 0.1182 (0.1182)  PSNR: 14.8627 (14.8627)  SSIM: 0.0986 (0.0986)  iter-time: 0.5409\n",
            "[08:25:10.725504] Epoch: [24]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0215 (0.0215)  MAE: 0.1205 (0.1204)  PSNR: 14.8627 (14.8620)  SSIM: 0.0959 (0.0967)  iter-time: 0.3313\n",
            "[08:25:10.868272] Epoch: [24] Total time: 0:00:01 (0.3799 s / it)\n",
            "[08:25:10.868439] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0215 (0.0215)  MAE: 0.1205 (0.1204)  PSNR: 14.8627 (14.8620)  SSIM: 0.0959 (0.0967)\n",
            "[08:25:10.869187] [Val] best loss: 0.0146 best  MSE: 0.0217 MAE: 0.1208 PSNR: 14.8291 SSIM: 0.0977 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:25:10.873915] [Time] 20.3s 9.5m/35.4m\n",
            "\n",
            "[08:25:10.873957] ~~~ Epoch 25/100 ~~~\n",
            "\n",
            "[08:25:17.953156] Epoch: [25]  [ 0/27]  eta: 0:03:10  loss: 0.0141 (0.0141)  MSE: 0.0202 (0.0202)  MAE: 0.1162 (0.1162)  PSNR: 14.7081 (14.7081)  SSIM: 0.1031 (0.1031)  lr: 0.000100  iter-time: 7.0725\n",
            "[08:25:22.643245] Epoch: [25]  [10/27]  eta: 0:00:18  loss: 0.0141 (0.0141)  MSE: 0.0208 (0.0209)  MAE: 0.1184 (0.1184)  PSNR: 14.8743 (14.8206)  SSIM: 0.1007 (0.0997)  lr: 0.000100  iter-time: 1.0692\n",
            "[08:25:27.453302] Epoch: [25]  [20/27]  eta: 0:00:05  loss: 0.0140 (0.0141)  MSE: 0.0209 (0.0209)  MAE: 0.1184 (0.1185)  PSNR: 14.8521 (14.8831)  SSIM: 0.0977 (0.0984)  lr: 0.000100  iter-time: 0.4748\n",
            "[08:25:29.572091] Epoch: [25]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0208 (0.0208)  MAE: 0.1183 (0.1183)  PSNR: 14.8436 (14.9259)  SSIM: 0.0966 (0.0982)  lr: 0.000100  iter-time: 0.4490\n",
            "[08:25:29.732422] Epoch: [25] Total time: 0:00:18 (0.6982 s / it)\n",
            "[08:25:29.733364] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0208 (0.0208)  MAE: 0.1183 (0.1183)  PSNR: 14.8436 (14.9259)  SSIM: 0.0966 (0.0982)  lr: 0.000100\n",
            "[08:25:30.431062] Epoch: [25]  [0/3]  eta: 0:00:02  loss: 0.0140 (0.0140)  MSE: 0.0208 (0.0208)  MAE: 0.1177 (0.1177)  PSNR: 14.8519 (14.8519)  SSIM: 0.0969 (0.0969)  iter-time: 0.6908\n",
            "[08:25:30.877393] Epoch: [25]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0214 (0.0214)  MAE: 0.1201 (0.1200)  PSNR: 14.8519 (14.8505)  SSIM: 0.0943 (0.0950)  iter-time: 0.3787\n",
            "[08:25:31.045800] Epoch: [25] Total time: 0:00:01 (0.4355 s / it)\n",
            "[08:25:31.046032] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0214 (0.0214)  MAE: 0.1201 (0.1200)  PSNR: 14.8519 (14.8505)  SSIM: 0.0943 (0.0950)\n",
            "[08:25:31.050263] Val loss improved from 0.014629139254490534 to 0.014620010430614153, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:25:38.038846] [Val] best loss: 0.0146 best  MSE: 0.0214 MAE: 0.1200 PSNR: 14.8505 SSIM: 0.0950 \n",
            "[08:25:38.041963] Creating training plots . . .\n",
            "[08:25:39.105109] [Time] 28.2s 9.9m/45.7m\n",
            "\n",
            "[08:25:39.105261] ~~~ Epoch 26/100 ~~~\n",
            "\n",
            "[08:25:42.404123] Epoch: [26]  [ 0/27]  eta: 0:01:28  loss: 0.0141 (0.0141)  MSE: 0.0203 (0.0203)  MAE: 0.1166 (0.1166)  PSNR: 14.7068 (14.7068)  SSIM: 0.0991 (0.0991)  lr: 0.000100  iter-time: 3.2948\n",
            "[08:25:51.227458] Epoch: [26]  [10/27]  eta: 0:00:18  loss: 0.0141 (0.0141)  MSE: 0.0207 (0.0208)  MAE: 0.1181 (0.1183)  PSNR: 14.9667 (14.9424)  SSIM: 0.0991 (0.0990)  lr: 0.000100  iter-time: 1.1004\n",
            "[08:25:55.999922] Epoch: [26]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0207 (0.0208)  MAE: 0.1182 (0.1183)  PSNR: 14.9667 (14.9886)  SSIM: 0.0952 (0.0969)  lr: 0.000100  iter-time: 0.6787\n",
            "[08:25:58.112887] Epoch: [26]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0207 (0.0207)  MAE: 0.1181 (0.1181)  PSNR: 14.9844 (15.0063)  SSIM: 0.0952 (0.0974)  lr: 0.000100  iter-time: 0.5544\n",
            "[08:25:58.209775] Epoch: [26] Total time: 0:00:19 (0.7075 s / it)\n",
            "[08:25:58.211696] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0207 (0.0207)  MAE: 0.1181 (0.1181)  PSNR: 14.9844 (15.0063)  SSIM: 0.0952 (0.0974)  lr: 0.000100\n",
            "[08:25:58.749946] Epoch: [26]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0207 (0.0207)  MAE: 0.1174 (0.1174)  PSNR: 14.8856 (14.8856)  SSIM: 0.0954 (0.0954)  iter-time: 0.5303\n",
            "[08:25:59.204290] Epoch: [26]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0212 (0.0212)  MAE: 0.1198 (0.1197)  PSNR: 14.8856 (14.8837)  SSIM: 0.0935 (0.0938)  iter-time: 0.3279\n",
            "[08:25:59.291937] Epoch: [26] Total time: 0:00:01 (0.3577 s / it)\n",
            "[08:25:59.292928] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0212 (0.0212)  MAE: 0.1198 (0.1197)  PSNR: 14.8856 (14.8837)  SSIM: 0.0935 (0.0938)\n",
            "[08:25:59.294690] [Val] best loss: 0.0146 best  MSE: 0.0214 MAE: 0.1200 PSNR: 14.8505 SSIM: 0.0950 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:25:59.297498] [Time] 20.2s 10.3m/35.5m\n",
            "\n",
            "[08:25:59.297549] ~~~ Epoch 27/100 ~~~\n",
            "\n",
            "[08:26:03.120130] Epoch: [27]  [ 0/27]  eta: 0:01:42  loss: 0.0142 (0.0142)  MSE: 0.0201 (0.0201)  MAE: 0.1161 (0.1161)  PSNR: 14.6269 (14.6269)  SSIM: 0.0963 (0.0963)  lr: 0.000100  iter-time: 3.8076\n",
            "[08:26:10.990990] Epoch: [27]  [10/27]  eta: 0:00:18  loss: 0.0141 (0.0141)  MSE: 0.0206 (0.0207)  MAE: 0.1177 (0.1181)  PSNR: 14.9804 (14.9462)  SSIM: 0.0987 (0.0980)  lr: 0.000100  iter-time: 1.0597\n",
            "[08:26:15.343178] Epoch: [27]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0141)  MSE: 0.0207 (0.0207)  MAE: 0.1180 (0.1181)  PSNR: 14.9783 (14.9581)  SSIM: 0.0954 (0.0965)  lr: 0.000100  iter-time: 0.6100\n",
            "[08:26:17.476923] Epoch: [27]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0206 (0.0207)  MAE: 0.1176 (0.1179)  PSNR: 14.9386 (14.9701)  SSIM: 0.0952 (0.0963)  lr: 0.000100  iter-time: 0.5395\n",
            "[08:26:17.577067] Epoch: [27] Total time: 0:00:18 (0.6769 s / it)\n",
            "[08:26:17.578144] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0206 (0.0207)  MAE: 0.1176 (0.1179)  PSNR: 14.9386 (14.9701)  SSIM: 0.0952 (0.0963)  lr: 0.000100\n",
            "[08:26:18.130707] Epoch: [27]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0206 (0.0206)  MAE: 0.1173 (0.1173)  PSNR: 14.8499 (14.8499)  SSIM: 0.0968 (0.0968)  iter-time: 0.5478\n",
            "[08:26:18.585718] Epoch: [27]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0212 (0.0212)  MAE: 0.1197 (0.1196)  PSNR: 14.8499 (14.8411)  SSIM: 0.0939 (0.0947)  iter-time: 0.3335\n",
            "[08:26:18.674874] Epoch: [27] Total time: 0:00:01 (0.3642 s / it)\n",
            "[08:26:18.675012] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0212 (0.0212)  MAE: 0.1197 (0.1196)  PSNR: 14.8499 (14.8411)  SSIM: 0.0939 (0.0947)\n",
            "[08:26:18.677634] [Val] best loss: 0.0146 best  MSE: 0.0214 MAE: 0.1200 PSNR: 14.8505 SSIM: 0.0950 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:26:18.680479] [Time] 19.4s 10.6m/34.5m\n",
            "\n",
            "[08:26:18.680557] ~~~ Epoch 28/100 ~~~\n",
            "\n",
            "[08:26:24.671345] Epoch: [28]  [ 0/27]  eta: 0:02:41  loss: 0.0142 (0.0142)  MSE: 0.0200 (0.0200)  MAE: 0.1159 (0.1159)  PSNR: 14.5048 (14.5048)  SSIM: 0.1006 (0.1006)  lr: 0.000100  iter-time: 5.9878\n",
            "[08:26:31.221044] Epoch: [28]  [10/27]  eta: 0:00:19  loss: 0.0141 (0.0142)  MSE: 0.0206 (0.0206)  MAE: 0.1178 (0.1180)  PSNR: 15.0079 (14.8742)  SSIM: 0.0994 (0.0974)  lr: 0.000100  iter-time: 1.1385\n",
            "[08:26:35.238973] Epoch: [28]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0142)  MSE: 0.0207 (0.0207)  MAE: 0.1179 (0.1180)  PSNR: 15.0079 (14.9103)  SSIM: 0.0944 (0.0962)  lr: 0.000100  iter-time: 0.5274\n",
            "[08:26:37.351817] Epoch: [28]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0206 (0.0206)  MAE: 0.1176 (0.1178)  PSNR: 15.0307 (14.9531)  SSIM: 0.0943 (0.0957)  lr: 0.000100  iter-time: 0.3880\n",
            "[08:26:37.455074] Epoch: [28] Total time: 0:00:18 (0.6953 s / it)\n",
            "[08:26:37.456348] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0206 (0.0206)  MAE: 0.1176 (0.1178)  PSNR: 15.0307 (14.9531)  SSIM: 0.0943 (0.0957)  lr: 0.000100\n",
            "[08:26:37.978978] Epoch: [28]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0205 (0.0205)  MAE: 0.1169 (0.1169)  PSNR: 14.9197 (14.9197)  SSIM: 0.0948 (0.0948)  iter-time: 0.5172\n",
            "[08:26:38.426541] Epoch: [28]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0211 (0.0210)  MAE: 0.1194 (0.1192)  PSNR: 14.9197 (14.8965)  SSIM: 0.0939 (0.0936)  iter-time: 0.3213\n",
            "[08:26:38.540358] Epoch: [28] Total time: 0:00:01 (0.3598 s / it)\n",
            "[08:26:38.540519] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0211 (0.0210)  MAE: 0.1194 (0.1192)  PSNR: 14.9197 (14.8965)  SSIM: 0.0939 (0.0936)\n",
            "[08:26:38.541233] Val loss improved from 0.014620010430614153 to 0.014617755698661009, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:26:45.461651] [Val] best loss: 0.0146 best  MSE: 0.0210 MAE: 0.1192 PSNR: 14.8965 SSIM: 0.0936 \n",
            "[08:26:45.465271] [Time] 26.8s 11.0m/43.6m\n",
            "\n",
            "[08:26:45.465345] ~~~ Epoch 29/100 ~~~\n",
            "\n",
            "[08:26:48.016847] Epoch: [29]  [ 0/27]  eta: 0:01:08  loss: 0.0143 (0.0143)  MSE: 0.0201 (0.0201)  MAE: 0.1162 (0.1162)  PSNR: 14.7590 (14.7590)  SSIM: 0.0944 (0.0944)  lr: 0.000100  iter-time: 2.5481\n",
            "[08:26:53.861069] Epoch: [29]  [10/27]  eta: 0:00:12  loss: 0.0142 (0.0142)  MSE: 0.0206 (0.0206)  MAE: 0.1178 (0.1178)  PSNR: 15.0014 (14.9408)  SSIM: 0.0989 (0.0982)  lr: 0.000100  iter-time: 0.7628\n",
            "[08:27:01.122780] Epoch: [29]  [20/27]  eta: 0:00:05  loss: 0.0142 (0.0142)  MSE: 0.0206 (0.0205)  MAE: 0.1178 (0.1177)  PSNR: 15.0126 (15.0173)  SSIM: 0.0974 (0.0972)  lr: 0.000100  iter-time: 0.6551\n",
            "[08:27:03.646604] Epoch: [29]  [26/27]  eta: 0:00:00  loss: 0.0142 (0.0141)  MSE: 0.0204 (0.0205)  MAE: 0.1176 (0.1174)  PSNR: 15.0126 (15.0302)  SSIM: 0.0964 (0.0972)  lr: 0.000100  iter-time: 0.5830\n",
            "[08:27:03.748752] Epoch: [29] Total time: 0:00:18 (0.6771 s / it)\n",
            "[08:27:03.752734] [Train] averaged stats: loss: 0.0142 (0.0141)  MSE: 0.0204 (0.0205)  MAE: 0.1176 (0.1174)  PSNR: 15.0126 (15.0302)  SSIM: 0.0964 (0.0972)  lr: 0.000100\n",
            "[08:27:04.280381] Epoch: [29]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0203 (0.0203)  MAE: 0.1166 (0.1166)  PSNR: 14.9953 (14.9953)  SSIM: 0.0944 (0.0944)  iter-time: 0.5226\n",
            "[08:27:04.732856] Epoch: [29]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0209 (0.0209)  MAE: 0.1190 (0.1189)  PSNR: 14.9953 (14.9743)  SSIM: 0.0942 (0.0937)  iter-time: 0.3248\n",
            "[08:27:04.819737] Epoch: [29] Total time: 0:00:01 (0.3543 s / it)\n",
            "[08:27:04.820669] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0209 (0.0209)  MAE: 0.1190 (0.1189)  PSNR: 14.9953 (14.9743)  SSIM: 0.0942 (0.0937)\n",
            "[08:27:04.822501] Val loss improved from 0.014617755698661009 to 0.014613592686752478, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:27:15.933540] [Val] best loss: 0.0146 best  MSE: 0.0209 MAE: 0.1189 PSNR: 14.9743 SSIM: 0.0937 \n",
            "[08:27:15.936664] [Time] 30.5s 11.5m/48.1m\n",
            "\n",
            "[08:27:15.936779] ~~~ Epoch 30/100 ~~~\n",
            "\n",
            "[08:27:19.484220] Epoch: [30]  [ 0/27]  eta: 0:01:35  loss: 0.0142 (0.0142)  MSE: 0.0197 (0.0197)  MAE: 0.1152 (0.1152)  PSNR: 14.8570 (14.8570)  SSIM: 0.0972 (0.0972)  lr: 0.000100  iter-time: 3.5407\n",
            "[08:27:25.680818] Epoch: [30]  [10/27]  eta: 0:00:15  loss: 0.0142 (0.0141)  MSE: 0.0203 (0.0203)  MAE: 0.1172 (0.1172)  PSNR: 14.9960 (15.0101)  SSIM: 0.0971 (0.0973)  lr: 0.000100  iter-time: 0.8844\n",
            "[08:27:32.642469] Epoch: [30]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0141)  MSE: 0.0205 (0.0203)  MAE: 0.1175 (0.1172)  PSNR: 15.0967 (15.0489)  SSIM: 0.0978 (0.0981)  lr: 0.000100  iter-time: 0.6572\n",
            "[08:27:34.773901] Epoch: [30]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0140)  MSE: 0.0203 (0.0203)  MAE: 0.1170 (0.1169)  PSNR: 15.0967 (15.0613)  SSIM: 0.0975 (0.0975)  lr: 0.000100  iter-time: 0.6145\n",
            "[08:27:34.874852] Epoch: [30] Total time: 0:00:18 (0.7013 s / it)\n",
            "[08:27:34.878267] [Train] averaged stats: loss: 0.0141 (0.0140)  MSE: 0.0203 (0.0203)  MAE: 0.1170 (0.1169)  PSNR: 15.0967 (15.0613)  SSIM: 0.0975 (0.0975)  lr: 0.000100\n",
            "[08:27:35.409340] Epoch: [30]  [0/3]  eta: 0:00:01  loss: 0.0139 (0.0139)  MSE: 0.0202 (0.0202)  MAE: 0.1162 (0.1162)  PSNR: 15.1623 (15.1623)  SSIM: 0.1024 (0.1024)  iter-time: 0.5265\n",
            "[08:27:35.860476] Epoch: [30]  [2/3]  eta: 0:00:00  loss: 0.0146 (0.0145)  MSE: 0.0208 (0.0208)  MAE: 0.1186 (0.1185)  PSNR: 15.1623 (15.1383)  SSIM: 0.0983 (0.0994)  iter-time: 0.3250\n",
            "[08:27:35.946544] Epoch: [30] Total time: 0:00:01 (0.3548 s / it)\n",
            "[08:27:35.946933] [Val] averaged stats: loss: 0.0146 (0.0145)  MSE: 0.0208 (0.0208)  MAE: 0.1186 (0.1185)  PSNR: 15.1623 (15.1383)  SSIM: 0.0983 (0.0994)\n",
            "[08:27:35.949390] Val loss improved from 0.014613592686752478 to 0.014543370033303896, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:27:44.418245] [Val] best loss: 0.0145 best  MSE: 0.0208 MAE: 0.1185 PSNR: 15.1383 SSIM: 0.0994 \n",
            "[08:27:44.421374] Creating training plots . . .\n",
            "[08:27:45.217831] [Time] 29.3s 12.0m/46.7m\n",
            "\n",
            "[08:27:45.219191] ~~~ Epoch 31/100 ~~~\n",
            "\n",
            "[08:27:47.894615] Epoch: [31]  [ 0/27]  eta: 0:01:12  loss: 0.0144 (0.0144)  MSE: 0.0199 (0.0199)  MAE: 0.1156 (0.1156)  PSNR: 14.5539 (14.5539)  SSIM: 0.1030 (0.1030)  lr: 0.000100  iter-time: 2.6715\n",
            "[08:27:52.541903] Epoch: [31]  [10/27]  eta: 0:00:11  loss: 0.0140 (0.0141)  MSE: 0.0201 (0.0202)  MAE: 0.1169 (0.1170)  PSNR: 15.0544 (15.0788)  SSIM: 0.1031 (0.1015)  lr: 0.000100  iter-time: 0.6640\n",
            "[08:28:01.415167] Epoch: [31]  [20/27]  eta: 0:00:05  loss: 0.0140 (0.0141)  MSE: 0.0202 (0.0201)  MAE: 0.1169 (0.1167)  PSNR: 15.0969 (15.1277)  SSIM: 0.1003 (0.1015)  lr: 0.000100  iter-time: 0.6752\n",
            "[08:28:04.540258] Epoch: [31]  [26/27]  eta: 0:00:00  loss: 0.0140 (0.0140)  MSE: 0.0199 (0.0199)  MAE: 0.1162 (0.1160)  PSNR: 15.2390 (15.1648)  SSIM: 0.1024 (0.1021)  lr: 0.000100  iter-time: 0.7090\n",
            "[08:28:04.640497] Epoch: [31] Total time: 0:00:19 (0.7192 s / it)\n",
            "[08:28:04.641449] [Train] averaged stats: loss: 0.0140 (0.0140)  MSE: 0.0199 (0.0199)  MAE: 0.1162 (0.1160)  PSNR: 15.2390 (15.1648)  SSIM: 0.1024 (0.1021)  lr: 0.000100\n",
            "[08:28:05.166613] Epoch: [31]  [0/3]  eta: 0:00:01  loss: 0.0139 (0.0139)  MSE: 0.0200 (0.0200)  MAE: 0.1156 (0.1156)  PSNR: 15.2612 (15.2612)  SSIM: 0.1079 (0.1079)  iter-time: 0.5202\n",
            "[08:28:05.617155] Epoch: [31]  [2/3]  eta: 0:00:00  loss: 0.0145 (0.0145)  MSE: 0.0203 (0.0205)  MAE: 0.1172 (0.1176)  PSNR: 15.2612 (15.3081)  SSIM: 0.1031 (0.1047)  iter-time: 0.3233\n",
            "[08:28:05.703438] Epoch: [31] Total time: 0:00:01 (0.3526 s / it)\n",
            "[08:28:05.703575] [Val] averaged stats: loss: 0.0145 (0.0145)  MSE: 0.0203 (0.0205)  MAE: 0.1172 (0.1176)  PSNR: 15.2612 (15.3081)  SSIM: 0.1031 (0.1047)\n",
            "[08:28:05.706248] Val loss improved from 0.014543370033303896 to 0.0145407784730196, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:28:20.925291] [Val] best loss: 0.0145 best  MSE: 0.0205 MAE: 0.1176 PSNR: 15.3081 SSIM: 0.1047 \n",
            "[08:28:20.928289] [Time] 35.7s 12.6m/54.3m\n",
            "\n",
            "[08:28:20.928375] ~~~ Epoch 32/100 ~~~\n",
            "\n",
            "[08:28:22.777160] Epoch: [32]  [ 0/27]  eta: 0:00:49  loss: 0.0150 (0.0150)  MSE: 0.0203 (0.0203)  MAE: 0.1166 (0.1166)  PSNR: 14.8637 (14.8637)  SSIM: 0.0935 (0.0935)  lr: 0.000100  iter-time: 1.8446\n",
            "[08:28:30.716707] Epoch: [32]  [10/27]  eta: 0:00:15  loss: 0.0144 (0.0142)  MSE: 0.0204 (0.0204)  MAE: 0.1173 (0.1173)  PSNR: 14.9866 (14.9793)  SSIM: 0.0997 (0.0989)  lr: 0.000100  iter-time: 0.8891\n",
            "[08:28:36.044800] Epoch: [32]  [20/27]  eta: 0:00:05  loss: 0.0144 (0.0142)  MSE: 0.0206 (0.0205)  MAE: 0.1175 (0.1174)  PSNR: 15.0067 (15.0240)  SSIM: 0.0961 (0.0968)  lr: 0.000100  iter-time: 0.6628\n",
            "[08:28:38.178538] Epoch: [32]  [26/27]  eta: 0:00:00  loss: 0.0143 (0.0142)  MSE: 0.0205 (0.0204)  MAE: 0.1175 (0.1172)  PSNR: 14.9536 (15.0010)  SSIM: 0.0945 (0.0961)  lr: 0.000100  iter-time: 0.5705\n",
            "[08:28:38.270166] Epoch: [32] Total time: 0:00:17 (0.6422 s / it)\n",
            "[08:28:38.272320] [Train] averaged stats: loss: 0.0143 (0.0142)  MSE: 0.0205 (0.0204)  MAE: 0.1175 (0.1172)  PSNR: 14.9536 (15.0010)  SSIM: 0.0945 (0.0961)  lr: 0.000100\n",
            "[08:28:38.785638] Epoch: [32]  [0/3]  eta: 0:00:01  loss: 0.0140 (0.0140)  MSE: 0.0200 (0.0200)  MAE: 0.1156 (0.1156)  PSNR: 15.0501 (15.0501)  SSIM: 0.0925 (0.0925)  iter-time: 0.5077\n",
            "[08:28:39.236797] Epoch: [32]  [2/3]  eta: 0:00:00  loss: 0.0148 (0.0146)  MSE: 0.0207 (0.0206)  MAE: 0.1183 (0.1180)  PSNR: 15.0501 (15.0276)  SSIM: 0.0925 (0.0923)  iter-time: 0.3189\n",
            "[08:28:39.320866] Epoch: [32] Total time: 0:00:01 (0.3481 s / it)\n",
            "[08:28:39.320994] [Val] averaged stats: loss: 0.0148 (0.0146)  MSE: 0.0207 (0.0206)  MAE: 0.1183 (0.1180)  PSNR: 15.0501 (15.0276)  SSIM: 0.0925 (0.0923)\n",
            "[08:28:39.323435] [Val] best loss: 0.0145 best  MSE: 0.0205 MAE: 0.1176 PSNR: 15.3081 SSIM: 0.1047 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:28:39.326228] [Time] 18.4s 12.9m/34.1m\n",
            "\n",
            "[08:28:39.326282] ~~~ Epoch 33/100 ~~~\n",
            "\n",
            "[08:28:41.189755] Epoch: [33]  [ 0/27]  eta: 0:00:50  loss: 0.0148 (0.0148)  MSE: 0.0200 (0.0200)  MAE: 0.1162 (0.1162)  PSNR: 14.8075 (14.8075)  SSIM: 0.0927 (0.0927)  lr: 0.000100  iter-time: 1.8549\n",
            "[08:28:51.876164] Epoch: [33]  [10/27]  eta: 0:00:19  loss: 0.0143 (0.0142)  MSE: 0.0202 (0.0203)  MAE: 0.1169 (0.1170)  PSNR: 14.9522 (14.9087)  SSIM: 0.0957 (0.0960)  lr: 0.000100  iter-time: 1.1397\n",
            "[08:28:57.383060] Epoch: [33]  [20/27]  eta: 0:00:06  loss: 0.0141 (0.0142)  MSE: 0.0202 (0.0203)  MAE: 0.1169 (0.1169)  PSNR: 14.9154 (14.9386)  SSIM: 0.0933 (0.0938)  lr: 0.000100  iter-time: 0.8091\n",
            "[08:28:59.520707] Epoch: [33]  [26/27]  eta: 0:00:00  loss: 0.0141 (0.0141)  MSE: 0.0202 (0.0202)  MAE: 0.1168 (0.1167)  PSNR: 14.8971 (14.9790)  SSIM: 0.0933 (0.0942)  lr: 0.000100  iter-time: 0.6739\n",
            "[08:28:59.622194] Epoch: [33] Total time: 0:00:20 (0.7516 s / it)\n",
            "[08:28:59.623188] [Train] averaged stats: loss: 0.0141 (0.0141)  MSE: 0.0202 (0.0202)  MAE: 0.1168 (0.1167)  PSNR: 14.8971 (14.9790)  SSIM: 0.0933 (0.0942)  lr: 0.000100\n",
            "[08:29:00.140766] Epoch: [33]  [0/3]  eta: 0:00:01  loss: 0.0139 (0.0139)  MSE: 0.0197 (0.0197)  MAE: 0.1147 (0.1147)  PSNR: 14.9464 (14.9464)  SSIM: 0.0910 (0.0910)  iter-time: 0.5110\n",
            "[08:29:00.598436] Epoch: [33]  [2/3]  eta: 0:00:00  loss: 0.0147 (0.0146)  MSE: 0.0203 (0.0203)  MAE: 0.1174 (0.1171)  PSNR: 14.9464 (14.8903)  SSIM: 0.0924 (0.0926)  iter-time: 0.3226\n",
            "[08:29:00.692931] Epoch: [33] Total time: 0:00:01 (0.3547 s / it)\n",
            "[08:29:00.693055] [Val] averaged stats: loss: 0.0147 (0.0146)  MSE: 0.0203 (0.0203)  MAE: 0.1174 (0.1171)  PSNR: 14.9464 (14.8903)  SSIM: 0.0924 (0.0926)\n",
            "[08:29:00.695956] [Val] best loss: 0.0145 best  MSE: 0.0205 MAE: 0.1176 PSNR: 15.3081 SSIM: 0.1047 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:29:00.698685] [Time] 21.4s 13.3m/37.5m\n",
            "\n",
            "[08:29:00.698735] ~~~ Epoch 34/100 ~~~\n",
            "\n",
            "[08:29:06.519983] Epoch: [34]  [ 0/27]  eta: 0:02:37  loss: 0.0148 (0.0148)  MSE: 0.0196 (0.0196)  MAE: 0.1150 (0.1150)  PSNR: 14.6721 (14.6721)  SSIM: 0.0874 (0.0874)  lr: 0.000100  iter-time: 5.8183\n",
            "[08:29:12.480376] Epoch: [34]  [10/27]  eta: 0:00:18  loss: 0.0143 (0.0141)  MSE: 0.0199 (0.0200)  MAE: 0.1161 (0.1163)  PSNR: 14.8863 (14.9427)  SSIM: 0.0928 (0.0940)  lr: 0.000100  iter-time: 1.0706\n",
            "[08:29:16.621280] Epoch: [34]  [20/27]  eta: 0:00:05  loss: 0.0141 (0.0141)  MSE: 0.0200 (0.0200)  MAE: 0.1165 (0.1162)  PSNR: 14.9693 (14.9542)  SSIM: 0.0927 (0.0934)  lr: 0.000100  iter-time: 0.5049\n",
            "[08:29:18.727048] Epoch: [34]  [26/27]  eta: 0:00:00  loss: 0.0140 (0.0140)  MSE: 0.0199 (0.0199)  MAE: 0.1161 (0.1158)  PSNR: 15.0538 (15.0374)  SSIM: 0.0949 (0.0946)  lr: 0.000100  iter-time: 0.3942\n",
            "[08:29:18.832567] Epoch: [34] Total time: 0:00:18 (0.6715 s / it)\n",
            "[08:29:18.834861] [Train] averaged stats: loss: 0.0140 (0.0140)  MSE: 0.0199 (0.0199)  MAE: 0.1161 (0.1158)  PSNR: 15.0538 (15.0374)  SSIM: 0.0949 (0.0946)  lr: 0.000100\n",
            "[08:29:19.376119] Epoch: [34]  [0/3]  eta: 0:00:01  loss: 0.0135 (0.0135)  MSE: 0.0197 (0.0197)  MAE: 0.1147 (0.1147)  PSNR: 15.2891 (15.2891)  SSIM: 0.0995 (0.0995)  iter-time: 0.5361\n",
            "[08:29:19.820217] Epoch: [34]  [2/3]  eta: 0:00:00  loss: 0.0141 (0.0142)  MSE: 0.0201 (0.0202)  MAE: 0.1166 (0.1168)  PSNR: 15.2827 (15.2425)  SSIM: 0.0936 (0.0953)  iter-time: 0.3264\n",
            "[08:29:19.958694] Epoch: [34] Total time: 0:00:01 (0.3732 s / it)\n",
            "[08:29:19.958900] [Val] averaged stats: loss: 0.0141 (0.0142)  MSE: 0.0201 (0.0202)  MAE: 0.1166 (0.1168)  PSNR: 15.2827 (15.2425)  SSIM: 0.0936 (0.0953)\n",
            "[08:29:19.962089] Val loss improved from 0.0145407784730196 to 0.014161898754537106, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:29:25.580254] [Val] best loss: 0.0142 best  MSE: 0.0202 MAE: 0.1168 PSNR: 15.2425 SSIM: 0.0953 \n",
            "[08:29:25.584047] [Time] 24.9s 13.7m/41.5m\n",
            "\n",
            "[08:29:25.587530] ~~~ Epoch 35/100 ~~~\n",
            "\n",
            "[08:29:27.715841] Epoch: [35]  [ 0/27]  eta: 0:00:57  loss: 0.0143 (0.0143)  MSE: 0.0197 (0.0197)  MAE: 0.1151 (0.1151)  PSNR: 14.7926 (14.7926)  SSIM: 0.0918 (0.0918)  lr: 0.000100  iter-time: 2.1246\n",
            "[08:29:33.538100] Epoch: [35]  [10/27]  eta: 0:00:12  loss: 0.0140 (0.0138)  MSE: 0.0197 (0.0199)  MAE: 0.1155 (0.1156)  PSNR: 15.0970 (15.0613)  SSIM: 0.1032 (0.1062)  lr: 0.000100  iter-time: 0.7221\n",
            "[08:29:41.750191] Epoch: [35]  [20/27]  eta: 0:00:05  loss: 0.0139 (0.0138)  MSE: 0.0198 (0.0199)  MAE: 0.1158 (0.1157)  PSNR: 15.1023 (15.1328)  SSIM: 0.1064 (0.1054)  lr: 0.000100  iter-time: 0.7011\n",
            "[08:29:43.859308] Epoch: [35]  [26/27]  eta: 0:00:00  loss: 0.0139 (0.0137)  MSE: 0.0200 (0.0198)  MAE: 0.1160 (0.1153)  PSNR: 15.0970 (15.1389)  SSIM: 0.1071 (0.1062)  lr: 0.000100  iter-time: 0.6077\n",
            "[08:29:43.953535] Epoch: [35] Total time: 0:00:18 (0.6801 s / it)\n",
            "[08:29:43.953682] [Train] averaged stats: loss: 0.0139 (0.0137)  MSE: 0.0200 (0.0198)  MAE: 0.1160 (0.1153)  PSNR: 15.0970 (15.1389)  SSIM: 0.1071 (0.1062)  lr: 0.000100\n",
            "[08:29:44.462154] Epoch: [35]  [0/3]  eta: 0:00:01  loss: 0.0134 (0.0134)  MSE: 0.0199 (0.0199)  MAE: 0.1154 (0.1154)  PSNR: 15.2893 (15.2893)  SSIM: 0.1008 (0.1008)  iter-time: 0.5019\n",
            "[08:29:44.907263] Epoch: [35]  [2/3]  eta: 0:00:00  loss: 0.0139 (0.0140)  MSE: 0.0202 (0.0204)  MAE: 0.1165 (0.1173)  PSNR: 15.2893 (15.2651)  SSIM: 0.0958 (0.0971)  iter-time: 0.3154\n",
            "[08:29:44.993984] Epoch: [35] Total time: 0:00:01 (0.3449 s / it)\n",
            "[08:29:44.994114] [Val] averaged stats: loss: 0.0139 (0.0140)  MSE: 0.0202 (0.0204)  MAE: 0.1165 (0.1173)  PSNR: 15.2893 (15.2651)  SSIM: 0.0958 (0.0971)\n",
            "[08:29:44.997166] Val loss improved from 0.014161898754537106 to 0.014006984420120716, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:29:52.032278] [Val] best loss: 0.0140 best  MSE: 0.0204 MAE: 0.1173 PSNR: 15.2651 SSIM: 0.0971 \n",
            "[08:29:52.034732] Creating training plots . . .\n",
            "[08:29:53.212526] [Time] 27.6s 14.2m/44.5m\n",
            "\n",
            "[08:29:53.214021] ~~~ Epoch 36/100 ~~~\n",
            "\n",
            "[08:29:57.050270] Epoch: [36]  [ 0/27]  eta: 0:01:43  loss: 0.0139 (0.0139)  MSE: 0.0198 (0.0198)  MAE: 0.1152 (0.1152)  PSNR: 14.6874 (14.6874)  SSIM: 0.0844 (0.0844)  lr: 0.000100  iter-time: 3.8286\n",
            "[08:30:02.932098] Epoch: [36]  [10/27]  eta: 0:00:14  loss: 0.0135 (0.0137)  MSE: 0.0198 (0.0199)  MAE: 0.1152 (0.1153)  PSNR: 15.1304 (14.9840)  SSIM: 0.1056 (0.1068)  lr: 0.000100  iter-time: 0.8817\n",
            "[08:30:07.878298] Epoch: [36]  [20/27]  eta: 0:00:04  loss: 0.0138 (0.0138)  MSE: 0.0198 (0.0198)  MAE: 0.1158 (0.1154)  PSNR: 15.1956 (15.1186)  SSIM: 0.1046 (0.1057)  lr: 0.000100  iter-time: 0.5404\n",
            "[08:30:10.023248] Epoch: [36]  [26/27]  eta: 0:00:00  loss: 0.0138 (0.0137)  MSE: 0.0198 (0.0197)  MAE: 0.1158 (0.1151)  PSNR: 15.2059 (15.1711)  SSIM: 0.1039 (0.1055)  lr: 0.000100  iter-time: 0.5031\n",
            "[08:30:10.161331] Epoch: [36] Total time: 0:00:16 (0.6275 s / it)\n",
            "[08:30:10.161520] [Train] averaged stats: loss: 0.0138 (0.0137)  MSE: 0.0198 (0.0197)  MAE: 0.1158 (0.1151)  PSNR: 15.2059 (15.1711)  SSIM: 0.1039 (0.1055)  lr: 0.000100\n",
            "[08:30:10.765970] Epoch: [36]  [0/3]  eta: 0:00:01  loss: 0.0131 (0.0131)  MSE: 0.0191 (0.0191)  MAE: 0.1128 (0.1128)  PSNR: 15.3502 (15.3502)  SSIM: 0.1025 (0.1025)  iter-time: 0.5966\n",
            "[08:30:11.222263] Epoch: [36]  [2/3]  eta: 0:00:00  loss: 0.0139 (0.0138)  MSE: 0.0197 (0.0198)  MAE: 0.1152 (0.1152)  PSNR: 15.3502 (15.2632)  SSIM: 0.0978 (0.0984)  iter-time: 0.3502\n",
            "[08:30:11.311175] Epoch: [36] Total time: 0:00:01 (0.3809 s / it)\n",
            "[08:30:11.311303] [Val] averaged stats: loss: 0.0139 (0.0138)  MSE: 0.0197 (0.0198)  MAE: 0.1152 (0.1152)  PSNR: 15.3502 (15.2632)  SSIM: 0.0978 (0.0984)\n",
            "[08:30:11.313879] Val loss improved from 0.014006984420120716 to 0.013800076519449552, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:30:20.275748] [Val] best loss: 0.0138 best  MSE: 0.0198 MAE: 0.1152 PSNR: 15.2632 SSIM: 0.0984 \n",
            "[08:30:20.278834] [Time] 27.1s 14.6m/43.9m\n",
            "\n",
            "[08:30:20.278918] ~~~ Epoch 37/100 ~~~\n",
            "\n",
            "[08:30:26.146086] Epoch: [37]  [ 0/27]  eta: 0:02:38  loss: 0.0136 (0.0136)  MSE: 0.0192 (0.0192)  MAE: 0.1137 (0.1137)  PSNR: 14.9699 (14.9699)  SSIM: 0.1008 (0.1008)  lr: 0.000100  iter-time: 5.8643\n",
            "[08:30:31.440543] Epoch: [37]  [10/27]  eta: 0:00:17  loss: 0.0137 (0.0138)  MSE: 0.0197 (0.0198)  MAE: 0.1150 (0.1154)  PSNR: 15.2965 (15.2320)  SSIM: 0.1047 (0.1058)  lr: 0.000100  iter-time: 1.0143\n",
            "[08:30:36.386924] Epoch: [37]  [20/27]  eta: 0:00:05  loss: 0.0137 (0.0137)  MSE: 0.0197 (0.0198)  MAE: 0.1153 (0.1154)  PSNR: 15.2761 (15.2330)  SSIM: 0.1085 (0.1072)  lr: 0.000100  iter-time: 0.5118\n",
            "[08:30:38.521309] Epoch: [37]  [26/27]  eta: 0:00:00  loss: 0.0134 (0.0134)  MSE: 0.0196 (0.0196)  MAE: 0.1148 (0.1147)  PSNR: 15.3068 (15.2831)  SSIM: 0.1119 (0.1102)  lr: 0.000100  iter-time: 0.4362\n",
            "[08:30:38.609376] Epoch: [37] Total time: 0:00:18 (0.6788 s / it)\n",
            "[08:30:38.610340] [Train] averaged stats: loss: 0.0134 (0.0134)  MSE: 0.0196 (0.0196)  MAE: 0.1148 (0.1147)  PSNR: 15.3068 (15.2831)  SSIM: 0.1119 (0.1102)  lr: 0.000100\n",
            "[08:30:39.152860] Epoch: [37]  [0/3]  eta: 0:00:01  loss: 0.0130 (0.0130)  MSE: 0.0200 (0.0200)  MAE: 0.1153 (0.1153)  PSNR: 15.5119 (15.5119)  SSIM: 0.1162 (0.1162)  iter-time: 0.5375\n",
            "[08:30:39.608863] Epoch: [37]  [2/3]  eta: 0:00:00  loss: 0.0132 (0.0136)  MSE: 0.0201 (0.0206)  MAE: 0.1153 (0.1170)  PSNR: 15.5119 (15.3669)  SSIM: 0.1198 (0.1199)  iter-time: 0.3303\n",
            "[08:30:39.705146] Epoch: [37] Total time: 0:00:01 (0.3635 s / it)\n",
            "[08:30:39.705283] [Val] averaged stats: loss: 0.0132 (0.0136)  MSE: 0.0201 (0.0206)  MAE: 0.1153 (0.1170)  PSNR: 15.5119 (15.3669)  SSIM: 0.1198 (0.1199)\n",
            "[08:30:39.706203] Val loss improved from 0.013800076519449552 to 0.013625016125539938, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:30:46.717054] [Val] best loss: 0.0136 best  MSE: 0.0206 MAE: 0.1170 PSNR: 15.3669 SSIM: 0.1199 \n",
            "[08:30:46.720580] [Time] 26.4s 15.0m/43.3m\n",
            "\n",
            "[08:30:46.720666] ~~~ Epoch 38/100 ~~~\n",
            "\n",
            "[08:30:49.682509] Epoch: [38]  [ 0/27]  eta: 0:01:19  loss: 0.0135 (0.0135)  MSE: 0.0207 (0.0207)  MAE: 0.1169 (0.1169)  PSNR: 14.7445 (14.7445)  SSIM: 0.0973 (0.0973)  lr: 0.000100  iter-time: 2.9523\n",
            "[08:30:53.965643] Epoch: [38]  [10/27]  eta: 0:00:11  loss: 0.0132 (0.0133)  MSE: 0.0198 (0.0198)  MAE: 0.1150 (0.1145)  PSNR: 15.0690 (14.9756)  SSIM: 0.1169 (0.1177)  lr: 0.000100  iter-time: 0.6572\n",
            "[08:31:00.927115] Epoch: [38]  [20/27]  eta: 0:00:04  loss: 0.0132 (0.0133)  MSE: 0.0197 (0.0197)  MAE: 0.1150 (0.1146)  PSNR: 15.1044 (15.1319)  SSIM: 0.1123 (0.1157)  lr: 0.000100  iter-time: 0.5618\n",
            "[08:31:03.495916] Epoch: [38]  [26/27]  eta: 0:00:00  loss: 0.0134 (0.0132)  MSE: 0.0194 (0.0196)  MAE: 0.1134 (0.1143)  PSNR: 15.1402 (15.2353)  SSIM: 0.1186 (0.1184)  lr: 0.000100  iter-time: 0.5667\n",
            "[08:31:03.602781] Epoch: [38] Total time: 0:00:16 (0.6252 s / it)\n",
            "[08:31:03.604456] [Train] averaged stats: loss: 0.0134 (0.0132)  MSE: 0.0194 (0.0196)  MAE: 0.1134 (0.1143)  PSNR: 15.1402 (15.2353)  SSIM: 0.1186 (0.1184)  lr: 0.000100\n",
            "[08:31:04.114783] Epoch: [38]  [0/3]  eta: 0:00:01  loss: 0.0123 (0.0123)  MSE: 0.0189 (0.0189)  MAE: 0.1112 (0.1112)  PSNR: 15.5142 (15.5142)  SSIM: 0.1313 (0.1313)  iter-time: 0.5043\n",
            "[08:31:04.565056] Epoch: [38]  [2/3]  eta: 0:00:00  loss: 0.0130 (0.0131)  MSE: 0.0193 (0.0195)  MAE: 0.1130 (0.1136)  PSNR: 15.2250 (15.0639)  SSIM: 0.1307 (0.1300)  iter-time: 0.3179\n",
            "[08:31:04.656264] Epoch: [38] Total time: 0:00:01 (0.3489 s / it)\n",
            "[08:31:04.656401] [Val] averaged stats: loss: 0.0130 (0.0131)  MSE: 0.0193 (0.0195)  MAE: 0.1130 (0.1136)  PSNR: 15.2250 (15.0639)  SSIM: 0.1307 (0.1300)\n",
            "[08:31:04.658981] Val loss improved from 0.013625016125539938 to 0.013104296910266081, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:31:14.411476] [Val] best loss: 0.0131 best  MSE: 0.0195 MAE: 0.1136 PSNR: 15.0639 SSIM: 0.1300 \n",
            "[08:31:14.414495] [Time] 27.7s 15.5m/44.6m\n",
            "\n",
            "[08:31:14.414749] ~~~ Epoch 39/100 ~~~\n",
            "\n",
            "[08:31:17.726196] Epoch: [39]  [ 0/27]  eta: 0:01:29  loss: 0.0134 (0.0134)  MSE: 0.0197 (0.0197)  MAE: 0.1148 (0.1148)  PSNR: 14.8949 (14.8949)  SSIM: 0.1126 (0.1126)  lr: 0.000100  iter-time: 3.3039\n",
            "[08:31:23.144162] Epoch: [39]  [10/27]  eta: 0:00:13  loss: 0.0127 (0.0129)  MSE: 0.0191 (0.0193)  MAE: 0.1126 (0.1134)  PSNR: 15.3849 (15.1972)  SSIM: 0.1206 (0.1274)  lr: 0.000100  iter-time: 0.7928\n",
            "[08:31:31.692188] Epoch: [39]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0130)  MSE: 0.0192 (0.0195)  MAE: 0.1131 (0.1140)  PSNR: 15.4125 (15.2740)  SSIM: 0.1206 (0.1261)  lr: 0.000100  iter-time: 0.6977\n",
            "[08:31:33.828922] Epoch: [39]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0128)  MSE: 0.0195 (0.0194)  MAE: 0.1133 (0.1135)  PSNR: 15.4125 (15.3515)  SSIM: 0.1279 (0.1287)  lr: 0.000100  iter-time: 0.6218\n",
            "[08:31:33.932378] Epoch: [39] Total time: 0:00:19 (0.7228 s / it)\n",
            "[08:31:33.933337] [Train] averaged stats: loss: 0.0128 (0.0128)  MSE: 0.0195 (0.0194)  MAE: 0.1133 (0.1135)  PSNR: 15.4125 (15.3515)  SSIM: 0.1279 (0.1287)  lr: 0.000100\n",
            "[08:31:34.482936] Epoch: [39]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0191 (0.0191)  MAE: 0.1116 (0.1116)  PSNR: 15.6531 (15.6531)  SSIM: 0.1418 (0.1418)  iter-time: 0.5440\n",
            "[08:31:34.934562] Epoch: [39]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0128)  MSE: 0.0194 (0.0197)  MAE: 0.1127 (0.1138)  PSNR: 15.5071 (15.3143)  SSIM: 0.1417 (0.1407)  iter-time: 0.3316\n",
            "[08:31:35.018542] Epoch: [39] Total time: 0:00:01 (0.3601 s / it)\n",
            "[08:31:35.018677] [Val] averaged stats: loss: 0.0126 (0.0128)  MSE: 0.0194 (0.0197)  MAE: 0.1127 (0.1138)  PSNR: 15.5071 (15.3143)  SSIM: 0.1417 (0.1407)\n",
            "[08:31:35.021180] Val loss improved from 0.013104296910266081 to 0.012843449910481771, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:31:45.305675] [Val] best loss: 0.0128 best  MSE: 0.0197 MAE: 0.1138 PSNR: 15.3143 SSIM: 0.1407 \n",
            "[08:31:45.309950] [Time] 30.9s 16.0m/48.0m\n",
            "\n",
            "[08:31:45.310775] ~~~ Epoch 40/100 ~~~\n",
            "\n",
            "[08:31:47.973488] Epoch: [40]  [ 0/27]  eta: 0:01:11  loss: 0.0134 (0.0134)  MSE: 0.0203 (0.0203)  MAE: 0.1161 (0.1161)  PSNR: 14.9549 (14.9549)  SSIM: 0.1178 (0.1178)  lr: 0.000100  iter-time: 2.6523\n",
            "[08:31:52.050654] Epoch: [40]  [10/27]  eta: 0:00:10  loss: 0.0127 (0.0128)  MSE: 0.0193 (0.0196)  MAE: 0.1131 (0.1138)  PSNR: 15.4765 (15.3545)  SSIM: 0.1213 (0.1285)  lr: 0.000100  iter-time: 0.6112\n",
            "[08:31:57.437749] Epoch: [40]  [20/27]  eta: 0:00:04  loss: 0.0127 (0.0129)  MSE: 0.0193 (0.0197)  MAE: 0.1131 (0.1142)  PSNR: 15.3708 (15.3699)  SSIM: 0.1213 (0.1252)  lr: 0.000100  iter-time: 0.4726\n",
            "[08:32:01.085890] Epoch: [40]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0127)  MSE: 0.0196 (0.0195)  MAE: 0.1134 (0.1136)  PSNR: 15.4765 (15.4576)  SSIM: 0.1254 (0.1281)  lr: 0.000100  iter-time: 0.5333\n",
            "[08:32:01.240491] Epoch: [40] Total time: 0:00:15 (0.5898 s / it)\n",
            "[08:32:01.241573] [Train] averaged stats: loss: 0.0127 (0.0127)  MSE: 0.0196 (0.0195)  MAE: 0.1134 (0.1136)  PSNR: 15.4765 (15.4576)  SSIM: 0.1254 (0.1281)  lr: 0.000100\n",
            "[08:32:01.831956] Epoch: [40]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0194 (0.0194)  MAE: 0.1125 (0.1125)  PSNR: 15.7802 (15.7802)  SSIM: 0.1459 (0.1459)  iter-time: 0.5840\n",
            "[08:32:02.290651] Epoch: [40]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0200)  MAE: 0.1128 (0.1145)  PSNR: 15.5938 (15.4131)  SSIM: 0.1435 (0.1433)  iter-time: 0.3473\n",
            "[08:32:02.380571] Epoch: [40] Total time: 0:00:01 (0.3778 s / it)\n",
            "[08:32:02.381468] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0200)  MAE: 0.1128 (0.1145)  PSNR: 15.5938 (15.4131)  SSIM: 0.1435 (0.1433)\n",
            "[08:32:02.383310] Val loss improved from 0.012843449910481771 to 0.012830666887263456, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:32:09.012077] [Val] best loss: 0.0128 best  MSE: 0.0200 MAE: 0.1145 PSNR: 15.4131 SSIM: 0.1433 \n",
            "[08:32:09.015015] Creating training plots . . .\n",
            "[08:32:09.828922] [Time] 24.5s 16.4m/41.4m\n",
            "\n",
            "[08:32:09.829044] ~~~ Epoch 41/100 ~~~\n",
            "\n",
            "[08:32:12.258002] Epoch: [41]  [ 0/27]  eta: 0:01:05  loss: 0.0134 (0.0134)  MSE: 0.0208 (0.0208)  MAE: 0.1170 (0.1170)  PSNR: 15.0274 (15.0274)  SSIM: 0.1197 (0.1197)  lr: 0.000100  iter-time: 2.4253\n",
            "[08:32:20.496637] Epoch: [41]  [10/27]  eta: 0:00:16  loss: 0.0129 (0.0128)  MSE: 0.0194 (0.0195)  MAE: 0.1130 (0.1136)  PSNR: 15.5172 (15.3698)  SSIM: 0.1252 (0.1299)  lr: 0.000100  iter-time: 0.9688\n",
            "[08:32:25.389569] Epoch: [41]  [20/27]  eta: 0:00:05  loss: 0.0129 (0.0129)  MSE: 0.0197 (0.0197)  MAE: 0.1140 (0.1141)  PSNR: 15.3664 (15.3626)  SSIM: 0.1247 (0.1254)  lr: 0.000100  iter-time: 0.6560\n",
            "[08:32:27.699981] Epoch: [41]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1140 (0.1135)  PSNR: 15.4255 (15.4422)  SSIM: 0.1264 (0.1286)  lr: 0.000100  iter-time: 0.4473\n",
            "[08:32:27.801726] Epoch: [41] Total time: 0:00:17 (0.6656 s / it)\n",
            "[08:32:27.803248] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1140 (0.1135)  PSNR: 15.4255 (15.4422)  SSIM: 0.1264 (0.1286)  lr: 0.000100\n",
            "[08:32:28.357217] Epoch: [41]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0189 (0.0189)  MAE: 0.1106 (0.1106)  PSNR: 15.7060 (15.7060)  SSIM: 0.1426 (0.1426)  iter-time: 0.5483\n",
            "[08:32:28.808086] Epoch: [41]  [2/3]  eta: 0:00:00  loss: 0.0127 (0.0128)  MSE: 0.0192 (0.0195)  MAE: 0.1121 (0.1129)  PSNR: 15.4781 (15.2931)  SSIM: 0.1394 (0.1396)  iter-time: 0.3321\n",
            "[08:32:28.902648] Epoch: [41] Total time: 0:00:01 (0.3649 s / it)\n",
            "[08:32:28.902792] [Val] averaged stats: loss: 0.0127 (0.0128)  MSE: 0.0192 (0.0195)  MAE: 0.1121 (0.1129)  PSNR: 15.4781 (15.2931)  SSIM: 0.1394 (0.1396)\n",
            "[08:32:28.908530] Val loss improved from 0.012830666887263456 to 0.012764130719006062, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:32:34.171074] [Val] best loss: 0.0128 best  MSE: 0.0195 MAE: 0.1129 PSNR: 15.2931 SSIM: 0.1396 \n",
            "[08:32:34.174309] [Time] 24.3s 16.8m/41.2m\n",
            "\n",
            "[08:32:34.174399] ~~~ Epoch 42/100 ~~~\n",
            "\n",
            "[08:32:37.049827] Epoch: [42]  [ 0/27]  eta: 0:01:17  loss: 0.0133 (0.0133)  MSE: 0.0199 (0.0199)  MAE: 0.1150 (0.1150)  PSNR: 14.9300 (14.9300)  SSIM: 0.1217 (0.1217)  lr: 0.000100  iter-time: 2.8715\n",
            "[08:32:43.189000] Epoch: [42]  [10/27]  eta: 0:00:13  loss: 0.0128 (0.0127)  MSE: 0.0197 (0.0194)  MAE: 0.1142 (0.1132)  PSNR: 15.3848 (15.3584)  SSIM: 0.1252 (0.1306)  lr: 0.000100  iter-time: 0.8181\n",
            "[08:32:49.203622] Epoch: [42]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0196 (0.0195)  MAE: 0.1137 (0.1139)  PSNR: 15.3848 (15.4050)  SSIM: 0.1236 (0.1272)  lr: 0.000100  iter-time: 0.6070\n",
            "[08:32:51.658615] Epoch: [42]  [26/27]  eta: 0:00:00  loss: 0.0129 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1136 (0.1133)  PSNR: 15.4694 (15.4679)  SSIM: 0.1272 (0.1306)  lr: 0.000100  iter-time: 0.5754\n",
            "[08:32:51.762230] Epoch: [42] Total time: 0:00:17 (0.6513 s / it)\n",
            "[08:32:51.764494] [Train] averaged stats: loss: 0.0129 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1136 (0.1133)  PSNR: 15.4694 (15.4679)  SSIM: 0.1272 (0.1306)  lr: 0.000100\n",
            "[08:32:52.267769] Epoch: [42]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0191 (0.0191)  MAE: 0.1114 (0.1114)  PSNR: 15.7614 (15.7614)  SSIM: 0.1457 (0.1457)  iter-time: 0.4960\n",
            "[08:32:52.715374] Epoch: [42]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0127)  MSE: 0.0193 (0.0197)  MAE: 0.1122 (0.1135)  PSNR: 15.5741 (15.3696)  SSIM: 0.1426 (0.1424)  iter-time: 0.3143\n",
            "[08:32:52.804266] Epoch: [42] Total time: 0:00:01 (0.3444 s / it)\n",
            "[08:32:52.804387] [Val] averaged stats: loss: 0.0125 (0.0127)  MSE: 0.0193 (0.0197)  MAE: 0.1122 (0.1135)  PSNR: 15.5741 (15.3696)  SSIM: 0.1426 (0.1424)\n",
            "[08:32:52.807016] Val loss improved from 0.012764130719006062 to 0.01268661767244339, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:33:03.027201] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "[08:33:03.034724] [Time] 28.9s 17.3m/45.7m\n",
            "\n",
            "[08:33:03.035398] ~~~ Epoch 43/100 ~~~\n",
            "\n",
            "[08:33:05.915983] Epoch: [43]  [ 0/27]  eta: 0:01:17  loss: 0.0132 (0.0132)  MSE: 0.0202 (0.0202)  MAE: 0.1158 (0.1158)  PSNR: 15.0550 (15.0550)  SSIM: 0.1223 (0.1223)  lr: 0.000100  iter-time: 2.8624\n",
            "[08:33:10.830116] Epoch: [43]  [10/27]  eta: 0:00:12  loss: 0.0128 (0.0128)  MSE: 0.0199 (0.0195)  MAE: 0.1147 (0.1135)  PSNR: 15.4207 (15.3384)  SSIM: 0.1273 (0.1312)  lr: 0.000100  iter-time: 0.7063\n",
            "[08:33:16.299101] Epoch: [43]  [20/27]  eta: 0:00:04  loss: 0.0128 (0.0129)  MSE: 0.0198 (0.0196)  MAE: 0.1141 (0.1140)  PSNR: 15.3989 (15.3785)  SSIM: 0.1220 (0.1276)  lr: 0.000100  iter-time: 0.5184\n",
            "[08:33:18.899631] Epoch: [43]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0128)  MSE: 0.0193 (0.0195)  MAE: 0.1134 (0.1136)  PSNR: 15.4373 (15.4625)  SSIM: 0.1302 (0.1304)  lr: 0.000100  iter-time: 0.5252\n",
            "[08:33:19.052246] Epoch: [43] Total time: 0:00:16 (0.5930 s / it)\n",
            "[08:33:19.053252] [Train] averaged stats: loss: 0.0128 (0.0128)  MSE: 0.0193 (0.0195)  MAE: 0.1134 (0.1136)  PSNR: 15.4373 (15.4625)  SSIM: 0.1302 (0.1304)  lr: 0.000100\n",
            "[08:33:19.752096] Epoch: [43]  [0/3]  eta: 0:00:02  loss: 0.0119 (0.0119)  MSE: 0.0188 (0.0188)  MAE: 0.1107 (0.1107)  PSNR: 15.7484 (15.7484)  SSIM: 0.1392 (0.1392)  iter-time: 0.6925\n",
            "[08:33:20.203470] Epoch: [43]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0127)  MSE: 0.0192 (0.0194)  MAE: 0.1120 (0.1129)  PSNR: 15.6673 (15.4547)  SSIM: 0.1384 (0.1373)  iter-time: 0.3804\n",
            "[08:33:20.291447] Epoch: [43] Total time: 0:00:01 (0.4109 s / it)\n",
            "[08:33:20.292314] [Val] averaged stats: loss: 0.0126 (0.0127)  MSE: 0.0192 (0.0194)  MAE: 0.1120 (0.1129)  PSNR: 15.6673 (15.4547)  SSIM: 0.1384 (0.1373)\n",
            "[08:33:20.294592] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:33:20.298218] [Time] 17.3s 17.6m/34.3m\n",
            "\n",
            "[08:33:20.298330] ~~~ Epoch 44/100 ~~~\n",
            "\n",
            "[08:33:22.457331] Epoch: [44]  [ 0/27]  eta: 0:00:58  loss: 0.0131 (0.0131)  MSE: 0.0198 (0.0198)  MAE: 0.1149 (0.1149)  PSNR: 14.9308 (14.9308)  SSIM: 0.1195 (0.1195)  lr: 0.000100  iter-time: 2.1534\n",
            "[08:33:27.707395] Epoch: [44]  [10/27]  eta: 0:00:11  loss: 0.0126 (0.0127)  MSE: 0.0195 (0.0193)  MAE: 0.1131 (0.1131)  PSNR: 15.4633 (15.3753)  SSIM: 0.1216 (0.1296)  lr: 0.000100  iter-time: 0.6727\n",
            "[08:33:34.320399] Epoch: [44]  [20/27]  eta: 0:00:04  loss: 0.0126 (0.0128)  MSE: 0.0194 (0.0195)  MAE: 0.1131 (0.1137)  PSNR: 15.4354 (15.4130)  SSIM: 0.1216 (0.1281)  lr: 0.000100  iter-time: 0.5929\n",
            "[08:33:37.079128] Epoch: [44]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1132 (0.1133)  PSNR: 15.3372 (15.4584)  SSIM: 0.1286 (0.1302)  lr: 0.000100  iter-time: 0.5960\n",
            "[08:33:37.175024] Epoch: [44] Total time: 0:00:16 (0.6250 s / it)\n",
            "[08:33:37.176509] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1132 (0.1133)  PSNR: 15.3372 (15.4584)  SSIM: 0.1286 (0.1302)  lr: 0.000100\n",
            "[08:33:37.723454] Epoch: [44]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0194 (0.0194)  MAE: 0.1128 (0.1128)  PSNR: 15.6163 (15.6163)  SSIM: 0.1295 (0.1295)  iter-time: 0.5403\n",
            "[08:33:38.177183] Epoch: [44]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0199)  MAE: 0.1131 (0.1146)  PSNR: 15.6163 (15.4971)  SSIM: 0.1295 (0.1297)  iter-time: 0.3305\n",
            "[08:33:38.263356] Epoch: [44] Total time: 0:00:01 (0.3604 s / it)\n",
            "[08:33:38.263575] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0199)  MAE: 0.1131 (0.1146)  PSNR: 15.6163 (15.4971)  SSIM: 0.1295 (0.1297)\n",
            "[08:33:38.266172] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:33:38.269232] [Time] 18.0s 17.9m/35.0m\n",
            "\n",
            "[08:33:38.269458] ~~~ Epoch 45/100 ~~~\n",
            "\n",
            "[08:33:41.894112] Epoch: [45]  [ 0/27]  eta: 0:01:37  loss: 0.0129 (0.0129)  MSE: 0.0198 (0.0198)  MAE: 0.1147 (0.1147)  PSNR: 15.0988 (15.0988)  SSIM: 0.1209 (0.1209)  lr: 0.000100  iter-time: 3.6180\n",
            "[08:33:46.039942] Epoch: [45]  [10/27]  eta: 0:00:11  loss: 0.0129 (0.0127)  MSE: 0.0196 (0.0194)  MAE: 0.1141 (0.1133)  PSNR: 15.3896 (15.2212)  SSIM: 0.1247 (0.1317)  lr: 0.000100  iter-time: 0.7054\n",
            "[08:33:52.331803] Epoch: [45]  [20/27]  eta: 0:00:04  loss: 0.0129 (0.0128)  MSE: 0.0196 (0.0196)  MAE: 0.1141 (0.1139)  PSNR: 15.3896 (15.3266)  SSIM: 0.1204 (0.1281)  lr: 0.000100  iter-time: 0.5214\n",
            "[08:33:54.476718] Epoch: [45]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0193 (0.0194)  MAE: 0.1127 (0.1133)  PSNR: 15.4406 (15.4097)  SSIM: 0.1307 (0.1306)  lr: 0.000100  iter-time: 0.5042\n",
            "[08:33:54.643248] Epoch: [45] Total time: 0:00:16 (0.6064 s / it)\n",
            "[08:33:54.645007] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0193 (0.0194)  MAE: 0.1127 (0.1133)  PSNR: 15.4406 (15.4097)  SSIM: 0.1307 (0.1306)  lr: 0.000100\n",
            "[08:33:55.289428] Epoch: [45]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0193 (0.0193)  MAE: 0.1125 (0.1125)  PSNR: 15.6399 (15.6399)  SSIM: 0.1413 (0.1413)  iter-time: 0.6362\n",
            "[08:33:55.738020] Epoch: [45]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0194 (0.0200)  MAE: 0.1127 (0.1145)  PSNR: 15.4855 (15.3062)  SSIM: 0.1396 (0.1390)  iter-time: 0.3607\n",
            "[08:33:55.822967] Epoch: [45] Total time: 0:00:01 (0.3901 s / it)\n",
            "[08:33:55.823095] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0194 (0.0200)  MAE: 0.1127 (0.1145)  PSNR: 15.4855 (15.3062)  SSIM: 0.1396 (0.1390)\n",
            "[08:33:55.825644] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "[08:33:55.828234] Creating training plots . . .\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:33:56.586950] [Time] 18.3s 18.2m/35.3m\n",
            "\n",
            "[08:33:56.587051] ~~~ Epoch 46/100 ~~~\n",
            "\n",
            "[08:33:59.435057] Epoch: [46]  [ 0/27]  eta: 0:01:16  loss: 0.0131 (0.0131)  MSE: 0.0203 (0.0203)  MAE: 0.1158 (0.1158)  PSNR: 14.8468 (14.8468)  SSIM: 0.1208 (0.1208)  lr: 0.000100  iter-time: 2.8403\n",
            "[08:34:04.917837] Epoch: [46]  [10/27]  eta: 0:00:12  loss: 0.0129 (0.0127)  MSE: 0.0196 (0.0193)  MAE: 0.1142 (0.1130)  PSNR: 15.4495 (15.2345)  SSIM: 0.1225 (0.1311)  lr: 0.000100  iter-time: 0.7563\n",
            "[08:34:13.100315] Epoch: [46]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0196 (0.0195)  MAE: 0.1140 (0.1136)  PSNR: 15.3865 (15.3064)  SSIM: 0.1217 (0.1274)  lr: 0.000100  iter-time: 0.6815\n",
            "[08:34:15.495898] Epoch: [46]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0193)  MAE: 0.1130 (0.1130)  PSNR: 15.3387 (15.3682)  SSIM: 0.1308 (0.1311)  lr: 0.000100  iter-time: 0.6088\n",
            "[08:34:15.595859] Epoch: [46] Total time: 0:00:19 (0.7039 s / it)\n",
            "[08:34:15.598602] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0193)  MAE: 0.1130 (0.1130)  PSNR: 15.3387 (15.3682)  SSIM: 0.1308 (0.1311)  lr: 0.000100\n",
            "[08:34:16.077965] Epoch: [46]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0196 (0.0196)  MAE: 0.1131 (0.1131)  PSNR: 15.7290 (15.7290)  SSIM: 0.1480 (0.1480)  iter-time: 0.4737\n",
            "[08:34:16.524491] Epoch: [46]  [2/3]  eta: 0:00:00  loss: 0.0124 (0.0129)  MSE: 0.0196 (0.0202)  MAE: 0.1131 (0.1148)  PSNR: 15.5509 (15.3636)  SSIM: 0.1447 (0.1449)  iter-time: 0.3065\n",
            "[08:34:16.614511] Epoch: [46] Total time: 0:00:01 (0.3370 s / it)\n",
            "[08:34:16.614634] [Val] averaged stats: loss: 0.0124 (0.0129)  MSE: 0.0196 (0.0202)  MAE: 0.1131 (0.1148)  PSNR: 15.5509 (15.3636)  SSIM: 0.1447 (0.1449)\n",
            "[08:34:16.617220] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[08:34:16.619844] [Time] 20.0s 18.5m/36.9m\n",
            "\n",
            "[08:34:16.619910] ~~~ Epoch 47/100 ~~~\n",
            "\n",
            "[08:34:19.502436] Epoch: [47]  [ 0/27]  eta: 0:01:17  loss: 0.0134 (0.0134)  MSE: 0.0208 (0.0208)  MAE: 0.1168 (0.1168)  PSNR: 14.7607 (14.7607)  SSIM: 0.1247 (0.1247)  lr: 0.000100  iter-time: 2.8788\n",
            "[08:34:24.053122] Epoch: [47]  [10/27]  eta: 0:00:11  loss: 0.0131 (0.0130)  MSE: 0.0198 (0.0194)  MAE: 0.1152 (0.1133)  PSNR: 15.1212 (15.2516)  SSIM: 0.1247 (0.1289)  lr: 0.000100  iter-time: 0.6747\n",
            "[08:34:31.627181] Epoch: [47]  [20/27]  eta: 0:00:04  loss: 0.0131 (0.0131)  MSE: 0.0197 (0.0194)  MAE: 0.1151 (0.1137)  PSNR: 15.3537 (15.3286)  SSIM: 0.1153 (0.1217)  lr: 0.000100  iter-time: 0.6051\n",
            "[08:34:33.768961] Epoch: [47]  [26/27]  eta: 0:00:00  loss: 0.0131 (0.0129)  MSE: 0.0191 (0.0192)  MAE: 0.1128 (0.1130)  PSNR: 15.3537 (15.3733)  SSIM: 0.1169 (0.1233)  lr: 0.000100  iter-time: 0.5891\n",
            "[08:34:33.869527] Epoch: [47] Total time: 0:00:17 (0.6388 s / it)\n",
            "[08:34:33.869675] [Train] averaged stats: loss: 0.0131 (0.0129)  MSE: 0.0191 (0.0192)  MAE: 0.1128 (0.1130)  PSNR: 15.3537 (15.3733)  SSIM: 0.1169 (0.1233)  lr: 0.000100\n",
            "[08:34:34.409936] Epoch: [47]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0191 (0.0191)  MAE: 0.1120 (0.1120)  PSNR: 15.3999 (15.3999)  SSIM: 0.1427 (0.1427)  iter-time: 0.5314\n",
            "[08:34:34.859729] Epoch: [47]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0193 (0.0198)  MAE: 0.1124 (0.1140)  PSNR: 15.1945 (15.0028)  SSIM: 0.1417 (0.1412)  iter-time: 0.3262\n",
            "[08:34:34.946816] Epoch: [47] Total time: 0:00:01 (0.3564 s / it)\n",
            "[08:34:34.947775] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0193 (0.0198)  MAE: 0.1124 (0.1140)  PSNR: 15.1945 (15.0028)  SSIM: 0.1417 (0.1412)\n",
            "[08:34:34.949579] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[08:34:34.952230] [Time] 18.3s 18.9m/35.4m\n",
            "\n",
            "[08:34:34.952291] ~~~ Epoch 48/100 ~~~\n",
            "\n",
            "[08:34:38.453066] Epoch: [48]  [ 0/27]  eta: 0:01:34  loss: 0.0132 (0.0132)  MSE: 0.0197 (0.0197)  MAE: 0.1145 (0.1145)  PSNR: 14.9596 (14.9596)  SSIM: 0.1171 (0.1171)  lr: 0.000100  iter-time: 3.4924\n",
            "[08:34:43.588390] Epoch: [48]  [10/27]  eta: 0:00:13  loss: 0.0129 (0.0128)  MSE: 0.0196 (0.0194)  MAE: 0.1140 (0.1131)  PSNR: 15.3444 (15.1999)  SSIM: 0.1347 (0.1355)  lr: 0.000100  iter-time: 0.7841\n",
            "[08:34:51.362089] Epoch: [48]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0194 (0.0194)  MAE: 0.1125 (0.1134)  PSNR: 15.3444 (15.2572)  SSIM: 0.1189 (0.1294)  lr: 0.000100  iter-time: 0.6450\n",
            "[08:34:53.526842] Epoch: [48]  [26/27]  eta: 0:00:00  loss: 0.0131 (0.0127)  MSE: 0.0192 (0.0192)  MAE: 0.1125 (0.1129)  PSNR: 15.3541 (15.3693)  SSIM: 0.1299 (0.1322)  lr: 0.000100  iter-time: 0.5798\n",
            "[08:34:53.626766] Epoch: [48] Total time: 0:00:18 (0.6916 s / it)\n",
            "[08:34:53.626922] [Train] averaged stats: loss: 0.0131 (0.0127)  MSE: 0.0192 (0.0192)  MAE: 0.1125 (0.1129)  PSNR: 15.3541 (15.3693)  SSIM: 0.1299 (0.1322)  lr: 0.000100\n",
            "[08:34:54.191588] Epoch: [48]  [0/3]  eta: 0:00:01  loss: 0.0124 (0.0124)  MSE: 0.0198 (0.0198)  MAE: 0.1145 (0.1145)  PSNR: 15.5734 (15.5734)  SSIM: 0.1401 (0.1401)  iter-time: 0.5597\n",
            "[08:34:54.642926] Epoch: [48]  [2/3]  eta: 0:00:00  loss: 0.0127 (0.0132)  MSE: 0.0199 (0.0205)  MAE: 0.1145 (0.1162)  PSNR: 15.5238 (15.3166)  SSIM: 0.1401 (0.1390)  iter-time: 0.3367\n",
            "[08:34:54.732377] Epoch: [48] Total time: 0:00:01 (0.3671 s / it)\n",
            "[08:34:54.733088] [Val] averaged stats: loss: 0.0127 (0.0132)  MSE: 0.0199 (0.0205)  MAE: 0.1145 (0.1162)  PSNR: 15.5238 (15.3166)  SSIM: 0.1401 (0.1390)\n",
            "[08:34:54.733866] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[08:34:54.738255] [Time] 19.8s 19.2m/36.7m\n",
            "\n",
            "[08:34:54.738336] ~~~ Epoch 49/100 ~~~\n",
            "\n",
            "[08:34:57.863856] Epoch: [49]  [ 0/27]  eta: 0:01:24  loss: 0.0130 (0.0130)  MSE: 0.0203 (0.0203)  MAE: 0.1157 (0.1157)  PSNR: 15.0224 (15.0224)  SSIM: 0.1240 (0.1240)  lr: 0.000100  iter-time: 3.1214\n",
            "[08:35:01.984248] Epoch: [49]  [10/27]  eta: 0:00:11  loss: 0.0130 (0.0129)  MSE: 0.0198 (0.0194)  MAE: 0.1145 (0.1134)  PSNR: 15.1428 (15.2097)  SSIM: 0.1271 (0.1314)  lr: 0.000100  iter-time: 0.6580\n",
            "[08:35:08.060238] Epoch: [49]  [20/27]  eta: 0:00:04  loss: 0.0131 (0.0131)  MSE: 0.0195 (0.0194)  MAE: 0.1136 (0.1137)  PSNR: 15.1429 (15.2898)  SSIM: 0.1193 (0.1259)  lr: 0.000100  iter-time: 0.5096\n",
            "[08:35:10.725739] Epoch: [49]  [26/27]  eta: 0:00:00  loss: 0.0131 (0.0129)  MSE: 0.0192 (0.0192)  MAE: 0.1132 (0.1130)  PSNR: 15.3022 (15.3464)  SSIM: 0.1213 (0.1271)  lr: 0.000100  iter-time: 0.5210\n",
            "[08:35:10.837555] Epoch: [49] Total time: 0:00:16 (0.5962 s / it)\n",
            "[08:35:10.838495] [Train] averaged stats: loss: 0.0131 (0.0129)  MSE: 0.0192 (0.0192)  MAE: 0.1132 (0.1130)  PSNR: 15.3022 (15.3464)  SSIM: 0.1213 (0.1271)  lr: 0.000100\n",
            "[08:35:11.325617] Epoch: [49]  [0/3]  eta: 0:00:01  loss: 0.0124 (0.0124)  MSE: 0.0193 (0.0193)  MAE: 0.1134 (0.1134)  PSNR: 15.3948 (15.3948)  SSIM: 0.1339 (0.1339)  iter-time: 0.4814\n",
            "[08:35:11.773653] Epoch: [49]  [2/3]  eta: 0:00:00  loss: 0.0128 (0.0131)  MSE: 0.0194 (0.0199)  MAE: 0.1134 (0.1152)  PSNR: 15.3168 (15.1292)  SSIM: 0.1339 (0.1330)  iter-time: 0.3095\n",
            "[08:35:11.881562] Epoch: [49] Total time: 0:00:01 (0.3461 s / it)\n",
            "[08:35:11.882656] [Val] averaged stats: loss: 0.0128 (0.0131)  MSE: 0.0194 (0.0199)  MAE: 0.1134 (0.1152)  PSNR: 15.3168 (15.1292)  SSIM: 0.1339 (0.1330)\n",
            "[08:35:11.884567] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[08:35:11.887449] [Time] 17.1s 19.5m/34.3m\n",
            "\n",
            "[08:35:11.887513] ~~~ Epoch 50/100 ~~~\n",
            "\n",
            "[08:35:15.262094] Epoch: [50]  [ 0/27]  eta: 0:01:30  loss: 0.0128 (0.0128)  MSE: 0.0191 (0.0191)  MAE: 0.1130 (0.1130)  PSNR: 14.8856 (14.8856)  SSIM: 0.1195 (0.1195)  lr: 0.000100  iter-time: 3.3679\n",
            "[08:35:19.788146] Epoch: [50]  [10/27]  eta: 0:00:12  loss: 0.0129 (0.0130)  MSE: 0.0192 (0.0194)  MAE: 0.1130 (0.1138)  PSNR: 15.1084 (15.0298)  SSIM: 0.1298 (0.1333)  lr: 0.000100  iter-time: 0.7171\n",
            "[08:35:25.098375] Epoch: [50]  [20/27]  eta: 0:00:04  loss: 0.0130 (0.0130)  MSE: 0.0196 (0.0196)  MAE: 0.1141 (0.1142)  PSNR: 15.1595 (15.0658)  SSIM: 0.1240 (0.1317)  lr: 0.000100  iter-time: 0.4913\n",
            "[08:35:27.363103] Epoch: [50]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0128)  MSE: 0.0197 (0.0194)  MAE: 0.1143 (0.1136)  PSNR: 15.1595 (15.0570)  SSIM: 0.1329 (0.1344)  lr: 0.000100  iter-time: 0.4609\n",
            "[08:35:27.565957] Epoch: [50] Total time: 0:00:15 (0.5806 s / it)\n",
            "[08:35:27.568341] [Train] averaged stats: loss: 0.0130 (0.0128)  MSE: 0.0197 (0.0194)  MAE: 0.1143 (0.1136)  PSNR: 15.1595 (15.0570)  SSIM: 0.1329 (0.1344)  lr: 0.000100\n",
            "[08:35:28.175673] Epoch: [50]  [0/3]  eta: 0:00:01  loss: 0.0125 (0.0125)  MSE: 0.0197 (0.0197)  MAE: 0.1144 (0.1144)  PSNR: 15.2574 (15.2574)  SSIM: 0.1396 (0.1396)  iter-time: 0.6008\n",
            "[08:35:28.627139] Epoch: [50]  [2/3]  eta: 0:00:00  loss: 0.0127 (0.0132)  MSE: 0.0197 (0.0203)  MAE: 0.1144 (0.1160)  PSNR: 15.0281 (14.8660)  SSIM: 0.1396 (0.1388)  iter-time: 0.3499\n",
            "[08:35:28.721263] Epoch: [50] Total time: 0:00:01 (0.3824 s / it)\n",
            "[08:35:28.721438] [Val] averaged stats: loss: 0.0127 (0.0132)  MSE: 0.0197 (0.0203)  MAE: 0.1144 (0.1160)  PSNR: 15.0281 (14.8660)  SSIM: 0.1396 (0.1388)\n",
            "[08:35:28.722380] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "[08:35:28.728402] Creating training plots . . .\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[08:35:29.478332] [Time] 17.6s 19.8m/34.7m\n",
            "\n",
            "[08:35:29.478391] ~~~ Epoch 51/100 ~~~\n",
            "\n",
            "[08:35:31.697049] Epoch: [51]  [ 0/27]  eta: 0:00:59  loss: 0.0133 (0.0133)  MSE: 0.0197 (0.0197)  MAE: 0.1145 (0.1145)  PSNR: 14.9507 (14.9507)  SSIM: 0.1155 (0.1155)  lr: 0.000100  iter-time: 2.2146\n",
            "[08:35:37.175214] Epoch: [51]  [10/27]  eta: 0:00:11  loss: 0.0133 (0.0130)  MSE: 0.0197 (0.0194)  MAE: 0.1145 (0.1135)  PSNR: 14.9551 (15.0852)  SSIM: 0.1307 (0.1332)  lr: 0.000100  iter-time: 0.6979\n",
            "[08:35:42.760548] Epoch: [51]  [20/27]  eta: 0:00:04  loss: 0.0130 (0.0131)  MSE: 0.0196 (0.0196)  MAE: 0.1144 (0.1141)  PSNR: 15.1428 (15.1203)  SSIM: 0.1220 (0.1292)  lr: 0.000100  iter-time: 0.5523\n",
            "[08:35:45.316611] Epoch: [51]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0129)  MSE: 0.0196 (0.0194)  MAE: 0.1144 (0.1134)  PSNR: 15.1428 (15.1489)  SSIM: 0.1249 (0.1310)  lr: 0.000100  iter-time: 0.5098\n",
            "[08:35:45.459233] Epoch: [51] Total time: 0:00:15 (0.5918 s / it)\n",
            "[08:35:45.459392] [Train] averaged stats: loss: 0.0130 (0.0129)  MSE: 0.0196 (0.0194)  MAE: 0.1144 (0.1134)  PSNR: 15.1428 (15.1489)  SSIM: 0.1249 (0.1310)  lr: 0.000100\n",
            "[08:35:46.071271] Epoch: [51]  [0/3]  eta: 0:00:01  loss: 0.0124 (0.0124)  MSE: 0.0194 (0.0194)  MAE: 0.1137 (0.1137)  PSNR: 15.1876 (15.1876)  SSIM: 0.1360 (0.1360)  iter-time: 0.6037\n",
            "[08:35:46.515275] Epoch: [51]  [2/3]  eta: 0:00:00  loss: 0.0128 (0.0131)  MSE: 0.0195 (0.0200)  MAE: 0.1137 (0.1154)  PSNR: 15.0865 (14.8861)  SSIM: 0.1360 (0.1367)  iter-time: 0.3489\n",
            "[08:35:46.598463] Epoch: [51] Total time: 0:00:01 (0.3772 s / it)\n",
            "[08:35:46.598617] [Val] averaged stats: loss: 0.0128 (0.0131)  MSE: 0.0195 (0.0200)  MAE: 0.1137 (0.1154)  PSNR: 15.0865 (14.8861)  SSIM: 0.1360 (0.1367)\n",
            "[08:35:46.601789] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[08:35:46.604505] [Time] 17.1s 20.0m/34.3m\n",
            "\n",
            "[08:35:46.604563] ~~~ Epoch 52/100 ~~~\n",
            "\n",
            "[08:35:50.842685] Epoch: [52]  [ 0/27]  eta: 0:01:54  loss: 0.0127 (0.0127)  MSE: 0.0191 (0.0191)  MAE: 0.1129 (0.1129)  PSNR: 14.8361 (14.8361)  SSIM: 0.1211 (0.1211)  lr: 0.000100  iter-time: 4.2295\n",
            "[08:35:54.917109] Epoch: [52]  [10/27]  eta: 0:00:12  loss: 0.0129 (0.0128)  MSE: 0.0192 (0.0194)  MAE: 0.1129 (0.1136)  PSNR: 14.9535 (14.9700)  SSIM: 0.1263 (0.1319)  lr: 0.000100  iter-time: 0.7543\n",
            "[08:36:03.384879] Epoch: [52]  [20/27]  eta: 0:00:05  loss: 0.0129 (0.0128)  MSE: 0.0194 (0.0196)  MAE: 0.1132 (0.1142)  PSNR: 15.0246 (15.0628)  SSIM: 0.1263 (0.1308)  lr: 0.000100  iter-time: 0.6265\n",
            "[08:36:05.509162] Epoch: [52]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1138 (0.1137)  PSNR: 14.9489 (15.0703)  SSIM: 0.1365 (0.1338)  lr: 0.000100  iter-time: 0.6114\n",
            "[08:36:05.609789] Epoch: [52] Total time: 0:00:19 (0.7038 s / it)\n",
            "[08:36:05.611348] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1138 (0.1137)  PSNR: 14.9489 (15.0703)  SSIM: 0.1365 (0.1338)  lr: 0.000100\n",
            "[08:36:06.117446] Epoch: [52]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0193 (0.0193)  MAE: 0.1121 (0.1121)  PSNR: 15.2833 (15.2833)  SSIM: 0.1442 (0.1442)  iter-time: 0.5006\n",
            "[08:36:06.565060] Epoch: [52]  [2/3]  eta: 0:00:00  loss: 0.0124 (0.0127)  MSE: 0.0195 (0.0199)  MAE: 0.1129 (0.1143)  PSNR: 14.9374 (14.7968)  SSIM: 0.1423 (0.1421)  iter-time: 0.3158\n",
            "[08:36:06.654379] Epoch: [52] Total time: 0:00:01 (0.3461 s / it)\n",
            "[08:36:06.654620] [Val] averaged stats: loss: 0.0124 (0.0127)  MSE: 0.0195 (0.0199)  MAE: 0.1129 (0.1143)  PSNR: 14.9374 (14.7968)  SSIM: 0.1423 (0.1421)\n",
            "[08:36:06.657169] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[08:36:06.659897] [Time] 20.1s 20.4m/36.8m\n",
            "\n",
            "[08:36:06.659962] ~~~ Epoch 53/100 ~~~\n",
            "\n",
            "[08:36:09.429091] Epoch: [53]  [ 0/27]  eta: 0:01:14  loss: 0.0132 (0.0132)  MSE: 0.0198 (0.0198)  MAE: 0.1148 (0.1148)  PSNR: 14.8171 (14.8171)  SSIM: 0.1205 (0.1205)  lr: 0.000100  iter-time: 2.7637\n",
            "[08:36:14.644716] Epoch: [53]  [10/27]  eta: 0:00:12  loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1137 (0.1133)  PSNR: 14.9462 (14.9904)  SSIM: 0.1237 (0.1326)  lr: 0.000100  iter-time: 0.7253\n",
            "[08:36:24.097285] Epoch: [53]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0195 (0.0195)  MAE: 0.1136 (0.1137)  PSNR: 15.0806 (15.0968)  SSIM: 0.1189 (0.1289)  lr: 0.000100  iter-time: 0.7333\n",
            "[08:36:26.209848] Epoch: [53]  [26/27]  eta: 0:00:00  loss: 0.0129 (0.0126)  MSE: 0.0196 (0.0194)  MAE: 0.1136 (0.1132)  PSNR: 15.2659 (15.1730)  SSIM: 0.1261 (0.1317)  lr: 0.000100  iter-time: 0.6673\n",
            "[08:36:26.313589] Epoch: [53] Total time: 0:00:19 (0.7278 s / it)\n",
            "[08:36:26.313741] [Train] averaged stats: loss: 0.0129 (0.0126)  MSE: 0.0196 (0.0194)  MAE: 0.1136 (0.1132)  PSNR: 15.2659 (15.1730)  SSIM: 0.1261 (0.1317)  lr: 0.000100\n",
            "[08:36:26.884340] Epoch: [53]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0195 (0.0195)  MAE: 0.1126 (0.1126)  PSNR: 15.2427 (15.2427)  SSIM: 0.1495 (0.1495)  iter-time: 0.5658\n",
            "[08:36:27.335809] Epoch: [53]  [2/3]  eta: 0:00:00  loss: 0.0124 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1131 (0.1147)  PSNR: 14.9026 (14.7533)  SSIM: 0.1483 (0.1477)  iter-time: 0.3388\n",
            "[08:36:27.424269] Epoch: [53] Total time: 0:00:01 (0.3688 s / it)\n",
            "[08:36:27.424395] [Val] averaged stats: loss: 0.0124 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1131 (0.1147)  PSNR: 14.9026 (14.7533)  SSIM: 0.1483 (0.1477)\n",
            "[08:36:27.426894] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 11 out of 20\n",
            "[08:36:27.429596] [Time] 20.8s 20.7m/37.3m\n",
            "\n",
            "[08:36:27.429657] ~~~ Epoch 54/100 ~~~\n",
            "\n",
            "[08:36:31.297670] Epoch: [54]  [ 0/27]  eta: 0:01:44  loss: 0.0131 (0.0131)  MSE: 0.0200 (0.0200)  MAE: 0.1151 (0.1151)  PSNR: 15.0084 (15.0084)  SSIM: 0.1229 (0.1229)  lr: 0.000100  iter-time: 3.8645\n",
            "[08:36:35.796582] Epoch: [54]  [10/27]  eta: 0:00:12  loss: 0.0128 (0.0127)  MSE: 0.0196 (0.0196)  MAE: 0.1142 (0.1136)  PSNR: 15.0767 (15.0279)  SSIM: 0.1293 (0.1345)  lr: 0.000100  iter-time: 0.7602\n",
            "[08:36:44.402324] Epoch: [54]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0196 (0.0196)  MAE: 0.1142 (0.1140)  PSNR: 15.0767 (15.0989)  SSIM: 0.1206 (0.1301)  lr: 0.000100  iter-time: 0.6547\n",
            "[08:36:46.517778] Epoch: [54]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0126)  MSE: 0.0196 (0.0195)  MAE: 0.1134 (0.1134)  PSNR: 15.0581 (15.1600)  SSIM: 0.1313 (0.1329)  lr: 0.000100  iter-time: 0.6325\n",
            "[08:36:46.621144] Epoch: [54] Total time: 0:00:19 (0.7107 s / it)\n",
            "[08:36:46.622133] [Train] averaged stats: loss: 0.0128 (0.0126)  MSE: 0.0196 (0.0195)  MAE: 0.1134 (0.1134)  PSNR: 15.0581 (15.1600)  SSIM: 0.1313 (0.1329)  lr: 0.000100\n",
            "[08:36:47.143148] Epoch: [54]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0195 (0.0195)  MAE: 0.1127 (0.1127)  PSNR: 15.3859 (15.3859)  SSIM: 0.1452 (0.1452)  iter-time: 0.5158\n",
            "[08:36:47.588284] Epoch: [54]  [2/3]  eta: 0:00:00  loss: 0.0124 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1131 (0.1147)  PSNR: 15.0603 (14.9173)  SSIM: 0.1452 (0.1448)  iter-time: 0.3200\n",
            "[08:36:47.682844] Epoch: [54] Total time: 0:00:01 (0.3521 s / it)\n",
            "[08:36:47.682985] [Val] averaged stats: loss: 0.0124 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1131 (0.1147)  PSNR: 15.0603 (14.9173)  SSIM: 0.1452 (0.1448)\n",
            "[08:36:47.685620] [Val] best loss: 0.0127 best  MSE: 0.0197 MAE: 0.1135 PSNR: 15.3696 SSIM: 0.1424 \n",
            "EarlyStopping counter: 12 out of 20\n",
            "[08:36:47.688461] [Time] 20.3s 21.1m/36.9m\n",
            "\n",
            "[08:36:47.688527] ~~~ Epoch 55/100 ~~~\n",
            "\n",
            "[08:36:50.301043] Epoch: [55]  [ 0/27]  eta: 0:01:10  loss: 0.0129 (0.0129)  MSE: 0.0200 (0.0200)  MAE: 0.1154 (0.1154)  PSNR: 14.7883 (14.7883)  SSIM: 0.1261 (0.1261)  lr: 0.000100  iter-time: 2.6046\n",
            "[08:36:59.141686] Epoch: [55]  [10/27]  eta: 0:00:17  loss: 0.0125 (0.0126)  MSE: 0.0197 (0.0196)  MAE: 0.1133 (0.1137)  PSNR: 15.0988 (14.8737)  SSIM: 0.1277 (0.1347)  lr: 0.000100  iter-time: 1.0402\n",
            "[08:37:04.134554] Epoch: [55]  [20/27]  eta: 0:00:05  loss: 0.0127 (0.0128)  MSE: 0.0197 (0.0197)  MAE: 0.1133 (0.1142)  PSNR: 15.0988 (15.0541)  SSIM: 0.1226 (0.1301)  lr: 0.000100  iter-time: 0.6908\n",
            "[08:37:06.250925] Epoch: [55]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0126)  MSE: 0.0197 (0.0195)  MAE: 0.1134 (0.1136)  PSNR: 15.3097 (15.1468)  SSIM: 0.1293 (0.1332)  lr: 0.000100  iter-time: 0.4535\n",
            "[08:37:06.350750] Epoch: [55] Total time: 0:00:18 (0.6911 s / it)\n",
            "[08:37:06.352989] [Train] averaged stats: loss: 0.0127 (0.0126)  MSE: 0.0197 (0.0195)  MAE: 0.1134 (0.1136)  PSNR: 15.3097 (15.1468)  SSIM: 0.1293 (0.1332)  lr: 0.000100\n",
            "[08:37:06.901848] Epoch: [55]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0195 (0.0195)  MAE: 0.1124 (0.1124)  PSNR: 15.3851 (15.3851)  SSIM: 0.1486 (0.1486)  iter-time: 0.5422\n",
            "[08:37:07.354560] Epoch: [55]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1130 (0.1145)  PSNR: 15.0651 (14.9259)  SSIM: 0.1484 (0.1472)  iter-time: 0.3303\n",
            "[08:37:07.440532] Epoch: [55] Total time: 0:00:01 (0.3607 s / it)\n",
            "[08:37:07.441458] [Val] averaged stats: loss: 0.0125 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1130 (0.1145)  PSNR: 15.0651 (14.9259)  SSIM: 0.1484 (0.1472)\n",
            "[08:37:07.443351] Val loss improved from 0.01268661767244339 to 0.012667426529030005, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:37:18.138763] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "[08:37:18.141746] Creating training plots . . .\n",
            "[08:37:18.902196] [Time] 31.2s 21.6m/45.5m\n",
            "\n",
            "[08:37:18.903984] ~~~ Epoch 56/100 ~~~\n",
            "\n",
            "[08:37:22.562169] Epoch: [56]  [ 0/27]  eta: 0:01:38  loss: 0.0130 (0.0130)  MSE: 0.0198 (0.0198)  MAE: 0.1147 (0.1147)  PSNR: 14.7809 (14.7809)  SSIM: 0.1256 (0.1256)  lr: 0.000100  iter-time: 3.6525\n",
            "[08:37:31.263584] Epoch: [56]  [10/27]  eta: 0:00:19  loss: 0.0127 (0.0127)  MSE: 0.0197 (0.0196)  MAE: 0.1137 (0.1138)  PSNR: 15.2220 (15.1543)  SSIM: 0.1296 (0.1352)  lr: 0.000100  iter-time: 1.1228\n",
            "[08:37:35.288642] Epoch: [56]  [20/27]  eta: 0:00:05  loss: 0.0127 (0.0128)  MSE: 0.0197 (0.0197)  MAE: 0.1137 (0.1142)  PSNR: 15.2220 (15.2471)  SSIM: 0.1250 (0.1313)  lr: 0.000100  iter-time: 0.6360\n",
            "[08:37:37.407400] Epoch: [56]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0126)  MSE: 0.0197 (0.0195)  MAE: 0.1135 (0.1135)  PSNR: 15.1192 (15.2608)  SSIM: 0.1310 (0.1337)  lr: 0.000100  iter-time: 0.5468\n",
            "[08:37:37.502366] Epoch: [56] Total time: 0:00:18 (0.6887 s / it)\n",
            "[08:37:37.503514] [Train] averaged stats: loss: 0.0127 (0.0126)  MSE: 0.0197 (0.0195)  MAE: 0.1135 (0.1135)  PSNR: 15.1192 (15.2608)  SSIM: 0.1310 (0.1337)  lr: 0.000100\n",
            "[08:37:38.059632] Epoch: [56]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0195 (0.0195)  MAE: 0.1126 (0.1126)  PSNR: 15.5185 (15.5185)  SSIM: 0.1453 (0.1453)  iter-time: 0.5487\n",
            "[08:37:38.511567] Epoch: [56]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1131 (0.1146)  PSNR: 15.2322 (15.0912)  SSIM: 0.1440 (0.1431)  iter-time: 0.3329\n",
            "[08:37:38.601317] Epoch: [56] Total time: 0:00:01 (0.3638 s / it)\n",
            "[08:37:38.601677] [Val] averaged stats: loss: 0.0125 (0.0127)  MSE: 0.0196 (0.0201)  MAE: 0.1131 (0.1146)  PSNR: 15.2322 (15.0912)  SSIM: 0.1440 (0.1431)\n",
            "[08:37:38.604226] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:37:38.607220] [Time] 19.7s 21.9m/36.7m\n",
            "\n",
            "[08:37:38.607278] ~~~ Epoch 57/100 ~~~\n",
            "\n",
            "[08:37:42.008197] Epoch: [57]  [ 0/27]  eta: 0:01:31  loss: 0.0130 (0.0130)  MSE: 0.0201 (0.0201)  MAE: 0.1154 (0.1154)  PSNR: 14.8694 (14.8694)  SSIM: 0.1248 (0.1248)  lr: 0.000100  iter-time: 3.3929\n",
            "[08:37:51.201186] Epoch: [57]  [10/27]  eta: 0:00:19  loss: 0.0128 (0.0127)  MSE: 0.0196 (0.0195)  MAE: 0.1141 (0.1133)  PSNR: 15.2859 (15.0920)  SSIM: 0.1265 (0.1358)  lr: 0.000100  iter-time: 1.1430\n",
            "[08:37:56.254537] Epoch: [57]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0129)  MSE: 0.0196 (0.0195)  MAE: 0.1141 (0.1137)  PSNR: 15.3072 (15.1968)  SSIM: 0.1221 (0.1286)  lr: 0.000100  iter-time: 0.7115\n",
            "[08:37:58.842960] Epoch: [57]  [26/27]  eta: 0:00:00  loss: 0.0129 (0.0127)  MSE: 0.0194 (0.0193)  MAE: 0.1131 (0.1131)  PSNR: 15.3354 (15.2723)  SSIM: 0.1211 (0.1302)  lr: 0.000100  iter-time: 0.4820\n",
            "[08:37:58.944942] Epoch: [57] Total time: 0:00:20 (0.7532 s / it)\n",
            "[08:37:58.947510] [Train] averaged stats: loss: 0.0129 (0.0127)  MSE: 0.0194 (0.0193)  MAE: 0.1131 (0.1131)  PSNR: 15.3354 (15.2723)  SSIM: 0.1211 (0.1302)  lr: 0.000100\n",
            "[08:37:59.492645] Epoch: [57]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0195 (0.0195)  MAE: 0.1129 (0.1129)  PSNR: 15.2730 (15.2730)  SSIM: 0.1438 (0.1438)  iter-time: 0.5399\n",
            "[08:37:59.952027] Epoch: [57]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0196 (0.0200)  MAE: 0.1130 (0.1147)  PSNR: 14.9495 (14.8093)  SSIM: 0.1438 (0.1429)  iter-time: 0.3326\n",
            "[08:38:00.136309] Epoch: [57] Total time: 0:00:01 (0.3948 s / it)\n",
            "[08:38:00.136543] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0196 (0.0200)  MAE: 0.1130 (0.1147)  PSNR: 14.9495 (14.8093)  SSIM: 0.1438 (0.1429)\n",
            "[08:38:00.140030] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:38:00.143041] [Time] 21.5s 22.3m/38.1m\n",
            "\n",
            "[08:38:00.144004] ~~~ Epoch 58/100 ~~~\n",
            "\n",
            "[08:38:05.328285] Epoch: [58]  [ 0/27]  eta: 0:02:19  loss: 0.0132 (0.0132)  MSE: 0.0198 (0.0198)  MAE: 0.1148 (0.1148)  PSNR: 14.7857 (14.7857)  SSIM: 0.1237 (0.1237)  lr: 0.000100  iter-time: 5.1790\n",
            "[08:38:12.803370] Epoch: [58]  [10/27]  eta: 0:00:19  loss: 0.0128 (0.0127)  MSE: 0.0198 (0.0196)  MAE: 0.1145 (0.1137)  PSNR: 15.0995 (15.0322)  SSIM: 0.1260 (0.1359)  lr: 0.000100  iter-time: 1.1492\n",
            "[08:38:17.432846] Epoch: [58]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0197 (0.0196)  MAE: 0.1132 (0.1138)  PSNR: 15.1333 (15.0920)  SSIM: 0.1210 (0.1299)  lr: 0.000100  iter-time: 0.6044\n",
            "[08:38:19.553159] Epoch: [58]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0126)  MSE: 0.0196 (0.0194)  MAE: 0.1132 (0.1132)  PSNR: 15.2516 (15.1704)  SSIM: 0.1239 (0.1322)  lr: 0.000100  iter-time: 0.4209\n",
            "[08:38:19.709299] Epoch: [58] Total time: 0:00:19 (0.7245 s / it)\n",
            "[08:38:19.710284] [Train] averaged stats: loss: 0.0128 (0.0126)  MSE: 0.0196 (0.0194)  MAE: 0.1132 (0.1132)  PSNR: 15.2516 (15.1704)  SSIM: 0.1239 (0.1322)  lr: 0.000100\n",
            "[08:38:20.482247] Epoch: [58]  [0/3]  eta: 0:00:02  loss: 0.0121 (0.0121)  MSE: 0.0197 (0.0197)  MAE: 0.1137 (0.1137)  PSNR: 15.3115 (15.3115)  SSIM: 0.1421 (0.1421)  iter-time: 0.7656\n",
            "[08:38:20.931218] Epoch: [58]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0129)  MSE: 0.0197 (0.0203)  MAE: 0.1137 (0.1155)  PSNR: 15.0040 (14.8525)  SSIM: 0.1421 (0.1407)  iter-time: 0.4039\n",
            "[08:38:21.099163] Epoch: [58] Total time: 0:00:01 (0.4612 s / it)\n",
            "[08:38:21.099295] [Val] averaged stats: loss: 0.0125 (0.0129)  MSE: 0.0197 (0.0203)  MAE: 0.1137 (0.1155)  PSNR: 15.0040 (14.8525)  SSIM: 0.1421 (0.1407)\n",
            "[08:38:21.100523] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:38:21.102168] [Time] 21.0s 22.6m/37.6m\n",
            "\n",
            "[08:38:21.102217] ~~~ Epoch 59/100 ~~~\n",
            "\n",
            "[08:38:24.058182] Epoch: [59]  [ 0/27]  eta: 0:01:19  loss: 0.0131 (0.0131)  MSE: 0.0200 (0.0200)  MAE: 0.1150 (0.1150)  PSNR: 14.9011 (14.9011)  SSIM: 0.1181 (0.1181)  lr: 0.000100  iter-time: 2.9437\n",
            "[08:38:29.399829] Epoch: [59]  [10/27]  eta: 0:00:12  loss: 0.0131 (0.0129)  MSE: 0.0197 (0.0195)  MAE: 0.1138 (0.1135)  PSNR: 15.0640 (14.9801)  SSIM: 0.1191 (0.1271)  lr: 0.000100  iter-time: 0.7526\n",
            "[08:38:36.061855] Epoch: [59]  [20/27]  eta: 0:00:04  loss: 0.0131 (0.0130)  MSE: 0.0197 (0.0195)  MAE: 0.1138 (0.1138)  PSNR: 15.0967 (15.0773)  SSIM: 0.1176 (0.1240)  lr: 0.000100  iter-time: 0.5997\n",
            "[08:38:38.205250] Epoch: [59]  [26/27]  eta: 0:00:00  loss: 0.0131 (0.0129)  MSE: 0.0195 (0.0193)  MAE: 0.1138 (0.1131)  PSNR: 15.2415 (15.1713)  SSIM: 0.1188 (0.1249)  lr: 0.000100  iter-time: 0.5581\n",
            "[08:38:38.373159] Epoch: [59] Total time: 0:00:17 (0.6396 s / it)\n",
            "[08:38:38.373356] [Train] averaged stats: loss: 0.0131 (0.0129)  MSE: 0.0195 (0.0193)  MAE: 0.1138 (0.1131)  PSNR: 15.2415 (15.1713)  SSIM: 0.1188 (0.1249)  lr: 0.000100\n",
            "[08:38:39.083673] Epoch: [59]  [0/3]  eta: 0:00:02  loss: 0.0121 (0.0121)  MSE: 0.0193 (0.0193)  MAE: 0.1130 (0.1130)  PSNR: 15.0724 (15.0724)  SSIM: 0.1361 (0.1361)  iter-time: 0.7001\n",
            "[08:38:39.531314] Epoch: [59]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0199)  MAE: 0.1132 (0.1148)  PSNR: 14.7789 (14.6384)  SSIM: 0.1361 (0.1363)  iter-time: 0.3817\n",
            "[08:38:39.636717] Epoch: [59] Total time: 0:00:01 (0.4180 s / it)\n",
            "[08:38:39.636903] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0199)  MAE: 0.1132 (0.1148)  PSNR: 14.7789 (14.6384)  SSIM: 0.1361 (0.1363)\n",
            "[08:38:39.637739] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[08:38:39.640241] [Time] 18.5s 22.9m/35.9m\n",
            "\n",
            "[08:38:39.640294] ~~~ Epoch 60/100 ~~~\n",
            "\n",
            "[08:38:43.034721] Epoch: [60]  [ 0/27]  eta: 0:01:31  loss: 0.0129 (0.0129)  MSE: 0.0194 (0.0194)  MAE: 0.1139 (0.1139)  PSNR: 14.7588 (14.7588)  SSIM: 0.1146 (0.1146)  lr: 0.000100  iter-time: 3.3899\n",
            "[08:38:47.127094] Epoch: [60]  [10/27]  eta: 0:00:11  loss: 0.0127 (0.0127)  MSE: 0.0197 (0.0197)  MAE: 0.1144 (0.1142)  PSNR: 14.7734 (14.7786)  SSIM: 0.1277 (0.1331)  lr: 0.000100  iter-time: 0.6795\n",
            "[08:38:52.850246] Epoch: [60]  [20/27]  eta: 0:00:04  loss: 0.0127 (0.0129)  MSE: 0.0199 (0.0198)  MAE: 0.1147 (0.1145)  PSNR: 14.8148 (14.9127)  SSIM: 0.1191 (0.1287)  lr: 0.000100  iter-time: 0.4903\n",
            "[08:38:55.045350] Epoch: [60]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1143 (0.1137)  PSNR: 14.9829 (15.0351)  SSIM: 0.1277 (0.1300)  lr: 0.000100  iter-time: 0.4788\n",
            "[08:38:55.197924] Epoch: [60] Total time: 0:00:15 (0.5761 s / it)\n",
            "[08:38:55.199075] [Train] averaged stats: loss: 0.0130 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1143 (0.1137)  PSNR: 14.9829 (15.0351)  SSIM: 0.1277 (0.1300)  lr: 0.000100\n",
            "[08:38:55.852900] Epoch: [60]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0193 (0.0193)  MAE: 0.1126 (0.1126)  PSNR: 15.2213 (15.2213)  SSIM: 0.1400 (0.1400)  iter-time: 0.6468\n",
            "[08:38:56.302652] Epoch: [60]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0199)  MAE: 0.1130 (0.1146)  PSNR: 14.8139 (14.7225)  SSIM: 0.1400 (0.1401)  iter-time: 0.3649\n",
            "[08:38:56.401761] Epoch: [60] Total time: 0:00:01 (0.3989 s / it)\n",
            "[08:38:56.401925] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0199)  MAE: 0.1130 (0.1146)  PSNR: 14.8139 (14.7225)  SSIM: 0.1400 (0.1401)\n",
            "[08:38:56.404683] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "[08:38:56.408473] Creating training plots . . .\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[08:38:57.268186] [Time] 17.6s 23.2m/35.3m\n",
            "\n",
            "[08:38:57.268251] ~~~ Epoch 61/100 ~~~\n",
            "\n",
            "[08:38:59.851913] Epoch: [61]  [ 0/27]  eta: 0:01:09  loss: 0.0128 (0.0128)  MSE: 0.0196 (0.0196)  MAE: 0.1145 (0.1145)  PSNR: 14.7497 (14.7497)  SSIM: 0.1197 (0.1197)  lr: 0.000100  iter-time: 2.5762\n",
            "[08:39:05.559587] Epoch: [61]  [10/27]  eta: 0:00:12  loss: 0.0128 (0.0127)  MSE: 0.0196 (0.0197)  MAE: 0.1142 (0.1141)  PSNR: 14.9791 (14.8649)  SSIM: 0.1334 (0.1355)  lr: 0.000100  iter-time: 0.7519\n",
            "[08:39:12.991149] Epoch: [61]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0129)  MSE: 0.0197 (0.0198)  MAE: 0.1142 (0.1145)  PSNR: 15.0079 (14.9860)  SSIM: 0.1225 (0.1317)  lr: 0.000100  iter-time: 0.6556\n",
            "[08:39:15.127968] Epoch: [61]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0196 (0.0195)  MAE: 0.1146 (0.1137)  PSNR: 15.0622 (15.0249)  SSIM: 0.1305 (0.1328)  lr: 0.000100  iter-time: 0.5787\n",
            "[08:39:15.232195] Epoch: [61] Total time: 0:00:17 (0.6652 s / it)\n",
            "[08:39:15.234178] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0196 (0.0195)  MAE: 0.1146 (0.1137)  PSNR: 15.0622 (15.0249)  SSIM: 0.1305 (0.1328)  lr: 0.000100\n",
            "[08:39:15.822796] Epoch: [61]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0194 (0.0194)  MAE: 0.1131 (0.1131)  PSNR: 15.2229 (15.2229)  SSIM: 0.1421 (0.1421)  iter-time: 0.5836\n",
            "[08:39:16.271198] Epoch: [61]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0196 (0.0200)  MAE: 0.1133 (0.1150)  PSNR: 14.8889 (14.7532)  SSIM: 0.1421 (0.1421)  iter-time: 0.3437\n",
            "[08:39:16.369227] Epoch: [61] Total time: 0:00:01 (0.3769 s / it)\n",
            "[08:39:16.369360] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0196 (0.0200)  MAE: 0.1133 (0.1150)  PSNR: 14.8889 (14.7532)  SSIM: 0.1421 (0.1421)\n",
            "[08:39:16.372086] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[08:39:16.375060] [Time] 19.1s 23.5m/36.3m\n",
            "\n",
            "[08:39:16.375293] ~~~ Epoch 62/100 ~~~\n",
            "\n",
            "[08:39:17.996269] Epoch: [62]  [ 0/27]  eta: 0:00:43  loss: 0.0131 (0.0131)  MSE: 0.0195 (0.0195)  MAE: 0.1139 (0.1139)  PSNR: 14.9829 (14.9829)  SSIM: 0.1172 (0.1172)  lr: 0.000100  iter-time: 1.6148\n",
            "[08:39:23.381079] Epoch: [62]  [10/27]  eta: 0:00:10  loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0196)  MAE: 0.1139 (0.1138)  PSNR: 14.8493 (14.9192)  SSIM: 0.1344 (0.1362)  lr: 0.000100  iter-time: 0.6353\n",
            "[08:39:31.755750] Epoch: [62]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0197 (0.0196)  MAE: 0.1140 (0.1142)  PSNR: 14.8715 (15.0467)  SSIM: 0.1281 (0.1320)  lr: 0.000100  iter-time: 0.6871\n",
            "[08:39:35.478895] Epoch: [62]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1140 (0.1135)  PSNR: 15.1347 (15.1056)  SSIM: 0.1282 (0.1340)  lr: 0.000100  iter-time: 0.6868\n",
            "[08:39:35.582368] Epoch: [62] Total time: 0:00:19 (0.7113 s / it)\n",
            "[08:39:35.582538] [Train] averaged stats: loss: 0.0127 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1140 (0.1135)  PSNR: 15.1347 (15.1056)  SSIM: 0.1282 (0.1340)  lr: 0.000100\n",
            "[08:39:36.100784] Epoch: [62]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0193 (0.0193)  MAE: 0.1124 (0.1124)  PSNR: 15.1244 (15.1244)  SSIM: 0.1428 (0.1428)  iter-time: 0.5123\n",
            "[08:39:36.550889] Epoch: [62]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0199)  MAE: 0.1131 (0.1145)  PSNR: 14.8031 (14.6803)  SSIM: 0.1428 (0.1427)  iter-time: 0.3205\n",
            "[08:39:36.635521] Epoch: [62] Total time: 0:00:01 (0.3493 s / it)\n",
            "[08:39:36.635649] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0199)  MAE: 0.1131 (0.1145)  PSNR: 14.8031 (14.6803)  SSIM: 0.1428 (0.1427)\n",
            "[08:39:36.638172] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[08:39:36.640973] [Time] 20.3s 23.9m/37.1m\n",
            "\n",
            "[08:39:36.641035] ~~~ Epoch 63/100 ~~~\n",
            "\n",
            "[08:39:38.598225] Epoch: [63]  [ 0/27]  eta: 0:00:52  loss: 0.0127 (0.0127)  MSE: 0.0195 (0.0195)  MAE: 0.1142 (0.1142)  PSNR: 14.9003 (14.9003)  SSIM: 0.1202 (0.1202)  lr: 0.000100  iter-time: 1.9532\n",
            "[08:39:44.798486] Epoch: [63]  [10/27]  eta: 0:00:12  loss: 0.0127 (0.0126)  MSE: 0.0197 (0.0196)  MAE: 0.1142 (0.1137)  PSNR: 15.0266 (14.8841)  SSIM: 0.1273 (0.1378)  lr: 0.000100  iter-time: 0.7408\n",
            "[08:39:53.462812] Epoch: [63]  [20/27]  eta: 0:00:05  loss: 0.0129 (0.0127)  MSE: 0.0199 (0.0197)  MAE: 0.1143 (0.1141)  PSNR: 15.0266 (15.0641)  SSIM: 0.1260 (0.1346)  lr: 0.000100  iter-time: 0.7429\n",
            "[08:39:55.569102] Epoch: [63]  [26/27]  eta: 0:00:00  loss: 0.0129 (0.0126)  MSE: 0.0198 (0.0195)  MAE: 0.1131 (0.1135)  PSNR: 15.0266 (15.1100)  SSIM: 0.1290 (0.1360)  lr: 0.000100  iter-time: 0.6229\n",
            "[08:39:55.680171] Epoch: [63] Total time: 0:00:19 (0.7051 s / it)\n",
            "[08:39:55.682214] [Train] averaged stats: loss: 0.0129 (0.0126)  MSE: 0.0198 (0.0195)  MAE: 0.1131 (0.1135)  PSNR: 15.0266 (15.1100)  SSIM: 0.1290 (0.1360)  lr: 0.000100\n",
            "[08:39:56.248203] Epoch: [63]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0195 (0.0195)  MAE: 0.1131 (0.1131)  PSNR: 15.2643 (15.2643)  SSIM: 0.1424 (0.1424)  iter-time: 0.5597\n",
            "[08:39:56.696791] Epoch: [63]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0196 (0.0200)  MAE: 0.1132 (0.1149)  PSNR: 14.9457 (14.8034)  SSIM: 0.1424 (0.1421)  iter-time: 0.3358\n",
            "[08:39:56.788379] Epoch: [63] Total time: 0:00:01 (0.3669 s / it)\n",
            "[08:39:56.788607] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0196 (0.0200)  MAE: 0.1132 (0.1149)  PSNR: 14.9457 (14.8034)  SSIM: 0.1424 (0.1421)\n",
            "[08:39:56.791273] [Val] best loss: 0.0127 best  MSE: 0.0201 MAE: 0.1145 PSNR: 14.9259 SSIM: 0.1472 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[08:39:56.794730] [Time] 20.2s 24.2m/37.0m\n",
            "\n",
            "[08:39:56.794805] ~~~ Epoch 64/100 ~~~\n",
            "\n",
            "[08:39:58.493820] Epoch: [64]  [ 0/27]  eta: 0:00:45  loss: 0.0129 (0.0129)  MSE: 0.0198 (0.0198)  MAE: 0.1148 (0.1148)  PSNR: 14.9007 (14.9007)  SSIM: 0.1188 (0.1188)  lr: 0.000100  iter-time: 1.6916\n",
            "[08:40:07.479012] Epoch: [64]  [10/27]  eta: 0:00:16  loss: 0.0129 (0.0126)  MSE: 0.0197 (0.0195)  MAE: 0.1137 (0.1135)  PSNR: 15.1455 (15.1246)  SSIM: 0.1281 (0.1343)  lr: 0.000100  iter-time: 0.9705\n",
            "[08:40:14.464509] Epoch: [64]  [20/27]  eta: 0:00:05  loss: 0.0129 (0.0128)  MSE: 0.0197 (0.0196)  MAE: 0.1137 (0.1140)  PSNR: 15.0971 (15.1115)  SSIM: 0.1272 (0.1310)  lr: 0.000100  iter-time: 0.7980\n",
            "[08:40:16.591092] Epoch: [64]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0127)  MSE: 0.0197 (0.0194)  MAE: 0.1140 (0.1134)  PSNR: 15.0470 (15.1256)  SSIM: 0.1287 (0.1339)  lr: 0.000100  iter-time: 0.5536\n",
            "[08:40:16.694099] Epoch: [64] Total time: 0:00:19 (0.7369 s / it)\n",
            "[08:40:16.697980] [Train] averaged stats: loss: 0.0130 (0.0127)  MSE: 0.0197 (0.0194)  MAE: 0.1140 (0.1134)  PSNR: 15.0470 (15.1256)  SSIM: 0.1287 (0.1339)  lr: 0.000100\n",
            "[08:40:17.209748] Epoch: [64]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0191 (0.0191)  MAE: 0.1113 (0.1113)  PSNR: 15.1485 (15.1485)  SSIM: 0.1456 (0.1456)  iter-time: 0.5067\n",
            "[08:40:17.658280] Epoch: [64]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0126)  MSE: 0.0193 (0.0196)  MAE: 0.1124 (0.1134)  PSNR: 14.7380 (14.6173)  SSIM: 0.1456 (0.1450)  iter-time: 0.3175\n",
            "[08:40:17.751042] Epoch: [64] Total time: 0:00:01 (0.3496 s / it)\n",
            "[08:40:17.751179] [Val] averaged stats: loss: 0.0125 (0.0126)  MSE: 0.0193 (0.0196)  MAE: 0.1124 (0.1134)  PSNR: 14.7380 (14.6173)  SSIM: 0.1456 (0.1450)\n",
            "[08:40:17.753648] Val loss improved from 0.012667426529030005 to 0.012640010255078474, saving model to /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n",
            "[08:40:26.270084] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "[08:40:26.273121] [Time] 29.5s 24.7m/42.9m\n",
            "\n",
            "[08:40:26.273224] ~~~ Epoch 65/100 ~~~\n",
            "\n",
            "[08:40:29.104838] Epoch: [65]  [ 0/27]  eta: 0:01:16  loss: 0.0128 (0.0128)  MSE: 0.0196 (0.0196)  MAE: 0.1146 (0.1146)  PSNR: 14.7599 (14.7599)  SSIM: 0.1190 (0.1190)  lr: 0.000100  iter-time: 2.8278\n",
            "[08:40:35.532263] Epoch: [65]  [10/27]  eta: 0:00:14  loss: 0.0128 (0.0126)  MSE: 0.0194 (0.0193)  MAE: 0.1136 (0.1132)  PSNR: 15.0673 (14.9181)  SSIM: 0.1256 (0.1330)  lr: 0.000100  iter-time: 0.8412\n",
            "[08:40:43.061940] Epoch: [65]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0194 (0.0194)  MAE: 0.1136 (0.1135)  PSNR: 15.0673 (15.0014)  SSIM: 0.1204 (0.1280)  lr: 0.000100  iter-time: 0.6974\n",
            "[08:40:45.199884] Epoch: [65]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0194 (0.0193)  MAE: 0.1131 (0.1130)  PSNR: 15.0875 (15.0337)  SSIM: 0.1267 (0.1300)  lr: 0.000100  iter-time: 0.6456\n",
            "[08:40:45.326883] Epoch: [65] Total time: 0:00:19 (0.7056 s / it)\n",
            "[08:40:45.327843] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0194 (0.0193)  MAE: 0.1131 (0.1130)  PSNR: 15.0875 (15.0337)  SSIM: 0.1267 (0.1300)  lr: 0.000100\n",
            "[08:40:45.861323] Epoch: [65]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0193 (0.0193)  MAE: 0.1125 (0.1125)  PSNR: 15.2126 (15.2126)  SSIM: 0.1408 (0.1408)  iter-time: 0.5286\n",
            "[08:40:46.308350] Epoch: [65]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0194 (0.0199)  MAE: 0.1128 (0.1144)  PSNR: 14.8913 (14.7476)  SSIM: 0.1408 (0.1396)  iter-time: 0.3242\n",
            "[08:40:46.410458] Epoch: [65] Total time: 0:00:01 (0.3595 s / it)\n",
            "[08:40:46.411270] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0194 (0.0199)  MAE: 0.1128 (0.1144)  PSNR: 14.8913 (14.7476)  SSIM: 0.1408 (0.1396)\n",
            "[08:40:46.413347] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "[08:40:46.416081] Creating training plots . . .\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:40:47.219157] [Time] 20.9s 25.1m/37.6m\n",
            "\n",
            "[08:40:47.219236] ~~~ Epoch 66/100 ~~~\n",
            "\n",
            "[08:40:49.608343] Epoch: [66]  [ 0/27]  eta: 0:01:04  loss: 0.0128 (0.0128)  MSE: 0.0195 (0.0195)  MAE: 0.1139 (0.1139)  PSNR: 14.8394 (14.8394)  SSIM: 0.1155 (0.1155)  lr: 0.000100  iter-time: 2.3757\n",
            "[08:41:00.104117] Epoch: [66]  [10/27]  eta: 0:00:19  loss: 0.0128 (0.0127)  MSE: 0.0195 (0.0193)  MAE: 0.1135 (0.1130)  PSNR: 15.0730 (14.9951)  SSIM: 0.1232 (0.1305)  lr: 0.000100  iter-time: 1.1698\n",
            "[08:41:05.290356] Epoch: [66]  [20/27]  eta: 0:00:06  loss: 0.0128 (0.0128)  MSE: 0.0195 (0.0193)  MAE: 0.1135 (0.1133)  PSNR: 15.1357 (15.1068)  SSIM: 0.1171 (0.1262)  lr: 0.000100  iter-time: 0.7831\n",
            "[08:41:07.446962] Epoch: [66]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0127)  MSE: 0.0192 (0.0191)  MAE: 0.1133 (0.1127)  PSNR: 15.0730 (15.1273)  SSIM: 0.1232 (0.1272)  lr: 0.000100  iter-time: 0.5656\n",
            "[08:41:07.560960] Epoch: [66] Total time: 0:00:20 (0.7532 s / it)\n",
            "[08:41:07.562606] [Train] averaged stats: loss: 0.0130 (0.0127)  MSE: 0.0192 (0.0191)  MAE: 0.1133 (0.1127)  PSNR: 15.0730 (15.1273)  SSIM: 0.1232 (0.1272)  lr: 0.000100\n",
            "[08:41:08.075737] Epoch: [66]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0192 (0.0192)  MAE: 0.1125 (0.1125)  PSNR: 15.1748 (15.1748)  SSIM: 0.1342 (0.1342)  iter-time: 0.5076\n",
            "[08:41:08.527252] Epoch: [66]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0128)  MSE: 0.0193 (0.0198)  MAE: 0.1129 (0.1144)  PSNR: 14.8636 (14.7405)  SSIM: 0.1342 (0.1342)  iter-time: 0.3189\n",
            "[08:41:08.616791] Epoch: [66] Total time: 0:00:01 (0.3499 s / it)\n",
            "[08:41:08.616917] [Val] averaged stats: loss: 0.0126 (0.0128)  MSE: 0.0193 (0.0198)  MAE: 0.1129 (0.1144)  PSNR: 14.8636 (14.7405)  SSIM: 0.1342 (0.1342)\n",
            "[08:41:08.619521] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:41:08.622421] [Time] 21.4s 25.4m/37.9m\n",
            "\n",
            "[08:41:08.622485] ~~~ Epoch 67/100 ~~~\n",
            "\n",
            "[08:41:11.762733] Epoch: [67]  [ 0/27]  eta: 0:01:24  loss: 0.0133 (0.0133)  MSE: 0.0193 (0.0193)  MAE: 0.1138 (0.1138)  PSNR: 14.9068 (14.9068)  SSIM: 0.1149 (0.1149)  lr: 0.000100  iter-time: 3.1262\n",
            "[08:41:20.999937] Epoch: [67]  [10/27]  eta: 0:00:19  loss: 0.0126 (0.0128)  MSE: 0.0195 (0.0195)  MAE: 0.1136 (0.1137)  PSNR: 14.9221 (14.9552)  SSIM: 0.1245 (0.1330)  lr: 0.000100  iter-time: 1.1237\n",
            "[08:41:25.370031] Epoch: [67]  [20/27]  eta: 0:00:05  loss: 0.0126 (0.0128)  MSE: 0.0196 (0.0196)  MAE: 0.1136 (0.1142)  PSNR: 14.9265 (14.9808)  SSIM: 0.1225 (0.1287)  lr: 0.000100  iter-time: 0.6800\n",
            "[08:41:27.493279] Epoch: [67]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1142 (0.1135)  PSNR: 14.9494 (15.0451)  SSIM: 0.1254 (0.1305)  lr: 0.000100  iter-time: 0.4402\n",
            "[08:41:27.602387] Epoch: [67] Total time: 0:00:18 (0.7029 s / it)\n",
            "[08:41:27.602572] [Train] averaged stats: loss: 0.0127 (0.0127)  MSE: 0.0197 (0.0195)  MAE: 0.1142 (0.1135)  PSNR: 14.9494 (15.0451)  SSIM: 0.1254 (0.1305)  lr: 0.000100\n",
            "[08:41:28.184268] Epoch: [67]  [0/3]  eta: 0:00:01  loss: 0.0122 (0.0122)  MSE: 0.0195 (0.0195)  MAE: 0.1136 (0.1136)  PSNR: 15.0730 (15.0730)  SSIM: 0.1345 (0.1345)  iter-time: 0.5763\n",
            "[08:41:28.628887] Epoch: [67]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0130)  MSE: 0.0196 (0.0201)  MAE: 0.1136 (0.1154)  PSNR: 14.7424 (14.6320)  SSIM: 0.1345 (0.1348)  iter-time: 0.3400\n",
            "[08:41:28.724252] Epoch: [67] Total time: 0:00:01 (0.3724 s / it)\n",
            "[08:41:28.724544] [Val] averaged stats: loss: 0.0126 (0.0130)  MSE: 0.0196 (0.0201)  MAE: 0.1136 (0.1154)  PSNR: 14.7424 (14.6320)  SSIM: 0.1345 (0.1348)\n",
            "[08:41:28.727454] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:41:28.730601] [Time] 20.1s 25.8m/37.1m\n",
            "\n",
            "[08:41:28.731426] ~~~ Epoch 68/100 ~~~\n",
            "\n",
            "[08:41:32.623427] Epoch: [68]  [ 0/27]  eta: 0:01:44  loss: 0.0130 (0.0130)  MSE: 0.0196 (0.0196)  MAE: 0.1143 (0.1143)  PSNR: 14.5725 (14.5725)  SSIM: 0.1161 (0.1161)  lr: 0.000100  iter-time: 3.8817\n",
            "[08:41:41.414792] Epoch: [68]  [10/27]  eta: 0:00:19  loss: 0.0130 (0.0127)  MSE: 0.0194 (0.0194)  MAE: 0.1133 (0.1134)  PSNR: 14.7205 (14.7738)  SSIM: 0.1284 (0.1301)  lr: 0.000100  iter-time: 1.1512\n",
            "[08:41:45.494152] Epoch: [68]  [20/27]  eta: 0:00:05  loss: 0.0131 (0.0129)  MSE: 0.0196 (0.0196)  MAE: 0.1136 (0.1140)  PSNR: 14.9907 (14.8732)  SSIM: 0.1197 (0.1260)  lr: 0.000100  iter-time: 0.6429\n",
            "[08:41:47.604379] Epoch: [68]  [26/27]  eta: 0:00:00  loss: 0.0129 (0.0127)  MSE: 0.0196 (0.0194)  MAE: 0.1136 (0.1133)  PSNR: 15.2076 (14.9656)  SSIM: 0.1284 (0.1284)  lr: 0.000100  iter-time: 0.5596\n",
            "[08:41:47.715083] Epoch: [68] Total time: 0:00:18 (0.7030 s / it)\n",
            "[08:41:47.716464] [Train] averaged stats: loss: 0.0129 (0.0127)  MSE: 0.0196 (0.0194)  MAE: 0.1136 (0.1133)  PSNR: 15.2076 (14.9656)  SSIM: 0.1284 (0.1284)  lr: 0.000100\n",
            "[08:41:48.258977] Epoch: [68]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0191 (0.0191)  MAE: 0.1120 (0.1120)  PSNR: 15.0008 (15.0008)  SSIM: 0.1362 (0.1362)  iter-time: 0.5366\n",
            "[08:41:48.702553] Epoch: [68]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0128)  MSE: 0.0193 (0.0197)  MAE: 0.1128 (0.1141)  PSNR: 14.6008 (14.4983)  SSIM: 0.1362 (0.1352)  iter-time: 0.3264\n",
            "[08:41:48.792789] Epoch: [68] Total time: 0:00:01 (0.3570 s / it)\n",
            "[08:41:48.792936] [Val] averaged stats: loss: 0.0126 (0.0128)  MSE: 0.0193 (0.0197)  MAE: 0.1128 (0.1141)  PSNR: 14.6008 (14.4983)  SSIM: 0.1362 (0.1352)\n",
            "[08:41:48.795476] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[08:41:48.798115] [Time] 20.1s 26.1m/37.1m\n",
            "\n",
            "[08:41:48.798168] ~~~ Epoch 69/100 ~~~\n",
            "\n",
            "[08:41:50.478375] Epoch: [69]  [ 0/27]  eta: 0:00:45  loss: 0.0129 (0.0129)  MSE: 0.0194 (0.0194)  MAE: 0.1140 (0.1140)  PSNR: 14.8118 (14.8118)  SSIM: 0.1114 (0.1114)  lr: 0.000100  iter-time: 1.6758\n",
            "[08:42:00.429172] Epoch: [69]  [10/27]  eta: 0:00:17  loss: 0.0127 (0.0126)  MSE: 0.0194 (0.0193)  MAE: 0.1131 (0.1132)  PSNR: 14.8919 (14.8749)  SSIM: 0.1317 (0.1306)  lr: 0.000100  iter-time: 1.0555\n",
            "[08:42:04.529439] Epoch: [69]  [20/27]  eta: 0:00:05  loss: 0.0127 (0.0128)  MSE: 0.0196 (0.0195)  MAE: 0.1131 (0.1137)  PSNR: 14.8919 (14.8997)  SSIM: 0.1185 (0.1272)  lr: 0.000100  iter-time: 0.7016\n",
            "[08:42:06.654216] Epoch: [69]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0126)  MSE: 0.0196 (0.0193)  MAE: 0.1131 (0.1131)  PSNR: 15.0258 (14.9507)  SSIM: 0.1317 (0.1291)  lr: 0.000100  iter-time: 0.3939\n",
            "[08:42:06.762725] Epoch: [69] Total time: 0:00:17 (0.6652 s / it)\n",
            "[08:42:06.763920] [Train] averaged stats: loss: 0.0130 (0.0126)  MSE: 0.0196 (0.0193)  MAE: 0.1131 (0.1131)  PSNR: 15.0258 (14.9507)  SSIM: 0.1317 (0.1291)  lr: 0.000100\n",
            "[08:42:07.328569] Epoch: [69]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0191 (0.0191)  MAE: 0.1118 (0.1118)  PSNR: 15.0609 (15.0609)  SSIM: 0.1396 (0.1396)  iter-time: 0.5569\n",
            "[08:42:07.776833] Epoch: [69]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0127)  MSE: 0.0193 (0.0197)  MAE: 0.1125 (0.1138)  PSNR: 14.6387 (14.5298)  SSIM: 0.1395 (0.1384)  iter-time: 0.3342\n",
            "[08:42:07.864935] Epoch: [69] Total time: 0:00:01 (0.3647 s / it)\n",
            "[08:42:07.865071] [Val] averaged stats: loss: 0.0125 (0.0127)  MSE: 0.0193 (0.0197)  MAE: 0.1125 (0.1138)  PSNR: 14.6387 (14.5298)  SSIM: 0.1395 (0.1384)\n",
            "[08:42:07.866618] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[08:42:07.867746] [Time] 19.1s 26.4m/36.6m\n",
            "\n",
            "[08:42:07.867792] ~~~ Epoch 70/100 ~~~\n",
            "\n",
            "[08:42:10.968613] Epoch: [70]  [ 0/27]  eta: 0:01:23  loss: 0.0129 (0.0129)  MSE: 0.0196 (0.0196)  MAE: 0.1144 (0.1144)  PSNR: 14.8543 (14.8543)  SSIM: 0.1112 (0.1112)  lr: 0.000100  iter-time: 3.0875\n",
            "[08:42:18.730847] Epoch: [70]  [10/27]  eta: 0:00:16  loss: 0.0129 (0.0126)  MSE: 0.0195 (0.0193)  MAE: 0.1138 (0.1131)  PSNR: 14.8543 (14.8098)  SSIM: 0.1263 (0.1311)  lr: 0.000100  iter-time: 0.9850\n",
            "[08:42:23.940820] Epoch: [70]  [20/27]  eta: 0:00:05  loss: 0.0129 (0.0128)  MSE: 0.0194 (0.0193)  MAE: 0.1138 (0.1133)  PSNR: 14.8707 (14.9535)  SSIM: 0.1167 (0.1265)  lr: 0.000100  iter-time: 0.6473\n",
            "[08:42:26.072330] Epoch: [70]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0127)  MSE: 0.0193 (0.0191)  MAE: 0.1132 (0.1127)  PSNR: 14.9980 (15.0134)  SSIM: 0.1234 (0.1292)  lr: 0.000100  iter-time: 0.4620\n",
            "[08:42:26.174769] Epoch: [70] Total time: 0:00:18 (0.6776 s / it)\n",
            "[08:42:26.176327] [Train] averaged stats: loss: 0.0130 (0.0127)  MSE: 0.0193 (0.0191)  MAE: 0.1132 (0.1127)  PSNR: 14.9980 (15.0134)  SSIM: 0.1234 (0.1292)  lr: 0.000100\n",
            "[08:42:26.701954] Epoch: [70]  [0/3]  eta: 0:00:01  loss: 0.0118 (0.0118)  MSE: 0.0192 (0.0192)  MAE: 0.1119 (0.1119)  PSNR: 14.8989 (14.8989)  SSIM: 0.1421 (0.1421)  iter-time: 0.5201\n",
            "[08:42:27.152435] Epoch: [70]  [2/3]  eta: 0:00:00  loss: 0.0124 (0.0127)  MSE: 0.0193 (0.0197)  MAE: 0.1124 (0.1138)  PSNR: 14.4258 (14.3392)  SSIM: 0.1421 (0.1420)  iter-time: 0.3228\n",
            "[08:42:27.288969] Epoch: [70] Total time: 0:00:01 (0.3693 s / it)\n",
            "[08:42:27.289095] [Val] averaged stats: loss: 0.0124 (0.0127)  MSE: 0.0193 (0.0197)  MAE: 0.1124 (0.1138)  PSNR: 14.4258 (14.3392)  SSIM: 0.1421 (0.1420)\n",
            "[08:42:27.289773] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "[08:42:27.291952] Creating training plots . . .\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[08:42:28.431446] [Time] 20.6s 26.7m/37.4m\n",
            "\n",
            "[08:42:28.432203] ~~~ Epoch 71/100 ~~~\n",
            "\n",
            "[08:42:33.338764] Epoch: [71]  [ 0/27]  eta: 0:02:12  loss: 0.0128 (0.0128)  MSE: 0.0194 (0.0194)  MAE: 0.1141 (0.1141)  PSNR: 14.7822 (14.7822)  SSIM: 0.1167 (0.1167)  lr: 0.000100  iter-time: 4.9016\n",
            "[08:42:39.536047] Epoch: [71]  [10/27]  eta: 0:00:17  loss: 0.0127 (0.0126)  MSE: 0.0194 (0.0195)  MAE: 0.1135 (0.1134)  PSNR: 14.7564 (14.7707)  SSIM: 0.1246 (0.1332)  lr: 0.000100  iter-time: 1.0087\n",
            "[08:42:44.144941] Epoch: [71]  [20/27]  eta: 0:00:05  loss: 0.0127 (0.0127)  MSE: 0.0195 (0.0194)  MAE: 0.1135 (0.1135)  PSNR: 14.7564 (14.9312)  SSIM: 0.1203 (0.1282)  lr: 0.000100  iter-time: 0.5400\n",
            "[08:42:46.267296] Epoch: [71]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0126)  MSE: 0.0193 (0.0192)  MAE: 0.1132 (0.1129)  PSNR: 15.0783 (14.9892)  SSIM: 0.1215 (0.1301)  lr: 0.000100  iter-time: 0.4180\n",
            "[08:42:46.457528] Epoch: [71] Total time: 0:00:18 (0.6675 s / it)\n",
            "[08:42:46.459695] [Train] averaged stats: loss: 0.0127 (0.0126)  MSE: 0.0193 (0.0192)  MAE: 0.1132 (0.1129)  PSNR: 15.0783 (14.9892)  SSIM: 0.1215 (0.1301)  lr: 0.000100\n",
            "[08:42:47.248470] Epoch: [71]  [0/3]  eta: 0:00:02  loss: 0.0120 (0.0120)  MSE: 0.0192 (0.0192)  MAE: 0.1124 (0.1124)  PSNR: 15.2719 (15.2719)  SSIM: 0.1375 (0.1375)  iter-time: 0.7823\n",
            "[08:42:47.700591] Epoch: [71]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0193 (0.0198)  MAE: 0.1127 (0.1143)  PSNR: 14.9454 (14.8115)  SSIM: 0.1375 (0.1372)  iter-time: 0.4111\n",
            "[08:42:47.840345] Epoch: [71] Total time: 0:00:01 (0.4584 s / it)\n",
            "[08:42:47.842749] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0193 (0.0198)  MAE: 0.1127 (0.1143)  PSNR: 14.9454 (14.8115)  SSIM: 0.1375 (0.1372)\n",
            "[08:42:47.843579] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[08:42:47.847585] [Time] 19.4s 27.1m/36.8m\n",
            "\n",
            "[08:42:47.847633] ~~~ Epoch 72/100 ~~~\n",
            "\n",
            "[08:42:51.082201] Epoch: [72]  [ 0/27]  eta: 0:01:27  loss: 0.0129 (0.0129)  MSE: 0.0195 (0.0195)  MAE: 0.1140 (0.1140)  PSNR: 14.8723 (14.8723)  SSIM: 0.1221 (0.1221)  lr: 0.000100  iter-time: 3.2241\n",
            "[08:42:57.118149] Epoch: [72]  [10/27]  eta: 0:00:14  loss: 0.0128 (0.0126)  MSE: 0.0193 (0.0192)  MAE: 0.1128 (0.1128)  PSNR: 15.0959 (14.9885)  SSIM: 0.1261 (0.1322)  lr: 0.000100  iter-time: 0.8407\n",
            "[08:43:04.208853] Epoch: [72]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0127)  MSE: 0.0193 (0.0193)  MAE: 0.1128 (0.1133)  PSNR: 15.0959 (15.0205)  SSIM: 0.1233 (0.1289)  lr: 0.000100  iter-time: 0.6556\n",
            "[08:43:06.380552] Epoch: [72]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0126)  MSE: 0.0193 (0.0191)  MAE: 0.1128 (0.1127)  PSNR: 15.0018 (14.9898)  SSIM: 0.1261 (0.1310)  lr: 0.000100  iter-time: 0.5852\n",
            "[08:43:06.562190] Epoch: [72] Total time: 0:00:18 (0.6930 s / it)\n",
            "[08:43:06.562814] [Train] averaged stats: loss: 0.0128 (0.0126)  MSE: 0.0193 (0.0191)  MAE: 0.1128 (0.1127)  PSNR: 15.0018 (14.9898)  SSIM: 0.1261 (0.1310)  lr: 0.000100\n",
            "[08:43:07.266204] Epoch: [72]  [0/3]  eta: 0:00:02  loss: 0.0119 (0.0119)  MSE: 0.0190 (0.0190)  MAE: 0.1118 (0.1118)  PSNR: 15.0245 (15.0245)  SSIM: 0.1388 (0.1388)  iter-time: 0.6961\n",
            "[08:43:07.718448] Epoch: [72]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0127)  MSE: 0.0192 (0.0196)  MAE: 0.1124 (0.1138)  PSNR: 14.6208 (14.5075)  SSIM: 0.1388 (0.1382)  iter-time: 0.3820\n",
            "[08:43:07.812046] Epoch: [72] Total time: 0:00:01 (0.4143 s / it)\n",
            "[08:43:07.812176] [Val] averaged stats: loss: 0.0125 (0.0127)  MSE: 0.0192 (0.0196)  MAE: 0.1124 (0.1138)  PSNR: 14.6208 (14.5075)  SSIM: 0.1388 (0.1382)\n",
            "[08:43:07.814662] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[08:43:07.817493] [Time] 20.0s 27.4m/37.1m\n",
            "\n",
            "[08:43:07.817548] ~~~ Epoch 73/100 ~~~\n",
            "\n",
            "[08:43:11.029242] Epoch: [73]  [ 0/27]  eta: 0:01:26  loss: 0.0129 (0.0129)  MSE: 0.0192 (0.0192)  MAE: 0.1134 (0.1134)  PSNR: 14.8748 (14.8748)  SSIM: 0.1178 (0.1178)  lr: 0.000100  iter-time: 3.2044\n",
            "[08:43:16.466140] Epoch: [73]  [10/27]  eta: 0:00:13  loss: 0.0128 (0.0126)  MSE: 0.0193 (0.0192)  MAE: 0.1134 (0.1127)  PSNR: 14.7992 (14.7490)  SSIM: 0.1208 (0.1316)  lr: 0.000100  iter-time: 0.7854\n",
            "[08:43:23.884829] Epoch: [73]  [20/27]  eta: 0:00:05  loss: 0.0127 (0.0128)  MSE: 0.0195 (0.0192)  MAE: 0.1132 (0.1132)  PSNR: 14.9747 (14.9685)  SSIM: 0.1180 (0.1274)  lr: 0.000100  iter-time: 0.6420\n",
            "[08:43:25.996122] Epoch: [73]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0126)  MSE: 0.0193 (0.0191)  MAE: 0.1124 (0.1125)  PSNR: 14.9918 (15.0004)  SSIM: 0.1258 (0.1299)  lr: 0.000100  iter-time: 0.5573\n",
            "[08:43:26.098063] Epoch: [73] Total time: 0:00:18 (0.6769 s / it)\n",
            "[08:43:26.098224] [Train] averaged stats: loss: 0.0127 (0.0126)  MSE: 0.0193 (0.0191)  MAE: 0.1124 (0.1125)  PSNR: 14.9918 (15.0004)  SSIM: 0.1258 (0.1299)  lr: 0.000100\n",
            "[08:43:26.672598] Epoch: [73]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0192 (0.0192)  MAE: 0.1121 (0.1121)  PSNR: 15.0354 (15.0354)  SSIM: 0.1433 (0.1433)  iter-time: 0.5680\n",
            "[08:43:27.121540] Epoch: [73]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0127)  MSE: 0.0194 (0.0198)  MAE: 0.1125 (0.1140)  PSNR: 14.5938 (14.4915)  SSIM: 0.1433 (0.1424)  iter-time: 0.3382\n",
            "[08:43:27.211263] Epoch: [73] Total time: 0:00:01 (0.3692 s / it)\n",
            "[08:43:27.212251] [Val] averaged stats: loss: 0.0125 (0.0127)  MSE: 0.0194 (0.0198)  MAE: 0.1125 (0.1140)  PSNR: 14.5938 (14.4915)  SSIM: 0.1433 (0.1424)\n",
            "[08:43:27.214251] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[08:43:27.217836] [Time] 19.4s 27.7m/36.8m\n",
            "\n",
            "[08:43:27.217935] ~~~ Epoch 74/100 ~~~\n",
            "\n",
            "[08:43:29.784280] Epoch: [74]  [ 0/27]  eta: 0:01:09  loss: 0.0133 (0.0133)  MSE: 0.0195 (0.0195)  MAE: 0.1140 (0.1140)  PSNR: 14.8707 (14.8707)  SSIM: 0.1190 (0.1190)  lr: 0.000100  iter-time: 2.5619\n",
            "[08:43:35.147238] Epoch: [74]  [10/27]  eta: 0:00:12  loss: 0.0125 (0.0125)  MSE: 0.0195 (0.0192)  MAE: 0.1129 (0.1127)  PSNR: 14.9056 (14.7990)  SSIM: 0.1253 (0.1337)  lr: 0.000100  iter-time: 0.7201\n",
            "[08:43:43.854335] Epoch: [74]  [20/27]  eta: 0:00:05  loss: 0.0125 (0.0127)  MSE: 0.0194 (0.0193)  MAE: 0.1129 (0.1132)  PSNR: 14.9056 (14.9413)  SSIM: 0.1237 (0.1296)  lr: 0.000100  iter-time: 0.7032\n",
            "[08:43:46.182745] Epoch: [74]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0126)  MSE: 0.0194 (0.0191)  MAE: 0.1130 (0.1126)  PSNR: 14.8644 (14.9447)  SSIM: 0.1283 (0.1320)  lr: 0.000100  iter-time: 0.6550\n",
            "[08:43:46.300399] Epoch: [74] Total time: 0:00:19 (0.7067 s / it)\n",
            "[08:43:46.300565] [Train] averaged stats: loss: 0.0130 (0.0126)  MSE: 0.0194 (0.0191)  MAE: 0.1130 (0.1126)  PSNR: 14.8644 (14.9447)  SSIM: 0.1283 (0.1320)  lr: 0.000100\n",
            "[08:43:46.863156] Epoch: [74]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0194 (0.0194)  MAE: 0.1126 (0.1126)  PSNR: 15.0000 (15.0000)  SSIM: 0.1408 (0.1408)  iter-time: 0.5565\n",
            "[08:43:47.312445] Epoch: [74]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0199)  MAE: 0.1128 (0.1145)  PSNR: 14.6598 (14.5124)  SSIM: 0.1408 (0.1402)  iter-time: 0.3350\n",
            "[08:43:47.410887] Epoch: [74] Total time: 0:00:01 (0.3684 s / it)\n",
            "[08:43:47.411015] [Val] averaged stats: loss: 0.0125 (0.0128)  MSE: 0.0195 (0.0199)  MAE: 0.1128 (0.1145)  PSNR: 14.6598 (14.5124)  SSIM: 0.1408 (0.1402)\n",
            "[08:43:47.413794] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[08:43:47.416545] [Time] 20.2s 28.1m/37.2m\n",
            "\n",
            "[08:43:47.417664] ~~~ Epoch 75/100 ~~~\n",
            "\n",
            "[08:43:50.420383] Epoch: [75]  [ 0/27]  eta: 0:01:20  loss: 0.0126 (0.0126)  MSE: 0.0195 (0.0195)  MAE: 0.1139 (0.1139)  PSNR: 14.8029 (14.8029)  SSIM: 0.1189 (0.1189)  lr: 0.000100  iter-time: 2.9986\n",
            "[08:43:59.656281] Epoch: [75]  [10/27]  eta: 0:00:18  loss: 0.0126 (0.0126)  MSE: 0.0193 (0.0192)  MAE: 0.1136 (0.1127)  PSNR: 14.9191 (14.8599)  SSIM: 0.1196 (0.1301)  lr: 0.000100  iter-time: 1.1121\n",
            "[08:44:05.541961] Epoch: [75]  [20/27]  eta: 0:00:06  loss: 0.0127 (0.0128)  MSE: 0.0191 (0.0191)  MAE: 0.1134 (0.1128)  PSNR: 15.0074 (15.0088)  SSIM: 0.1158 (0.1235)  lr: 0.000100  iter-time: 0.7557\n",
            "[08:44:07.662850] Epoch: [75]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0189 (0.0190)  MAE: 0.1128 (0.1123)  PSNR: 15.0074 (15.0330)  SSIM: 0.1174 (0.1246)  lr: 0.000100  iter-time: 0.7175\n",
            "[08:44:07.792041] Epoch: [75] Total time: 0:00:20 (0.7545 s / it)\n",
            "[08:44:07.793073] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0189 (0.0190)  MAE: 0.1128 (0.1123)  PSNR: 15.0074 (15.0330)  SSIM: 0.1174 (0.1246)  lr: 0.000100\n",
            "[08:44:08.373712] Epoch: [75]  [0/3]  eta: 0:00:01  loss: 0.0122 (0.0122)  MSE: 0.0192 (0.0192)  MAE: 0.1131 (0.1131)  PSNR: 14.6864 (14.6864)  SSIM: 0.1327 (0.1327)  iter-time: 0.5753\n",
            "[08:44:08.828240] Epoch: [75]  [2/3]  eta: 0:00:00  loss: 0.0127 (0.0130)  MSE: 0.0193 (0.0198)  MAE: 0.1131 (0.1149)  PSNR: 14.3214 (14.2077)  SSIM: 0.1327 (0.1322)  iter-time: 0.3430\n",
            "[08:44:08.917054] Epoch: [75] Total time: 0:00:01 (0.3731 s / it)\n",
            "[08:44:08.917215] [Val] averaged stats: loss: 0.0127 (0.0130)  MSE: 0.0193 (0.0198)  MAE: 0.1131 (0.1149)  PSNR: 14.3214 (14.2077)  SSIM: 0.1327 (0.1322)\n",
            "[08:44:08.919607] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "[08:44:08.923097] Creating training plots . . .\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[08:44:09.737004] [Time] 22.3s 28.4m/38.1m\n",
            "\n",
            "[08:44:09.737067] ~~~ Epoch 76/100 ~~~\n",
            "\n",
            "[08:44:12.634261] Epoch: [76]  [ 0/27]  eta: 0:01:18  loss: 0.0129 (0.0129)  MSE: 0.0189 (0.0189)  MAE: 0.1124 (0.1124)  PSNR: 14.8081 (14.8081)  SSIM: 0.1094 (0.1094)  lr: 0.000100  iter-time: 2.8932\n",
            "[08:44:21.328104] Epoch: [76]  [10/27]  eta: 0:00:17  loss: 0.0129 (0.0129)  MSE: 0.0191 (0.0192)  MAE: 0.1129 (0.1131)  PSNR: 14.8193 (14.7054)  SSIM: 0.1166 (0.1269)  lr: 0.000100  iter-time: 1.0524\n",
            "[08:44:26.034825] Epoch: [76]  [20/27]  eta: 0:00:05  loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0193)  MAE: 0.1132 (0.1135)  PSNR: 14.8193 (14.7631)  SSIM: 0.1151 (0.1242)  lr: 0.000100  iter-time: 0.6694\n",
            "[08:44:28.161698] Epoch: [76]  [26/27]  eta: 0:00:00  loss: 0.0126 (0.0127)  MSE: 0.0196 (0.0192)  MAE: 0.1134 (0.1129)  PSNR: 14.8193 (14.7704)  SSIM: 0.1275 (0.1278)  lr: 0.000100  iter-time: 0.4428\n",
            "[08:44:28.267272] Epoch: [76] Total time: 0:00:18 (0.6862 s / it)\n",
            "[08:44:28.267452] [Train] averaged stats: loss: 0.0126 (0.0127)  MSE: 0.0196 (0.0192)  MAE: 0.1134 (0.1129)  PSNR: 14.8193 (14.7704)  SSIM: 0.1275 (0.1278)  lr: 0.000100\n",
            "[08:44:28.829590] Epoch: [76]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0193 (0.0193)  MAE: 0.1128 (0.1128)  PSNR: 14.8169 (14.8169)  SSIM: 0.1354 (0.1354)  iter-time: 0.5557\n",
            "[08:44:29.284440] Epoch: [76]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0199)  MAE: 0.1131 (0.1148)  PSNR: 14.4654 (14.3503)  SSIM: 0.1354 (0.1343)  iter-time: 0.3366\n",
            "[08:44:29.378623] Epoch: [76] Total time: 0:00:01 (0.3685 s / it)\n",
            "[08:44:29.378794] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0199)  MAE: 0.1131 (0.1148)  PSNR: 14.4654 (14.3503)  SSIM: 0.1354 (0.1343)\n",
            "[08:44:29.381291] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 12 out of 20\n",
            "[08:44:29.384127] [Time] 19.6s 28.8m/36.9m\n",
            "\n",
            "[08:44:29.384183] ~~~ Epoch 77/100 ~~~\n",
            "\n",
            "[08:44:31.952078] Epoch: [77]  [ 0/27]  eta: 0:01:09  loss: 0.0129 (0.0129)  MSE: 0.0190 (0.0190)  MAE: 0.1129 (0.1129)  PSNR: 14.9423 (14.9423)  SSIM: 0.1090 (0.1090)  lr: 0.000100  iter-time: 2.5652\n",
            "[08:44:42.827126] Epoch: [77]  [10/27]  eta: 0:00:20  loss: 0.0125 (0.0126)  MSE: 0.0190 (0.0191)  MAE: 0.1127 (0.1129)  PSNR: 14.8093 (14.7818)  SSIM: 0.1183 (0.1262)  lr: 0.000100  iter-time: 1.2216\n",
            "[08:44:46.864896] Epoch: [77]  [20/27]  eta: 0:00:05  loss: 0.0126 (0.0128)  MSE: 0.0192 (0.0193)  MAE: 0.1127 (0.1134)  PSNR: 14.7080 (14.8510)  SSIM: 0.1183 (0.1239)  lr: 0.000100  iter-time: 0.7453\n",
            "[08:44:48.975227] Epoch: [77]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0126)  MSE: 0.0194 (0.0192)  MAE: 0.1137 (0.1129)  PSNR: 14.7080 (14.8540)  SSIM: 0.1296 (0.1267)  lr: 0.000100  iter-time: 0.3874\n",
            "[08:44:49.078181] Epoch: [77] Total time: 0:00:19 (0.7293 s / it)\n",
            "[08:44:49.079391] [Train] averaged stats: loss: 0.0128 (0.0126)  MSE: 0.0194 (0.0192)  MAE: 0.1137 (0.1129)  PSNR: 14.7080 (14.8540)  SSIM: 0.1296 (0.1267)  lr: 0.000100\n",
            "[08:44:49.578697] Epoch: [77]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0193 (0.0193)  MAE: 0.1129 (0.1129)  PSNR: 14.9584 (14.9584)  SSIM: 0.1390 (0.1390)  iter-time: 0.4942\n",
            "[08:44:50.030738] Epoch: [77]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0199)  MAE: 0.1131 (0.1148)  PSNR: 14.5460 (14.4499)  SSIM: 0.1371 (0.1366)  iter-time: 0.3147\n",
            "[08:44:50.119617] Epoch: [77] Total time: 0:00:01 (0.3453 s / it)\n",
            "[08:44:50.120637] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0199)  MAE: 0.1131 (0.1148)  PSNR: 14.5460 (14.4499)  SSIM: 0.1371 (0.1366)\n",
            "[08:44:50.122397] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 13 out of 20\n",
            "[08:44:50.125456] [Time] 20.7s 29.1m/37.4m\n",
            "\n",
            "[08:44:50.125522] ~~~ Epoch 78/100 ~~~\n",
            "\n",
            "[08:44:54.629450] Epoch: [78]  [ 0/27]  eta: 0:02:01  loss: 0.0127 (0.0127)  MSE: 0.0193 (0.0193)  MAE: 0.1136 (0.1136)  PSNR: 14.8620 (14.8620)  SSIM: 0.1117 (0.1117)  lr: 0.000100  iter-time: 4.4965\n",
            "[08:45:02.310095] Epoch: [78]  [10/27]  eta: 0:00:18  loss: 0.0128 (0.0127)  MSE: 0.0192 (0.0191)  MAE: 0.1130 (0.1127)  PSNR: 14.9090 (14.8114)  SSIM: 0.1214 (0.1263)  lr: 0.000100  iter-time: 1.1064\n",
            "[08:45:06.599070] Epoch: [78]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0192 (0.0192)  MAE: 0.1130 (0.1131)  PSNR: 14.9090 (14.8178)  SSIM: 0.1169 (0.1232)  lr: 0.000100  iter-time: 0.5980\n",
            "[08:45:08.717989] Epoch: [78]  [26/27]  eta: 0:00:00  loss: 0.0130 (0.0127)  MSE: 0.0193 (0.0191)  MAE: 0.1133 (0.1126)  PSNR: 14.8990 (14.8489)  SSIM: 0.1229 (0.1257)  lr: 0.000100  iter-time: 0.4030\n",
            "[08:45:08.857251] Epoch: [78] Total time: 0:00:18 (0.6936 s / it)\n",
            "[08:45:08.861025] [Train] averaged stats: loss: 0.0130 (0.0127)  MSE: 0.0193 (0.0191)  MAE: 0.1133 (0.1126)  PSNR: 14.8990 (14.8489)  SSIM: 0.1229 (0.1257)  lr: 0.000100\n",
            "[08:45:09.392028] Epoch: [78]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0194 (0.0194)  MAE: 0.1131 (0.1131)  PSNR: 14.7757 (14.7757)  SSIM: 0.1378 (0.1378)  iter-time: 0.5257\n",
            "[08:45:09.847115] Epoch: [78]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0129)  MSE: 0.0194 (0.0200)  MAE: 0.1131 (0.1148)  PSNR: 14.3472 (14.2427)  SSIM: 0.1378 (0.1371)  iter-time: 0.3266\n",
            "[08:45:09.989576] Epoch: [78] Total time: 0:00:01 (0.3747 s / it)\n",
            "[08:45:09.989767] [Val] averaged stats: loss: 0.0125 (0.0129)  MSE: 0.0194 (0.0200)  MAE: 0.1131 (0.1148)  PSNR: 14.3472 (14.2427)  SSIM: 0.1378 (0.1371)\n",
            "[08:45:09.993428] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 14 out of 20\n",
            "[08:45:09.996529] [Time] 19.9s 29.4m/37.1m\n",
            "\n",
            "[08:45:09.996580] ~~~ Epoch 79/100 ~~~\n",
            "\n",
            "[08:45:13.626157] Epoch: [79]  [ 0/27]  eta: 0:01:37  loss: 0.0128 (0.0128)  MSE: 0.0194 (0.0194)  MAE: 0.1137 (0.1137)  PSNR: 14.7724 (14.7724)  SSIM: 0.1097 (0.1097)  lr: 0.000100  iter-time: 3.6241\n",
            "[08:45:21.730097] Epoch: [79]  [10/27]  eta: 0:00:18  loss: 0.0128 (0.0128)  MSE: 0.0193 (0.0192)  MAE: 0.1137 (0.1129)  PSNR: 14.6582 (14.6558)  SSIM: 0.1231 (0.1277)  lr: 0.000100  iter-time: 1.0644\n",
            "[08:45:25.864772] Epoch: [79]  [20/27]  eta: 0:00:05  loss: 0.0129 (0.0129)  MSE: 0.0193 (0.0192)  MAE: 0.1137 (0.1131)  PSNR: 14.7743 (14.8241)  SSIM: 0.1126 (0.1226)  lr: 0.000100  iter-time: 0.6108\n",
            "[08:45:28.002113] Epoch: [79]  [26/27]  eta: 0:00:00  loss: 0.0129 (0.0128)  MSE: 0.0192 (0.0190)  MAE: 0.1137 (0.1126)  PSNR: 14.9888 (14.9032)  SSIM: 0.1218 (0.1249)  lr: 0.000100  iter-time: 0.4298\n",
            "[08:45:28.119981] Epoch: [79] Total time: 0:00:18 (0.6711 s / it)\n",
            "[08:45:28.120156] [Train] averaged stats: loss: 0.0129 (0.0128)  MSE: 0.0192 (0.0190)  MAE: 0.1137 (0.1126)  PSNR: 14.9888 (14.9032)  SSIM: 0.1218 (0.1249)  lr: 0.000100\n",
            "[08:45:28.885851] Epoch: [79]  [0/3]  eta: 0:00:02  loss: 0.0121 (0.0121)  MSE: 0.0192 (0.0192)  MAE: 0.1126 (0.1126)  PSNR: 14.5958 (14.5958)  SSIM: 0.1378 (0.1378)  iter-time: 0.7563\n",
            "[08:45:29.335652] Epoch: [79]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0193 (0.0197)  MAE: 0.1129 (0.1145)  PSNR: 14.2979 (14.1596)  SSIM: 0.1378 (0.1383)  iter-time: 0.4016\n",
            "[08:45:29.481162] Epoch: [79] Total time: 0:00:01 (0.4509 s / it)\n",
            "[08:45:29.481296] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0193 (0.0197)  MAE: 0.1129 (0.1145)  PSNR: 14.2979 (14.1596)  SSIM: 0.1378 (0.1383)\n",
            "[08:45:29.482048] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 15 out of 20\n",
            "[08:45:29.486943] [Time] 19.5s 29.8m/36.9m\n",
            "\n",
            "[08:45:29.486987] ~~~ Epoch 80/100 ~~~\n",
            "\n",
            "[08:45:32.124484] Epoch: [80]  [ 0/27]  eta: 0:01:11  loss: 0.0129 (0.0129)  MSE: 0.0187 (0.0187)  MAE: 0.1122 (0.1122)  PSNR: 14.8822 (14.8822)  SSIM: 0.1065 (0.1065)  lr: 0.000100  iter-time: 2.6322\n",
            "[08:45:40.519174] Epoch: [80]  [10/27]  eta: 0:00:17  loss: 0.0129 (0.0129)  MSE: 0.0192 (0.0193)  MAE: 0.1128 (0.1133)  PSNR: 14.5791 (14.6437)  SSIM: 0.1200 (0.1270)  lr: 0.000100  iter-time: 1.0019\n",
            "[08:45:45.542140] Epoch: [80]  [20/27]  eta: 0:00:05  loss: 0.0128 (0.0128)  MSE: 0.0193 (0.0193)  MAE: 0.1131 (0.1135)  PSNR: 14.5816 (14.7121)  SSIM: 0.1196 (0.1256)  lr: 0.000100  iter-time: 0.6704\n",
            "[08:45:47.696964] Epoch: [80]  [26/27]  eta: 0:00:00  loss: 0.0126 (0.0127)  MSE: 0.0197 (0.0193)  MAE: 0.1137 (0.1132)  PSNR: 14.5816 (14.6755)  SSIM: 0.1387 (0.1300)  lr: 0.000100  iter-time: 0.4453\n",
            "[08:45:47.859868] Epoch: [80] Total time: 0:00:18 (0.6803 s / it)\n",
            "[08:45:47.861586] [Train] averaged stats: loss: 0.0126 (0.0127)  MSE: 0.0197 (0.0193)  MAE: 0.1137 (0.1132)  PSNR: 14.5816 (14.6755)  SSIM: 0.1387 (0.1300)  lr: 0.000100\n",
            "[08:45:48.656103] Epoch: [80]  [0/3]  eta: 0:00:02  loss: 0.0120 (0.0120)  MSE: 0.0198 (0.0198)  MAE: 0.1138 (0.1138)  PSNR: 14.5846 (14.5846)  SSIM: 0.1444 (0.1444)  iter-time: 0.7871\n",
            "[08:45:49.108569] Epoch: [80]  [2/3]  eta: 0:00:00  loss: 0.0125 (0.0129)  MSE: 0.0199 (0.0204)  MAE: 0.1138 (0.1157)  PSNR: 14.1130 (14.0306)  SSIM: 0.1430 (0.1423)  iter-time: 0.4118\n",
            "[08:45:49.256293] Epoch: [80] Total time: 0:00:01 (0.4629 s / it)\n",
            "[08:45:49.256455] [Val] averaged stats: loss: 0.0125 (0.0129)  MSE: 0.0199 (0.0204)  MAE: 0.1138 (0.1157)  PSNR: 14.1130 (14.0306)  SSIM: 0.1430 (0.1423)\n",
            "[08:45:49.257276] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "[08:45:49.259539] Creating training plots . . .\n",
            "EarlyStopping counter: 16 out of 20\n",
            "[08:45:50.436028] [Time] 20.9s 30.1m/37.4m\n",
            "\n",
            "[08:45:50.436097] ~~~ Epoch 81/100 ~~~\n",
            "\n",
            "[08:45:52.961699] Epoch: [81]  [ 0/27]  eta: 0:01:08  loss: 0.0129 (0.0129)  MSE: 0.0197 (0.0197)  MAE: 0.1146 (0.1146)  PSNR: 14.7559 (14.7559)  SSIM: 0.1111 (0.1111)  lr: 0.000100  iter-time: 2.5202\n",
            "[08:45:59.001225] Epoch: [81]  [10/27]  eta: 0:00:13  loss: 0.0128 (0.0127)  MSE: 0.0192 (0.0191)  MAE: 0.1131 (0.1129)  PSNR: 14.8290 (14.7684)  SSIM: 0.1241 (0.1288)  lr: 0.000100  iter-time: 0.7780\n",
            "[08:46:04.936036] Epoch: [81]  [20/27]  eta: 0:00:04  loss: 0.0127 (0.0128)  MSE: 0.0192 (0.0192)  MAE: 0.1131 (0.1132)  PSNR: 14.9153 (14.9181)  SSIM: 0.1192 (0.1250)  lr: 0.000100  iter-time: 0.5985\n",
            "[08:46:07.068756] Epoch: [81]  [26/27]  eta: 0:00:00  loss: 0.0127 (0.0127)  MSE: 0.0193 (0.0191)  MAE: 0.1131 (0.1127)  PSNR: 14.9153 (14.9351)  SSIM: 0.1241 (0.1271)  lr: 0.000100  iter-time: 0.5264\n",
            "[08:46:07.231378] Epoch: [81] Total time: 0:00:16 (0.6219 s / it)\n",
            "[08:46:07.232321] [Train] averaged stats: loss: 0.0127 (0.0127)  MSE: 0.0193 (0.0191)  MAE: 0.1131 (0.1127)  PSNR: 14.9153 (14.9351)  SSIM: 0.1241 (0.1271)  lr: 0.000100\n",
            "[08:46:07.910098] Epoch: [81]  [0/3]  eta: 0:00:02  loss: 0.0121 (0.0121)  MSE: 0.0193 (0.0193)  MAE: 0.1130 (0.1130)  PSNR: 14.9199 (14.9199)  SSIM: 0.1354 (0.1354)  iter-time: 0.6710\n",
            "[08:46:08.361370] Epoch: [81]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0199)  MAE: 0.1134 (0.1151)  PSNR: 14.7492 (14.5809)  SSIM: 0.1354 (0.1347)  iter-time: 0.3738\n",
            "[08:46:08.464728] Epoch: [81] Total time: 0:00:01 (0.4088 s / it)\n",
            "[08:46:08.465061] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0199)  MAE: 0.1134 (0.1151)  PSNR: 14.7492 (14.5809)  SSIM: 0.1354 (0.1347)\n",
            "[08:46:08.467993] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 17 out of 20\n",
            "[08:46:08.471016] [Time] 18.0s 30.4m/36.4m\n",
            "\n",
            "[08:46:08.471075] ~~~ Epoch 82/100 ~~~\n",
            "\n",
            "[08:46:11.344653] Epoch: [82]  [ 0/27]  eta: 0:01:17  loss: 0.0127 (0.0127)  MSE: 0.0189 (0.0189)  MAE: 0.1123 (0.1123)  PSNR: 14.9647 (14.9647)  SSIM: 0.1129 (0.1129)  lr: 0.000100  iter-time: 2.8601\n",
            "[08:46:16.436198] Epoch: [82]  [10/27]  eta: 0:00:12  loss: 0.0128 (0.0128)  MSE: 0.0190 (0.0192)  MAE: 0.1123 (0.1131)  PSNR: 14.8318 (14.6477)  SSIM: 0.1192 (0.1289)  lr: 0.000100  iter-time: 0.7227\n",
            "[08:46:23.074944] Epoch: [82]  [20/27]  eta: 0:00:04  loss: 0.0129 (0.0128)  MSE: 0.0194 (0.0193)  MAE: 0.1131 (0.1135)  PSNR: 14.7989 (14.7494)  SSIM: 0.1186 (0.1254)  lr: 0.000100  iter-time: 0.5858\n",
            "[08:46:26.456572] Epoch: [82]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0126)  MSE: 0.0195 (0.0192)  MAE: 0.1136 (0.1131)  PSNR: 14.6403 (14.7394)  SSIM: 0.1272 (0.1288)  lr: 0.000100  iter-time: 0.5820\n",
            "[08:46:26.591838] Epoch: [82] Total time: 0:00:18 (0.6711 s / it)\n",
            "[08:46:26.593074] [Train] averaged stats: loss: 0.0128 (0.0126)  MSE: 0.0195 (0.0192)  MAE: 0.1136 (0.1131)  PSNR: 14.6403 (14.7394)  SSIM: 0.1272 (0.1288)  lr: 0.000100\n",
            "[08:46:27.142882] Epoch: [82]  [0/3]  eta: 0:00:01  loss: 0.0119 (0.0119)  MSE: 0.0195 (0.0195)  MAE: 0.1127 (0.1127)  PSNR: 14.6834 (14.6834)  SSIM: 0.1403 (0.1403)  iter-time: 0.5416\n",
            "[08:46:27.585589] Epoch: [82]  [2/3]  eta: 0:00:00  loss: 0.0124 (0.0127)  MSE: 0.0196 (0.0200)  MAE: 0.1131 (0.1146)  PSNR: 14.2041 (14.1025)  SSIM: 0.1394 (0.1389)  iter-time: 0.3278\n",
            "[08:46:27.673591] Epoch: [82] Total time: 0:00:01 (0.3577 s / it)\n",
            "[08:46:27.673713] [Val] averaged stats: loss: 0.0124 (0.0127)  MSE: 0.0196 (0.0200)  MAE: 0.1131 (0.1146)  PSNR: 14.2041 (14.1025)  SSIM: 0.1394 (0.1389)\n",
            "[08:46:27.676305] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 18 out of 20\n",
            "[08:46:27.679047] [Time] 19.2s 30.7m/36.8m\n",
            "\n",
            "[08:46:27.679108] ~~~ Epoch 83/100 ~~~\n",
            "\n",
            "[08:46:30.301189] Epoch: [83]  [ 0/27]  eta: 0:01:10  loss: 0.0131 (0.0131)  MSE: 0.0193 (0.0193)  MAE: 0.1137 (0.1137)  PSNR: 14.8000 (14.8000)  SSIM: 0.1073 (0.1073)  lr: 0.000100  iter-time: 2.6156\n",
            "[08:46:35.713324] Epoch: [83]  [10/27]  eta: 0:00:12  loss: 0.0129 (0.0127)  MSE: 0.0193 (0.0193)  MAE: 0.1137 (0.1132)  PSNR: 14.5299 (14.6206)  SSIM: 0.1205 (0.1280)  lr: 0.000100  iter-time: 0.7296\n",
            "[08:46:40.361641] Epoch: [83]  [20/27]  eta: 0:00:04  loss: 0.0128 (0.0128)  MSE: 0.0194 (0.0193)  MAE: 0.1139 (0.1133)  PSNR: 14.7294 (14.8236)  SSIM: 0.1187 (0.1243)  lr: 0.000100  iter-time: 0.5028\n",
            "[08:46:44.605274] Epoch: [83]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0194 (0.0191)  MAE: 0.1139 (0.1128)  PSNR: 14.7294 (14.7803)  SSIM: 0.1242 (0.1275)  lr: 0.000100  iter-time: 0.5423\n",
            "[08:46:44.713283] Epoch: [83] Total time: 0:00:17 (0.6308 s / it)\n",
            "[08:46:44.714309] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0194 (0.0191)  MAE: 0.1139 (0.1128)  PSNR: 14.7294 (14.7803)  SSIM: 0.1242 (0.1275)  lr: 0.000100\n",
            "[08:46:45.252324] Epoch: [83]  [0/3]  eta: 0:00:01  loss: 0.0121 (0.0121)  MSE: 0.0194 (0.0194)  MAE: 0.1132 (0.1132)  PSNR: 14.7074 (14.7074)  SSIM: 0.1338 (0.1338)  iter-time: 0.5307\n",
            "[08:46:45.698984] Epoch: [83]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0200)  MAE: 0.1134 (0.1152)  PSNR: 14.4260 (14.3032)  SSIM: 0.1338 (0.1343)  iter-time: 0.3255\n",
            "[08:46:45.790051] Epoch: [83] Total time: 0:00:01 (0.3565 s / it)\n",
            "[08:46:45.790185] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0195 (0.0200)  MAE: 0.1134 (0.1152)  PSNR: 14.4260 (14.3032)  SSIM: 0.1338 (0.1343)\n",
            "[08:46:45.792761] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 19 out of 20\n",
            "[08:46:45.795525] [Time] 18.1s 31.0m/36.5m\n",
            "\n",
            "[08:46:45.795587] ~~~ Epoch 84/100 ~~~\n",
            "\n",
            "[08:46:48.603149] Epoch: [84]  [ 0/27]  eta: 0:01:15  loss: 0.0128 (0.0128)  MSE: 0.0192 (0.0192)  MAE: 0.1133 (0.1133)  PSNR: 14.6778 (14.6778)  SSIM: 0.1126 (0.1126)  lr: 0.000100  iter-time: 2.8008\n",
            "[08:46:54.452128] Epoch: [84]  [10/27]  eta: 0:00:13  loss: 0.0127 (0.0126)  MSE: 0.0192 (0.0191)  MAE: 0.1129 (0.1128)  PSNR: 14.7555 (14.6972)  SSIM: 0.1273 (0.1315)  lr: 0.000100  iter-time: 0.7855\n",
            "[08:47:02.487955] Epoch: [84]  [20/27]  eta: 0:00:05  loss: 0.0127 (0.0128)  MSE: 0.0193 (0.0192)  MAE: 0.1129 (0.1132)  PSNR: 14.7555 (14.7308)  SSIM: 0.1194 (0.1277)  lr: 0.000100  iter-time: 0.6937\n",
            "[08:47:04.629331] Epoch: [84]  [26/27]  eta: 0:00:00  loss: 0.0128 (0.0127)  MSE: 0.0194 (0.0191)  MAE: 0.1138 (0.1126)  PSNR: 14.6617 (14.7975)  SSIM: 0.1256 (0.1300)  lr: 0.000100  iter-time: 0.6614\n",
            "[08:47:04.740326] Epoch: [84] Total time: 0:00:18 (0.7015 s / it)\n",
            "[08:47:04.741316] [Train] averaged stats: loss: 0.0128 (0.0127)  MSE: 0.0194 (0.0191)  MAE: 0.1138 (0.1126)  PSNR: 14.6617 (14.7975)  SSIM: 0.1256 (0.1300)  lr: 0.000100\n",
            "[08:47:05.248075] Epoch: [84]  [0/3]  eta: 0:00:01  loss: 0.0120 (0.0120)  MSE: 0.0193 (0.0193)  MAE: 0.1128 (0.1128)  PSNR: 14.6933 (14.6933)  SSIM: 0.1392 (0.1392)  iter-time: 0.5015\n",
            "[08:47:05.698685] Epoch: [84]  [2/3]  eta: 0:00:00  loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0199)  MAE: 0.1132 (0.1148)  PSNR: 14.3989 (14.2651)  SSIM: 0.1392 (0.1380)  iter-time: 0.3171\n",
            "[08:47:05.792242] Epoch: [84] Total time: 0:00:01 (0.3488 s / it)\n",
            "[08:47:05.792381] [Val] averaged stats: loss: 0.0126 (0.0129)  MSE: 0.0194 (0.0199)  MAE: 0.1132 (0.1148)  PSNR: 14.3989 (14.2651)  SSIM: 0.1392 (0.1380)\n",
            "[08:47:05.794879] [Val] best loss: 0.0126 best  MSE: 0.0196 MAE: 0.1134 PSNR: 14.6173 SSIM: 0.1450 \n",
            "EarlyStopping counter: 20 out of 20\n",
            "[08:47:05.797549] Early stopping\n",
            "[08:47:05.797619] Training time: 0:31:22\n",
            "[08:47:05.798918] Train loss: 0.012669503274891112\n",
            "[08:47:05.799541] Train MSE: 0.019075689906323398\n",
            "[08:47:05.799593] Train MAE: 0.11264915764331818\n",
            "[08:47:05.799639] Train PSNR: 14.79746543036567\n",
            "[08:47:05.799683] Train SSIM: 0.1299565633138021\n",
            "[08:47:05.799728] Validation loss: 0.012640010255078474\n",
            "[08:47:05.799791] Validation MSE: 0.019641518592834473\n",
            "[08:47:05.799839] Validation MAE: 0.11341036111116409\n",
            "[08:47:05.799889] Validation PSNR: 14.617319107055664\n",
            "[08:47:05.799934] Validation SSIM: 0.14502249658107758\n",
            "[08:47:05.799975] Finished Training\n",
            "[08:47:09.960189] Releasing memory . . .\n",
            "[08:47:09.960555] ######################\n",
            "[08:47:09.962185] #   LOAD TEST DATA   #\n",
            "[08:47:09.962243] ######################\n",
            "[08:47:09.962306] 2) Loading test images . . .\n",
            "[08:47:09.962390] Loading data from /content/data/train/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00, 10.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:47:10.203602] *** Loaded data shape is (1, 165, 768, 1024, 1)\n",
            "[08:47:10.217652] ############################\n",
            "[08:47:10.218398] #  PREPARE TEST GENERATOR  #\n",
            "[08:47:10.218486] ############################\n",
            "[08:47:12.243686] Loading checkpoint from file /content/output/my_3d_self_supervision/checkpoints/my_3d_self_supervision_1-checkpoint-best.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:47:13.522674] Model weights loaded!\n",
            "[08:47:13.527104] ###############\n",
            "[08:47:13.527898] #  INFERENCE  #\n",
            "[08:47:13.527951] ###############\n",
            "[08:47:13.527994] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:47:15.480576] Processing image: training.tif\n",
            "[08:47:15.482162] ### 3D-OV-CROP ###\n",
            "[08:47:15.483049] Cropping (165, 768, 1024, 1) images into (96, 96, 96, 1) with overlapping . . .\n",
            "[08:47:15.483838] Minimum overlap selected: (0, 0, 0)\n",
            "[08:47:15.484615] Padding: (12, 12, 12)\n",
            "[08:47:15.948609] Real overlapping (%): (0.3472222222222222, 0.027777777777777776, 0.05555555555555555)\n",
            "[08:47:15.949834] Real overlapping (pixels): (25.0, 2.0, 4.0)\n",
            "[08:47:15.950537] (3, 15, 11) patches per (z,y,x) axis\n",
            "[08:47:17.592568] **** New data shape is: (495, 96, 96, 96, 1)\n",
            "[08:47:17.592690] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/83 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/self_supervised.py:373: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  1%|          | 1/83 [00:01<01:42,  1.25s/it]\u001b[A\n",
            "  2%|\u258f         | 2/83 [00:01<00:48,  1.67it/s]\u001b[A\n",
            "  4%|\u258e         | 3/83 [00:01<00:31,  2.53it/s]\u001b[A\n",
            "  5%|\u258d         | 4/83 [00:01<00:23,  3.34it/s]\u001b[A\n",
            "  6%|\u258c         | 5/83 [00:01<00:19,  3.99it/s]\u001b[A\n",
            "  7%|\u258b         | 6/83 [00:02<00:17,  4.52it/s]\u001b[A\n",
            "  8%|\u258a         | 7/83 [00:02<00:15,  5.01it/s]\u001b[A\n",
            " 10%|\u2589         | 8/83 [00:02<00:13,  5.41it/s]\u001b[A\n",
            " 11%|\u2588         | 9/83 [00:02<00:13,  5.65it/s]\u001b[A\n",
            " 12%|\u2588\u258f        | 10/83 [00:02<00:12,  5.80it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 11/83 [00:02<00:12,  5.74it/s]\u001b[A\n",
            " 14%|\u2588\u258d        | 12/83 [00:03<00:12,  5.70it/s]\u001b[A\n",
            " 16%|\u2588\u258c        | 13/83 [00:03<00:12,  5.76it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 14/83 [00:03<00:11,  5.82it/s]\u001b[A\n",
            " 18%|\u2588\u258a        | 15/83 [00:03<00:11,  5.89it/s]\u001b[A\n",
            " 19%|\u2588\u2589        | 16/83 [00:03<00:11,  5.91it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 17/83 [00:03<00:11,  5.62it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 18/83 [00:04<00:11,  5.49it/s]\u001b[A\n",
            " 23%|\u2588\u2588\u258e       | 19/83 [00:04<00:11,  5.59it/s]\u001b[A\n",
            " 24%|\u2588\u2588\u258d       | 20/83 [00:04<00:11,  5.67it/s]\u001b[A\n",
            " 25%|\u2588\u2588\u258c       | 21/83 [00:04<00:10,  5.70it/s]\u001b[A\n",
            " 27%|\u2588\u2588\u258b       | 22/83 [00:04<00:10,  5.61it/s]\u001b[A\n",
            " 28%|\u2588\u2588\u258a       | 23/83 [00:04<00:10,  5.62it/s]\u001b[A\n",
            " 29%|\u2588\u2588\u2589       | 24/83 [00:05<00:10,  5.56it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 25/83 [00:05<00:10,  5.51it/s]\u001b[A\n",
            " 31%|\u2588\u2588\u2588\u258f      | 26/83 [00:05<00:10,  5.38it/s]\u001b[A\n",
            " 33%|\u2588\u2588\u2588\u258e      | 27/83 [00:05<00:10,  5.49it/s]\u001b[A\n",
            " 34%|\u2588\u2588\u2588\u258e      | 28/83 [00:05<00:10,  5.41it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 29/83 [00:06<00:10,  5.35it/s]\u001b[A\n",
            " 36%|\u2588\u2588\u2588\u258c      | 30/83 [00:06<00:09,  5.43it/s]\u001b[A\n",
            " 37%|\u2588\u2588\u2588\u258b      | 31/83 [00:06<00:09,  5.51it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u258a      | 32/83 [00:06<00:09,  5.59it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2589      | 33/83 [00:06<00:09,  5.50it/s]\u001b[A\n",
            " 41%|\u2588\u2588\u2588\u2588      | 34/83 [00:06<00:08,  5.55it/s]\u001b[A\n",
            " 42%|\u2588\u2588\u2588\u2588\u258f     | 35/83 [00:07<00:08,  5.47it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 36/83 [00:07<00:08,  5.52it/s]\u001b[A\n",
            " 45%|\u2588\u2588\u2588\u2588\u258d     | 37/83 [00:07<00:08,  5.57it/s]\u001b[A\n",
            " 46%|\u2588\u2588\u2588\u2588\u258c     | 38/83 [00:07<00:08,  5.61it/s]\u001b[A\n",
            " 47%|\u2588\u2588\u2588\u2588\u258b     | 39/83 [00:07<00:08,  5.46it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 40/83 [00:08<00:07,  5.52it/s]\u001b[A\n",
            " 49%|\u2588\u2588\u2588\u2588\u2589     | 41/83 [00:08<00:07,  5.54it/s]\u001b[A\n",
            " 51%|\u2588\u2588\u2588\u2588\u2588     | 42/83 [00:08<00:07,  5.57it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 43/83 [00:08<00:07,  5.52it/s]\u001b[A\n",
            " 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 44/83 [00:08<00:07,  5.40it/s]\u001b[A\n",
            " 54%|\u2588\u2588\u2588\u2588\u2588\u258d    | 45/83 [00:08<00:06,  5.46it/s]\u001b[A\n",
            " 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 46/83 [00:09<00:07,  4.72it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 47/83 [00:09<00:09,  3.80it/s]\u001b[A\n",
            " 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 48/83 [00:10<00:12,  2.71it/s]\u001b[A\n",
            " 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 49/83 [00:10<00:11,  2.95it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 50/83 [00:10<00:10,  3.11it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588\u258f   | 51/83 [00:11<00:09,  3.42it/s]\u001b[A\n",
            " 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 52/83 [00:11<00:12,  2.44it/s]\u001b[A\n",
            " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258d   | 53/83 [00:12<00:12,  2.44it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 54/83 [00:12<00:10,  2.82it/s]\u001b[A\n",
            " 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 55/83 [00:12<00:08,  3.32it/s]\u001b[A\n",
            " 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 56/83 [00:12<00:07,  3.79it/s]\u001b[A\n",
            " 69%|\u2588\u2588\u2588\u2588\u2588\u2588\u258a   | 57/83 [00:12<00:06,  4.16it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 58/83 [00:13<00:05,  4.49it/s]\u001b[A\n",
            " 71%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 59/83 [00:13<00:04,  4.83it/s]\u001b[A\n",
            " 72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 60/83 [00:13<00:04,  4.97it/s]\u001b[A\n",
            " 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 61/83 [00:13<00:04,  5.15it/s]\u001b[A\n",
            " 75%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 62/83 [00:13<00:03,  5.29it/s]\u001b[A\n",
            " 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 63/83 [00:13<00:03,  5.35it/s]\u001b[A\n",
            " 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 64/83 [00:14<00:03,  5.41it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 65/83 [00:14<00:03,  5.48it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589  | 66/83 [00:14<00:03,  5.42it/s]\u001b[A\n",
            " 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 67/83 [00:14<00:02,  5.44it/s]\u001b[A\n",
            " 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 68/83 [00:14<00:02,  5.35it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 69/83 [00:15<00:02,  5.45it/s]\u001b[A\n",
            " 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 70/83 [00:15<00:02,  5.50it/s]\u001b[A\n",
            " 86%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 71/83 [00:15<00:02,  5.54it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 72/83 [00:15<00:01,  5.63it/s]\u001b[A\n",
            " 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 73/83 [00:15<00:01,  5.43it/s]\u001b[A\n",
            " 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 74/83 [00:15<00:01,  5.43it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 75/83 [00:16<00:01,  5.30it/s]\u001b[A\n",
            " 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 76/83 [00:16<00:01,  5.45it/s]\u001b[A\n",
            " 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 77/83 [00:16<00:01,  5.50it/s]\u001b[A\n",
            " 94%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d| 78/83 [00:16<00:00,  5.57it/s]\u001b[A\n",
            " 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 79/83 [00:16<00:00,  5.21it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 80/83 [00:17<00:00,  5.27it/s]\u001b[A\n",
            " 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 81/83 [00:17<00:00,  5.44it/s]\u001b[A\n",
            " 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 82/83 [00:17<00:00,  5.56it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 83/83 [00:17<00:00,  3.66it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:47:35.668454] ### MERGE-3D-OV-CROP ###\n",
            "[08:47:35.669654] Merging (495, 96, 96, 96, 1) images into (165, 768, 1024, 1) with overlapping . . .\n",
            "[08:47:35.672400] Minimum overlap selected: (0, 0, 0)\n",
            "[08:47:35.672486] Padding: (12, 12, 12)\n",
            "[08:47:35.712262] Real overlapping (%): (0.3472222222222222, 0.027777777777777776, 0.05555555555555555)\n",
            "[08:47:35.712417] Real overlapping (pixels): (25.0, 2.0, 4.0)\n",
            "[08:47:35.713579] (3, 15, 11) patches per (z,y,x) axis\n",
            "[08:47:38.007649] **** New data shape is: (165, 768, 1024, 1)\n",
            "[08:47:38.008686] ### END MERGE-3D-OV-CROP ###\n",
            "[08:47:38.008797] ### MERGE-3D-OV-CROP ###\n",
            "[08:47:38.008844] Merging (495, 96, 96, 96, 1) images into (165, 768, 1024, 1) with overlapping . . .\n",
            "[08:47:38.010689] Minimum overlap selected: (0, 0, 0)\n",
            "[08:47:38.010758] Padding: (12, 12, 12)\n",
            "[08:47:38.049799] Real overlapping (%): (0.3472222222222222, 0.027777777777777776, 0.05555555555555555)\n",
            "[08:47:38.049942] Real overlapping (pixels): (25.0, 2.0, 4.0)\n",
            "[08:47:38.049991] (3, 15, 11) patches per (z,y,x) axis\n",
            "[08:47:40.109661] **** New data shape is: (165, 768, 1024, 1)\n",
            "[08:47:40.111244] ### END MERGE-3D-OV-CROP ###\n",
            "[08:47:40.112085] ### MERGE-3D-OV-CROP ###\n",
            "[08:47:40.112969] Merging (495, 96, 96, 96, 1) images into (165, 768, 1024, 1) with overlapping . . .\n",
            "[08:47:40.113751] Minimum overlap selected: (0, 0, 0)\n",
            "[08:47:40.114521] Padding: (12, 12, 12)\n",
            "[08:47:40.153402] Real overlapping (%): (0.3472222222222222, 0.027777777777777776, 0.05555555555555555)\n",
            "[08:47:40.154592] Real overlapping (pixels): (25.0, 2.0, 4.0)\n",
            "[08:47:40.155461] (3, 15, 11) patches per (z,y,x) axis\n",
            "[08:47:43.138911] **** New data shape is: (165, 768, 1024, 1)\n",
            "[08:47:43.139066] ### END MERGE-3D-OV-CROP ###\n",
            "[08:47:44.027885] Saving (1, 165, 768, 1024, 1) data as .tif in folder: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:04<00:00,  4.28s/it]\u001b[A\n",
            "                                             \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:47:48.324864] Saving (1, 165, 768, 1024, 1) data as .tif in folder: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:08<00:00,  8.54s/it]\u001b[A\n",
            "                                             \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:47:56.882104] Saving (1, 165, 768, 1024, 1) data as .tif in folder: /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:12<00:00, 12.32s/it]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:56<00:00, 56.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:48:09.897791] Releasing memory . . .\n",
            "[08:48:09.900994] #############\n",
            "[08:48:09.901055] #  RESULTS  #\n",
            "[08:48:09.901101] #############\n",
            "[08:48:09.901173] Epoch number: 84\n",
            "[08:48:09.901224] Train time (s): 0:31:22\n",
            "[08:48:09.901453] Train loss: 0.012580806527424741\n",
            "[08:48:09.901591] Train MSE: 0.018952889229964326\n",
            "[08:48:09.906115] Train MAE: 0.11231640284812008\n",
            "[08:48:09.906247] Train PSNR: 15.467930581834581\n",
            "[08:48:09.906332] Train SSIM: 0.13599483116909308\n",
            "[08:48:09.908209] Validation loss: 0.012640010255078474\n",
            "[08:48:09.908301] Validation MSE: 0.019641518592834473\n",
            "[08:48:09.908357] Validation MAE: 0.11341036111116409\n",
            "[08:48:09.908421] Validation PSNR: 14.617319107055664\n",
            "[08:48:09.908476] Validation SSIM: 0.14502249658107758\n",
            "[08:48:09.908614] FINISHED JOB my_3d_self_supervision_1 !!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play to train the model\n",
        "import os\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# remove template file it is exists\n",
        "template_file = '3d_self-supervised.yaml'\n",
        "if os.path.exists( template_file ):\n",
        "    os.remove( template_file )\n",
        "\n",
        "# Download template file\n",
        "!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/self-supervised/3d_self-supervised.yaml &> /dev/null\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No images found in dir {}\".format(train_data_path))\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( template_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "biapy_config['DATA']['TRAIN']\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = train_data_path\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size)+', '+str(patch_size)+', '+ str(patch_size)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding = patch_size // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+ str(padding)+', '+ str(padding)+', '+ str(padding)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# change source to build model - biapy, torchvision or bmz\n",
        "if changed_source:\n",
        "    if source.value == \"BiaPy\":\n",
        "        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "    elif source.value == 'BioImage Model Zoo':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n",
        "        biapy_config['MODEL']['BMZ'] = {}\n",
        "        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_ID'] = str(bmz.value).strip()\n",
        "else:\n",
        "    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"MAE\", \"U-Net\", \"Residual U-Net\", \"Attention U-Net\",\n",
        "# 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\", \"UNETR-Small\",\n",
        "# \"UNETR-Base\", \"EDSR\", \"RCAN\", \"WDSR\", \"DFCAN\"\n",
        "architecture = 'mae'\n",
        "if model_architecture == \"MAE\":\n",
        "    architecture = 'mae'\n",
        "elif model_architecture == \"U-Net\":\n",
        "    architecture = 'unet'\n",
        "elif model_architecture == \"Residual U-Net\":\n",
        "    architecture = 'resunet'\n",
        "elif model_architecture == \"Attention U-Net\":\n",
        "    architecture = 'attention_unet'\n",
        "elif model_architecture == \"MultiResUNet\":\n",
        "    architecture = 'multiresunet'\n",
        "elif model_architecture == \"SEUNet\":\n",
        "    architecture = 'seunet'\n",
        "elif model_architecture == \"ResUNet++\":\n",
        "    architecture = 'resunet++'\n",
        "elif model_architecture == \"RCAN\":\n",
        "    architecture = 'rcan'\n",
        "elif model_architecture == \"WDSR\":\n",
        "    architecture = 'wdsr'\n",
        "elif model_architecture == \"SRUNET\":\n",
        "    architecture = 'srunet'\n",
        "elif model_architecture == \"DFCAN\":\n",
        "    architecture = 'dfcan'\n",
        "elif model_architecture == \"UNETR-Mini\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 64\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 4\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4. # to get 256\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 4\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 1\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "elif model_architecture == \"UNETR-Small\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 128\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 8\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4. # to get 512\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 8\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 2\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "else: # UNETR-Base\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 256\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 12\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 3. # to get 768\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 12\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 3\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "# SSL configuration\n",
        "biapy_config['PROBLEM']['SELF_SUPERVISED'] = {}\n",
        "biapy_config['PROBLEM']['SELF_SUPERVISED']['PRETEXT_TASK'] = pretext_task\n",
        "\n",
        "# update test parameters\n",
        "biapy_config['TEST']['ENABLE'] = True\n",
        "\n",
        "# model weights\n",
        "if checkpoint_path != '':\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4i0N2vOWUes"
      },
      "source": [
        "## **Inspection of the loss function and the Peak signal-to-noise ratio (PSNR)**\n",
        "---\n",
        "\n",
        "First, it is good practice to evaluate the training progress by comparing the training loss with the validation loss. The latter is a metric which shows how well the network performs on a subset of unseen data which is set aside from the training dataset. For more information on this, see for example [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n",
        "\n",
        "**Training loss** describes an error value after each epoch for the difference between the model's prediction and its ground-truth target.\n",
        "\n",
        "**Validation loss** describes the same error value between the model's prediction on a validation image and compared to it's target.\n",
        "\n",
        "During training both values should decrease before reaching a minimal value which does not decrease further even after more training. Comparing the development of the validation loss with the training loss can give insights into the model's performance.\n",
        "\n",
        "Decreasing **Training loss** and **Validation loss** indicates that training is still necessary and increasing the `number_of_epochs` is recommended. Note that the curves can look flat towards the right side, just because of the y-axis scaling. The network has reached convergence once the curves flatten out. After this point no further training is required. If the **Validation loss** suddenly increases again an the **Training loss** simultaneously goes towards zero, it means that the network is overfitting to the training data. In other words the network is remembering the exact patterns from the training data and no longer generalizes well to unseen data. In this case the training dataset has to be increased.\n",
        "\n",
        "The **Peak signal-to-noise ratio** (PSNR) ratio is used as a quality measurement between the original and a reconstructed image. The **higher the PSNR, the better the quality** of the reconstructed image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ur21krhZVwX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724748491220,
          "user_tz": -120,
          "elapsed": 880,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "81d74f8e-cd1a-4203-9043-d74a787f4df2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play the cell to show a plot of training error vs. epoch number and PSNR vs epoch number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n",
        "\n",
        "psnr_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_PSNR.png' )\n",
        "\n",
        "fig = plt.figure( figsize = (20,10))\n",
        "ax1 = plt.subplot( 1, 2, 1 )\n",
        "_ = plt.imshow( loss_plot )\n",
        "_ = plt.axis('off')\n",
        "ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n",
        "\n",
        "ax2 = plt.subplot( 1, 2, 2 )\n",
        "_ = plt.imshow( psnr_plot )\n",
        "_ = plt.axis('off')\n",
        "_= ax2.set_title( 'Peak signal-to-noise ratio (PSNR) vs epoch number', fontdict = {'fontsize':22})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30kYCWjYI9W1"
      },
      "source": [
        "## **Visualize self-supervision reconstruction results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DFPUsjCUNgNl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389,
          "referenced_widgets": [
            "2f216a1772be48a494ea4f13a0ad0ee3",
            "e74d2220addd482783e9df34c3f77406",
            "f2e7802308c04031a544958030ce2e55",
            "7225e5ecd69141098789f252428f64f4",
            "d8b0739e8e4346fe800795290efe6dc6",
            "ec980c9699d04ae0b54ef45bc9b8c112",
            "8722e4a1887b49eb8c14bf1bf2689337"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724749251866,
          "user_tz": -120,
          "elapsed": 9722,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "b55fa992-94d6-429a-9cad-c1ba13bf063c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=82, description='z', max=165, min=1), Output()), _dom_classes=('widget-i\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f216a1772be48a494ea4f13a0ad0ee3"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "#@markdown ###Play to visualize results\n",
        "#@markdown The current model will be applied to some **training images** and results will be shown as browsable 2D stacks displaying:\n",
        "#@markdown 1. The original **Source** image.\n",
        "#@markdown 2. Its corresponding **Masked** image.\n",
        "#@markdown 2. The **Reconstructed + visible** (wihtout masks) image produced by the model.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from numpy.random import randint, seed\n",
        "from matplotlib import pyplot as plt\n",
        "from ipywidgets import interact, fixed\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "from pathlib import Path\n",
        "import glob\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "if pretext_task == \"crappify\":\n",
        "    final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "    ssl_results = os.path.join(final_results, \"per_image\")\n",
        "\n",
        "    ids_input = sorted(next(os.walk(train_data_path))[2])\n",
        "    ids_pred = sorted(next(os.walk(ssl_results))[2])\n",
        "\n",
        "    samples_to_show = min(len(ids_input), 3)\n",
        "    chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n",
        "    seed(1)\n",
        "\n",
        "    test_samples = []\n",
        "    test_sample_preds = []\n",
        "\n",
        "    # read 3D images again\n",
        "    for i in range(len(chosen_images)):\n",
        "        aux = imread(os.path.join(train_data_path, ids_input[chosen_images[i]]))\n",
        "        test_samples.append(aux)\n",
        "\n",
        "        aux = imread(os.path.join(ssl_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n",
        "        test_sample_preds.append(aux)\n",
        "\n",
        "    # function to show results in 3D within a widget\n",
        "    def scroll_in_z(z, j):\n",
        "        plt.figure(figsize=(25,5))\n",
        "        # Source\n",
        "        plt.subplot(1,4,1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_samples[j][z-1], cmap='gray')\n",
        "        plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        # Prediction\n",
        "        plt.subplot(1,4,3)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_preds[j][z-1], cmap='gray')\n",
        "        plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    for j in range(samples_to_show):\n",
        "        interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_sample_preds[j].shape[0], step=1, value=test_sample_preds[j].shape[0]//2), j=fixed(j));\n",
        "else:\n",
        "    final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "    ssl_results = os.path.join(final_results, \"per_image\")\n",
        "\n",
        "    ids_orig = sorted(Path(ssl_results).glob('*.tif'))\n",
        "    ids_orig = [x for x in ids_orig if '_masked.tif' not in str(x) and '_reconstruction_and_visible.tif' not in str(x)]\n",
        "    ids_masked = sorted(Path(ssl_results).glob('*_masked.tif'))\n",
        "    ids_recon_visible = sorted(Path(ssl_results).glob('*_reconstruction_and_visible.tif'))\n",
        "\n",
        "    samples_to_show = min(len(ids_masked), 3)\n",
        "    chosen_images = np.random.choice(len(ids_masked), samples_to_show, replace=False)\n",
        "    seed(1)\n",
        "\n",
        "    test_samples = []\n",
        "    test_sample_masked = []\n",
        "    test_sample_recon = []\n",
        "    test_sample_recon_visi = []\n",
        "\n",
        "    # read 3D images again\n",
        "    for i in range(len(chosen_images)):\n",
        "        aux = imread(ids_orig[chosen_images[i]])\n",
        "        test_samples.append(aux)\n",
        "\n",
        "        aux = imread(ids_masked[chosen_images[i]])\n",
        "        test_sample_masked.append(aux)\n",
        "\n",
        "        aux = imread(ids_recon_visible[chosen_images[i]])\n",
        "        test_sample_recon_visi.append(aux)\n",
        "\n",
        "    # function to show results in 3D within a widget\n",
        "    def scroll_in_z(z, j):\n",
        "        plt.figure(figsize=(25,5))\n",
        "        # Source\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_samples[j][z-1], cmap='gray')\n",
        "        plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        # Masked\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_masked[j][z-1], cmap='gray')\n",
        "        plt.title('Masked (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        # Reconstructed + visible\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_recon_visi[j][z-1], cmap='gray')\n",
        "        plt.title('Reconstructed + visible (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    for j in range(samples_to_show):\n",
        "        interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_samples[j].shape[0], step=1, value=test_samples[j].shape[0]//2), j=fixed(j));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlQnAH6uAawl",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724748498624,
          "user_tz": -120,
          "elapsed": 14,
          "user": {
            "displayName": "Ignacio Arganda-Carreras",
            "userId": "01445877781580243171"
          }
        },
        "outputId": "ac2358b0-39cd-4388-f8ef-d30773cfbff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:48:17.319218] Output paths:\n",
            "[08:48:17.320759]     Self-supervision output files are in /content/output/my_3d_self_supervision/results/my_3d_self_supervision_1/MAE_checks\n"
          ]
        }
      ],
      "source": [
        "#@markdown ###Play to display the paths to the output files (one 3D TIFF image for each input image).\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "if pretext_task == \"crappify\":\n",
        "    if biapy_config['TEST']['FULL_IMG'] == True:\n",
        "        prob_results = os.path.join(final_results, \"full_image\")\n",
        "    else:\n",
        "        prob_results = os.path.join(final_results, \"per_image\")\n",
        "else:\n",
        "    prob_results = os.path.join(final_results, \"MAE_checks\")\n",
        "print(\"Output paths:\")\n",
        "print(\"    Self-supervision output files are in {}\".format(prob_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdCIYo4ohcAw"
      },
      "source": [
        "## **Download  results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gnRa9DOUP0FM",
        "outputId": "70d0e040-ee5b-46b3-9d39-370b86da33c5"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_3efed76b-9e9a-49cc-8cbe-5e7e95355e57\", \"self-supervision_results.zip\", 454086347)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download a zip file with all self-supervision results in test.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!zip -q -j /content/self-supervision_results.zip $ssl_results/*.tif\n",
        "\n",
        "files.download(\"/content/self-supervision_results.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwt72WYddVgl"
      },
      "source": [
        "## **Download train model (weights and configuration file)**\n",
        "---\n",
        "The main purpose of this workflow is to **reuse the trained model in the future** . For that reason, you can download both the model weights and its configuration file (.YAML) by running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XoFclBfEduZC",
        "outputId": "5a63a473-3c2a-4afe-9ce1-8d84848a96fa"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_fdb85dc7-6453-45d8-9db6-ec486edccf20\", \"model_weights_my_2d_self_supervision_1.h5\", 15766000)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "#@markdown ###Play to download the model weights\n",
        "\n",
        "checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n",
        "\n",
        "weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n",
        "\n",
        "files.download( os.path.join( checkpoints_path, weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "raDdSsz1dujE",
        "outputId": "4e666271-9802-4623-d8c9-c20edfcd1b5a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4566094d-d409-4bfc-b446-935c0e6540ef\", \"my_2d_self_supervision.yaml\", 934)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download the model configuration file (.YAML)\n",
        "\n",
        "config_path = os.path.join(output_path, job_name, 'config_files')\n",
        "\n",
        "files.download( os.path.join( config_path, yaml_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaD7Q9b3rtJM"
      },
      "source": [
        "## **Export your model to BioImage Model Zoo format**\n",
        "---\n",
        "If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWHr_sQK_-qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##Construct model's metadata to export it to the BioImage Model Zoo format. Choose just one option:\n",
        "\n",
        "#@markdown **Option 1: Reuse previous BioImage Model Zoo model configuration**\n",
        "\n",
        "#@markdown With this option, if you were using a model from BioImage Model Zoo you can select this option to reuse its configuration instead of provide all fields manually. If that's not the case and you try to use this option an error will be thrown.\n",
        "reuse_previous_BMZ_model_config = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Option 2: Manual export fields**\n",
        "\n",
        "#@markdown With this option you need to introduce manually the metadata of the model.\n",
        "\n",
        "# ------------- User input ------------\n",
        "# information about the model\n",
        "trained_model_name    = \"\" #@param {type:\"string\"}\n",
        "trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n",
        "trained_model_authors_github_user =  \"[First Author Github User, Second Author Github User, Third Author Github User]\" #@param {type:\"string\"}\n",
        "trained_model_description = \"\" #@param {type:\"string\"}\n",
        "trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n",
        "trained_model_references = [\"Ronneberger et al. arXiv in 2015\", \"Franco-Barranco, Daniel, et al. ISBI in 2023\"] #@param {type:\"string\"}\n",
        "trained_model_references_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n",
        "trained_model_tags = \"[\\\"tag-1\\\", \\\"tag-2\\\"]\" #@param {type:\"string\"}\n",
        "trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KH8UuC_CgpH2"
      },
      "outputs": [],
      "source": [
        "# @markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "bmz_results = os.path.join(final_results, \"bmz_model\")\n",
        "\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "\n",
        "    # create the author spec input\n",
        "    auth_names = trained_model_authors[1:-1].split(\",\")\n",
        "    auth_githubusers = trained_model_authors_github_user[1:-1].split(\",\")\n",
        "    assert len(auth_names) == len(auth_githubusers)\n",
        "    authors = [{\"name\": auth_name, \"github_user\": auth_guser} for auth_name, auth_guser in zip(auth_names, auth_githubusers)]\n",
        "\n",
        "    # create the citation input spec\n",
        "    assert len(trained_model_references_DOI) == len(trained_model_references)\n",
        "    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_references_DOI)]\n",
        "\n",
        "    tags = [t for t in trained_model_tags.split(\",\")]\n",
        "\n",
        "    with open(trained_model_documentation, \"w\") as f:\n",
        "        f.write(\"### **Description**\\n\")\n",
        "        f.write(f\"{trained_model_description}\\n\\n\")\n",
        "        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n",
        "\n",
        "    bmz_cfg = {}\n",
        "    # Description of the model\n",
        "    bmz_cfg['description'] = trained_model_description\n",
        "    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Daniel\", \"github_user\": \"danifranco\"}]\n",
        "    bmz_cfg['authors'] = authors\n",
        "    # License of the model. E.g. \"CC-BY-4.0\"\n",
        "    bmz_cfg['license'] = trained_model_license\n",
        "    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n",
        "    bmz_cfg['tags'] = tags\n",
        "    # Tags to make models more findable on the website, e.g. tags=[\"electron-microscopy\", \"mitochondria\"]\n",
        "    bmz_cfg['cite'] = citations\n",
        "    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n",
        "    bmz_cfg['doc'] = trained_model_documentation\n",
        "    # Name of the model\n",
        "    bmz_cfg[\"model_name\"] = trained_model_name\n",
        "    biapy.export_model_to_bmz(bmz_results, bmz_cfg)\n",
        "else:\n",
        "    try:\n",
        "        biapy.export_model_to_bmz(bmz_results, reuse_original_bmz_config=True)\n",
        "    except:\n",
        "        print(\"Seems that the was a problem reusing BMZ model specs. Please uncheck 'reuse_previous_BMZ_model_config' and do it manually\")\n",
        "\n",
        "download = True\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "    bmz_zip_path = f\"/{bmz_results}/{trained_model_name}.zip\"\n",
        "else:\n",
        "    ids = sorted(next(os.walk(bmz_results))[2])\n",
        "    ids = [x for x in ids if x.endswith(\".zip\")]\n",
        "    if len(ids) > 1:\n",
        "        print(f\"There are more than one ZIP files in {bmz_results} folder. Please check which one you want you want to download and do it manually.\")\n",
        "        download = False\n",
        "    elif len(ids) == 0:\n",
        "        print(f\"BMZ zip file could not be found.\")\n",
        "        download = False\n",
        "    else: # only one zip\n",
        "        ids = ids[0]\n",
        "    bmz_zip_path = f\"/{bmz_results}/{ids}\"\n",
        "\n",
        "if download and os.path.exists(bmz_zip_path):\n",
        "    files.download(bmz_zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How to use the trained model with new data**\n",
        "---\n",
        "To directly infer new data to the trained model, you can use [this notebook](https://github.com/BiaPyX/BiaPy/blob/master/notebooks/BiaPy_Inference.ipynb). It will be necessary to upload the downloaded YAML configuration file and model weights to that notebook."
      ],
      "metadata": {
        "id": "PFVjWbF8GZ2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjSgLwe0x-P0"
      },
      "source": [
        "## **Acknowledgments**\n",
        "---\n",
        "We would like to acknowledge the inspiration provided by the excellent [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki). In particular, we have reused some of their descriptions of metrics and parameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [
        {
          "file_id": "https://github.com/BiaPyX/BiaPy/blob/master/notebooks/self-supervised/BiaPy_3D_Self_Supervision.ipynb",
          "timestamp": 1718610076272
        }
      ],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}