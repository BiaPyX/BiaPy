{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAryclxsQJ5"
      },
      "source": [
        "# **2D Classification pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook we show how to apply a [BiaPy](https://biapyx.github.io/) pipeline for **2D classification** of [Butterfly](https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification) data.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/classification/butterfly_1.jpg' width='100px'/>\n",
        "<img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/classification/butterfly_2.jpg' width='100px'/>\n",
        "<img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/classification/butterfly_3.jpg' width='100px'/>\n",
        "<img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/classification/butterfly_4.jpg' width='100px'/>\n",
        "<img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/classification/butterfly_5.jpg' width='100px'/>\n",
        "\n",
        "<figcaption><b>Figure 1</b>: Example of a 2D classification problem. These examples belong to various classes and were sourced from  <a href=\"https://www.kaggle.com/\">  Kaggle</a>, specifically from the Butterfly Image Classification dataset which is a large collection of different butterfly images .</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Without any coding, we'll guide you step-by-step through the process to:\n",
        "1. **Upload a set of training and test images** along with their corresponding instance label images.\n",
        "2. **Train a Deep Neural Network (DNN)** model using the training set.\n",
        "3. **Apply the model** to the test images.\n",
        "4. **Download the segmentation results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired by the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "\n",
        "**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus), [Lenka Backov\u00e1](mailto:lenka.backova@ehu.eus) and [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5ClE_HHQaE"
      },
      "source": [
        "## **Expected Inputs and Outputs**\n",
        "___\n",
        "\n",
        "### **Inputs**\n",
        "\n",
        "This notebook expects the following folders as input:\n",
        "\n",
        "1. **Training Raw Images**: Contains the raw 2D images used for training the model.\n",
        "2. **Test Raw Images**: Houses the raw 2D images for testing the model.\n",
        "3. **Output Folder**: A designated path where the classification results will be saved.\n",
        "\n",
        "### **Outputs**\n",
        "\n",
        "Upon successful execution, a new folder will be generated, housing the classification results. The results will be saved in a CSV file, which can be easily downloaded at the end of this notebook.\n",
        "\n",
        "<font color='red'><b>Note:</b></font> For testing purposes, you can utilize the **example datasets provided under 'Manage File(s) Source > Option 3'**.\n",
        "\n",
        "**Data structure**\n",
        "\n",
        "Input images are expected to be separated into different folders, which correspond to their classification label. Each image label is obtained from the directory name in which that image resides. That is why is so important to follow the directory tree as described below. If you have a .csv file with each image label, as is provided by <a class=\"reference external\" href=\"https://medmnist.com/\">MedMNIST v2</a>, you can use our script <a class=\"reference external\" href=\"https://github.com/BiaPyX/BiaPy/blob/master/biapy/utils/scripts/from_class_csv_to_folders.py\">from_class_csv_to_folders.py</a> to create the directory tree as below:\n",
        "```\n",
        "dataset/\n",
        "\u251c\u2500\u2500 train\n",
        "\u2502   \u251c\u2500\u2500 0\n",
        "\u2502   \u2502   \u251c\u2500\u2500 train0_0.png\n",
        "\u2502   \u2502   \u251c\u2500\u2500 train1013_0.png\n",
        "\u2502   \u2502   \u251c\u2500\u2500 . . .\n",
        "\u2502   \u2502   \u2514\u2500\u2500 train932_0.png\n",
        "\u2502   \u251c\u2500\u2500 1\n",
        "\u2502   \u2502   \u251c\u2500\u2500 train104_1.png\n",
        "\u2502   \u2502   \u251c\u2500\u2500 train1049_1.png\n",
        "\u2502   \u2502   \u251c\u2500\u2500 . . .\n",
        "\u2502   \u2502   \u2514\u2500\u2500 train964_1.png\n",
        "| . . .\n",
        "\u2502   \u2514\u2500\u2500 6\n",
        "\u2502       \u251c\u2500\u2500 train1105_6.png\n",
        "\u2502       \u251c\u2500\u2500 train1148_6.png\n",
        "\u2502       \u251c\u2500\u2500 . . .\n",
        "\u2502       \u2514\u2500\u2500 train98_6.png\n",
        "\u2514\u2500\u2500 test\n",
        "    \u251c\u2500\u2500 0\n",
        "    \u2502   \u251c\u2500\u2500 test1008_0.png\n",
        "    \u2502   \u251c\u2500\u2500 test1084_0.png\n",
        "    \u2502   \u251c\u2500\u2500 . . .\n",
        "    \u2502   \u2514\u2500\u2500 test914_0.png\n",
        "    \u251c\u2500\u2500 1\n",
        "    \u2502   \u251c\u2500\u2500 test10_1.png\n",
        "    \u2502   \u251c\u2500\u2500 test1034_1.png\n",
        "    \u2502   \u251c\u2500\u2500 . . .\n",
        "    \u2502   \u2514\u2500\u2500 test984_1.png\n",
        "  . . .\n",
        "    \u2514\u2500\u2500 6\n",
        "        \u251c\u2500\u2500 test1021_6.png\n",
        "        \u251c\u2500\u2500 test1069_6.png\n",
        "        \u251c\u2500\u2500 . . .\n",
        "        \u2514\u2500\u2500 test806_6.png\n",
        "```\n",
        "\n",
        "Here each directory is a number but it can be any string. Notice that they will be considered the class names. Regarding the test, if you have no classes it doesn\u2019t matter if the images are separated in several folders or are all in one folder. But, if `DATA.TEST.LOAD_GT` is enabled, each folder in test path (i.e. ```DATA.TEST.PATH```) will be considered as a class (as done for training and validation).\n",
        "\n",
        "**Input Format Support**\n",
        "\n",
        "This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.png`, `.jpg`, `.npy`, `.h5`, `.hdf5` (every extension supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGSj0DrpUJoY"
      },
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bj_sbDFTiZ7"
      },
      "source": [
        "## **Check for GPU Access**\n",
        "---\n",
        "\n",
        "By default, the session is configured to use Python 3 with GPU acceleration. However, it's a good practice to double-check these settings:\n",
        "\n",
        "1. Navigate to **Runtime** in the top menu and select **Change the Runtime type**.\n",
        "2. Ensure the following settings:\n",
        "   - **Runtime type:** Python 3 (This program is written in the Python 3 programming language.)\n",
        "   - **Accelerator:** GPU (Graphics Processing Unit)\n",
        "\n",
        "This will ensure that you're using Python 3 and taking advantage of GPU acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRBWe5F9EQ3-"
      },
      "source": [
        "## **Install BiaPy**\n",
        "---\n",
        "This might take some minutes depending on the current installed libraries in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0eed14f-3888-48e7-d753-8df7a074d5bb",
        "cellView": "form",
        "id": "-PMAJk3pEQ3_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biapy==3.6.0\n",
            "  Downloading biapy-3.6.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (1.6.1)\n",
            "Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (3.0.4)\n",
            "Collecting yacs>=0.1.8 (from biapy==3.6.0)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (0.25.2)\n",
            "Collecting edt>=2.3.2 (from biapy==3.6.0)\n",
            "  Downloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy>2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (2.0.2)\n",
            "Collecting fill-voids>=2.0.6 (from biapy==3.6.0)\n",
            "  Downloading fill_voids-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.76 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (2.2.2)\n",
            "Collecting torchinfo>=1.8.0 (from biapy==3.6.0)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.6.2.2 (from biapy==3.6.0)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: h5py>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (3.14.0)\n",
            "Collecting zarr<3.0,>=2.16.1 (from biapy==3.6.0)\n",
            "  Downloading zarr-2.18.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting bioimageio.core==0.8.0 (from biapy==3.6.0)\n",
            "  Downloading bioimageio_core-0.8.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting imagecodecs>=2024.1.1 (from biapy==3.6.0)\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pooch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.0) (1.8.2)\n",
            "Collecting diplib>=3.5.1 (from biapy==3.6.0)\n",
            "  Downloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting xarray==2025.1.* (from biapy==3.6.0)\n",
            "  Downloading xarray-2025.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bioimageio.spec==0.5.4.1 (from bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading bioimageio.spec-0.5.4.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: imageio>=2.10 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.0) (2.37.0)\n",
            "Collecting loguru (from bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic-settings<3,>=2.5 (from bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.0) (2.11.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.0) (2.32.3)\n",
            "Collecting ruyaml (from bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading ruyaml-0.91.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.0) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray==2025.1.*->biapy==3.6.0) (24.2)\n",
            "Requirement already satisfied: annotated-types<1,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (0.7.0)\n",
            "Collecting email-validator (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (3.8.2)\n",
            "Collecting pydantic<3,>=2.7.0 (from bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (2.9.0.post0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (13.9.4)\n",
            "Requirement already satisfied: tifffile>=2020.7.4 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (2025.6.11)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (3.23.0)\n",
            "Collecting fastremap (from fill-voids>=2.0.6->biapy==3.6.0)\n",
            "  Downloading fastremap-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.0) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.0) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.0) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.0) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.0) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.6.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.6.0) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.8.1->biapy==3.6.0) (4.3.8)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.6.0) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.6.0) (3.5)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.6.0) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.6.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.6.0) (5.29.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8->biapy==3.6.0) (6.0.2)\n",
            "Collecting asciitree (from zarr<3.0,>=2.16.1->biapy==3.6.0)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasteners (from zarr<3.0,>=2.16.1->biapy==3.6.0)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0 (from zarr<3.0,>=2.16.1->biapy==3.6.0)\n",
            "  Downloading numcodecs-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting deprecated (from numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0->zarr<3.0,>=2.16.1->biapy==3.6.0)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<3,>=2.7.0->bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3,>=2.5->bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3,>=2.5->bioimageio.core==0.8.0->biapy==3.6.0) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.0) (2025.6.15)\n",
            "Requirement already satisfied: distro>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.8.0->biapy==3.6.0) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=39.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.8.0->biapy==3.6.0) (75.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0->zarr<3.0,>=2.16.1->biapy==3.6.0) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.0) (0.1.2)\n",
            "Downloading biapy-3.6.0-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.5/434.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio_core-0.8.0-py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xarray-2025.1.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.spec-0.5.4.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading zarr-2.18.7-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numcodecs-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading fastremap-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruyaml-0.91.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5031 sha256=3b95bd78a0851c0339854e4a7f43f0b16596e044043b1bb15db862a1e2618361\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c1/da/23077eb3b87d24d6f3852ed1ed1a1ac2d3c885ad6ebd2b4a07\n",
            "Successfully built asciitree\n",
            "Installing collected packages: asciitree, yacs, torchinfo, tensorboardX, ruyaml, python-dotenv, pydantic-core, loguru, imagecodecs, fastremap, fasteners, edt, dnspython, diplib, deprecated, pydantic, numcodecs, fill-voids, email-validator, zarr, xarray, pydantic-settings, bioimageio.spec, bioimageio.core, biapy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2025.3.1\n",
            "    Uninstalling xarray-2025.3.1:\n",
            "      Successfully uninstalled xarray-2025.3.1\n",
            "Successfully installed asciitree-0.3.3 biapy-3.6.0 bioimageio.core-0.8.0 bioimageio.spec-0.5.4.1 deprecated-1.2.18 diplib-3.5.2 dnspython-2.7.0 edt-3.0.0 email-validator-2.2.0 fasteners-0.19 fastremap-1.17.1 fill-voids-2.1.0 imagecodecs-2025.3.30 loguru-0.7.3 numcodecs-0.15.1 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.10.1 python-dotenv-1.1.1 ruyaml-0.91.0 tensorboardX-2.6.4 torchinfo-1.8.0 xarray-2025.1.2 yacs-0.1.8 zarr-2.18.7\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
            "Collecting timm==1.0.14\n",
            "  Downloading timm-1.0.14-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting torchmetrics==1.4.* (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (2.4.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (0.19.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (0.33.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (0.5.3)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (24.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (1.15.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.86)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.14) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.14) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm==1.0.14) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (2025.6.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm==1.0.14) (1.3.0)\n",
            "Downloading timm-1.0.14-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-msssim, torch-fidelity, timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.16\n",
            "    Uninstalling timm-1.0.16:\n",
            "      Successfully uninstalled timm-1.0.16\n",
            "Successfully installed lightning-utilities-0.14.3 pytorch-msssim-1.0.0 timm-1.0.14 torch-fidelity-0.3.0 torchmetrics-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "# Install latest release of BiaPy\n",
        "!pip install biapy==3.6.0\n",
        "\n",
        "# Then install Pytorch + CUDA 11.8\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Finally install some packages that rely on the Pytorch installation\n",
        "!pip install timm==1.0.14 pytorch-msssim torchmetrics[image]==1.4.*\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "from biapy import BiaPy\n",
        "\n",
        "changed_source = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZmI9c09OhSo"
      },
      "source": [
        "## **Manage File(s) Source**\n",
        "---\n",
        "\n",
        "The input folder can be provided using three different options:\n",
        "1. **Direct Upload**: Directly upload the desired folder.\n",
        "2. **Google Drive**: Use a folder stored in your Google Drive.\n",
        "3. **Sample Data**: Use a sample dataset provided by us.\n",
        "\n",
        "The steps you'll need to follow vary depending on your chosen option. These steps are detailed in the subsequent sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPksHcHLO0SU"
      },
      "source": [
        "### **Option 1: Upload Local Files to the Notebook**\n",
        "---\n",
        "\n",
        "To use this option, you will be prompted to upload your files to Colab. The uploaded files will be stored in the `/content/input/` directory. Ensure that you upload a ZIP file that contains the 'train', 'val' (if applicable), and 'test' folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xGS5LCaHPWR8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train raw images)\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train\n",
        "%cd /content/input/train\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "custom": {
          "metadata": {
            "cellView": "form"
          }
        },
        "id": "eA8rmMbVzOBk",
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "# @title  { display-mode: \"code\" }\n",
        "#@markdown ##Play the cell to upload local files (test raw images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test\n",
        "%cd /content/input/test\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXGd55gUYjK"
      },
      "source": [
        "### **Option 2: Mount Your Google Drive**\n",
        "---\n",
        "\n",
        "If you wish to use this notebook with data from your Google Drive, you'll first need to mount the drive to this notebook.\n",
        "\n",
        "Execute the cell below to initiate the Google Drive mounting process. A link will be displayed click on it. In the new browser window that opens, choose your drive and click 'Allow'. Copy the code that appears, return to this notebook, paste the code into the cell, and press 'Enter'. This action grants Colab access to your Google Drive data.\n",
        "\n",
        "After this process, you can access your data via the **Files** tab, located on the top left of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h-yXrZLdUk3Z"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL.\n",
        "\n",
        "#@markdown * Sign in your Google Account.\n",
        "\n",
        "#@markdown * Copy the authorization code.\n",
        "\n",
        "#@markdown * Enter the authorization code.\n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9FcxFB3H7az"
      },
      "source": [
        "### **Option 3: Download an Example Dataset**\n",
        "---\n",
        "Don't have data readily available but still want to test the notebook? No problem! Simply execute the following cell to download a sample dataset.\n",
        "\n",
        "Specifically, we'll use the [Butterfly](https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification) dataset,which is publicly available online.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD3aoo-ZUtW4",
        "outputId": "7d5547cc-0bae-4567-8007-e7fa65e8837f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "\n",
        "import os\n",
        "\n",
        "!pip install gdown==5.1.0 --quiet\n",
        "import gdown\n",
        "\n",
        "os.chdir('/content/')\n",
        "gdown.download(\"https://drive.google.com/uc?id=1m4_3UAgUsZ8FDjB4HyfA50Sht7_XkfdB\", \"data.zip\", quiet=True)\n",
        "\n",
        "!unzip -q data.zip\n",
        "!rm data.zip\n",
        "\n",
        "print('Dataset downloaded and unzipped under /content/data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEv7FBXFQvjv"
      },
      "source": [
        "## **Paths for Input Images and Output Files**\n",
        "___\n",
        "\n",
        "Depending on the option you chose for managing file sources, you'll set your paths differently:\n",
        "\n",
        "- **Option 1 (Upload from Local Machine)**:\n",
        "  - Set `train_data_path` to `/content/input/train`\n",
        "  - Set `test_data_path` to `/content/input/test`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "  \n",
        "- **Option 2 (Use Google Drive Data)**:\n",
        "  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n",
        "  \n",
        "- **Option 3 (Use Our Sample Data)**:\n",
        "  - Set `train_data_path` to `/content/data/train`\n",
        "  - Set `test_data_path` to `/content/data/test`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "\n",
        "  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n",
        "\n",
        "**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "vl4e0UIGYZcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dd34a7-6339-4e80-dedd-32c599dba772"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 2550\n",
            "Number of test images: 750\n"
          ]
        }
      ],
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test images\n",
        "test_data_path = '/content/data/test' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def count_image_files(directory):\n",
        "    if not directory or not os.path.exists(directory):\n",
        "        return 0\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.tif', '.npy', '.tiff', '.h5', '.hd5', '.zarr'}\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in image_extensions:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "num_train_images = count_image_files(train_data_path)\n",
        "num_test_images = count_image_files(test_data_path)\n",
        "\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of test images: {num_test_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAuw6-Grj_9q"
      },
      "source": [
        "## **Dataset Visualization**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597,
          "referenced_widgets": [
            "609a955d7aef41e7a7f65d0067c93944",
            "2e77a1ae22144b6abfb0509016c2ea94",
            "1efbb99aaf6e40b18d46e1e8d72b0331",
            "57d5a9f843014702994caa027994dcf9",
            "ab59de165f4d4da2bc76a11f3f7f2b24",
            "a43455abaa5f458eabf92d5e9ce99096",
            "9d5a45606fd9444eabf02ae281662542",
            "a7a185ac2bc745309ba6ecaf520ad163",
            "6827da300f8e4dbfa46a7d43c3cada0b",
            "2e5789e44789437792bc96d228ae6653",
            "c825225df6fc42609105cbac5f0a7ba3",
            "de7fab1686304fe1b30b4ad7b159451c",
            "24450666d1424fab892e04e0cdc7036a"
          ]
        },
        "id": "dAhsGNaIMEvt",
        "outputId": "cde89159-aa4b-4740-a591-3142acb6fafa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Set:', options=('training-set', 'test-set'), value='training-set'), Dropd\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "609a955d7aef41e7a7f65d0067c93944"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de7fab1686304fe1b30b4ad7b159451c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ## Play to visualize some data samples\n",
        "# @markdown Select the *Set* (training or test) and the *Class* to visualize samples from, and use the *Instance* scroll to navigate among samples.\n",
        "\n",
        "# @markdown **Note**: it might take a few seconds to refresh the images.\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread\n",
        "import os\n",
        "from ipywidgets import interact, IntSlider, Layout, Dropdown, HBox, VBox, Output\n",
        "\n",
        "# Initialize id directories\n",
        "classes = sorted(next(os.walk(train_data_path))[1])\n",
        "ids_train = {}\n",
        "ids_test = {}\n",
        "for c in classes:\n",
        "    train_class_path = os.path.join(train_data_path, c)\n",
        "    test_class_path = os.path.join(test_data_path, c)\n",
        "\n",
        "    ids_train[c] = [os.path.join(c, f) for f in sorted(next(os.walk(train_class_path))[2])]\n",
        "    ids_test[c] = [os.path.join(c, f) for f in sorted(next(os.walk(test_class_path))[2])]\n",
        "\n",
        "# Initialize attributes\n",
        "class_value = classes[0] # initial class\n",
        "input_path = train_data_path\n",
        "ids_input = ids_train\n",
        "\n",
        "# Initialize widgets\n",
        "\n",
        "# Dropdown widget to choose training or test set\n",
        "train_test_dropdown = Dropdown(\n",
        "    options=['training-set', 'test-set'],\n",
        "    value='training-set',\n",
        "    description='Set:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Dropdown widget to choose class\n",
        "class_dropdown = Dropdown(\n",
        "    options=classes,\n",
        "    value=classes[0],\n",
        "    description='Class:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Slider widget to choose instance\n",
        "instance_slider= IntSlider(\n",
        "    value=1,\n",
        "    min=1,\n",
        "    max=len(ids_train[class_value]),\n",
        "    step=1,\n",
        "    description='Instance:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "instance_slider.style.description_width = 'initial'\n",
        "instance_slider.style.handle_color='blue'\n",
        "\n",
        "# Initialize Output instance to handle code output cell\n",
        "output = Output()\n",
        "\n",
        "# Function to update path and image IDs (input_path, ids_input) depending on dropdown\n",
        "def update_paths(change):\n",
        "    global ids_input, input_path, classes\n",
        "    if change.new == 'test-set':\n",
        "        ids_input = ids_test\n",
        "        input_path = test_data_path\n",
        "    else:\n",
        "        ids_input = ids_train\n",
        "        input_path = train_data_path\n",
        "\n",
        "    # Reset class slider value when dropdown changes\n",
        "    class_dropdown.value = classes[0]\n",
        "    update_class({'new': classes[0]})\n",
        "\n",
        "# Function to update class_value attribute depending on the class dropdown\n",
        "def update_class(change):\n",
        "    global class_value, ids_input\n",
        "    class_value = change['new']\n",
        "\n",
        "    # Reset instance slider value when dropdown changes\n",
        "    instance_slider.value = 1\n",
        "    instance_slider.max = len(ids_input[class_value])\n",
        "    display_images({'new': 1})\n",
        "\n",
        "# Function to display images depending on instance slider value\n",
        "def display_images(change):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "        index = change['new']\n",
        "\n",
        "        global input_path, ids_input, class_value\n",
        "        input_img = imread(os.path.join(input_path, ids_input[class_value][index-1]))\n",
        "\n",
        "        # # Print image path to ensure the image displayed is correct\n",
        "        # print(\"Image path: \")\n",
        "        # print(os.path.join(input_path, ids_input[class_value][index-1]))\n",
        "\n",
        "        # Display images\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f\"Class: {class_value}, Instance: {index}\")\n",
        "        plt.imshow(input_img)\n",
        "        # plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create a VBox to hold the dropdown and slider\n",
        "controls = VBox([train_test_dropdown, class_dropdown, instance_slider])\n",
        "display(controls, output)\n",
        "\n",
        "# Link widgets to functions\n",
        "train_test_dropdown.observe(update_paths, names='value')\n",
        "class_dropdown.observe(update_class, names='value')\n",
        "instance_slider.observe(display_images, names='value')\n",
        "\n",
        "# Initial display\n",
        "display_images({'new': instance_slider.value})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZwoZC20rK42"
      },
      "source": [
        "## **Configure and train the DNN model**\n",
        "---\n",
        "[BiaPy](https://biapy.readthedocs.io/en/latest/) contains a few deep learning models to perform classification.\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "33687ad6-d5a0-4916-d2bd-d62baefb88e0",
        "cellView": "form",
        "id": "daGtIo-V_Ydt"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ###OPTIONAL: Check BioImage Model Zoo (BMZ) models compatible with BiaPy\n",
        "# @markdown Use this option to generate a full list of the available BiaPy-compatible models in the BMZ.\n",
        "\n",
        "# @markdown **Important:** To select one of the listed models (if any), you will have to run the next cell and select \"BioImage Model Zoo\" as the source of the model. Then, paste the corresponding model's nickname into the created field.\n",
        "# @markdown <div><img src=\"https://bioimage.io/static/img/bioimage-io-logo.svg\" width=\"600\"/></div>\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pooch\n",
        "import yaml\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "from biapy.models import check_bmz_model_compatibility\n",
        "from packaging.version import Version\n",
        "from typing import Optional, Dict, Tuple, List, Literal\n",
        "\n",
        "# Change pooch verbosity\n",
        "logger = pooch.get_logger()\n",
        "logger.setLevel(\"WARNING\")\n",
        "\n",
        "# Extracted from BiaPy-GUI.\n",
        "# Adapted from BiaPy commit: 284ec3838766392c9a333ac9d27b55816a267bb9 (3.5.2)\n",
        "def check_model_restrictions(\n",
        "    model_rdf,\n",
        "    workflow_specs,\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks model restrictions to be applied into the current configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_rdf : dict\n",
        "        BMZ model RDF that contains all the information of the model.\n",
        "\n",
        "    workflow_specs : dict\n",
        "        Specifications of the workflow. If not provided all possible models will be considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    option_list: dict\n",
        "        Variables and values to change in current configuration. These changes\n",
        "        are imposed by the selected model.\n",
        "    \"\"\"\n",
        "    specific_workflow = workflow_specs[\"workflow_type\"]\n",
        "\n",
        "    # Version of the model\n",
        "    model_version = Version(model_rdf[\"format_version\"])\n",
        "    opts = {}\n",
        "\n",
        "    # 1) Change PATCH_SIZE with the one stored in the model description. This differs from the code of BiaPy where\n",
        "    # get_test_inputs() is simply used as there a ModelDescr is build out of the RDF. Here we try to do it manually\n",
        "    # to avoid fetching files using the network as it may be slow.\n",
        "    input_image_shape = []\n",
        "    if \"shape\" in model_rdf[\"inputs\"][0]:\n",
        "        input_image_shape = model_rdf[\"inputs\"][0][\"shape\"]\n",
        "        # \"CebraNET Cellular Membranes in Volume SEM\" ('format_version': '0.4.10')\n",
        "        #   have: {'min': [1, 1, 64, 64, 64], 'step': [0, 0, 16, 16, 16]}\n",
        "        if isinstance(input_image_shape, dict) and \"min\" in input_image_shape:\n",
        "            input_image_shape = input_image_shape[\"min\"]\n",
        "    else:\n",
        "        # Check axes and dimension\n",
        "        input_image_shape = []\n",
        "        for axis in model_rdf[\"inputs\"][0][\"axes\"]:\n",
        "            if 'type' in axis:\n",
        "                if axis['type'] == \"batch\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif axis['type'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif 'id' in axis and 'size' in axis:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "            elif 'id' in axis:\n",
        "                if axis['id'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                else:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "    if len(input_image_shape) == 0:\n",
        "        raise ValueError(\"Couldn't load input info from BMZ model's RDF: {}\".format(model_rdf[\"inputs\"][0]))\n",
        "    opts[\"DATA.PATCH_SIZE\"] = tuple(input_image_shape[2:]) + (input_image_shape[1],)\n",
        "\n",
        "    # Capture model kwargs\n",
        "    if \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]:\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"kwargs\"]\n",
        "    elif (\n",
        "        \"architecture\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]\n",
        "        and \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"]\n",
        "    ):\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"][\"kwargs\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Couldn't extract kwargs from model description.\")\n",
        "\n",
        "    # 2) Workflow specific restrictions\n",
        "    # Classes in semantic segmentation\n",
        "    if specific_workflow in [\"SEMANTIC_SEG\"]:\n",
        "        # Check number of classes\n",
        "        classes = -1\n",
        "        if \"n_classes\" in model_kwargs: # BiaPy\n",
        "            classes = model_kwargs[\"n_classes\"]\n",
        "        elif \"out_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"out_channels\"]\n",
        "        elif \"classes\" in model_kwargs:\n",
        "            classes = model_kwargs[\"classes\"]\n",
        "\n",
        "        if isinstance(classes, list):\n",
        "            classes = classes[0]\n",
        "        if not isinstance(classes, int):\n",
        "            raise ValueError(f\"Classes not extracted correctly. Obtained {classes}\")\n",
        "\n",
        "        if specific_workflow == \"SEMANTIC_SEG\" and classes == -1:\n",
        "            raise ValueError(\"Classes not found for semantic segmentation dir. \")\n",
        "        opts[\"MODEL.N_CLASSES\"] = max(2,classes)\n",
        "    elif specific_workflow in [\"INSTANCE_SEG\"]:\n",
        "        # Assumed it's BC. This needs a more elaborated process. Still deciding this:\n",
        "        # https://github.com/bioimage-io/spec-bioimage-io/issues/621\n",
        "        channels = 2\n",
        "        if \"out_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"out_channels\"]\n",
        "        if channels == 1:\n",
        "            channel_code = \"C\"\n",
        "        elif channels == 2:\n",
        "            channel_code = \"BC\"\n",
        "        elif channels == 3:\n",
        "            channel_code = \"BCM\"\n",
        "        if channels > 3:\n",
        "            raise ValueError(f\"Not recognized number of channels for instance segmentation. Obtained {channels}\")\n",
        "\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\"] = channel_code\n",
        "\n",
        "    if \"preprocessing\" not in model_rdf[\"inputs\"][0]:\n",
        "        return opts\n",
        "\n",
        "    preproc_info = model_rdf[\"inputs\"][0][\"preprocessing\"]\n",
        "    if len(preproc_info) == 0:\n",
        "        return opts\n",
        "    preproc_info = preproc_info[0]\n",
        "\n",
        "    # 3) Change preprocessing to the one stablished by BMZ by translate BMZ keywords into BiaPy's\n",
        "    # 'zero_mean_unit_variance' and 'fixed_zero_mean_unit_variance' norms of BMZ can be translated to our 'custom' norm\n",
        "    # providing mean and std\n",
        "    key_to_find = \"id\" if model_version > Version(\"0.5.0\") else \"name\"\n",
        "    if key_to_find in preproc_info:\n",
        "        if preproc_info[key_to_find] in [\"fixed_zero_mean_unit_variance\", \"zero_mean_unit_variance\"]:\n",
        "            if (\n",
        "                \"kwargs\" in preproc_info\n",
        "                and \"mean\" in preproc_info[\"kwargs\"]\n",
        "            ):\n",
        "                mean = preproc_info[\"kwargs\"][\"mean\"]\n",
        "                std = preproc_info[\"kwargs\"][\"std\"]\n",
        "            elif \"mean\" in preproc_info:\n",
        "                mean = preproc_info[\"mean\"]\n",
        "                std = preproc_info[\"std\"]\n",
        "            else:\n",
        "                mean, std = -1., -1.\n",
        "\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"custom\"\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_MEAN\"] = mean\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_STD\"] = std\n",
        "\n",
        "        # 'scale_linear' norm of BMZ is close to our 'div' norm (TODO: we need to control the \"gain\" arg)\n",
        "        elif preproc_info[key_to_find] == \"scale_linear\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"div\"\n",
        "\n",
        "        # 'scale_range' norm of BMZ is as our PERC_CLIP + 'scale_range' norm\n",
        "        elif preproc_info[key_to_find] == \"scale_range\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"scale_range\"\n",
        "            if (\n",
        "                float(preproc_info[\"kwargs\"][\"min_percentile\"]) != 0\n",
        "                or float(preproc_info[\"kwargs\"][\"max_percentile\"]) != 100\n",
        "            ):\n",
        "                opts[\"DATA.NORMALIZATION.PERC_CLIP\"] = True\n",
        "                opts[\"DATA.NORMALIZATION.PERC_LOWER\"] = float(preproc_info[\"kwargs\"][\"min_percentile\"])\n",
        "                opts[\"DATA.NORMALIZATION.PERC_UPPER\"] = float(preproc_info[\"kwargs\"][\"max_percentile\"])\n",
        "\n",
        "    return opts\n",
        "\n",
        "# Check the models that BiaPy can consume\n",
        "COLLECTION_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/collection.json\"\n",
        "collection_path = Path(pooch.retrieve(COLLECTION_URL, known_hash=None))\n",
        "with collection_path.open() as f:\n",
        "    collection = json.load(f)\n",
        "\n",
        "model_urls = [entry[\"rdf_source\"] for entry in collection[\"collection\"] if entry[\"type\"] == \"model\"]\n",
        "\n",
        "model_rdfs = []\n",
        "for mu in model_urls:\n",
        "    with open(Path(pooch.retrieve(mu, known_hash=None)), 'rt', encoding='utf8') as stream:\n",
        "        try:\n",
        "            model_rdfs.append(yaml.safe_load(stream))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "\n",
        "# Check axes, preprocessing functions used and postprocessing.\n",
        "pytorch_models = []\n",
        "imposed_vars = []\n",
        "\n",
        "workflow_specs = {\n",
        "    \"workflow_type\": \"CLASSIFICATION\",\n",
        "    \"ndim\": \"2D\",\n",
        "    \"nclasses\": \"all\",\n",
        "}\n",
        "for model_rdf in model_rdfs:\n",
        "    try:\n",
        "        (\n",
        "            preproc_info,\n",
        "            error,\n",
        "            error_message\n",
        "        ) = check_bmz_model_compatibility(model_rdf, workflow_specs=workflow_specs)\n",
        "    except:\n",
        "        error = True\n",
        "\n",
        "    if not error:\n",
        "        model_imposed_vars = check_model_restrictions(model_rdf, workflow_specs=workflow_specs)\n",
        "        imposed_vars.append(model_imposed_vars)\n",
        "        pytorch_models.append(model_rdf)\n",
        "\n",
        "# Print the possible models\n",
        "html = \"<table style='width:100%''>\"\n",
        "c = 0\n",
        "for i, model in enumerate(pytorch_models):\n",
        "\n",
        "    if 'nickname' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['nickname']\n",
        "        nickname_icon = model['config']['bioimageio']['nickname_icon']\n",
        "    elif 'id' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['id']\n",
        "        nickname_icon = model['config']['bioimageio']['id_emoji']\n",
        "    else:\n",
        "        doi = \"/\".join(model['id'].split(\"/\")[:2])\n",
        "        nickname = doi\n",
        "        nickname_icon = doi\n",
        "    cover_url = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/\"+nickname+\"/\"+str(model[\"version\"])+\"/files/\"+model['covers'][0]\n",
        "    restrictions = \"\"\n",
        "    for key, val in imposed_vars[i].items():\n",
        "        if key == 'MODEL.N_CLASSES':\n",
        "            restrictions += \"<p>number_of_classes: {}</p>\".format(val)\n",
        "        elif key == \"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\":\n",
        "            problem_channels = 'Binary mask + Contours'\n",
        "            if val == \"BC\":\n",
        "                problem_channels = \"Binary mask + Contours\"\n",
        "            elif val == 'BP':\n",
        "                problem_channels = \"Binary mask + Central points\"\n",
        "            elif val == 'BD':\n",
        "                problem_channels = \"Binary mask + Distance map\"\n",
        "            elif val == 'BCM':\n",
        "                problem_channels = \"Binary mask + Contours + Foreground mask\"\n",
        "            elif val == 'BCD':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map\"\n",
        "            elif val == 'BCDv2':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map with background\"\n",
        "            elif val == 'Dv2':\n",
        "                problem_channels = \"Distance map with background\"\n",
        "            restrictions += \"<p>problem_representation: {}</p>\".format(problem_channels)\n",
        "    if c == 0:\n",
        "        html += \"<tr>\"\n",
        "    html += \"<td style='width:33%'>\"\n",
        "    html += \"<p style='color:#2196f3'>%s</p><p>Nickname: %s (%s)</p>%s<img src='%s' height='200'></td>\"%(\n",
        "        model['name'],\n",
        "        nickname,\n",
        "        nickname_icon,\n",
        "        restrictions,\n",
        "        cover_url,\n",
        "    )\n",
        "    c +=1\n",
        "    if c == 3:\n",
        "        html += \"</tr>\"\n",
        "        c=0\n",
        "html += \"</table>\"\n",
        "if len( pytorch_models ) == 0:\n",
        "    display(HTML('<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>'))\n",
        "else:\n",
        "    display(HTML('<h1>List of models that can be used in BiaPy:</h1><br>'))\n",
        "    display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "5d5775b8538d41c68f81b28e594584bf",
            "a7573bba6278491f86ddb27fb961663a",
            "057c09192c52434bbbe4716afc0e7d8d"
          ]
        },
        "id": "YLShZSQZdoSR",
        "outputId": "f50b516e-e5e0-4cd8-8fed-080e3bbe420a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='Source:', options=('BiaPy', 'Torchvision', 'BioImage Model Zoo'), tooltips=('Models\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d5775b8538d41c68f81b28e594584bf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ###Play to select the source to build the model (BiaPy, Torchvision or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown **BiaPy**: to use the models implemented in BiaPy.\n",
        "\n",
        "#@markdown **Torchvision**: to use models from [Torchvision](https://pytorch.org/vision/stable/index.html).\n",
        "\n",
        "#@markdown **Bioimage Model Zoo (BMZ)**: to use models from the [BMZ repository](https://bioimage.io/#/). You can run the above cell to generate an updated list of the models that can be used with BiaPy. Copy the nickname from the model and paste it below.\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "\n",
        "changed_source = True\n",
        "exists_tv = False\n",
        "exists_bmz = False\n",
        "# create widgets\n",
        "source = widgets.ToggleButtons(\n",
        "    options=['BiaPy', 'Torchvision', 'BioImage Model Zoo'],\n",
        "    description='Source:',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltips=['Models created during this workflow', 'Torchvision model', 'BioImage Model Zoo model'],\n",
        "#     icons=['check'] * 3\n",
        ")\n",
        "\n",
        "\n",
        "t_vision = widgets.Dropdown(\n",
        "    options=['deeplabv3_mobilenet_v3_large', 'deeplabv3_resnet101', 'deeplabv3_resnet50', 'fcn_resnet101', 'fcn_resnet50', 'lraspp_mobilenet_v3_large'],\n",
        "    value='fcn_resnet50',\n",
        "    description='Supported:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "bmz = widgets.Text(\n",
        "    # value='10.5281/zenodo.5764892',\n",
        "    placeholder='Nickname of BMZ model',\n",
        "    description='ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# display the first widget\n",
        "display(source)\n",
        "\n",
        "# intialize the output - second widget\n",
        "out = Output()\n",
        "\n",
        "def changed(change):\n",
        "    '''\n",
        "    Monitor change in the first widget\n",
        "    '''\n",
        "    global out\n",
        "    global exists_bmz\n",
        "    global exists_tv\n",
        "    if source.value == 'BiaPy':\n",
        "        bmz.layout.display = 'none'\n",
        "        t_vision.layout.display = 'none'\n",
        "        out.clear_output() #clear output\n",
        "        out = Output() # redefine output\n",
        "    else:\n",
        "        if source.value == 'Torchvision':\n",
        "          bmz.layout.display = 'none'\n",
        "          t_vision.layout.display = 'none'\n",
        "          t_vision.layout.display = 'flex'\n",
        "          if not exists_tv:\n",
        "            out.append_display_data(t_vision)\n",
        "            display(out)\n",
        "          exists_tv = True\n",
        "        else:\n",
        "          t_vision.layout.display = 'none'\n",
        "          bmz.layout.display = 'none'\n",
        "          bmz.layout.display = 'flex'\n",
        "          if not exists_bmz:\n",
        "            out.append_display_data(bmz)\n",
        "            display(out)\n",
        "          exists_bmz = True\n",
        "\n",
        "# monitor the source widget for changes\n",
        "source.observe(changed, 'value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfUyeHEP4vY3"
      },
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "* **`test_ground_truth`:** Select to use test data folder order as the ground truth class to measure the performance of the model's result. **Default value: True**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`number_of_classes`:** Input number of classes present in the problem. It must be equal to the number of subfolders in training and validation (if not extracted from train) folders.\n",
        "\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 3**\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. For the example dataset, reasonable results can already be observed after 100 epochs. **Default value: 100**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 20**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: ViT, EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7 and simple CNN. **Default value: ViT**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 12**\n",
        "\n",
        "* **`patch_size`:** Input the size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 100**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization.**Default value: ADAMW**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM or ADAMW as optimizer, this value should be around 10e-4. **Default value: 0.0001**\n",
        "\n",
        " **`learning_rate_scheduler`:** Select to adjust the learning rate between epochs. Options: \"None\", \"Reduce on plateau\", \"One cycle\", \"Warm-up cosine decay\". **Default value: None**\n",
        "\n",
        "* **`aggressive_data_augmentation`:** Select to apply more aggressive data augmentation (CutBlur, CutNoise, GridMask, etc.) during training. Otherwise, simple flips and rotations will be applied. **Default value: True**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "RLdMygZVT5aH"
      },
      "outputs": [],
      "source": [
        "###Name of the model:\n",
        "model_name = \"my_2d_classification_butterfly\" #@param {type:\"string\"}\n",
        "\n",
        "### Data management:\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "test_ground_truth = True #@param {type:\"boolean\"}\n",
        "\n",
        "### Basic training parameters:\n",
        "number_of_classes = 75#@param {type:\"number\"}\n",
        "input_channels = 3 #@param {type:\"number\"}\n",
        "number_of_epochs =  100 #@param {type:\"number\"}\n",
        "patience =  20 # @param {type:\"number\"}\n",
        "\n",
        "### Advanced training parameters:\n",
        "\n",
        "model_architecture = \"ViT\" #@param [\"ViT\", \"EfficientNetB0\", \"EfficientNetB1\", \"EfficientNetB2\", \"EfficientNetB3\", \"EfficientNetB4\", \"EfficientNetB5\", \"EfficientNetB6\", \"EfficientNetB7\", \"simple_cnn\"]\n",
        "\n",
        "batch_size =  32#@param {type:\"number\"}\n",
        "patch_size = 100 #@param {type:\"number\"}\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n",
        "initial_learning_rate = 0.0001 #@param {type:\"number\"}\n",
        "learning_rate_scheduler = \"None\" #@param [\"None\", \"Reduce on plateau\",\"One cycle\", \"Warm-up cosine decay\"]\n",
        "aggressive_data_augmentation = True #@param {type:\"boolean\"}\n",
        "\n",
        "checkpoint_path = ''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YnNG7feZWNJs"
      },
      "outputs": [],
      "source": [
        "#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n",
        "#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n",
        "\n",
        "#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n",
        "from google.colab import files\n",
        "\n",
        "#s.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "checkpoint_path = '/content/' + list(uploaded.keys())[0]\n",
        "\n",
        "# open previously configured file, if exists\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# edit previous configuration file if it exists to load the checkpoint model\n",
        "if os.path.exists( yaml_file ):\n",
        "    import yaml\n",
        "    with open( yaml_file, 'r') as stream:\n",
        "        try:\n",
        "            biapy_config = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "    # save file\n",
        "    with open( yaml_file, 'w') as outfile:\n",
        "        yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Pre-trained model loaded and ready to re-train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNWZYlu4zSG"
      },
      "source": [
        "### **Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CZKK9EoVmH-Y",
        "outputId": "3718dad2-b171-41d5-c331-167505566099",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration finished.\n",
            "Date     : 2025-07-10 08:08:29\n",
            "Arguments: Namespace(config='/content/my_2d_classification_butterfly.yaml', result_dir='/content/output', name='my_2d_classification_butterfly', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "Job      : my_2d_classification_butterfly_1\n",
            "BiaPy    : 3.6.0\n",
            "Python   : 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "PyTorch  : 2.4.0+cu118\n",
            "The following changes were made in order to adapt the input configuration:\n",
            "Not using distributed mode\n",
            "[08:08:29.398443] Found 75 test classes\n",
            "[08:08:29.398854] Configuration details:\n",
            "[08:08:29.398892] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: True\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: True\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: True\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: True\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_CHANNEL_PB: 0.5\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: True\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: True\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: False\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FILTER_BY_IMAGE: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    MEASURE_BY: image\n",
            "    PERC_CLIP:\n",
            "      ENABLE: False\n",
            "      LOWER_PERC: -1.0\n",
            "      LOWER_VALUE: -1.0\n",
            "      UPPER_PERC: -1.0\n",
            "      UPPER_VALUE: -1.0\n",
            "    TYPE: zero_mean_unit_variance\n",
            "    ZERO_MEAN_UNIT_VAR:\n",
            "      MEAN_VAL: -1.0\n",
            "      STD_VAL: -1.0\n",
            "  PATCH_SIZE: (100, 100, 3)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: (3, 3, 1)\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  SAVE_FILTERED_IMAGES: False\n",
            "  SAVE_FILTERED_IMAGES_NUM: 3\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/test/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/test/y_detection_masks_2\n",
            "    FILTER_SAMPLES:\n",
            "      ENABLE: False\n",
            "      NORM_BEFORE: False\n",
            "      PROPS: []\n",
            "      SIGNS: []\n",
            "      VALUES: []\n",
            "    GT_PATH: user_data/test/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_ID_PATH: annotations.ids\n",
            "    INPUT_ZARR_MULTIPLE_DATA_LOCATIONS_PATH: annotations.locations\n",
            "    INPUT_ZARR_MULTIPLE_DATA_PARTNERS_PATH: annotations.presynaptic_site.partners\n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RESOLUTION_PATH: volumes.raw\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/test/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: True\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (12, 12)\n",
            "    PATH: /content/data/test\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/test_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/train/y_detection_masks_2\n",
            "    FILTER_SAMPLES:\n",
            "      ENABLE: False\n",
            "      NORM_BEFORE: False\n",
            "      PROPS: []\n",
            "      SIGNS: []\n",
            "      VALUES: []\n",
            "    GT_PATH: user_data/train/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_ID_PATH: annotations.ids\n",
            "    INPUT_ZARR_MULTIPLE_DATA_LOCATIONS_PATH: annotations.locations\n",
            "    INPUT_ZARR_MULTIPLE_DATA_PARTNERS_PATH: annotations.presynaptic_site.partners\n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RESOLUTION_PATH: volumes.raw\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /content/data/train\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks_2\n",
            "    DIST_EVAL: True\n",
            "    FILTER_SAMPLES:\n",
            "      ENABLE: False\n",
            "      NORM_BEFORE: False\n",
            "      PROPS: []\n",
            "      SIGNS: []\n",
            "      VALUES: []\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_ID_PATH: annotations.ids\n",
            "    INPUT_ZARR_MULTIPLE_DATA_LOCATIONS_PATH: annotations.locations\n",
            "    INPUT_ZARR_MULTIPLE_DATA_PARTNERS_PATH: annotations.presynaptic_site.partners\n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RESOLUTION_PATH: volumes.raw\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0)\n",
            "    PADDING: (0, 0)\n",
            "    PATH: /path/to/data\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: /path/to/data_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_2d_classification_butterfly/train_logs\n",
            "  LOG_FILE_PREFIX: my_2d_classification_butterfly_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: False\n",
            "  IGNORE_VALUES: False\n",
            "  TYPE: CE\n",
            "  VALUE_TO_IGNORE: -1\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: ELU\n",
            "  ARCHITECTURE: ViT\n",
            "  BMZ:\n",
            "    EXPORT:\n",
            "      AUTHORS: []\n",
            "      CITE: []\n",
            "      DATASET_INFO: [{}]\n",
            "      DESCRIPTION: \n",
            "      DOCUMENTATION: \n",
            "      ENABLE: False\n",
            "      LICENSE: CC-BY-4.0\n",
            "      MODEL_NAME: \n",
            "      MODEL_VERSION: 0.1.0\n",
            "      REUSE_BMZ_CONFIG: False\n",
            "      TAGS: []\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0.0]\n",
            "  FEATURE_MAPS: [16, 32, 64, 128, 256]\n",
            "  ISOTROPY: [True, True, True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LOAD_CHECKPOINT: False\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  LOAD_MODEL_FROM_CHECKPOINT: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 75\n",
            "  RCAN_CONV_FILTERS: 16\n",
            "  RCAN_RCAB_BLOCK_NUM: 20\n",
            "  RCAN_REDUCTION_RATIO: 16\n",
            "  RCAN_RG_BLOCK_NUM: 10\n",
            "  RCAN_UPSCALING_LAYER: True\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SKIP_UNMATCHED_LAYERS: False\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: pre\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [2, 2, 2, 2]\n",
            "PATHS:\n",
            "  BMZ_EXPORT_PATH: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/BMZ_files\n",
            "  CHARTS: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/charts\n",
            "  CHECKPOINT: /content/output/my_2d_classification_butterfly/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/aug\n",
            "  FIL_SAMPLES_DIR: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/filtering_information\n",
            "  GEN_CHECKS: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/gen_mask_check\n",
            "  MAE_OUT_DIR: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/MAE_checks\n",
            "  PROB_MAP_DIR: /content/output/my_2d_classification_butterfly/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/per_image_local_max_check\n",
            "    DET_LOCAL_MAX_COORDS_CHECK_POST_PROCESSING: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/per_image_local_max_check_post_processing\n",
            "    FULL_IMAGE: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/instance_associations\n",
            "    PATH: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1\n",
            "    PER_IMAGE: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/per_image_post_processing\n",
            "  TEST_FULL_GT_H5: user_data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/train_BC_instance_channels\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_2d_classification_butterfly/results/my_2d_classification_butterfly_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    LOAD_GT_DATA: False\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [2]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    SYNAPSES:\n",
            "      BLOB_LOG_MAX_SIGMA: 10\n",
            "      BLOB_LOG_MIN_SIGMA: 5\n",
            "      BLOB_LOG_NUM_SIGMA: 2\n",
            "      EXCLUDE_BORDER: False\n",
            "      MIN_TH_TO_BE_PEAK: 0.2\n",
            "      NORMALIZE_DISTANCES: False\n",
            "      PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "      POINT_CREATION_FUNCTION: peak_local_max\n",
            "      POSTSITE_DILATION: [2, 4, 4]\n",
            "      POSTSITE_DILATION_DISTANCE_CHANNELS: [3, 10, 10]\n",
            "      REMOVE_CLOSE_POINTS_RADIUS_BY_MASK: False\n",
            "      REMOVE_CLOSE_POST_POINTS_RADIUS: 0\n",
            "      REMOVE_CLOSE_PRE_POINTS_RADIUS: 0\n",
            "      TH_TYPE: auto\n",
            "    TYPE: regular\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 2D\n",
            "  PRINT_OLD_KEY_CHANGES: True\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1)\n",
            "  TYPE: CLASSIFICATION\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: -1\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: 0.2\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TH_TYPE: manual\n",
            "  DET_TOLERANCE: 10\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['accuracy']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [-1, -1]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGNS: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: 0\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: False\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 32\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 100\n",
            "  LR: 0.0001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: \n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "  METRICS: ['accuracy', 'top-5-accuracy']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 20\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[08:08:29.593491] DIPlib -- a quantitative image analysis library\n",
            "[08:08:29.593602] Version 3.5.2 (Dec 27 2024)\n",
            "[08:08:29.593630] For more information see https://diplib.org\n",
            "[08:08:29.594379] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[08:08:29.594424] Initializing Classification_Workflow\n",
            "[08:08:29.594447] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[08:08:29.825866] Creating normalization module . . .\n",
            "[08:08:29.826041] Normalization: using mean None and std: None\n",
            "[08:08:29.826452] ### LOAD ###\n",
            "[08:08:29.826841] Found 75 classes\n",
            "[08:08:35.396515] * Loading train images . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 2295/2295 [00:02<00:00, 789.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:08:38.307447] Samples of shape (100, 100, 3) will be randomly extracted. Number of samples: 2295\n",
            "[08:08:38.307507] * Loading validation images . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 255/255 [00:00<00:00, 651.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:08:38.703517] Samples of shape (100, 100, 3) will be randomly extracted. Number of samples: 255\n",
            "[08:08:38.703692] ### LOAD RESULTS ###\n",
            "[08:08:38.703754] *** Loaded train data shape is: (2295, 100, 100, 3)\n",
            "[08:08:38.703790] *** Loaded validation data shape is: (255, 100, 100, 3)\n",
            "[08:08:38.703818] ### END LOAD ###\n",
            "[08:08:38.703864] ###############\n",
            "[08:08:38.703894] # Build model #\n",
            "[08:08:38.703922] ###############\n",
            "[08:08:42.282257] ##############################\n",
            "[08:08:42.282390] #  PREPARE TRAIN GENERATORS  #\n",
            "[08:08:42.282419] ##############################\n",
            "[08:08:42.282534] Initializing train data generator . . .\n",
            "[08:08:42.285353] Normalization config used for X: {'type': 'zero_mean_unit_variance', 'measure_by': 'image', 'mask_norm': 'as_mask', 'out_dtype': 'float32', 'do_percentile_clipping': False, 'channels_to_analize': None, 'channel_info': None, 'train_normalization': True, 'eps': 1e-06, 'mean': 71.91075414540816, 'std': 64.62318442178312, 'last_X_norm': None, 'last_Y_norm': None}\n",
            "[08:08:42.285471] Initializing val data generator . . .\n",
            "[08:08:42.287678] Normalization config used for X: {'type': 'zero_mean_unit_variance', 'measure_by': 'image', 'mask_norm': 'as_mask', 'out_dtype': 'float32', 'do_percentile_clipping': False, 'channels_to_analize': None, 'channel_info': None, 'train_normalization': True, 'eps': 1e-06, 'mean': 71.91075414540816, 'std': 64.62318442178312, 'last_X_norm': None, 'last_Y_norm': None}\n",
            "[08:08:42.287786] Creating generator samples . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 17.19it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:00, 22.65it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:00<00:00, 28.33it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00<00:00, 27.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:08:42.661244] ### END TR-SAMPLES ###\n",
            "[08:08:42.661448] Train/val generators with 5 workers\n",
            "[08:08:42.661506] Accumulate grad iterations: 1\n",
            "[08:08:42.661536] Effective batch size: 32\n",
            "[08:08:42.661566] Sampler_train = None\n",
            "[08:08:42.665221] #######################\n",
            "[08:08:42.665262] # Prepare logging tool #\n",
            "[08:08:42.665280] #######################\n",
            "[08:08:42.667424] AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.02\n",
            ")\n",
            "[08:08:42.667548] #####################\n",
            "[08:08:42.667569] #  TRAIN THE MODEL  #\n",
            "[08:08:42.667586] #####################\n",
            "[08:08:42.667607] Start training in epoch 1 - Total: 100\n",
            "[08:08:42.667637] ~~~ Epoch 1/100 ~~~\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:08:44.329805] Epoch: [1]  [ 0/72]  eta: 0:01:59  loss: 4.4145 (4.4145)  Accuracy: 0.0000 (0.0000)  Top 5 accuracy: 0.0625 (0.0625)  lr: 0.000100  iter-time: 1.6595\n",
            "[08:08:46.241393] Epoch: [1]  [10/72]  eta: 0:00:20  loss: 4.5296 (4.6018)  Accuracy: 0.0312 (0.0369)  Top 5 accuracy: 0.1250 (0.1278)  lr: 0.000100  iter-time: 0.3245\n",
            "[08:08:48.148015] Epoch: [1]  [20/72]  eta: 0:00:13  loss: 4.3688 (4.4264)  Accuracy: 0.0312 (0.0432)  Top 5 accuracy: 0.1250 (0.1369)  lr: 0.000100  iter-time: 0.1908\n",
            "[08:08:50.043451] Epoch: [1]  [30/72]  eta: 0:00:09  loss: 4.1984 (4.3327)  Accuracy: 0.0312 (0.0454)  Top 5 accuracy: 0.1250 (0.1462)  lr: 0.000100  iter-time: 0.1900\n",
            "[08:08:52.017460] Epoch: [1]  [40/72]  eta: 0:00:07  loss: 4.1241 (4.2667)  Accuracy: 0.0312 (0.0389)  Top 5 accuracy: 0.1250 (0.1448)  lr: 0.000100  iter-time: 0.1934\n",
            "[08:08:54.108680] Epoch: [1]  [50/72]  eta: 0:00:04  loss: 4.0516 (4.2205)  Accuracy: 0.0312 (0.0423)  Top 5 accuracy: 0.1562 (0.1520)  lr: 0.000100  iter-time: 0.2032\n",
            "[08:08:56.052666] Epoch: [1]  [60/72]  eta: 0:00:02  loss: 3.9681 (4.1658)  Accuracy: 0.0625 (0.0461)  Top 5 accuracy: 0.1875 (0.1665)  lr: 0.000100  iter-time: 0.2016\n",
            "[08:08:57.954447] Epoch: [1]  [70/72]  eta: 0:00:00  loss: 3.8796 (4.1216)  Accuracy: 0.0625 (0.0471)  Top 5 accuracy: 0.1875 (0.1774)  lr: 0.000100  iter-time: 0.1922\n",
            "[08:08:58.195991] Epoch: [1]  [71/72]  eta: 0:00:00  loss: 3.8937 (4.1189)  Accuracy: 0.0625 (0.0464)  Top 5 accuracy: 0.1875 (0.1761)  lr: 0.000100  iter-time: 0.1944\n",
            "[08:08:58.282030] Epoch: [1] Total time: 0:00:15 (0.2168 s / it)\n",
            "[08:08:58.282153] [Train] averaged stats: loss: 3.8937 (4.1189)  Accuracy: 0.0625 (0.0464)  Top 5 accuracy: 0.1875 (0.1761)  lr: 0.000100\n",
            "[08:08:58.990511] Epoch: [1]  [0/8]  eta: 0:00:05  loss: 3.5047 (3.5047)  Accuracy: 0.1562 (0.1562)  Top 5 accuracy: 0.3438 (0.3437)  iter-time: 0.7060\n",
            "[08:08:59.482932] Epoch: [1]  [7/8]  eta: 0:00:00  loss: 3.8557 (3.8080)  Accuracy: 0.0312 (0.0630)  Top 5 accuracy: 0.2812 (0.2394)  iter-time: 0.1497\n",
            "[08:08:59.576567] Epoch: [1] Total time: 0:00:01 (0.1616 s / it)\n",
            "[08:08:59.576646] [Val] averaged stats: loss: 3.8557 (3.8080)  Accuracy: 0.0312 (0.0630)  Top 5 accuracy: 0.2812 (0.2394)\n",
            "[08:08:59.577291] Val loss improved from inf to 3.8079535961151123, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:09:04.423700] [Val] best loss: 3.8080 best  Accuracy: 0.0630 Top 5 accuracy: 0.2394 \n",
            "[08:09:04.425611] [Time] 21.8s 21.8s/36.6m\n",
            "\n",
            "[08:09:04.425695] ~~~ Epoch 2/100 ~~~\n",
            "\n",
            "[08:09:06.096920] Epoch: [2]  [ 0/72]  eta: 0:02:00  loss: 3.6960 (3.6960)  Accuracy: 0.1250 (0.1250)  Top 5 accuracy: 0.3125 (0.3125)  lr: 0.000100  iter-time: 1.6689\n",
            "[08:09:08.228190] Epoch: [2]  [10/72]  eta: 0:00:21  loss: 3.8080 (3.8088)  Accuracy: 0.0625 (0.0540)  Top 5 accuracy: 0.2500 (0.2443)  lr: 0.000100  iter-time: 0.3453\n",
            "[08:09:10.196439] Epoch: [2]  [20/72]  eta: 0:00:14  loss: 3.8059 (3.7674)  Accuracy: 0.0625 (0.0685)  Top 5 accuracy: 0.2500 (0.2693)  lr: 0.000100  iter-time: 0.2047\n",
            "[08:09:12.146205] Epoch: [2]  [30/72]  eta: 0:00:10  loss: 3.7239 (3.7428)  Accuracy: 0.0625 (0.0726)  Top 5 accuracy: 0.2812 (0.2792)  lr: 0.000100  iter-time: 0.1957\n",
            "[08:09:14.101820] Epoch: [2]  [40/72]  eta: 0:00:07  loss: 3.6328 (3.7162)  Accuracy: 0.0625 (0.0785)  Top 5 accuracy: 0.3125 (0.2942)  lr: 0.000100  iter-time: 0.1952\n",
            "[08:09:16.070435] Epoch: [2]  [50/72]  eta: 0:00:05  loss: 3.5981 (3.7059)  Accuracy: 0.0938 (0.0797)  Top 5 accuracy: 0.3125 (0.2953)  lr: 0.000100  iter-time: 0.1961\n",
            "[08:09:18.095873] Epoch: [2]  [60/72]  eta: 0:00:02  loss: 3.5981 (3.6894)  Accuracy: 0.1250 (0.0866)  Top 5 accuracy: 0.3438 (0.3043)  lr: 0.000100  iter-time: 0.1996\n",
            "[08:09:20.084355] Epoch: [2]  [70/72]  eta: 0:00:00  loss: 3.6486 (3.6919)  Accuracy: 0.0938 (0.0836)  Top 5 accuracy: 0.3125 (0.3033)  lr: 0.000100  iter-time: 0.2006\n",
            "[08:09:20.238487] Epoch: [2]  [71/72]  eta: 0:00:00  loss: 3.6404 (3.6890)  Accuracy: 0.0625 (0.0831)  Top 5 accuracy: 0.3125 (0.3039)  lr: 0.000100  iter-time: 0.1981\n",
            "[08:09:20.334704] Epoch: [2] Total time: 0:00:15 (0.2209 s / it)\n",
            "[08:09:20.335093] [Train] averaged stats: loss: 3.6404 (3.6890)  Accuracy: 0.0625 (0.0831)  Top 5 accuracy: 0.3125 (0.3039)  lr: 0.000100\n",
            "[08:09:20.829441] Epoch: [2]  [0/8]  eta: 0:00:03  loss: 3.3560 (3.3560)  Accuracy: 0.2500 (0.2500)  Top 5 accuracy: 0.3438 (0.3437)  iter-time: 0.4917\n",
            "[08:09:21.372352] Epoch: [2]  [7/8]  eta: 0:00:00  loss: 3.4815 (3.5924)  Accuracy: 0.0625 (0.0861)  Top 5 accuracy: 0.3438 (0.3247)  iter-time: 0.1279\n",
            "[08:09:21.465532] Epoch: [2] Total time: 0:00:01 (0.1411 s / it)\n",
            "[08:09:21.465613] [Val] averaged stats: loss: 3.4815 (3.5924)  Accuracy: 0.0625 (0.0861)  Top 5 accuracy: 0.3438 (0.3247)\n",
            "[08:09:21.466435] Val loss improved from 3.8079535961151123 to 3.59243643283844, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:09:25.071478] [Val] best loss: 3.5924 best  Accuracy: 0.0861 Top 5 accuracy: 0.3247 \n",
            "[08:09:25.073244] [Time] 20.6s 42.4s/34.8m\n",
            "\n",
            "[08:09:25.073306] ~~~ Epoch 3/100 ~~~\n",
            "\n",
            "[08:09:26.174270] Epoch: [3]  [ 0/72]  eta: 0:01:19  loss: 3.5665 (3.5665)  Accuracy: 0.0625 (0.0625)  Top 5 accuracy: 0.2500 (0.2500)  lr: 0.000100  iter-time: 1.0985\n",
            "[08:09:28.224758] Epoch: [3]  [10/72]  eta: 0:00:17  loss: 3.5665 (3.5029)  Accuracy: 0.0938 (0.1193)  Top 5 accuracy: 0.3750 (0.3438)  lr: 0.000100  iter-time: 0.2861\n",
            "[08:09:30.256212] Epoch: [3]  [20/72]  eta: 0:00:12  loss: 3.5470 (3.5320)  Accuracy: 0.0938 (0.1012)  Top 5 accuracy: 0.3125 (0.3333)  lr: 0.000100  iter-time: 0.2040\n",
            "[08:09:32.426859] Epoch: [3]  [30/72]  eta: 0:00:09  loss: 3.4854 (3.5314)  Accuracy: 0.0938 (0.1109)  Top 5 accuracy: 0.3125 (0.3367)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:09:34.462075] Epoch: [3]  [40/72]  eta: 0:00:07  loss: 3.4534 (3.5027)  Accuracy: 0.1250 (0.1181)  Top 5 accuracy: 0.3750 (0.3567)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:09:36.492260] Epoch: [3]  [50/72]  eta: 0:00:04  loss: 3.4887 (3.5078)  Accuracy: 0.1250 (0.1201)  Top 5 accuracy: 0.3750 (0.3597)  lr: 0.000100  iter-time: 0.2031\n",
            "[08:09:38.516623] Epoch: [3]  [60/72]  eta: 0:00:02  loss: 3.5316 (3.5300)  Accuracy: 0.0938 (0.1178)  Top 5 accuracy: 0.3438 (0.3519)  lr: 0.000100  iter-time: 0.2026\n",
            "[08:09:40.521288] Epoch: [3]  [70/72]  eta: 0:00:00  loss: 3.5169 (3.5275)  Accuracy: 0.0938 (0.1122)  Top 5 accuracy: 0.3125 (0.3534)  lr: 0.000100  iter-time: 0.2013\n",
            "[08:09:40.677950] Epoch: [3]  [71/72]  eta: 0:00:00  loss: 3.5116 (3.5241)  Accuracy: 0.0938 (0.1131)  Top 5 accuracy: 0.3125 (0.3558)  lr: 0.000100  iter-time: 0.1989\n",
            "[08:09:40.780013] Epoch: [3] Total time: 0:00:15 (0.2181 s / it)\n",
            "[08:09:40.780271] [Train] averaged stats: loss: 3.5116 (3.5241)  Accuracy: 0.0938 (0.1131)  Top 5 accuracy: 0.3125 (0.3558)  lr: 0.000100\n",
            "[08:09:41.274851] Epoch: [3]  [0/8]  eta: 0:00:03  loss: 3.1501 (3.1501)  Accuracy: 0.1875 (0.1875)  Top 5 accuracy: 0.4062 (0.4062)  iter-time: 0.4911\n",
            "[08:09:41.829042] Epoch: [3]  [7/8]  eta: 0:00:00  loss: 3.3283 (3.4476)  Accuracy: 0.0938 (0.1174)  Top 5 accuracy: 0.4062 (0.4115)  iter-time: 0.1293\n",
            "[08:09:41.937538] Epoch: [3] Total time: 0:00:01 (0.1443 s / it)\n",
            "[08:09:41.937614] [Val] averaged stats: loss: 3.3283 (3.4476)  Accuracy: 0.0938 (0.1174)  Top 5 accuracy: 0.4062 (0.4115)\n",
            "[08:09:41.938196] Val loss improved from 3.59243643283844 to 3.4476305842399597, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:09:46.812161] [Val] best loss: 3.4476 best  Accuracy: 0.1174 Top 5 accuracy: 0.4115 \n",
            "[08:09:46.813829] [Time] 21.7s 1.1m/36.6m\n",
            "\n",
            "[08:09:46.813886] ~~~ Epoch 4/100 ~~~\n",
            "\n",
            "[08:09:48.124802] Epoch: [4]  [ 0/72]  eta: 0:01:33  loss: 3.1827 (3.1827)  Accuracy: 0.1875 (0.1875)  Top 5 accuracy: 0.4688 (0.4687)  lr: 0.000100  iter-time: 1.3053\n",
            "[08:09:50.160387] Epoch: [4]  [10/72]  eta: 0:00:18  loss: 3.2752 (3.2953)  Accuracy: 0.1562 (0.1449)  Top 5 accuracy: 0.4688 (0.4688)  lr: 0.000100  iter-time: 0.3035\n",
            "[08:09:52.188446] Epoch: [4]  [20/72]  eta: 0:00:13  loss: 3.3033 (3.3180)  Accuracy: 0.1562 (0.1488)  Top 5 accuracy: 0.4375 (0.4539)  lr: 0.000100  iter-time: 0.2030\n",
            "[08:09:54.211215] Epoch: [4]  [30/72]  eta: 0:00:10  loss: 3.3103 (3.3066)  Accuracy: 0.1562 (0.1562)  Top 5 accuracy: 0.4375 (0.4526)  lr: 0.000100  iter-time: 0.2024\n",
            "[08:09:56.314568] Epoch: [4]  [40/72]  eta: 0:00:07  loss: 3.2546 (3.2838)  Accuracy: 0.1562 (0.1570)  Top 5 accuracy: 0.4688 (0.4619)  lr: 0.000100  iter-time: 0.2062\n",
            "[08:09:58.511918] Epoch: [4]  [50/72]  eta: 0:00:05  loss: 3.2451 (3.2786)  Accuracy: 0.1562 (0.1630)  Top 5 accuracy: 0.4688 (0.4614)  lr: 0.000100  iter-time: 0.2146\n",
            "[08:10:00.591764] Epoch: [4]  [60/72]  eta: 0:00:02  loss: 3.2455 (3.2851)  Accuracy: 0.1562 (0.1598)  Top 5 accuracy: 0.4062 (0.4565)  lr: 0.000100  iter-time: 0.2134\n",
            "[08:10:02.657563] Epoch: [4]  [70/72]  eta: 0:00:00  loss: 3.1575 (3.2672)  Accuracy: 0.1250 (0.1580)  Top 5 accuracy: 0.4375 (0.4604)  lr: 0.000100  iter-time: 0.2072\n",
            "[08:10:02.819950] Epoch: [4]  [71/72]  eta: 0:00:00  loss: 3.2041 (3.2696)  Accuracy: 0.1250 (0.1588)  Top 5 accuracy: 0.4375 (0.4606)  lr: 0.000100  iter-time: 0.2037\n",
            "[08:10:02.917353] Epoch: [4] Total time: 0:00:16 (0.2236 s / it)\n",
            "[08:10:02.917713] [Train] averaged stats: loss: 3.2041 (3.2696)  Accuracy: 0.1250 (0.1588)  Top 5 accuracy: 0.4375 (0.4606)  lr: 0.000100\n",
            "[08:10:03.497379] Epoch: [4]  [0/8]  eta: 0:00:04  loss: 2.6749 (2.6749)  Accuracy: 0.2188 (0.2187)  Top 5 accuracy: 0.6562 (0.6562)  iter-time: 0.5769\n",
            "[08:10:04.010351] Epoch: [4]  [7/8]  eta: 0:00:00  loss: 3.1235 (3.2132)  Accuracy: 0.1613 (0.1608)  Top 5 accuracy: 0.4375 (0.4821)  iter-time: 0.1355\n",
            "[08:10:04.103426] Epoch: [4] Total time: 0:00:01 (0.1480 s / it)\n",
            "[08:10:04.103499] [Val] averaged stats: loss: 3.1235 (3.2132)  Accuracy: 0.1613 (0.1608)  Top 5 accuracy: 0.4375 (0.4821)\n",
            "[08:10:04.104522] Val loss improved from 3.4476305842399597 to 3.2132056057453156, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:10:09.147920] [Val] best loss: 3.2132 best  Accuracy: 0.1608 Top 5 accuracy: 0.4821 \n",
            "[08:10:09.150097] [Time] 22.3s 1.4m/37.6m\n",
            "\n",
            "[08:10:09.150199] ~~~ Epoch 5/100 ~~~\n",
            "\n",
            "[08:10:10.171109] Epoch: [5]  [ 0/72]  eta: 0:01:13  loss: 3.2141 (3.2141)  Accuracy: 0.0938 (0.0937)  Top 5 accuracy: 0.5000 (0.5000)  lr: 0.000100  iter-time: 1.0174\n",
            "[08:10:12.297830] Epoch: [5]  [10/72]  eta: 0:00:17  loss: 3.1344 (3.1665)  Accuracy: 0.1875 (0.1648)  Top 5 accuracy: 0.4688 (0.4744)  lr: 0.000100  iter-time: 0.2857\n",
            "[08:10:14.387458] Epoch: [5]  [20/72]  eta: 0:00:12  loss: 3.1486 (3.1664)  Accuracy: 0.1875 (0.1815)  Top 5 accuracy: 0.4688 (0.4821)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:10:16.488501] Epoch: [5]  [30/72]  eta: 0:00:09  loss: 3.1362 (3.1501)  Accuracy: 0.2188 (0.1925)  Top 5 accuracy: 0.4375 (0.4808)  lr: 0.000100  iter-time: 0.2094\n",
            "[08:10:18.613227] Epoch: [5]  [40/72]  eta: 0:00:07  loss: 3.0504 (3.1556)  Accuracy: 0.2188 (0.1928)  Top 5 accuracy: 0.4375 (0.4825)  lr: 0.000100  iter-time: 0.2112\n",
            "[08:10:20.811979] Epoch: [5]  [50/72]  eta: 0:00:05  loss: 3.0950 (3.1375)  Accuracy: 0.1875 (0.1930)  Top 5 accuracy: 0.5312 (0.4957)  lr: 0.000100  iter-time: 0.2161\n",
            "[08:10:23.096964] Epoch: [5]  [60/72]  eta: 0:00:02  loss: 3.0271 (3.1170)  Accuracy: 0.1875 (0.1931)  Top 5 accuracy: 0.5312 (0.5036)  lr: 0.000100  iter-time: 0.2237\n",
            "[08:10:25.246830] Epoch: [5]  [70/72]  eta: 0:00:00  loss: 3.0583 (3.1343)  Accuracy: 0.1562 (0.1901)  Top 5 accuracy: 0.5312 (0.5031)  lr: 0.000100  iter-time: 0.2213\n",
            "[08:10:25.416777] Epoch: [5]  [71/72]  eta: 0:00:00  loss: 3.0605 (3.1412)  Accuracy: 0.1739 (0.1899)  Top 5 accuracy: 0.5312 (0.5033)  lr: 0.000100  iter-time: 0.2175\n",
            "[08:10:25.509436] Epoch: [5] Total time: 0:00:16 (0.2272 s / it)\n",
            "[08:10:25.510024] [Train] averaged stats: loss: 3.0605 (3.1412)  Accuracy: 0.1739 (0.1899)  Top 5 accuracy: 0.5312 (0.5033)  lr: 0.000100\n",
            "[08:10:25.955519] Epoch: [5]  [0/8]  eta: 0:00:03  loss: 2.9802 (2.9802)  Accuracy: 0.2812 (0.2812)  Top 5 accuracy: 0.5312 (0.5312)  iter-time: 0.4429\n",
            "[08:10:26.561510] Epoch: [5]  [7/8]  eta: 0:00:00  loss: 2.9386 (2.9742)  Accuracy: 0.2500 (0.2431)  Top 5 accuracy: 0.5484 (0.5490)  iter-time: 0.1310\n",
            "[08:10:26.654634] Epoch: [5] Total time: 0:00:01 (0.1428 s / it)\n",
            "[08:10:26.654709] [Val] averaged stats: loss: 2.9386 (2.9742)  Accuracy: 0.2500 (0.2431)  Top 5 accuracy: 0.5484 (0.5490)\n",
            "[08:10:26.655538] Val loss improved from 3.2132056057453156 to 2.9742306768894196, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:10:31.590687] [Val] best loss: 2.9742 best  Accuracy: 0.2431 Top 5 accuracy: 0.5490 \n",
            "[08:10:31.592431] Creating training plots . . .\n",
            "[08:10:31.971968] [Time] 22.8s 1.8m/38.3m\n",
            "\n",
            "[08:10:31.972084] ~~~ Epoch 6/100 ~~~\n",
            "\n",
            "[08:10:33.533947] Epoch: [6]  [ 0/72]  eta: 0:01:51  loss: 3.1476 (3.1476)  Accuracy: 0.1875 (0.1875)  Top 5 accuracy: 0.4688 (0.4687)  lr: 0.000100  iter-time: 1.5509\n",
            "[08:10:35.798172] Epoch: [6]  [10/72]  eta: 0:00:21  loss: 2.8939 (2.8971)  Accuracy: 0.2500 (0.2386)  Top 5 accuracy: 0.5312 (0.5511)  lr: 0.000100  iter-time: 0.3463\n",
            "[08:10:37.929518] Epoch: [6]  [20/72]  eta: 0:00:14  loss: 2.8939 (2.9737)  Accuracy: 0.2188 (0.2202)  Top 5 accuracy: 0.5625 (0.5417)  lr: 0.000100  iter-time: 0.2195\n",
            "[08:10:40.057172] Epoch: [6]  [30/72]  eta: 0:00:10  loss: 2.9993 (2.9841)  Accuracy: 0.1875 (0.2147)  Top 5 accuracy: 0.5312 (0.5302)  lr: 0.000100  iter-time: 0.2128\n",
            "[08:10:42.181682] Epoch: [6]  [40/72]  eta: 0:00:07  loss: 2.9309 (2.9428)  Accuracy: 0.2188 (0.2195)  Top 5 accuracy: 0.5312 (0.5427)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:10:44.309269] Epoch: [6]  [50/72]  eta: 0:00:05  loss: 2.7502 (2.9000)  Accuracy: 0.2500 (0.2279)  Top 5 accuracy: 0.5938 (0.5564)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:10:46.501443] Epoch: [6]  [60/72]  eta: 0:00:02  loss: 2.7585 (2.9053)  Accuracy: 0.2812 (0.2336)  Top 5 accuracy: 0.5938 (0.5543)  lr: 0.000100  iter-time: 0.2159\n",
            "[08:10:48.644214] Epoch: [6]  [70/72]  eta: 0:00:00  loss: 2.9502 (2.9283)  Accuracy: 0.2188 (0.2284)  Top 5 accuracy: 0.5312 (0.5515)  lr: 0.000100  iter-time: 0.2167\n",
            "[08:10:48.808656] Epoch: [6]  [71/72]  eta: 0:00:00  loss: 2.9502 (2.9279)  Accuracy: 0.2188 (0.2295)  Top 5 accuracy: 0.5312 (0.5517)  lr: 0.000100  iter-time: 0.2142\n",
            "[08:10:48.918969] Epoch: [6] Total time: 0:00:16 (0.2354 s / it)\n",
            "[08:10:48.919390] [Train] averaged stats: loss: 2.9502 (2.9279)  Accuracy: 0.2188 (0.2295)  Top 5 accuracy: 0.5312 (0.5517)  lr: 0.000100\n",
            "[08:10:49.363593] Epoch: [6]  [0/8]  eta: 0:00:03  loss: 2.8552 (2.8552)  Accuracy: 0.1875 (0.1875)  Top 5 accuracy: 0.5312 (0.5312)  iter-time: 0.4415\n",
            "[08:10:49.970118] Epoch: [6]  [7/8]  eta: 0:00:00  loss: 3.0849 (3.0893)  Accuracy: 0.1562 (0.1880)  Top 5 accuracy: 0.5000 (0.5139)  iter-time: 0.1309\n",
            "[08:10:50.066116] Epoch: [6] Total time: 0:00:01 (0.1431 s / it)\n",
            "[08:10:50.066212] [Val] averaged stats: loss: 3.0849 (3.0893)  Accuracy: 0.1562 (0.1880)  Top 5 accuracy: 0.5000 (0.5139)\n",
            "[08:10:50.066868] [Val] best loss: 2.9742 best  Accuracy: 0.2431 Top 5 accuracy: 0.5490 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:10:50.068201] [Time] 18.1s 2.1m/30.8m\n",
            "\n",
            "[08:10:50.068231] ~~~ Epoch 7/100 ~~~\n",
            "\n",
            "[08:10:50.840216] Epoch: [7]  [ 0/72]  eta: 0:00:55  loss: 3.2970 (3.2970)  Accuracy: 0.2500 (0.2500)  Top 5 accuracy: 0.4375 (0.4375)  lr: 0.000100  iter-time: 0.7661\n",
            "[08:10:53.018745] Epoch: [7]  [10/72]  eta: 0:00:16  loss: 2.8035 (2.8403)  Accuracy: 0.1562 (0.2216)  Top 5 accuracy: 0.5625 (0.5795)  lr: 0.000100  iter-time: 0.2676\n",
            "[08:10:55.159642] Epoch: [7]  [20/72]  eta: 0:00:12  loss: 2.8035 (2.8545)  Accuracy: 0.2188 (0.2381)  Top 5 accuracy: 0.5938 (0.5878)  lr: 0.000100  iter-time: 0.2159\n",
            "[08:10:57.283952] Epoch: [7]  [30/72]  eta: 0:00:09  loss: 2.7476 (2.7956)  Accuracy: 0.2812 (0.2621)  Top 5 accuracy: 0.5938 (0.5897)  lr: 0.000100  iter-time: 0.2131\n",
            "[08:10:59.509269] Epoch: [7]  [40/72]  eta: 0:00:07  loss: 2.7476 (2.8099)  Accuracy: 0.2812 (0.2622)  Top 5 accuracy: 0.5625 (0.5854)  lr: 0.000100  iter-time: 0.2172\n",
            "[08:11:01.681513] Epoch: [7]  [50/72]  eta: 0:00:05  loss: 2.7824 (2.7998)  Accuracy: 0.2500 (0.2598)  Top 5 accuracy: 0.5625 (0.5907)  lr: 0.000100  iter-time: 0.2196\n",
            "[08:11:03.806041] Epoch: [7]  [60/72]  eta: 0:00:02  loss: 2.8155 (2.8151)  Accuracy: 0.2500 (0.2567)  Top 5 accuracy: 0.5625 (0.5850)  lr: 0.000100  iter-time: 0.2147\n",
            "[08:11:05.914254] Epoch: [7]  [70/72]  eta: 0:00:00  loss: 2.8921 (2.8139)  Accuracy: 0.2500 (0.2597)  Top 5 accuracy: 0.5625 (0.5836)  lr: 0.000100  iter-time: 0.2115\n",
            "[08:11:06.076038] Epoch: [7]  [71/72]  eta: 0:00:00  loss: 2.8921 (2.8153)  Accuracy: 0.2500 (0.2585)  Top 5 accuracy: 0.5625 (0.5828)  lr: 0.000100  iter-time: 0.2088\n",
            "[08:11:06.179966] Epoch: [7] Total time: 0:00:16 (0.2238 s / it)\n",
            "[08:11:06.180336] [Train] averaged stats: loss: 2.8921 (2.8153)  Accuracy: 0.2500 (0.2585)  Top 5 accuracy: 0.5625 (0.5828)  lr: 0.000100\n",
            "[08:11:06.775197] Epoch: [7]  [0/8]  eta: 0:00:04  loss: 2.4605 (2.4605)  Accuracy: 0.4062 (0.4062)  Top 5 accuracy: 0.5938 (0.5937)  iter-time: 0.5924\n",
            "[08:11:07.226473] Epoch: [7]  [7/8]  eta: 0:00:00  loss: 2.7358 (2.7779)  Accuracy: 0.2812 (0.2707)  Top 5 accuracy: 0.5938 (0.6001)  iter-time: 0.1304\n",
            "[08:11:07.318719] Epoch: [7] Total time: 0:00:01 (0.1421 s / it)\n",
            "[08:11:07.318853] [Val] averaged stats: loss: 2.7358 (2.7779)  Accuracy: 0.2812 (0.2707)  Top 5 accuracy: 0.5938 (0.6001)\n",
            "[08:11:07.319610] Val loss improved from 2.9742306768894196 to 2.77794548869133, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:11:12.457484] [Val] best loss: 2.7779 best  Accuracy: 0.2707 Top 5 accuracy: 0.6001 \n",
            "[08:11:12.459361] [Time] 22.4s 2.5m/37.6m\n",
            "\n",
            "[08:11:12.459448] ~~~ Epoch 8/100 ~~~\n",
            "\n",
            "[08:11:13.766226] Epoch: [8]  [ 0/72]  eta: 0:01:33  loss: 3.0970 (3.0970)  Accuracy: 0.2500 (0.2500)  Top 5 accuracy: 0.5312 (0.5312)  lr: 0.000100  iter-time: 1.3011\n",
            "[08:11:15.856843] Epoch: [8]  [10/72]  eta: 0:00:19  loss: 2.6443 (2.6704)  Accuracy: 0.3125 (0.2955)  Top 5 accuracy: 0.6562 (0.6506)  lr: 0.000100  iter-time: 0.3082\n",
            "[08:11:17.908515] Epoch: [8]  [20/72]  eta: 0:00:13  loss: 2.6443 (2.6845)  Accuracy: 0.2812 (0.2917)  Top 5 accuracy: 0.6250 (0.6369)  lr: 0.000100  iter-time: 0.2070\n",
            "[08:11:19.972076] Epoch: [8]  [30/72]  eta: 0:00:10  loss: 2.7615 (2.7119)  Accuracy: 0.2500 (0.2772)  Top 5 accuracy: 0.5938 (0.6190)  lr: 0.000100  iter-time: 0.2057\n",
            "[08:11:22.041032] Epoch: [8]  [40/72]  eta: 0:00:07  loss: 2.7615 (2.7279)  Accuracy: 0.2500 (0.2744)  Top 5 accuracy: 0.5625 (0.6105)  lr: 0.000100  iter-time: 0.2065\n",
            "[08:11:24.171836] Epoch: [8]  [50/72]  eta: 0:00:05  loss: 2.7437 (2.7316)  Accuracy: 0.2500 (0.2788)  Top 5 accuracy: 0.5938 (0.6140)  lr: 0.000100  iter-time: 0.2098\n",
            "[08:11:26.396457] Epoch: [8]  [60/72]  eta: 0:00:02  loss: 2.8115 (2.7548)  Accuracy: 0.2500 (0.2741)  Top 5 accuracy: 0.5938 (0.6050)  lr: 0.000100  iter-time: 0.2176\n",
            "[08:11:28.479101] Epoch: [8]  [70/72]  eta: 0:00:00  loss: 2.8083 (2.7587)  Accuracy: 0.2500 (0.2702)  Top 5 accuracy: 0.5625 (0.6008)  lr: 0.000100  iter-time: 0.2153\n",
            "[08:11:28.643284] Epoch: [8]  [71/72]  eta: 0:00:00  loss: 2.7935 (2.7587)  Accuracy: 0.2500 (0.2701)  Top 5 accuracy: 0.5625 (0.6009)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:11:28.759212] Epoch: [8] Total time: 0:00:16 (0.2264 s / it)\n",
            "[08:11:28.759597] [Train] averaged stats: loss: 2.7935 (2.7587)  Accuracy: 0.2500 (0.2701)  Top 5 accuracy: 0.5625 (0.6009)  lr: 0.000100\n",
            "[08:11:29.464438] Epoch: [8]  [0/8]  eta: 0:00:05  loss: 2.5426 (2.5426)  Accuracy: 0.3125 (0.3125)  Top 5 accuracy: 0.5625 (0.5625)  iter-time: 0.7010\n",
            "[08:11:29.930567] Epoch: [8]  [7/8]  eta: 0:00:00  loss: 2.9166 (2.8945)  Accuracy: 0.2188 (0.2547)  Top 5 accuracy: 0.5625 (0.5722)  iter-time: 0.1446\n",
            "[08:11:30.034104] Epoch: [8] Total time: 0:00:01 (0.1591 s / it)\n",
            "[08:11:30.034190] [Val] averaged stats: loss: 2.9166 (2.8945)  Accuracy: 0.2188 (0.2547)  Top 5 accuracy: 0.5625 (0.5722)\n",
            "[08:11:30.034632] [Val] best loss: 2.7779 best  Accuracy: 0.2707 Top 5 accuracy: 0.6001 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:11:30.036113] [Time] 17.6s 2.8m/30.0m\n",
            "\n",
            "[08:11:30.036155] ~~~ Epoch 9/100 ~~~\n",
            "\n",
            "[08:11:30.897083] Epoch: [9]  [ 0/72]  eta: 0:01:01  loss: 2.8211 (2.8211)  Accuracy: 0.2812 (0.2812)  Top 5 accuracy: 0.5938 (0.5937)  lr: 0.000100  iter-time: 0.8584\n",
            "[08:11:33.069239] Epoch: [9]  [10/72]  eta: 0:00:17  loss: 2.6294 (2.6810)  Accuracy: 0.2500 (0.2642)  Top 5 accuracy: 0.5938 (0.6023)  lr: 0.000100  iter-time: 0.2754\n",
            "[08:11:35.175441] Epoch: [9]  [20/72]  eta: 0:00:12  loss: 2.6265 (2.6498)  Accuracy: 0.2500 (0.2872)  Top 5 accuracy: 0.6250 (0.6176)  lr: 0.000100  iter-time: 0.2138\n",
            "[08:11:37.320415] Epoch: [9]  [30/72]  eta: 0:00:09  loss: 2.6487 (2.6517)  Accuracy: 0.2812 (0.2843)  Top 5 accuracy: 0.6562 (0.6250)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:11:39.568049] Epoch: [9]  [40/72]  eta: 0:00:07  loss: 2.5537 (2.6292)  Accuracy: 0.2812 (0.2858)  Top 5 accuracy: 0.6875 (0.6341)  lr: 0.000100  iter-time: 0.2195\n",
            "[08:11:41.693141] Epoch: [9]  [50/72]  eta: 0:00:05  loss: 2.5347 (2.6328)  Accuracy: 0.3125 (0.2904)  Top 5 accuracy: 0.6562 (0.6360)  lr: 0.000100  iter-time: 0.2185\n",
            "[08:11:43.821116] Epoch: [9]  [60/72]  eta: 0:00:02  loss: 2.6349 (2.6315)  Accuracy: 0.3125 (0.2935)  Top 5 accuracy: 0.6562 (0.6373)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:11:45.946422] Epoch: [9]  [70/72]  eta: 0:00:00  loss: 2.5785 (2.6223)  Accuracy: 0.2812 (0.2918)  Top 5 accuracy: 0.6875 (0.6413)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:11:46.108864] Epoch: [9]  [71/72]  eta: 0:00:00  loss: 2.6191 (2.6237)  Accuracy: 0.2812 (0.2932)  Top 5 accuracy: 0.6562 (0.6408)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:11:46.211463] Epoch: [9] Total time: 0:00:16 (0.2246 s / it)\n",
            "[08:11:46.211962] [Train] averaged stats: loss: 2.6191 (2.6237)  Accuracy: 0.2812 (0.2932)  Top 5 accuracy: 0.6562 (0.6408)  lr: 0.000100\n",
            "[08:11:46.690799] Epoch: [9]  [0/8]  eta: 0:00:03  loss: 2.6778 (2.6778)  Accuracy: 0.3125 (0.3125)  Top 5 accuracy: 0.5312 (0.5312)  iter-time: 0.4762\n",
            "[08:11:47.236040] Epoch: [9]  [7/8]  eta: 0:00:00  loss: 2.7811 (2.8715)  Accuracy: 0.2500 (0.2470)  Top 5 accuracy: 0.5938 (0.6162)  iter-time: 0.1273\n",
            "[08:11:47.332171] Epoch: [9] Total time: 0:00:01 (0.1398 s / it)\n",
            "[08:11:47.332243] [Val] averaged stats: loss: 2.7811 (2.8715)  Accuracy: 0.2500 (0.2470)  Top 5 accuracy: 0.5938 (0.6162)\n",
            "[08:11:47.332862] [Val] best loss: 2.7779 best  Accuracy: 0.2707 Top 5 accuracy: 0.6001 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:11:47.334431] [Time] 17.3s 3.1m/29.6m\n",
            "\n",
            "[08:11:47.334463] ~~~ Epoch 10/100 ~~~\n",
            "\n",
            "[08:11:48.340201] Epoch: [10]  [ 0/72]  eta: 0:01:11  loss: 2.6489 (2.6489)  Accuracy: 0.2812 (0.2812)  Top 5 accuracy: 0.5312 (0.5312)  lr: 0.000100  iter-time: 0.9992\n",
            "[08:11:50.654470] Epoch: [10]  [10/72]  eta: 0:00:18  loss: 2.6489 (2.6534)  Accuracy: 0.2812 (0.2983)  Top 5 accuracy: 0.6250 (0.6392)  lr: 0.000100  iter-time: 0.3011\n",
            "[08:11:52.868790] Epoch: [10]  [20/72]  eta: 0:00:13  loss: 2.5761 (2.6175)  Accuracy: 0.3125 (0.2961)  Top 5 accuracy: 0.6250 (0.6518)  lr: 0.000100  iter-time: 0.2263\n",
            "[08:11:54.989680] Epoch: [10]  [30/72]  eta: 0:00:10  loss: 2.5184 (2.6088)  Accuracy: 0.3125 (0.2873)  Top 5 accuracy: 0.6562 (0.6573)  lr: 0.000100  iter-time: 0.2166\n",
            "[08:11:57.121410] Epoch: [10]  [40/72]  eta: 0:00:07  loss: 2.4801 (2.5713)  Accuracy: 0.3125 (0.2934)  Top 5 accuracy: 0.6875 (0.6646)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:11:59.249500] Epoch: [10]  [50/72]  eta: 0:00:05  loss: 2.4854 (2.5737)  Accuracy: 0.3125 (0.2990)  Top 5 accuracy: 0.6562 (0.6642)  lr: 0.000100  iter-time: 0.2129\n",
            "[08:12:01.371814] Epoch: [10]  [60/72]  eta: 0:00:02  loss: 2.5495 (2.5661)  Accuracy: 0.2812 (0.3007)  Top 5 accuracy: 0.6562 (0.6665)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:12:03.493170] Epoch: [10]  [70/72]  eta: 0:00:00  loss: 2.6060 (2.5826)  Accuracy: 0.2812 (0.3015)  Top 5 accuracy: 0.6250 (0.6576)  lr: 0.000100  iter-time: 0.2120\n",
            "[08:12:03.660795] Epoch: [10]  [71/72]  eta: 0:00:00  loss: 2.6170 (2.5842)  Accuracy: 0.2812 (0.3021)  Top 5 accuracy: 0.6250 (0.6581)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:12:03.812805] Epoch: [10] Total time: 0:00:16 (0.2288 s / it)\n",
            "[08:12:03.813207] [Train] averaged stats: loss: 2.6170 (2.5842)  Accuracy: 0.2812 (0.3021)  Top 5 accuracy: 0.6250 (0.6581)  lr: 0.000100\n",
            "[08:12:04.288016] Epoch: [10]  [0/8]  eta: 0:00:03  loss: 2.2465 (2.2465)  Accuracy: 0.3750 (0.3750)  Top 5 accuracy: 0.6250 (0.6250)  iter-time: 0.4717\n",
            "[08:12:04.887513] Epoch: [10]  [7/8]  eta: 0:00:00  loss: 2.6130 (2.7190)  Accuracy: 0.1875 (0.2549)  Top 5 accuracy: 0.6250 (0.6074)  iter-time: 0.1338\n",
            "[08:12:04.979720] Epoch: [10] Total time: 0:00:01 (0.1455 s / it)\n",
            "[08:12:04.979825] [Val] averaged stats: loss: 2.6130 (2.7190)  Accuracy: 0.1875 (0.2549)  Top 5 accuracy: 0.6250 (0.6074)\n",
            "[08:12:04.980297] Val loss improved from 2.77794548869133 to 2.7189579010009766, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:12:09.946217] [Val] best loss: 2.7190 best  Accuracy: 0.2549 Top 5 accuracy: 0.6074 \n",
            "[08:12:09.947889] Creating training plots . . .\n",
            "[08:12:10.249991] [Time] 22.9s 3.5m/38.2m\n",
            "\n",
            "[08:12:10.250088] ~~~ Epoch 11/100 ~~~\n",
            "\n",
            "[08:12:11.232456] Epoch: [11]  [ 0/72]  eta: 0:01:10  loss: 2.7755 (2.7755)  Accuracy: 0.2188 (0.2187)  Top 5 accuracy: 0.5312 (0.5312)  lr: 0.000100  iter-time: 0.9781\n",
            "[08:12:13.362610] Epoch: [11]  [10/72]  eta: 0:00:17  loss: 2.4221 (2.5050)  Accuracy: 0.3438 (0.3153)  Top 5 accuracy: 0.6875 (0.6790)  lr: 0.000100  iter-time: 0.2821\n",
            "[08:12:15.546143] Epoch: [11]  [20/72]  eta: 0:00:13  loss: 2.4221 (2.4407)  Accuracy: 0.3438 (0.3348)  Top 5 accuracy: 0.6875 (0.6964)  lr: 0.000100  iter-time: 0.2154\n",
            "[08:12:17.721712] Epoch: [11]  [30/72]  eta: 0:00:10  loss: 2.4688 (2.4560)  Accuracy: 0.3750 (0.3397)  Top 5 accuracy: 0.7188 (0.6845)  lr: 0.000100  iter-time: 0.2178\n",
            "[08:12:19.811720] Epoch: [11]  [40/72]  eta: 0:00:07  loss: 2.4475 (2.4656)  Accuracy: 0.3438 (0.3392)  Top 5 accuracy: 0.6562 (0.6723)  lr: 0.000100  iter-time: 0.2131\n",
            "[08:12:21.914027] Epoch: [11]  [50/72]  eta: 0:00:05  loss: 2.5389 (2.4896)  Accuracy: 0.3438 (0.3346)  Top 5 accuracy: 0.6562 (0.6691)  lr: 0.000100  iter-time: 0.2095\n",
            "[08:12:24.016786] Epoch: [11]  [60/72]  eta: 0:00:02  loss: 2.5758 (2.5094)  Accuracy: 0.3125 (0.3299)  Top 5 accuracy: 0.6875 (0.6624)  lr: 0.000100  iter-time: 0.2101\n",
            "[08:12:26.120793] Epoch: [11]  [70/72]  eta: 0:00:00  loss: 2.4967 (2.5093)  Accuracy: 0.3125 (0.3305)  Top 5 accuracy: 0.6562 (0.6629)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:12:26.285790] Epoch: [11]  [71/72]  eta: 0:00:00  loss: 2.5131 (2.5094)  Accuracy: 0.3125 (0.3296)  Top 5 accuracy: 0.6562 (0.6627)  lr: 0.000100  iter-time: 0.2078\n",
            "[08:12:26.382821] Epoch: [11] Total time: 0:00:16 (0.2240 s / it)\n",
            "[08:12:26.383203] [Train] averaged stats: loss: 2.5131 (2.5094)  Accuracy: 0.3125 (0.3296)  Top 5 accuracy: 0.6562 (0.6627)  lr: 0.000100\n",
            "[08:12:27.270216] Epoch: [11]  [0/8]  eta: 0:00:06  loss: 2.3096 (2.3096)  Accuracy: 0.3438 (0.3437)  Top 5 accuracy: 0.6875 (0.6875)  iter-time: 0.8736\n",
            "[08:12:27.792241] Epoch: [11]  [7/8]  eta: 0:00:00  loss: 2.4953 (2.5699)  Accuracy: 0.3125 (0.2976)  Top 5 accuracy: 0.5938 (0.6474)  iter-time: 0.1734\n",
            "[08:12:27.961834] Epoch: [11] Total time: 0:00:01 (0.1971 s / it)\n",
            "[08:12:27.961924] [Val] averaged stats: loss: 2.4953 (2.5699)  Accuracy: 0.3125 (0.2976)  Top 5 accuracy: 0.5938 (0.6474)\n",
            "[08:12:27.962513] Val loss improved from 2.7189579010009766 to 2.5698719024658203, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:12:33.117819] [Val] best loss: 2.5699 best  Accuracy: 0.2976 Top 5 accuracy: 0.6474 \n",
            "[08:12:33.119684] [Time] 22.9s 3.8m/38.1m\n",
            "\n",
            "[08:12:33.119758] ~~~ Epoch 12/100 ~~~\n",
            "\n",
            "[08:12:34.298008] Epoch: [12]  [ 0/72]  eta: 0:01:24  loss: 2.2290 (2.2290)  Accuracy: 0.3438 (0.3437)  Top 5 accuracy: 0.7188 (0.7187)  lr: 0.000100  iter-time: 1.1762\n",
            "[08:12:36.401906] Epoch: [12]  [10/72]  eta: 0:00:18  loss: 2.2290 (2.2300)  Accuracy: 0.3438 (0.3438)  Top 5 accuracy: 0.7812 (0.7727)  lr: 0.000100  iter-time: 0.2981\n",
            "[08:12:38.505100] Epoch: [12]  [20/72]  eta: 0:00:13  loss: 2.3311 (2.3226)  Accuracy: 0.3438 (0.3363)  Top 5 accuracy: 0.7500 (0.7455)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:12:40.689322] Epoch: [12]  [30/72]  eta: 0:00:10  loss: 2.4623 (2.4025)  Accuracy: 0.3125 (0.3246)  Top 5 accuracy: 0.6875 (0.7228)  lr: 0.000100  iter-time: 0.2143\n",
            "[08:12:42.887560] Epoch: [12]  [40/72]  eta: 0:00:07  loss: 2.5475 (2.4278)  Accuracy: 0.3125 (0.3216)  Top 5 accuracy: 0.6562 (0.7119)  lr: 0.000100  iter-time: 0.2190\n",
            "[08:12:45.000840] Epoch: [12]  [50/72]  eta: 0:00:05  loss: 2.3873 (2.4402)  Accuracy: 0.3438 (0.3235)  Top 5 accuracy: 0.6562 (0.7053)  lr: 0.000100  iter-time: 0.2155\n",
            "[08:12:47.125524] Epoch: [12]  [60/72]  eta: 0:00:02  loss: 2.3387 (2.4170)  Accuracy: 0.3438 (0.3320)  Top 5 accuracy: 0.6875 (0.7049)  lr: 0.000100  iter-time: 0.2118\n",
            "[08:12:49.253490] Epoch: [12]  [70/72]  eta: 0:00:00  loss: 2.3028 (2.4107)  Accuracy: 0.3750 (0.3310)  Top 5 accuracy: 0.6875 (0.7051)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:12:49.418383] Epoch: [12]  [71/72]  eta: 0:00:00  loss: 2.3296 (2.4196)  Accuracy: 0.3438 (0.3294)  Top 5 accuracy: 0.6875 (0.7038)  lr: 0.000100  iter-time: 0.2101\n",
            "[08:12:49.517282] Epoch: [12] Total time: 0:00:16 (0.2277 s / it)\n",
            "[08:12:49.517473] [Train] averaged stats: loss: 2.3296 (2.4196)  Accuracy: 0.3438 (0.3294)  Top 5 accuracy: 0.6875 (0.7038)  lr: 0.000100\n",
            "[08:12:50.114800] Epoch: [12]  [0/8]  eta: 0:00:04  loss: 2.3545 (2.3545)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.7188 (0.7187)  iter-time: 0.5932\n",
            "[08:12:50.585822] Epoch: [12]  [7/8]  eta: 0:00:00  loss: 2.3545 (2.5578)  Accuracy: 0.3125 (0.3565)  Top 5 accuracy: 0.6562 (0.6661)  iter-time: 0.1318\n",
            "[08:12:50.678080] Epoch: [12] Total time: 0:00:01 (0.1446 s / it)\n",
            "[08:12:50.678149] [Val] averaged stats: loss: 2.3545 (2.5578)  Accuracy: 0.3125 (0.3565)  Top 5 accuracy: 0.6562 (0.6661)\n",
            "[08:12:50.678601] Val loss improved from 2.5698719024658203 to 2.5578175485134125, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:12:55.663612] [Val] best loss: 2.5578 best  Accuracy: 0.3565 Top 5 accuracy: 0.6661 \n",
            "[08:12:55.665284] [Time] 22.5s 4.2m/37.7m\n",
            "\n",
            "[08:12:55.665336] ~~~ Epoch 13/100 ~~~\n",
            "\n",
            "[08:12:56.540580] Epoch: [13]  [ 0/72]  eta: 0:01:02  loss: 2.6478 (2.6478)  Accuracy: 0.3125 (0.3125)  Top 5 accuracy: 0.5938 (0.5937)  lr: 0.000100  iter-time: 0.8718\n",
            "[08:12:58.791341] Epoch: [13]  [10/72]  eta: 0:00:17  loss: 2.3245 (2.2812)  Accuracy: 0.3125 (0.3636)  Top 5 accuracy: 0.7188 (0.7159)  lr: 0.000100  iter-time: 0.2837\n",
            "[08:13:00.926260] Epoch: [13]  [20/72]  eta: 0:00:13  loss: 2.3972 (2.3986)  Accuracy: 0.3125 (0.3452)  Top 5 accuracy: 0.6875 (0.6711)  lr: 0.000100  iter-time: 0.2191\n",
            "[08:13:03.145136] Epoch: [13]  [30/72]  eta: 0:00:10  loss: 2.3200 (2.3562)  Accuracy: 0.3125 (0.3448)  Top 5 accuracy: 0.6875 (0.6885)  lr: 0.000100  iter-time: 0.2176\n",
            "[08:13:05.805710] Epoch: [13]  [40/72]  eta: 0:00:07  loss: 2.2861 (2.3626)  Accuracy: 0.3438 (0.3430)  Top 5 accuracy: 0.7188 (0.6898)  lr: 0.000100  iter-time: 0.2439\n",
            "[08:13:08.252653] Epoch: [13]  [50/72]  eta: 0:00:05  loss: 2.2818 (2.3426)  Accuracy: 0.3438 (0.3480)  Top 5 accuracy: 0.7188 (0.6985)  lr: 0.000100  iter-time: 0.2545\n",
            "[08:13:10.528827] Epoch: [13]  [60/72]  eta: 0:00:02  loss: 2.2501 (2.3350)  Accuracy: 0.3750 (0.3535)  Top 5 accuracy: 0.7500 (0.6998)  lr: 0.000100  iter-time: 0.2353\n",
            "[08:13:12.739156] Epoch: [13]  [70/72]  eta: 0:00:00  loss: 2.2542 (2.3493)  Accuracy: 0.3125 (0.3499)  Top 5 accuracy: 0.7500 (0.6998)  lr: 0.000100  iter-time: 0.2242\n",
            "[08:13:12.901364] Epoch: [13]  [71/72]  eta: 0:00:00  loss: 2.2542 (2.3489)  Accuracy: 0.3125 (0.3493)  Top 5 accuracy: 0.7500 (0.7016)  lr: 0.000100  iter-time: 0.2203\n",
            "[08:13:13.001456] Epoch: [13] Total time: 0:00:17 (0.2408 s / it)\n",
            "[08:13:13.001804] [Train] averaged stats: loss: 2.2542 (2.3489)  Accuracy: 0.3125 (0.3493)  Top 5 accuracy: 0.7500 (0.7016)  lr: 0.000100\n",
            "[08:13:13.629563] Epoch: [13]  [0/8]  eta: 0:00:05  loss: 2.4989 (2.4989)  Accuracy: 0.3750 (0.3750)  Top 5 accuracy: 0.6250 (0.6250)  iter-time: 0.6253\n",
            "[08:13:14.102445] Epoch: [13]  [7/8]  eta: 0:00:00  loss: 2.5547 (2.6395)  Accuracy: 0.2581 (0.2549)  Top 5 accuracy: 0.6562 (0.6667)  iter-time: 0.1372\n",
            "[08:13:14.245898] Epoch: [13] Total time: 0:00:01 (0.1553 s / it)\n",
            "[08:13:14.245980] [Val] averaged stats: loss: 2.5547 (2.6395)  Accuracy: 0.2581 (0.2549)  Top 5 accuracy: 0.6562 (0.6667)\n",
            "[08:13:14.246569] [Val] best loss: 2.5578 best  Accuracy: 0.3565 Top 5 accuracy: 0.6661 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:13:14.248099] [Time] 18.6s 4.5m/31.8m\n",
            "\n",
            "[08:13:14.248133] ~~~ Epoch 14/100 ~~~\n",
            "\n",
            "[08:13:15.293630] Epoch: [14]  [ 0/72]  eta: 0:01:15  loss: 2.0437 (2.0437)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7812 (0.7812)  lr: 0.000100  iter-time: 1.0426\n",
            "[08:13:17.841281] Epoch: [14]  [10/72]  eta: 0:00:20  loss: 2.2000 (2.1785)  Accuracy: 0.3750 (0.4062)  Top 5 accuracy: 0.7500 (0.7557)  lr: 0.000100  iter-time: 0.3251\n",
            "[08:13:20.195174] Epoch: [14]  [20/72]  eta: 0:00:14  loss: 2.2018 (2.2341)  Accuracy: 0.3750 (0.3824)  Top 5 accuracy: 0.7188 (0.7366)  lr: 0.000100  iter-time: 0.2443\n",
            "[08:13:22.420949] Epoch: [14]  [30/72]  eta: 0:00:11  loss: 2.3395 (2.3115)  Accuracy: 0.3438 (0.3679)  Top 5 accuracy: 0.6875 (0.7218)  lr: 0.000100  iter-time: 0.2289\n",
            "[08:13:24.634101] Epoch: [14]  [40/72]  eta: 0:00:08  loss: 2.3395 (2.3079)  Accuracy: 0.3438 (0.3681)  Top 5 accuracy: 0.7188 (0.7210)  lr: 0.000100  iter-time: 0.2217\n",
            "[08:13:26.799174] Epoch: [14]  [50/72]  eta: 0:00:05  loss: 2.2274 (2.2825)  Accuracy: 0.3750 (0.3781)  Top 5 accuracy: 0.7500 (0.7255)  lr: 0.000100  iter-time: 0.2187\n",
            "[08:13:28.948017] Epoch: [14]  [60/72]  eta: 0:00:02  loss: 2.2413 (2.2870)  Accuracy: 0.3750 (0.3714)  Top 5 accuracy: 0.7188 (0.7234)  lr: 0.000100  iter-time: 0.2156\n",
            "[08:13:31.059237] Epoch: [14]  [70/72]  eta: 0:00:00  loss: 2.3430 (2.2876)  Accuracy: 0.3438 (0.3671)  Top 5 accuracy: 0.7188 (0.7245)  lr: 0.000100  iter-time: 0.2129\n",
            "[08:13:31.222846] Epoch: [14]  [71/72]  eta: 0:00:00  loss: 2.3430 (2.2862)  Accuracy: 0.3438 (0.3668)  Top 5 accuracy: 0.7188 (0.7247)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:13:31.377777] Epoch: [14] Total time: 0:00:17 (0.2379 s / it)\n",
            "[08:13:31.377999] [Train] averaged stats: loss: 2.3430 (2.2862)  Accuracy: 0.3438 (0.3668)  Top 5 accuracy: 0.7188 (0.7247)  lr: 0.000100\n",
            "[08:13:32.091969] Epoch: [14]  [0/8]  eta: 0:00:05  loss: 1.8506 (1.8506)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.7056\n",
            "[08:13:32.540571] Epoch: [14]  [7/8]  eta: 0:00:00  loss: 2.5984 (2.5663)  Accuracy: 0.2500 (0.3017)  Top 5 accuracy: 0.5938 (0.6429)  iter-time: 0.1440\n",
            "[08:13:32.633176] Epoch: [14] Total time: 0:00:01 (0.1565 s / it)\n",
            "[08:13:32.633251] [Val] averaged stats: loss: 2.5984 (2.5663)  Accuracy: 0.2500 (0.3017)  Top 5 accuracy: 0.5938 (0.6429)\n",
            "[08:13:32.633782] [Val] best loss: 2.5578 best  Accuracy: 0.3565 Top 5 accuracy: 0.6661 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:13:32.635016] [Time] 18.4s 4.8m/31.5m\n",
            "\n",
            "[08:13:32.635047] ~~~ Epoch 15/100 ~~~\n",
            "\n",
            "[08:13:33.634131] Epoch: [15]  [ 0/72]  eta: 0:01:11  loss: 2.0617 (2.0617)  Accuracy: 0.4062 (0.4062)  Top 5 accuracy: 0.7812 (0.7812)  lr: 0.000100  iter-time: 0.9964\n",
            "[08:13:35.758331] Epoch: [15]  [10/72]  eta: 0:00:17  loss: 2.0617 (2.0505)  Accuracy: 0.3750 (0.3920)  Top 5 accuracy: 0.7812 (0.7841)  lr: 0.000100  iter-time: 0.2836\n",
            "[08:13:37.854516] Epoch: [15]  [20/72]  eta: 0:00:12  loss: 2.0677 (2.1037)  Accuracy: 0.3750 (0.3958)  Top 5 accuracy: 0.7812 (0.7812)  lr: 0.000100  iter-time: 0.2109\n",
            "[08:13:39.958159] Epoch: [15]  [30/72]  eta: 0:00:09  loss: 2.2156 (2.1452)  Accuracy: 0.3750 (0.3901)  Top 5 accuracy: 0.7188 (0.7591)  lr: 0.000100  iter-time: 0.2099\n",
            "[08:13:42.046462] Epoch: [15]  [40/72]  eta: 0:00:07  loss: 2.2113 (2.1515)  Accuracy: 0.4375 (0.4009)  Top 5 accuracy: 0.7188 (0.7546)  lr: 0.000100  iter-time: 0.2094\n",
            "[08:13:44.241774] Epoch: [15]  [50/72]  eta: 0:00:05  loss: 2.1921 (2.1670)  Accuracy: 0.4375 (0.3977)  Top 5 accuracy: 0.7188 (0.7488)  lr: 0.000100  iter-time: 0.2137\n",
            "[08:13:46.385789] Epoch: [15]  [60/72]  eta: 0:00:02  loss: 2.3257 (2.2152)  Accuracy: 0.3438 (0.3837)  Top 5 accuracy: 0.7188 (0.7387)  lr: 0.000100  iter-time: 0.2166\n",
            "[08:13:48.470109] Epoch: [15]  [70/72]  eta: 0:00:00  loss: 2.4495 (2.2360)  Accuracy: 0.3438 (0.3816)  Top 5 accuracy: 0.6875 (0.7342)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:13:48.630371] Epoch: [15]  [71/72]  eta: 0:00:00  loss: 2.3966 (2.2363)  Accuracy: 0.3438 (0.3829)  Top 5 accuracy: 0.6875 (0.7342)  lr: 0.000100  iter-time: 0.2074\n",
            "[08:13:48.727977] Epoch: [15] Total time: 0:00:16 (0.2235 s / it)\n",
            "[08:13:48.728331] [Train] averaged stats: loss: 2.3966 (2.2363)  Accuracy: 0.3438 (0.3829)  Top 5 accuracy: 0.6875 (0.7342)  lr: 0.000100\n",
            "[08:13:49.328615] Epoch: [15]  [0/8]  eta: 0:00:04  loss: 2.1569 (2.1569)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.5979\n",
            "[08:13:49.778099] Epoch: [15]  [7/8]  eta: 0:00:00  loss: 2.4207 (2.6011)  Accuracy: 0.2500 (0.3093)  Top 5 accuracy: 0.6250 (0.6351)  iter-time: 0.1308\n",
            "[08:13:49.870721] Epoch: [15] Total time: 0:00:01 (0.1426 s / it)\n",
            "[08:13:49.870862] [Val] averaged stats: loss: 2.4207 (2.6011)  Accuracy: 0.2500 (0.3093)  Top 5 accuracy: 0.6250 (0.6351)\n",
            "[08:13:49.871492] [Val] best loss: 2.5578 best  Accuracy: 0.3565 Top 5 accuracy: 0.6661 \n",
            "[08:13:49.872776] Creating training plots . . .\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:13:50.200283] [Time] 17.6s 5.1m/30.3m\n",
            "\n",
            "[08:13:50.200319] ~~~ Epoch 16/100 ~~~\n",
            "\n",
            "[08:13:51.272205] Epoch: [16]  [ 0/72]  eta: 0:01:16  loss: 2.3087 (2.3087)  Accuracy: 0.2812 (0.2812)  Top 5 accuracy: 0.7500 (0.7500)  lr: 0.000100  iter-time: 1.0663\n",
            "[08:13:53.394596] Epoch: [16]  [10/72]  eta: 0:00:17  loss: 2.0736 (2.0882)  Accuracy: 0.3750 (0.4034)  Top 5 accuracy: 0.7500 (0.7585)  lr: 0.000100  iter-time: 0.2897\n",
            "[08:13:55.510357] Epoch: [16]  [20/72]  eta: 0:00:13  loss: 2.0736 (2.1392)  Accuracy: 0.3750 (0.3899)  Top 5 accuracy: 0.7500 (0.7470)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:13:57.703996] Epoch: [16]  [30/72]  eta: 0:00:10  loss: 2.1207 (2.1504)  Accuracy: 0.3438 (0.3861)  Top 5 accuracy: 0.7188 (0.7419)  lr: 0.000100  iter-time: 0.2147\n",
            "[08:13:59.817766] Epoch: [16]  [40/72]  eta: 0:00:07  loss: 2.1170 (2.1414)  Accuracy: 0.3438 (0.3857)  Top 5 accuracy: 0.7188 (0.7462)  lr: 0.000100  iter-time: 0.2150\n",
            "[08:14:01.942206] Epoch: [16]  [50/72]  eta: 0:00:05  loss: 2.1497 (2.1558)  Accuracy: 0.3438 (0.3848)  Top 5 accuracy: 0.7500 (0.7426)  lr: 0.000100  iter-time: 0.2117\n",
            "[08:14:04.046853] Epoch: [16]  [60/72]  eta: 0:00:02  loss: 2.1497 (2.1603)  Accuracy: 0.3750 (0.3858)  Top 5 accuracy: 0.7500 (0.7423)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:14:06.139251] Epoch: [16]  [70/72]  eta: 0:00:00  loss: 2.1122 (2.1669)  Accuracy: 0.4062 (0.3891)  Top 5 accuracy: 0.7500 (0.7443)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:14:06.302699] Epoch: [16]  [71/72]  eta: 0:00:00  loss: 2.1912 (2.1775)  Accuracy: 0.4062 (0.3867)  Top 5 accuracy: 0.7500 (0.7412)  lr: 0.000100  iter-time: 0.2071\n",
            "[08:14:06.431509] Epoch: [16] Total time: 0:00:16 (0.2254 s / it)\n",
            "[08:14:06.431941] [Train] averaged stats: loss: 2.1912 (2.1775)  Accuracy: 0.4062 (0.3867)  Top 5 accuracy: 0.7500 (0.7412)  lr: 0.000100\n",
            "[08:14:06.996062] Epoch: [16]  [0/8]  eta: 0:00:04  loss: 1.6064 (1.6064)  Accuracy: 0.5938 (0.5937)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.5615\n",
            "[08:14:07.462279] Epoch: [16]  [7/8]  eta: 0:00:00  loss: 2.4496 (2.4562)  Accuracy: 0.3125 (0.3524)  Top 5 accuracy: 0.6562 (0.6743)  iter-time: 0.1274\n",
            "[08:14:07.554233] Epoch: [16] Total time: 0:00:01 (0.1400 s / it)\n",
            "[08:14:07.554305] [Val] averaged stats: loss: 2.4496 (2.4562)  Accuracy: 0.3125 (0.3524)  Top 5 accuracy: 0.6562 (0.6743)\n",
            "[08:14:07.554849] Val loss improved from 2.5578175485134125 to 2.456211417913437, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:14:11.359479] [Val] best loss: 2.4562 best  Accuracy: 0.3524 Top 5 accuracy: 0.6743 \n",
            "[08:14:11.361722] [Time] 21.2s 5.5m/35.5m\n",
            "\n",
            "[08:14:11.361817] ~~~ Epoch 17/100 ~~~\n",
            "\n",
            "[08:14:12.309687] Epoch: [17]  [ 0/72]  eta: 0:01:07  loss: 2.3546 (2.3546)  Accuracy: 0.2500 (0.2500)  Top 5 accuracy: 0.7500 (0.7500)  lr: 0.000100  iter-time: 0.9402\n",
            "[08:14:14.462198] Epoch: [17]  [10/72]  eta: 0:00:17  loss: 1.9447 (2.0079)  Accuracy: 0.4062 (0.4062)  Top 5 accuracy: 0.8125 (0.8011)  lr: 0.000100  iter-time: 0.2810\n",
            "[08:14:16.544614] Epoch: [17]  [20/72]  eta: 0:00:12  loss: 2.0291 (2.0371)  Accuracy: 0.4062 (0.4182)  Top 5 accuracy: 0.8125 (0.7902)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:14:18.630021] Epoch: [17]  [30/72]  eta: 0:00:09  loss: 2.0740 (2.0725)  Accuracy: 0.4062 (0.4113)  Top 5 accuracy: 0.7500 (0.7732)  lr: 0.000100  iter-time: 0.2083\n",
            "[08:14:20.736096] Epoch: [17]  [40/72]  eta: 0:00:07  loss: 2.0629 (2.0697)  Accuracy: 0.4062 (0.4146)  Top 5 accuracy: 0.7500 (0.7698)  lr: 0.000100  iter-time: 0.2095\n",
            "[08:14:22.981228] Epoch: [17]  [50/72]  eta: 0:00:05  loss: 2.0525 (2.0801)  Accuracy: 0.4375 (0.4179)  Top 5 accuracy: 0.7500 (0.7659)  lr: 0.000100  iter-time: 0.2169\n",
            "[08:14:25.104098] Epoch: [17]  [60/72]  eta: 0:00:02  loss: 2.0609 (2.0787)  Accuracy: 0.4375 (0.4216)  Top 5 accuracy: 0.7500 (0.7649)  lr: 0.000100  iter-time: 0.2178\n",
            "[08:14:27.227823] Epoch: [17]  [70/72]  eta: 0:00:00  loss: 2.0116 (2.0678)  Accuracy: 0.4062 (0.4177)  Top 5 accuracy: 0.7812 (0.7702)  lr: 0.000100  iter-time: 0.2122\n",
            "[08:14:27.389985] Epoch: [17]  [71/72]  eta: 0:00:00  loss: 2.0808 (2.0684)  Accuracy: 0.4062 (0.4179)  Top 5 accuracy: 0.7812 (0.7692)  lr: 0.000100  iter-time: 0.2099\n",
            "[08:14:27.501841] Epoch: [17] Total time: 0:00:16 (0.2241 s / it)\n",
            "[08:14:27.502201] [Train] averaged stats: loss: 2.0808 (2.0684)  Accuracy: 0.4062 (0.4179)  Top 5 accuracy: 0.7812 (0.7692)  lr: 0.000100\n",
            "[08:14:28.009179] Epoch: [17]  [0/8]  eta: 0:00:04  loss: 1.8800 (1.8800)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.5012\n",
            "[08:14:28.522060] Epoch: [17]  [7/8]  eta: 0:00:00  loss: 2.3348 (2.4232)  Accuracy: 0.2812 (0.3485)  Top 5 accuracy: 0.7188 (0.7251)  iter-time: 0.1267\n",
            "[08:14:28.618236] Epoch: [17] Total time: 0:00:01 (0.1392 s / it)\n",
            "[08:14:28.618309] [Val] averaged stats: loss: 2.3348 (2.4232)  Accuracy: 0.2812 (0.3485)  Top 5 accuracy: 0.7188 (0.7251)\n",
            "[08:14:28.618860] Val loss improved from 2.456211417913437 to 2.4231842160224915, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:14:33.594651] [Val] best loss: 2.4232 best  Accuracy: 0.3485 Top 5 accuracy: 0.7251 \n",
            "[08:14:33.601512] [Time] 22.2s 5.8m/37.0m\n",
            "\n",
            "[08:14:33.601590] ~~~ Epoch 18/100 ~~~\n",
            "\n",
            "[08:14:35.077207] Epoch: [18]  [ 0/72]  eta: 0:01:46  loss: 2.0013 (2.0013)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.7500 (0.7500)  lr: 0.000100  iter-time: 1.4727\n",
            "[08:14:37.267794] Epoch: [18]  [10/72]  eta: 0:00:20  loss: 2.0093 (1.9908)  Accuracy: 0.4688 (0.4432)  Top 5 accuracy: 0.8125 (0.7983)  lr: 0.000100  iter-time: 0.3324\n",
            "[08:14:39.387261] Epoch: [18]  [20/72]  eta: 0:00:14  loss: 2.0842 (2.0283)  Accuracy: 0.4062 (0.4211)  Top 5 accuracy: 0.7812 (0.7812)  lr: 0.000100  iter-time: 0.2151\n",
            "[08:14:41.514517] Epoch: [18]  [30/72]  eta: 0:00:10  loss: 2.1043 (2.0713)  Accuracy: 0.3438 (0.4083)  Top 5 accuracy: 0.7500 (0.7772)  lr: 0.000100  iter-time: 0.2122\n",
            "[08:14:43.639184] Epoch: [18]  [40/72]  eta: 0:00:07  loss: 2.0614 (2.0708)  Accuracy: 0.4375 (0.4177)  Top 5 accuracy: 0.7812 (0.7729)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:14:45.781310] Epoch: [18]  [50/72]  eta: 0:00:05  loss: 2.0428 (2.0834)  Accuracy: 0.4062 (0.4167)  Top 5 accuracy: 0.7812 (0.7751)  lr: 0.000100  iter-time: 0.2129\n",
            "[08:14:48.018993] Epoch: [18]  [60/72]  eta: 0:00:02  loss: 2.1285 (2.1026)  Accuracy: 0.4062 (0.4124)  Top 5 accuracy: 0.7500 (0.7679)  lr: 0.000100  iter-time: 0.2186\n",
            "[08:14:50.180509] Epoch: [18]  [70/72]  eta: 0:00:00  loss: 2.1241 (2.0840)  Accuracy: 0.4375 (0.4151)  Top 5 accuracy: 0.7500 (0.7724)  lr: 0.000100  iter-time: 0.2198\n",
            "[08:14:50.345470] Epoch: [18]  [71/72]  eta: 0:00:00  loss: 2.1285 (2.0852)  Accuracy: 0.4375 (0.4153)  Top 5 accuracy: 0.7500 (0.7714)  lr: 0.000100  iter-time: 0.2175\n",
            "[08:14:50.442557] Epoch: [18] Total time: 0:00:16 (0.2339 s / it)\n",
            "[08:14:50.442728] [Train] averaged stats: loss: 2.1285 (2.0852)  Accuracy: 0.4375 (0.4153)  Top 5 accuracy: 0.7500 (0.7714)  lr: 0.000100\n",
            "[08:14:51.019852] Epoch: [18]  [0/8]  eta: 0:00:04  loss: 1.5036 (1.5036)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.5745\n",
            "[08:14:51.477790] Epoch: [18]  [7/8]  eta: 0:00:00  loss: 2.3825 (2.3826)  Accuracy: 0.2812 (0.3603)  Top 5 accuracy: 0.6562 (0.6942)  iter-time: 0.1289\n",
            "[08:14:51.589615] Epoch: [18] Total time: 0:00:01 (0.1431 s / it)\n",
            "[08:14:51.589691] [Val] averaged stats: loss: 2.3825 (2.3826)  Accuracy: 0.2812 (0.3603)  Top 5 accuracy: 0.6562 (0.6942)\n",
            "[08:14:51.590444] Val loss improved from 2.4231842160224915 to 2.382619470357895, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:14:56.546208] [Val] best loss: 2.3826 best  Accuracy: 0.3603 Top 5 accuracy: 0.6942 \n",
            "[08:14:56.547981] [Time] 22.9s 6.2m/38.0m\n",
            "\n",
            "[08:14:56.548065] ~~~ Epoch 19/100 ~~~\n",
            "\n",
            "[08:14:57.628982] Epoch: [19]  [ 0/72]  eta: 0:01:17  loss: 1.5549 (1.5549)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 1.0740\n",
            "[08:14:59.884420] Epoch: [19]  [10/72]  eta: 0:00:18  loss: 2.0366 (2.0146)  Accuracy: 0.4688 (0.4602)  Top 5 accuracy: 0.8125 (0.7926)  lr: 0.000100  iter-time: 0.3025\n",
            "[08:15:02.114152] Epoch: [19]  [20/72]  eta: 0:00:13  loss: 2.0366 (2.0078)  Accuracy: 0.4375 (0.4494)  Top 5 accuracy: 0.7812 (0.7857)  lr: 0.000100  iter-time: 0.2241\n",
            "[08:15:04.223194] Epoch: [19]  [30/72]  eta: 0:00:10  loss: 1.9924 (2.0130)  Accuracy: 0.4375 (0.4395)  Top 5 accuracy: 0.7500 (0.7823)  lr: 0.000100  iter-time: 0.2168\n",
            "[08:15:06.325524] Epoch: [19]  [40/72]  eta: 0:00:07  loss: 1.9822 (1.9863)  Accuracy: 0.4375 (0.4428)  Top 5 accuracy: 0.7812 (0.7851)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:15:08.442318] Epoch: [19]  [50/72]  eta: 0:00:05  loss: 1.9911 (2.0138)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.7812 (0.7819)  lr: 0.000100  iter-time: 0.2108\n",
            "[08:15:10.559298] Epoch: [19]  [60/72]  eta: 0:00:02  loss: 2.1732 (2.0264)  Accuracy: 0.4062 (0.4278)  Top 5 accuracy: 0.7500 (0.7792)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:15:12.685116] Epoch: [19]  [70/72]  eta: 0:00:00  loss: 2.1233 (2.0282)  Accuracy: 0.3750 (0.4269)  Top 5 accuracy: 0.7500 (0.7786)  lr: 0.000100  iter-time: 0.2120\n",
            "[08:15:12.848642] Epoch: [19]  [71/72]  eta: 0:00:00  loss: 2.1282 (2.0322)  Accuracy: 0.4062 (0.4270)  Top 5 accuracy: 0.7500 (0.7775)  lr: 0.000100  iter-time: 0.2095\n",
            "[08:15:12.989512] Epoch: [19] Total time: 0:00:16 (0.2283 s / it)\n",
            "[08:15:12.989738] [Train] averaged stats: loss: 2.1282 (2.0322)  Accuracy: 0.4062 (0.4270)  Top 5 accuracy: 0.7500 (0.7775)  lr: 0.000100\n",
            "[08:15:13.715736] Epoch: [19]  [0/8]  eta: 0:00:05  loss: 1.9017 (1.9017)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.7226\n",
            "[08:15:14.169922] Epoch: [19]  [7/8]  eta: 0:00:00  loss: 2.1841 (2.4254)  Accuracy: 0.3438 (0.3574)  Top 5 accuracy: 0.6875 (0.7141)  iter-time: 0.1470\n",
            "[08:15:14.262530] Epoch: [19] Total time: 0:00:01 (0.1587 s / it)\n",
            "[08:15:14.262599] [Val] averaged stats: loss: 2.1841 (2.4254)  Accuracy: 0.3438 (0.3574)  Top 5 accuracy: 0.6875 (0.7141)\n",
            "[08:15:14.263076] [Val] best loss: 2.3826 best  Accuracy: 0.3603 Top 5 accuracy: 0.6942 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:15:14.264361] [Time] 17.7s 6.5m/30.7m\n",
            "\n",
            "[08:15:14.264393] ~~~ Epoch 20/100 ~~~\n",
            "\n",
            "[08:15:15.144177] Epoch: [20]  [ 0/72]  eta: 0:01:02  loss: 1.8920 (1.8920)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 0.8708\n",
            "[08:15:17.289699] Epoch: [20]  [10/72]  eta: 0:00:16  loss: 1.8920 (1.9153)  Accuracy: 0.4688 (0.4943)  Top 5 accuracy: 0.8125 (0.7926)  lr: 0.000100  iter-time: 0.2738\n",
            "[08:15:19.393858] Epoch: [20]  [20/72]  eta: 0:00:12  loss: 1.8955 (1.9484)  Accuracy: 0.4688 (0.4643)  Top 5 accuracy: 0.8125 (0.8036)  lr: 0.000100  iter-time: 0.2122\n",
            "[08:15:21.497870] Epoch: [20]  [30/72]  eta: 0:00:09  loss: 1.8959 (1.9330)  Accuracy: 0.4688 (0.4667)  Top 5 accuracy: 0.7812 (0.8044)  lr: 0.000100  iter-time: 0.2103\n",
            "[08:15:23.612230] Epoch: [20]  [40/72]  eta: 0:00:07  loss: 1.9238 (1.9524)  Accuracy: 0.4375 (0.4581)  Top 5 accuracy: 0.7812 (0.7973)  lr: 0.000100  iter-time: 0.2108\n",
            "[08:15:25.867698] Epoch: [20]  [50/72]  eta: 0:00:04  loss: 2.0139 (1.9404)  Accuracy: 0.4375 (0.4571)  Top 5 accuracy: 0.7812 (0.7978)  lr: 0.000100  iter-time: 0.2183\n",
            "[08:15:28.021726] Epoch: [20]  [60/72]  eta: 0:00:02  loss: 1.9580 (1.9554)  Accuracy: 0.4375 (0.4554)  Top 5 accuracy: 0.7812 (0.7935)  lr: 0.000100  iter-time: 0.2203\n",
            "[08:15:30.119295] Epoch: [20]  [70/72]  eta: 0:00:00  loss: 2.0595 (1.9665)  Accuracy: 0.3750 (0.4503)  Top 5 accuracy: 0.7812 (0.7927)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:15:30.282380] Epoch: [20]  [71/72]  eta: 0:00:00  loss: 2.0763 (1.9820)  Accuracy: 0.3750 (0.4464)  Top 5 accuracy: 0.7812 (0.7907)  lr: 0.000100  iter-time: 0.2087\n",
            "[08:15:30.381350] Epoch: [20] Total time: 0:00:16 (0.2238 s / it)\n",
            "[08:15:30.381693] [Train] averaged stats: loss: 2.0763 (1.9820)  Accuracy: 0.3750 (0.4464)  Top 5 accuracy: 0.7812 (0.7907)  lr: 0.000100\n",
            "[08:15:30.819384] Epoch: [20]  [0/8]  eta: 0:00:03  loss: 1.8073 (1.8073)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.4347\n",
            "[08:15:31.423856] Epoch: [20]  [7/8]  eta: 0:00:00  loss: 2.4327 (2.3927)  Accuracy: 0.3548 (0.3608)  Top 5 accuracy: 0.7188 (0.7099)  iter-time: 0.1294\n",
            "[08:15:31.529980] Epoch: [20] Total time: 0:00:01 (0.1432 s / it)\n",
            "[08:15:31.530053] [Val] averaged stats: loss: 2.4327 (2.3927)  Accuracy: 0.3548 (0.3608)  Top 5 accuracy: 0.7188 (0.7099)\n",
            "[08:15:31.530509] [Val] best loss: 2.3826 best  Accuracy: 0.3603 Top 5 accuracy: 0.6942 \n",
            "[08:15:31.531756] Creating training plots . . .\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:15:31.869387] [Time] 17.6s 6.8m/30.6m\n",
            "\n",
            "[08:15:31.869425] ~~~ Epoch 21/100 ~~~\n",
            "\n",
            "[08:15:33.050524] Epoch: [21]  [ 0/72]  eta: 0:01:24  loss: 1.7379 (1.7379)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 1.1786\n",
            "[08:15:35.182701] Epoch: [21]  [10/72]  eta: 0:00:18  loss: 1.7386 (1.8239)  Accuracy: 0.4688 (0.4886)  Top 5 accuracy: 0.8438 (0.8239)  lr: 0.000100  iter-time: 0.3008\n",
            "[08:15:37.302204] Epoch: [21]  [20/72]  eta: 0:00:13  loss: 1.8478 (1.8735)  Accuracy: 0.4688 (0.4643)  Top 5 accuracy: 0.7812 (0.8140)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:15:39.520238] Epoch: [21]  [30/72]  eta: 0:00:10  loss: 1.7601 (1.8398)  Accuracy: 0.4688 (0.4758)  Top 5 accuracy: 0.7812 (0.8155)  lr: 0.000100  iter-time: 0.2167\n",
            "[08:15:41.611222] Epoch: [21]  [40/72]  eta: 0:00:07  loss: 1.7580 (1.8336)  Accuracy: 0.5000 (0.4748)  Top 5 accuracy: 0.8125 (0.8148)  lr: 0.000100  iter-time: 0.2153\n",
            "[08:15:43.700551] Epoch: [21]  [50/72]  eta: 0:00:05  loss: 1.8617 (1.8726)  Accuracy: 0.4062 (0.4620)  Top 5 accuracy: 0.8125 (0.8088)  lr: 0.000100  iter-time: 0.2089\n",
            "[08:15:45.796229] Epoch: [21]  [60/72]  eta: 0:00:02  loss: 1.9753 (1.8962)  Accuracy: 0.4062 (0.4529)  Top 5 accuracy: 0.8125 (0.8074)  lr: 0.000100  iter-time: 0.2091\n",
            "[08:15:47.885413] Epoch: [21]  [70/72]  eta: 0:00:00  loss: 1.9965 (1.9128)  Accuracy: 0.4375 (0.4525)  Top 5 accuracy: 0.7812 (0.7997)  lr: 0.000100  iter-time: 0.2091\n",
            "[08:15:48.050029] Epoch: [21]  [71/72]  eta: 0:00:00  loss: 1.9965 (1.9171)  Accuracy: 0.4375 (0.4528)  Top 5 accuracy: 0.7812 (0.7983)  lr: 0.000100  iter-time: 0.2068\n",
            "[08:15:48.149054] Epoch: [21] Total time: 0:00:16 (0.2261 s / it)\n",
            "[08:15:48.149403] [Train] averaged stats: loss: 1.9965 (1.9171)  Accuracy: 0.4375 (0.4528)  Top 5 accuracy: 0.7812 (0.7983)  lr: 0.000100\n",
            "[08:15:48.729899] Epoch: [21]  [0/8]  eta: 0:00:04  loss: 1.9845 (1.9845)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.6875 (0.6875)  iter-time: 0.5777\n",
            "[08:15:49.191821] Epoch: [21]  [7/8]  eta: 0:00:00  loss: 2.1993 (2.2924)  Accuracy: 0.2903 (0.3488)  Top 5 accuracy: 0.7188 (0.7491)  iter-time: 0.1299\n",
            "[08:15:49.346827] Epoch: [21] Total time: 0:00:01 (0.1494 s / it)\n",
            "[08:15:49.346928] [Val] averaged stats: loss: 2.1993 (2.2924)  Accuracy: 0.2903 (0.3488)  Top 5 accuracy: 0.7188 (0.7491)\n",
            "[08:15:49.349166] Val loss improved from 2.382619470357895 to 2.2923712879419327, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:15:56.687051] [Val] best loss: 2.2924 best  Accuracy: 0.3488 Top 5 accuracy: 0.7491 \n",
            "[08:15:56.688567] [Time] 24.8s 7.2m/40.3m\n",
            "\n",
            "[08:15:56.688696] ~~~ Epoch 22/100 ~~~\n",
            "\n",
            "[08:15:57.742244] Epoch: [22]  [ 0/72]  eta: 0:01:15  loss: 1.4738 (1.4738)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 1.0465\n",
            "[08:15:59.855811] Epoch: [22]  [10/72]  eta: 0:00:17  loss: 1.8655 (1.8002)  Accuracy: 0.5312 (0.5057)  Top 5 accuracy: 0.7500 (0.8040)  lr: 0.000100  iter-time: 0.2872\n",
            "[08:16:01.976530] Epoch: [22]  [20/72]  eta: 0:00:13  loss: 1.8286 (1.7900)  Accuracy: 0.5000 (0.5030)  Top 5 accuracy: 0.7812 (0.8125)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:16:04.237857] Epoch: [22]  [30/72]  eta: 0:00:10  loss: 1.6868 (1.7764)  Accuracy: 0.5000 (0.5010)  Top 5 accuracy: 0.8438 (0.8236)  lr: 0.000100  iter-time: 0.2190\n",
            "[08:16:06.355587] Epoch: [22]  [40/72]  eta: 0:00:07  loss: 1.7577 (1.8122)  Accuracy: 0.4688 (0.4863)  Top 5 accuracy: 0.8438 (0.8186)  lr: 0.000100  iter-time: 0.2184\n",
            "[08:16:08.458260] Epoch: [22]  [50/72]  eta: 0:00:05  loss: 1.9518 (1.8612)  Accuracy: 0.4375 (0.4700)  Top 5 accuracy: 0.8125 (0.8156)  lr: 0.000100  iter-time: 0.2105\n",
            "[08:16:10.579080] Epoch: [22]  [60/72]  eta: 0:00:02  loss: 2.0294 (1.8832)  Accuracy: 0.4062 (0.4652)  Top 5 accuracy: 0.7812 (0.8028)  lr: 0.000100  iter-time: 0.2110\n",
            "[08:16:12.706246] Epoch: [22]  [70/72]  eta: 0:00:00  loss: 1.8690 (1.8794)  Accuracy: 0.4688 (0.4648)  Top 5 accuracy: 0.7500 (0.8019)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:16:12.869430] Epoch: [22]  [71/72]  eta: 0:00:00  loss: 1.8690 (1.8786)  Accuracy: 0.4375 (0.4644)  Top 5 accuracy: 0.7500 (0.8023)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:16:12.967579] Epoch: [22] Total time: 0:00:16 (0.2261 s / it)\n",
            "[08:16:12.967800] [Train] averaged stats: loss: 1.8690 (1.8786)  Accuracy: 0.4375 (0.4644)  Top 5 accuracy: 0.7500 (0.8023)  lr: 0.000100\n",
            "[08:16:13.460647] Epoch: [22]  [0/8]  eta: 0:00:03  loss: 1.6485 (1.6485)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.4900\n",
            "[08:16:13.988921] Epoch: [22]  [7/8]  eta: 0:00:00  loss: 2.5280 (2.4101)  Accuracy: 0.3226 (0.3528)  Top 5 accuracy: 0.6562 (0.6825)  iter-time: 0.1262\n",
            "[08:16:14.081452] Epoch: [22] Total time: 0:00:01 (0.1389 s / it)\n",
            "[08:16:14.081549] [Val] averaged stats: loss: 2.5280 (2.4101)  Accuracy: 0.3226 (0.3528)  Top 5 accuracy: 0.6562 (0.6825)\n",
            "[08:16:14.082166] [Val] best loss: 2.2924 best  Accuracy: 0.3488 Top 5 accuracy: 0.7491 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:16:14.083557] [Time] 17.4s 7.5m/30.4m\n",
            "\n",
            "[08:16:14.083589] ~~~ Epoch 23/100 ~~~\n",
            "\n",
            "[08:16:15.303221] Epoch: [23]  [ 0/72]  eta: 0:01:27  loss: 1.5546 (1.5546)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 1.2173\n",
            "[08:16:17.662981] Epoch: [23]  [10/72]  eta: 0:00:20  loss: 1.8035 (1.8324)  Accuracy: 0.4688 (0.4602)  Top 5 accuracy: 0.8438 (0.8210)  lr: 0.000100  iter-time: 0.3250\n",
            "[08:16:19.837684] Epoch: [23]  [20/72]  eta: 0:00:14  loss: 1.8163 (1.8530)  Accuracy: 0.4375 (0.4479)  Top 5 accuracy: 0.8438 (0.8110)  lr: 0.000100  iter-time: 0.2263\n",
            "[08:16:21.994182] Epoch: [23]  [30/72]  eta: 0:00:10  loss: 1.8371 (1.8559)  Accuracy: 0.4375 (0.4536)  Top 5 accuracy: 0.8125 (0.8105)  lr: 0.000100  iter-time: 0.2162\n",
            "[08:16:24.151384] Epoch: [23]  [40/72]  eta: 0:00:07  loss: 1.8448 (1.8724)  Accuracy: 0.4375 (0.4497)  Top 5 accuracy: 0.8125 (0.8049)  lr: 0.000100  iter-time: 0.2155\n",
            "[08:16:26.316682] Epoch: [23]  [50/72]  eta: 0:00:05  loss: 1.8727 (1.8691)  Accuracy: 0.4375 (0.4540)  Top 5 accuracy: 0.8125 (0.8100)  lr: 0.000100  iter-time: 0.2160\n",
            "[08:16:28.501255] Epoch: [23]  [60/72]  eta: 0:00:02  loss: 1.8158 (1.8623)  Accuracy: 0.4688 (0.4585)  Top 5 accuracy: 0.8125 (0.8115)  lr: 0.000100  iter-time: 0.2174\n",
            "[08:16:30.661522] Epoch: [23]  [70/72]  eta: 0:00:00  loss: 1.8158 (1.8681)  Accuracy: 0.4688 (0.4604)  Top 5 accuracy: 0.8125 (0.8107)  lr: 0.000100  iter-time: 0.2169\n",
            "[08:16:30.827950] Epoch: [23]  [71/72]  eta: 0:00:00  loss: 1.8158 (1.8689)  Accuracy: 0.4688 (0.4606)  Top 5 accuracy: 0.8125 (0.8110)  lr: 0.000100  iter-time: 0.2143\n",
            "[08:16:30.926716] Epoch: [23] Total time: 0:00:16 (0.2339 s / it)\n",
            "[08:16:30.927468] [Train] averaged stats: loss: 1.8158 (1.8689)  Accuracy: 0.4688 (0.4606)  Top 5 accuracy: 0.8125 (0.8110)  lr: 0.000100\n",
            "[08:16:31.462919] Epoch: [23]  [0/8]  eta: 0:00:04  loss: 2.1180 (2.1180)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7812 (0.7812)  iter-time: 0.5324\n",
            "[08:16:31.971079] Epoch: [23]  [7/8]  eta: 0:00:00  loss: 2.2587 (2.2899)  Accuracy: 0.3125 (0.3686)  Top 5 accuracy: 0.7500 (0.7450)  iter-time: 0.1293\n",
            "[08:16:32.062292] Epoch: [23] Total time: 0:00:01 (0.1416 s / it)\n",
            "[08:16:32.062368] [Val] averaged stats: loss: 2.2587 (2.2899)  Accuracy: 0.3125 (0.3686)  Top 5 accuracy: 0.7500 (0.7450)\n",
            "[08:16:32.063051] Val loss improved from 2.2923712879419327 to 2.2898880392313004, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:16:37.260377] [Val] best loss: 2.2899 best  Accuracy: 0.3686 Top 5 accuracy: 0.7450 \n",
            "[08:16:37.262046] [Time] 23.2s 7.9m/38.0m\n",
            "\n",
            "[08:16:37.262098] ~~~ Epoch 24/100 ~~~\n",
            "\n",
            "[08:16:38.254701] Epoch: [24]  [ 0/72]  eta: 0:01:11  loss: 1.6477 (1.6477)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8125 (0.8125)  lr: 0.000100  iter-time: 0.9900\n",
            "[08:16:40.395258] Epoch: [24]  [10/72]  eta: 0:00:17  loss: 1.7482 (1.7637)  Accuracy: 0.5312 (0.5398)  Top 5 accuracy: 0.8125 (0.8210)  lr: 0.000100  iter-time: 0.2843\n",
            "[08:16:42.625836] Epoch: [24]  [20/72]  eta: 0:00:13  loss: 1.6679 (1.7569)  Accuracy: 0.5312 (0.5179)  Top 5 accuracy: 0.8438 (0.8229)  lr: 0.000100  iter-time: 0.2183\n",
            "[08:16:44.748145] Epoch: [24]  [30/72]  eta: 0:00:10  loss: 1.7420 (1.7802)  Accuracy: 0.5000 (0.5060)  Top 5 accuracy: 0.8125 (0.8226)  lr: 0.000100  iter-time: 0.2175\n",
            "[08:16:46.853243] Epoch: [24]  [40/72]  eta: 0:00:07  loss: 1.7420 (1.7841)  Accuracy: 0.4688 (0.4962)  Top 5 accuracy: 0.8125 (0.8262)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:16:48.958819] Epoch: [24]  [50/72]  eta: 0:00:05  loss: 1.7901 (1.7844)  Accuracy: 0.4688 (0.4908)  Top 5 accuracy: 0.8438 (0.8266)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:16:51.064234] Epoch: [24]  [60/72]  eta: 0:00:02  loss: 1.9010 (1.8375)  Accuracy: 0.4062 (0.4739)  Top 5 accuracy: 0.8125 (0.8217)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:16:53.167443] Epoch: [24]  [70/72]  eta: 0:00:00  loss: 1.9488 (1.8472)  Accuracy: 0.4062 (0.4714)  Top 5 accuracy: 0.7812 (0.8156)  lr: 0.000100  iter-time: 0.2103\n",
            "[08:16:53.332588] Epoch: [24]  [71/72]  eta: 0:00:00  loss: 2.0021 (1.8511)  Accuracy: 0.4062 (0.4703)  Top 5 accuracy: 0.7812 (0.8157)  lr: 0.000100  iter-time: 0.2079\n",
            "[08:16:53.507298] Epoch: [24] Total time: 0:00:16 (0.2256 s / it)\n",
            "[08:16:53.507529] [Train] averaged stats: loss: 2.0021 (1.8511)  Accuracy: 0.4062 (0.4703)  Top 5 accuracy: 0.7812 (0.8157)  lr: 0.000100\n",
            "[08:16:54.465315] Epoch: [24]  [0/8]  eta: 0:00:07  loss: 2.0375 (2.0375)  Accuracy: 0.3750 (0.3750)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.9541\n",
            "[08:16:54.993629] Epoch: [24]  [7/8]  eta: 0:00:00  loss: 2.2719 (2.3957)  Accuracy: 0.3438 (0.3565)  Top 5 accuracy: 0.7742 (0.7374)  iter-time: 0.1852\n",
            "[08:16:55.087872] Epoch: [24] Total time: 0:00:01 (0.1972 s / it)\n",
            "[08:16:55.087948] [Val] averaged stats: loss: 2.2719 (2.3957)  Accuracy: 0.3438 (0.3565)  Top 5 accuracy: 0.7742 (0.7374)\n",
            "[08:16:55.088500] [Val] best loss: 2.2899 best  Accuracy: 0.3686 Top 5 accuracy: 0.7450 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:16:55.089546] [Time] 17.8s 8.2m/31.1m\n",
            "\n",
            "[08:16:55.089578] ~~~ Epoch 25/100 ~~~\n",
            "\n",
            "[08:16:55.980852] Epoch: [25]  [ 0/72]  eta: 0:01:04  loss: 1.4828 (1.4828)  Accuracy: 0.5938 (0.5937)  Top 5 accuracy: 0.8438 (0.8437)  lr: 0.000100  iter-time: 0.8889\n",
            "[08:16:58.121771] Epoch: [25]  [10/72]  eta: 0:00:17  loss: 1.7556 (1.7134)  Accuracy: 0.5000 (0.5085)  Top 5 accuracy: 0.8438 (0.8608)  lr: 0.000100  iter-time: 0.2753\n",
            "[08:17:00.234501] Epoch: [25]  [20/72]  eta: 0:00:12  loss: 1.7556 (1.7606)  Accuracy: 0.5000 (0.4955)  Top 5 accuracy: 0.8438 (0.8467)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:17:02.345562] Epoch: [25]  [30/72]  eta: 0:00:09  loss: 1.7999 (1.7909)  Accuracy: 0.4688 (0.4829)  Top 5 accuracy: 0.8438 (0.8438)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:17:04.470447] Epoch: [25]  [40/72]  eta: 0:00:07  loss: 1.8656 (1.8132)  Accuracy: 0.4375 (0.4840)  Top 5 accuracy: 0.8125 (0.8346)  lr: 0.000100  iter-time: 0.2117\n",
            "[08:17:06.634436] Epoch: [25]  [50/72]  eta: 0:00:04  loss: 1.8619 (1.8030)  Accuracy: 0.4688 (0.4841)  Top 5 accuracy: 0.8125 (0.8339)  lr: 0.000100  iter-time: 0.2144\n",
            "[08:17:08.848351] Epoch: [25]  [60/72]  eta: 0:00:02  loss: 1.7308 (1.7947)  Accuracy: 0.5000 (0.4908)  Top 5 accuracy: 0.8125 (0.8325)  lr: 0.000100  iter-time: 0.2188\n",
            "[08:17:10.956574] Epoch: [25]  [70/72]  eta: 0:00:00  loss: 1.7014 (1.7823)  Accuracy: 0.5000 (0.4956)  Top 5 accuracy: 0.8125 (0.8345)  lr: 0.000100  iter-time: 0.2160\n",
            "[08:17:11.120257] Epoch: [25]  [71/72]  eta: 0:00:00  loss: 1.7014 (1.7836)  Accuracy: 0.5000 (0.4954)  Top 5 accuracy: 0.8125 (0.8338)  lr: 0.000100  iter-time: 0.2131\n",
            "[08:17:11.217109] Epoch: [25] Total time: 0:00:16 (0.2240 s / it)\n",
            "[08:17:11.217465] [Train] averaged stats: loss: 1.7014 (1.7836)  Accuracy: 0.5000 (0.4954)  Top 5 accuracy: 0.8125 (0.8338)  lr: 0.000100\n",
            "[08:17:11.741790] Epoch: [25]  [0/8]  eta: 0:00:04  loss: 1.6441 (1.6441)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8750 (0.8750)  iter-time: 0.5070\n",
            "[08:17:12.275158] Epoch: [25]  [7/8]  eta: 0:00:00  loss: 2.1221 (2.1490)  Accuracy: 0.3548 (0.3959)  Top 5 accuracy: 0.7500 (0.7492)  iter-time: 0.1299\n",
            "[08:17:12.370207] Epoch: [25] Total time: 0:00:01 (0.1438 s / it)\n",
            "[08:17:12.370281] [Val] averaged stats: loss: 2.1221 (2.1490)  Accuracy: 0.3548 (0.3959)  Top 5 accuracy: 0.7500 (0.7492)\n",
            "[08:17:12.370790] Val loss improved from 2.2898880392313004 to 2.1489836424589157, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:17:17.348515] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "[08:17:17.350180] Creating training plots . . .\n",
            "[08:17:17.665671] [Time] 22.6s 8.6m/37.2m\n",
            "\n",
            "[08:17:17.665792] ~~~ Epoch 26/100 ~~~\n",
            "\n",
            "[08:17:19.011922] Epoch: [26]  [ 0/72]  eta: 0:01:36  loss: 1.7711 (1.7711)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.8125 (0.8125)  lr: 0.000100  iter-time: 1.3443\n",
            "[08:17:21.271870] Epoch: [26]  [10/72]  eta: 0:00:20  loss: 1.7711 (1.6783)  Accuracy: 0.5625 (0.5312)  Top 5 accuracy: 0.8438 (0.8381)  lr: 0.000100  iter-time: 0.3275\n",
            "[08:17:23.383536] Epoch: [26]  [20/72]  eta: 0:00:14  loss: 1.5667 (1.6487)  Accuracy: 0.5312 (0.5253)  Top 5 accuracy: 0.8438 (0.8438)  lr: 0.000100  iter-time: 0.2185\n",
            "[08:17:25.471221] Epoch: [26]  [30/72]  eta: 0:00:10  loss: 1.7166 (1.7041)  Accuracy: 0.5000 (0.5121)  Top 5 accuracy: 0.8438 (0.8357)  lr: 0.000100  iter-time: 0.2098\n",
            "[08:17:27.574361] Epoch: [26]  [40/72]  eta: 0:00:07  loss: 1.7197 (1.6928)  Accuracy: 0.4688 (0.5145)  Top 5 accuracy: 0.8125 (0.8377)  lr: 0.000100  iter-time: 0.2094\n",
            "[08:17:29.671097] Epoch: [26]  [50/72]  eta: 0:00:05  loss: 1.6079 (1.6824)  Accuracy: 0.5312 (0.5190)  Top 5 accuracy: 0.8438 (0.8370)  lr: 0.000100  iter-time: 0.2099\n",
            "[08:17:31.810102] Epoch: [26]  [60/72]  eta: 0:00:02  loss: 1.6538 (1.7040)  Accuracy: 0.5000 (0.5118)  Top 5 accuracy: 0.8125 (0.8345)  lr: 0.000100  iter-time: 0.2117\n",
            "[08:17:33.953042] Epoch: [26]  [70/72]  eta: 0:00:00  loss: 1.7625 (1.7173)  Accuracy: 0.4688 (0.5084)  Top 5 accuracy: 0.8125 (0.8349)  lr: 0.000100  iter-time: 0.2140\n",
            "[08:17:34.118281] Epoch: [26]  [71/72]  eta: 0:00:00  loss: 1.7859 (1.7182)  Accuracy: 0.4688 (0.5073)  Top 5 accuracy: 0.8125 (0.8348)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:17:34.228267] Epoch: [26] Total time: 0:00:16 (0.2300 s / it)\n",
            "[08:17:34.228634] [Train] averaged stats: loss: 1.7859 (1.7182)  Accuracy: 0.4688 (0.5073)  Top 5 accuracy: 0.8125 (0.8348)  lr: 0.000100\n",
            "[08:17:34.798985] Epoch: [26]  [0/8]  eta: 0:00:04  loss: 1.6956 (1.6956)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8750 (0.8750)  iter-time: 0.5678\n",
            "[08:17:35.263276] Epoch: [26]  [7/8]  eta: 0:00:00  loss: 2.2671 (2.3176)  Accuracy: 0.3438 (0.3650)  Top 5 accuracy: 0.7500 (0.7411)  iter-time: 0.1288\n",
            "[08:17:35.355939] Epoch: [26] Total time: 0:00:01 (0.1407 s / it)\n",
            "[08:17:35.356039] [Val] averaged stats: loss: 2.2671 (2.3176)  Accuracy: 0.3438 (0.3650)  Top 5 accuracy: 0.7500 (0.7411)\n",
            "[08:17:35.356679] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:17:35.357529] [Time] 17.7s 8.9m/31.0m\n",
            "\n",
            "[08:17:35.357580] ~~~ Epoch 27/100 ~~~\n",
            "\n",
            "[08:17:36.336304] Epoch: [27]  [ 0/72]  eta: 0:01:10  loss: 2.3238 (2.3238)  Accuracy: 0.3438 (0.3437)  Top 5 accuracy: 0.7188 (0.7187)  lr: 0.000100  iter-time: 0.9729\n",
            "[08:17:38.504469] Epoch: [27]  [10/72]  eta: 0:00:17  loss: 1.6417 (1.6733)  Accuracy: 0.5312 (0.5284)  Top 5 accuracy: 0.8438 (0.8438)  lr: 0.000100  iter-time: 0.2850\n",
            "[08:17:40.639095] Epoch: [27]  [20/72]  eta: 0:00:13  loss: 1.6383 (1.6639)  Accuracy: 0.5312 (0.5283)  Top 5 accuracy: 0.8438 (0.8467)  lr: 0.000100  iter-time: 0.2148\n",
            "[08:17:42.783028] Epoch: [27]  [30/72]  eta: 0:00:10  loss: 1.7415 (1.6935)  Accuracy: 0.5312 (0.5212)  Top 5 accuracy: 0.8438 (0.8397)  lr: 0.000100  iter-time: 0.2138\n",
            "[08:17:44.985766] Epoch: [27]  [40/72]  eta: 0:00:07  loss: 1.7259 (1.7060)  Accuracy: 0.5000 (0.5160)  Top 5 accuracy: 0.8438 (0.8392)  lr: 0.000100  iter-time: 0.2172\n",
            "[08:17:47.211473] Epoch: [27]  [50/72]  eta: 0:00:05  loss: 1.6664 (1.6890)  Accuracy: 0.5000 (0.5214)  Top 5 accuracy: 0.8438 (0.8450)  lr: 0.000100  iter-time: 0.2213\n",
            "[08:17:49.335209] Epoch: [27]  [60/72]  eta: 0:00:02  loss: 1.7320 (1.6965)  Accuracy: 0.5000 (0.5220)  Top 5 accuracy: 0.8750 (0.8448)  lr: 0.000100  iter-time: 0.2174\n",
            "[08:17:51.458126] Epoch: [27]  [70/72]  eta: 0:00:00  loss: 1.8306 (1.7170)  Accuracy: 0.4688 (0.5154)  Top 5 accuracy: 0.8125 (0.8393)  lr: 0.000100  iter-time: 0.2122\n",
            "[08:17:51.621582] Epoch: [27]  [71/72]  eta: 0:00:00  loss: 1.8306 (1.7181)  Accuracy: 0.4688 (0.5155)  Top 5 accuracy: 0.8125 (0.8392)  lr: 0.000100  iter-time: 0.2099\n",
            "[08:17:51.716177] Epoch: [27] Total time: 0:00:16 (0.2272 s / it)\n",
            "[08:17:51.716529] [Train] averaged stats: loss: 1.8306 (1.7181)  Accuracy: 0.4688 (0.5155)  Top 5 accuracy: 0.8125 (0.8392)  lr: 0.000100\n",
            "[08:17:52.194925] Epoch: [27]  [0/8]  eta: 0:00:03  loss: 1.8121 (1.8121)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.4759\n",
            "[08:17:52.723619] Epoch: [27]  [7/8]  eta: 0:00:00  loss: 2.2947 (2.2874)  Accuracy: 0.3750 (0.3683)  Top 5 accuracy: 0.7500 (0.7335)  iter-time: 0.1250\n",
            "[08:17:52.815233] Epoch: [27] Total time: 0:00:01 (0.1371 s / it)\n",
            "[08:17:52.815307] [Val] averaged stats: loss: 2.2947 (2.2874)  Accuracy: 0.3750 (0.3683)  Top 5 accuracy: 0.7500 (0.7335)\n",
            "[08:17:52.815770] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:17:52.816524] [Time] 17.5s 9.2m/30.7m\n",
            "\n",
            "[08:17:52.816568] ~~~ Epoch 28/100 ~~~\n",
            "\n",
            "[08:17:53.828055] Epoch: [28]  [ 0/72]  eta: 0:01:12  loss: 1.2813 (1.2813)  Accuracy: 0.5938 (0.5937)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 1.0087\n",
            "[08:17:55.967860] Epoch: [28]  [10/72]  eta: 0:00:17  loss: 1.6808 (1.6461)  Accuracy: 0.5312 (0.5227)  Top 5 accuracy: 0.8438 (0.8409)  lr: 0.000100  iter-time: 0.2861\n",
            "[08:17:58.155743] Epoch: [28]  [20/72]  eta: 0:00:13  loss: 1.6808 (1.6306)  Accuracy: 0.5000 (0.5298)  Top 5 accuracy: 0.8750 (0.8601)  lr: 0.000100  iter-time: 0.2163\n",
            "[08:18:00.347136] Epoch: [28]  [30/72]  eta: 0:00:10  loss: 1.7221 (1.6729)  Accuracy: 0.5000 (0.5111)  Top 5 accuracy: 0.8438 (0.8468)  lr: 0.000100  iter-time: 0.2188\n",
            "[08:18:02.458312] Epoch: [28]  [40/72]  eta: 0:00:07  loss: 1.7283 (1.6744)  Accuracy: 0.5000 (0.5091)  Top 5 accuracy: 0.8438 (0.8422)  lr: 0.000100  iter-time: 0.2150\n",
            "[08:18:04.596422] Epoch: [28]  [50/72]  eta: 0:00:05  loss: 1.6732 (1.6827)  Accuracy: 0.4688 (0.5086)  Top 5 accuracy: 0.8438 (0.8407)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:18:06.715877] Epoch: [28]  [60/72]  eta: 0:00:02  loss: 1.6732 (1.6766)  Accuracy: 0.5312 (0.5123)  Top 5 accuracy: 0.8438 (0.8391)  lr: 0.000100  iter-time: 0.2127\n",
            "[08:18:08.811837] Epoch: [28]  [70/72]  eta: 0:00:00  loss: 1.7050 (1.6947)  Accuracy: 0.5000 (0.5057)  Top 5 accuracy: 0.8438 (0.8389)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:18:08.973721] Epoch: [28]  [71/72]  eta: 0:00:00  loss: 1.7050 (1.6945)  Accuracy: 0.5000 (0.5053)  Top 5 accuracy: 0.8438 (0.8387)  lr: 0.000100  iter-time: 0.2081\n",
            "[08:18:09.076996] Epoch: [28] Total time: 0:00:16 (0.2258 s / it)\n",
            "[08:18:09.077200] [Train] averaged stats: loss: 1.7050 (1.6945)  Accuracy: 0.5000 (0.5053)  Top 5 accuracy: 0.8438 (0.8387)  lr: 0.000100\n",
            "[08:18:10.078636] Epoch: [28]  [0/8]  eta: 0:00:07  loss: 1.6161 (1.6161)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.9981\n",
            "[08:18:10.648683] Epoch: [28]  [7/8]  eta: 0:00:00  loss: 2.1422 (2.2297)  Accuracy: 0.3438 (0.3766)  Top 5 accuracy: 0.7500 (0.7571)  iter-time: 0.1959\n",
            "[08:18:10.795067] Epoch: [28] Total time: 0:00:01 (0.2144 s / it)\n",
            "[08:18:10.795161] [Val] averaged stats: loss: 2.1422 (2.2297)  Accuracy: 0.3438 (0.3766)  Top 5 accuracy: 0.7500 (0.7571)\n",
            "[08:18:10.795725] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:18:10.796521] [Time] 18.0s 9.5m/31.3m\n",
            "\n",
            "[08:18:10.796568] ~~~ Epoch 29/100 ~~~\n",
            "\n",
            "[08:18:12.092044] Epoch: [29]  [ 0/72]  eta: 0:01:32  loss: 1.4074 (1.4074)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 1.2895\n",
            "[08:18:14.218387] Epoch: [29]  [10/72]  eta: 0:00:19  loss: 1.3705 (1.4064)  Accuracy: 0.6250 (0.5909)  Top 5 accuracy: 0.9375 (0.9148)  lr: 0.000100  iter-time: 0.3096\n",
            "[08:18:16.310973] Epoch: [29]  [20/72]  eta: 0:00:13  loss: 1.4225 (1.4632)  Accuracy: 0.5625 (0.5759)  Top 5 accuracy: 0.8750 (0.8899)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:18:18.398825] Epoch: [29]  [30/72]  eta: 0:00:10  loss: 1.5881 (1.5310)  Accuracy: 0.5312 (0.5544)  Top 5 accuracy: 0.8438 (0.8740)  lr: 0.000100  iter-time: 0.2089\n",
            "[08:18:20.485800] Epoch: [29]  [40/72]  eta: 0:00:07  loss: 1.6209 (1.5415)  Accuracy: 0.5312 (0.5534)  Top 5 accuracy: 0.8438 (0.8681)  lr: 0.000100  iter-time: 0.2086\n",
            "[08:18:22.608974] Epoch: [29]  [50/72]  eta: 0:00:05  loss: 1.5795 (1.5585)  Accuracy: 0.5312 (0.5460)  Top 5 accuracy: 0.8438 (0.8646)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:18:24.817628] Epoch: [29]  [60/72]  eta: 0:00:02  loss: 1.5623 (1.5585)  Accuracy: 0.5312 (0.5446)  Top 5 accuracy: 0.8438 (0.8658)  lr: 0.000100  iter-time: 0.2163\n",
            "[08:18:26.903051] Epoch: [29]  [70/72]  eta: 0:00:00  loss: 1.5721 (1.5810)  Accuracy: 0.5000 (0.5401)  Top 5 accuracy: 0.8438 (0.8640)  lr: 0.000100  iter-time: 0.2144\n",
            "[08:18:27.062106] Epoch: [29]  [71/72]  eta: 0:00:00  loss: 1.5965 (1.5818)  Accuracy: 0.5000 (0.5404)  Top 5 accuracy: 0.8438 (0.8635)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:18:27.178900] Epoch: [29] Total time: 0:00:16 (0.2275 s / it)\n",
            "[08:18:27.179279] [Train] averaged stats: loss: 1.5965 (1.5818)  Accuracy: 0.5000 (0.5404)  Top 5 accuracy: 0.8438 (0.8635)  lr: 0.000100\n",
            "[08:18:27.604511] Epoch: [29]  [0/8]  eta: 0:00:03  loss: 2.0138 (2.0138)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7188 (0.7187)  iter-time: 0.4227\n",
            "[08:18:28.244760] Epoch: [29]  [7/8]  eta: 0:00:00  loss: 2.2560 (2.2873)  Accuracy: 0.3871 (0.3882)  Top 5 accuracy: 0.7188 (0.7374)  iter-time: 0.1310\n",
            "[08:18:28.340187] Epoch: [29] Total time: 0:00:01 (0.1449 s / it)\n",
            "[08:18:28.340262] [Val] averaged stats: loss: 2.2560 (2.2873)  Accuracy: 0.3871 (0.3882)  Top 5 accuracy: 0.7188 (0.7374)\n",
            "[08:18:28.340941] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[08:18:28.342334] [Time] 17.5s 9.8m/30.8m\n",
            "\n",
            "[08:18:28.342367] ~~~ Epoch 30/100 ~~~\n",
            "\n",
            "[08:18:29.235190] Epoch: [30]  [ 0/72]  eta: 0:01:03  loss: 1.5638 (1.5638)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 0.8886\n",
            "[08:18:31.354640] Epoch: [30]  [10/72]  eta: 0:00:16  loss: 1.5489 (1.4366)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.9062 (0.9006)  lr: 0.000100  iter-time: 0.2733\n",
            "[08:18:33.449051] Epoch: [30]  [20/72]  eta: 0:00:12  loss: 1.4451 (1.4516)  Accuracy: 0.5312 (0.5610)  Top 5 accuracy: 0.9062 (0.8988)  lr: 0.000100  iter-time: 0.2105\n",
            "[08:18:35.576431] Epoch: [30]  [30/72]  eta: 0:00:09  loss: 1.4451 (1.4382)  Accuracy: 0.5625 (0.5685)  Top 5 accuracy: 0.8750 (0.8952)  lr: 0.000100  iter-time: 0.2108\n",
            "[08:18:37.810022] Epoch: [30]  [40/72]  eta: 0:00:07  loss: 1.4685 (1.4634)  Accuracy: 0.5625 (0.5633)  Top 5 accuracy: 0.8750 (0.8880)  lr: 0.000100  iter-time: 0.2178\n",
            "[08:18:39.931653] Epoch: [30]  [50/72]  eta: 0:00:04  loss: 1.4685 (1.4732)  Accuracy: 0.5625 (0.5650)  Top 5 accuracy: 0.8438 (0.8805)  lr: 0.000100  iter-time: 0.2176\n",
            "[08:18:42.026635] Epoch: [30]  [60/72]  eta: 0:00:02  loss: 1.6113 (1.5173)  Accuracy: 0.5312 (0.5543)  Top 5 accuracy: 0.8438 (0.8786)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:18:44.128000] Epoch: [30]  [70/72]  eta: 0:00:00  loss: 1.6499 (1.5432)  Accuracy: 0.5000 (0.5493)  Top 5 accuracy: 0.8438 (0.8702)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:18:44.295711] Epoch: [30]  [71/72]  eta: 0:00:00  loss: 1.6270 (1.5365)  Accuracy: 0.5000 (0.5519)  Top 5 accuracy: 0.8438 (0.8714)  lr: 0.000100  iter-time: 0.2076\n",
            "[08:18:44.392805] Epoch: [30] Total time: 0:00:16 (0.2229 s / it)\n",
            "[08:18:44.393147] [Train] averaged stats: loss: 1.6270 (1.5365)  Accuracy: 0.5000 (0.5519)  Top 5 accuracy: 0.8438 (0.8714)  lr: 0.000100\n",
            "[08:18:45.055185] Epoch: [30]  [0/8]  eta: 0:00:05  loss: 1.7156 (1.7156)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.7188 (0.7187)  iter-time: 0.6597\n",
            "[08:18:45.500840] Epoch: [30]  [7/8]  eta: 0:00:00  loss: 2.3662 (2.3047)  Accuracy: 0.3750 (0.3997)  Top 5 accuracy: 0.7188 (0.7298)  iter-time: 0.1381\n",
            "[08:18:45.594818] Epoch: [30] Total time: 0:00:01 (0.1500 s / it)\n",
            "[08:18:45.594894] [Val] averaged stats: loss: 2.3662 (2.3047)  Accuracy: 0.3750 (0.3997)  Top 5 accuracy: 0.7188 (0.7298)\n",
            "[08:18:45.595325] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "[08:18:45.596521] Creating training plots . . .\n",
            "EarlyStopping counter: 5 out of 20\n",
            "[08:18:46.274363] [Time] 17.9s 10.1m/31.3m\n",
            "\n",
            "[08:18:46.274399] ~~~ Epoch 31/100 ~~~\n",
            "\n",
            "[08:18:46.998264] Epoch: [31]  [ 0/72]  eta: 0:00:51  loss: 1.5988 (1.5988)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8438 (0.8437)  lr: 0.000100  iter-time: 0.7169\n",
            "[08:18:49.412107] Epoch: [31]  [10/72]  eta: 0:00:17  loss: 1.5779 (1.5560)  Accuracy: 0.5625 (0.5597)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 0.2841\n",
            "[08:18:51.617096] Epoch: [31]  [20/72]  eta: 0:00:13  loss: 1.4452 (1.4752)  Accuracy: 0.5938 (0.5789)  Top 5 accuracy: 0.9062 (0.8943)  lr: 0.000100  iter-time: 0.2305\n",
            "[08:18:53.722271] Epoch: [31]  [30/72]  eta: 0:00:10  loss: 1.4374 (1.5019)  Accuracy: 0.5938 (0.5675)  Top 5 accuracy: 0.8750 (0.8891)  lr: 0.000100  iter-time: 0.2152\n",
            "[08:18:55.836083] Epoch: [31]  [40/72]  eta: 0:00:07  loss: 1.5701 (1.5384)  Accuracy: 0.5312 (0.5595)  Top 5 accuracy: 0.8750 (0.8742)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:18:57.951032] Epoch: [31]  [50/72]  eta: 0:00:05  loss: 1.6446 (1.5678)  Accuracy: 0.5312 (0.5502)  Top 5 accuracy: 0.8438 (0.8676)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:19:00.071342] Epoch: [31]  [60/72]  eta: 0:00:02  loss: 1.6347 (1.5643)  Accuracy: 0.5625 (0.5533)  Top 5 accuracy: 0.8438 (0.8673)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:19:02.195316] Epoch: [31]  [70/72]  eta: 0:00:00  loss: 1.5526 (1.5760)  Accuracy: 0.5625 (0.5524)  Top 5 accuracy: 0.8438 (0.8653)  lr: 0.000100  iter-time: 0.2121\n",
            "[08:19:02.358096] Epoch: [31]  [71/72]  eta: 0:00:00  loss: 1.6347 (1.5777)  Accuracy: 0.5625 (0.5526)  Top 5 accuracy: 0.8438 (0.8648)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:19:02.497112] Epoch: [31] Total time: 0:00:16 (0.2253 s / it)\n",
            "[08:19:02.497496] [Train] averaged stats: loss: 1.6347 (1.5777)  Accuracy: 0.5625 (0.5526)  Top 5 accuracy: 0.8438 (0.8648)  lr: 0.000100\n",
            "[08:19:02.998017] Epoch: [31]  [0/8]  eta: 0:00:03  loss: 1.3765 (1.3765)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.8750 (0.8750)  iter-time: 0.4978\n",
            "[08:19:03.608935] Epoch: [31]  [7/8]  eta: 0:00:00  loss: 2.5841 (2.3555)  Accuracy: 0.3125 (0.3484)  Top 5 accuracy: 0.6562 (0.7137)  iter-time: 0.1374\n",
            "[08:19:03.702301] Epoch: [31] Total time: 0:00:01 (0.1504 s / it)\n",
            "[08:19:03.702374] [Val] averaged stats: loss: 2.5841 (2.3555)  Accuracy: 0.3125 (0.3484)  Top 5 accuracy: 0.6562 (0.7137)\n",
            "[08:19:03.702856] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[08:19:03.704107] [Time] 17.4s 10.4m/30.7m\n",
            "\n",
            "[08:19:03.704138] ~~~ Epoch 32/100 ~~~\n",
            "\n",
            "[08:19:04.823483] Epoch: [32]  [ 0/72]  eta: 0:01:20  loss: 1.2382 (1.2382)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 1.1167\n",
            "[08:19:06.990013] Epoch: [32]  [10/72]  eta: 0:00:18  loss: 1.3774 (1.3822)  Accuracy: 0.5625 (0.5881)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 0.2983\n",
            "[08:19:09.092294] Epoch: [32]  [20/72]  eta: 0:00:13  loss: 1.4915 (1.4533)  Accuracy: 0.5625 (0.5670)  Top 5 accuracy: 0.9062 (0.8943)  lr: 0.000100  iter-time: 0.2133\n",
            "[08:19:11.217977] Epoch: [32]  [30/72]  eta: 0:00:10  loss: 1.5715 (1.4715)  Accuracy: 0.5312 (0.5575)  Top 5 accuracy: 0.8438 (0.8851)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:19:13.352988] Epoch: [32]  [40/72]  eta: 0:00:07  loss: 1.5772 (1.5108)  Accuracy: 0.5312 (0.5556)  Top 5 accuracy: 0.8438 (0.8765)  lr: 0.000100  iter-time: 0.2129\n",
            "[08:19:15.632257] Epoch: [32]  [50/72]  eta: 0:00:05  loss: 1.6032 (1.5339)  Accuracy: 0.5312 (0.5545)  Top 5 accuracy: 0.8438 (0.8707)  lr: 0.000100  iter-time: 0.2203\n",
            "[08:19:17.756884] Epoch: [32]  [60/72]  eta: 0:00:02  loss: 1.5690 (1.5312)  Accuracy: 0.5312 (0.5523)  Top 5 accuracy: 0.8438 (0.8678)  lr: 0.000100  iter-time: 0.2198\n",
            "[08:19:19.867437] Epoch: [32]  [70/72]  eta: 0:00:00  loss: 1.6462 (1.5577)  Accuracy: 0.5312 (0.5458)  Top 5 accuracy: 0.8438 (0.8631)  lr: 0.000100  iter-time: 0.2117\n",
            "[08:19:20.032195] Epoch: [32]  [71/72]  eta: 0:00:00  loss: 1.6462 (1.5624)  Accuracy: 0.5312 (0.5436)  Top 5 accuracy: 0.8438 (0.8608)  lr: 0.000100  iter-time: 0.2093\n",
            "[08:19:20.127514] Epoch: [32] Total time: 0:00:16 (0.2281 s / it)\n",
            "[08:19:20.127875] [Train] averaged stats: loss: 1.6462 (1.5624)  Accuracy: 0.5312 (0.5436)  Top 5 accuracy: 0.8438 (0.8608)  lr: 0.000100\n",
            "[08:19:20.707512] Epoch: [32]  [0/8]  eta: 0:00:04  loss: 1.9583 (1.9583)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.5733\n",
            "[08:19:21.163108] Epoch: [32]  [7/8]  eta: 0:00:00  loss: 2.3065 (2.3859)  Accuracy: 0.3226 (0.3684)  Top 5 accuracy: 0.7188 (0.7099)  iter-time: 0.1285\n",
            "[08:19:21.255452] Epoch: [32] Total time: 0:00:01 (0.1407 s / it)\n",
            "[08:19:21.255543] [Val] averaged stats: loss: 2.3065 (2.3859)  Accuracy: 0.3226 (0.3684)  Top 5 accuracy: 0.7188 (0.7099)\n",
            "[08:19:21.257555] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[08:19:21.259184] [Time] 17.6s 10.6m/30.8m\n",
            "\n",
            "[08:19:21.259216] ~~~ Epoch 33/100 ~~~\n",
            "\n",
            "[08:19:22.143187] Epoch: [33]  [ 0/72]  eta: 0:01:03  loss: 1.8973 (1.8973)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.8125 (0.8125)  lr: 0.000100  iter-time: 0.8800\n",
            "[08:19:24.294993] Epoch: [33]  [10/72]  eta: 0:00:17  loss: 1.4689 (1.5400)  Accuracy: 0.5312 (0.5540)  Top 5 accuracy: 0.9062 (0.9006)  lr: 0.000100  iter-time: 0.2754\n",
            "[08:19:26.433808] Epoch: [33]  [20/72]  eta: 0:00:12  loss: 1.4689 (1.5230)  Accuracy: 0.5625 (0.5714)  Top 5 accuracy: 0.9062 (0.8899)  lr: 0.000100  iter-time: 0.2144\n",
            "[08:19:28.676076] Epoch: [33]  [30/72]  eta: 0:00:10  loss: 1.4645 (1.4938)  Accuracy: 0.5938 (0.5736)  Top 5 accuracy: 0.8750 (0.8921)  lr: 0.000100  iter-time: 0.2189\n",
            "[08:19:30.783030] Epoch: [33]  [40/72]  eta: 0:00:07  loss: 1.4692 (1.5079)  Accuracy: 0.5312 (0.5595)  Top 5 accuracy: 0.8750 (0.8910)  lr: 0.000100  iter-time: 0.2174\n",
            "[08:19:32.889728] Epoch: [33]  [50/72]  eta: 0:00:05  loss: 1.5042 (1.5280)  Accuracy: 0.5312 (0.5607)  Top 5 accuracy: 0.8750 (0.8817)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:19:34.993701] Epoch: [33]  [60/72]  eta: 0:00:02  loss: 1.6905 (1.5569)  Accuracy: 0.5000 (0.5507)  Top 5 accuracy: 0.8438 (0.8770)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:19:37.096610] Epoch: [33]  [70/72]  eta: 0:00:00  loss: 1.6497 (1.5508)  Accuracy: 0.5000 (0.5511)  Top 5 accuracy: 0.8438 (0.8776)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:19:37.259659] Epoch: [33]  [71/72]  eta: 0:00:00  loss: 1.6497 (1.5505)  Accuracy: 0.5000 (0.5500)  Top 5 accuracy: 0.8438 (0.8769)  lr: 0.000100  iter-time: 0.2079\n",
            "[08:19:37.356801] Epoch: [33] Total time: 0:00:16 (0.2236 s / it)\n",
            "[08:19:37.357155] [Train] averaged stats: loss: 1.6497 (1.5505)  Accuracy: 0.5000 (0.5500)  Top 5 accuracy: 0.8438 (0.8769)  lr: 0.000100\n",
            "[08:19:37.764677] Epoch: [33]  [0/8]  eta: 0:00:03  loss: 1.3539 (1.3539)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.9062 (0.9062)  iter-time: 0.4047\n",
            "[08:19:38.459978] Epoch: [33]  [7/8]  eta: 0:00:00  loss: 2.2645 (2.2155)  Accuracy: 0.4062 (0.4118)  Top 5 accuracy: 0.7188 (0.7651)  iter-time: 0.1364\n",
            "[08:19:38.613575] Epoch: [33] Total time: 0:00:01 (0.1568 s / it)\n",
            "[08:19:38.613704] [Val] averaged stats: loss: 2.2645 (2.2155)  Accuracy: 0.4062 (0.4118)  Top 5 accuracy: 0.7188 (0.7651)\n",
            "[08:19:38.614439] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[08:19:38.615872] [Time] 17.4s 10.9m/30.6m\n",
            "\n",
            "[08:19:38.615914] ~~~ Epoch 34/100 ~~~\n",
            "\n",
            "[08:19:40.157060] Epoch: [34]  [ 0/72]  eta: 0:01:50  loss: 1.7713 (1.7713)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.7500 (0.7500)  lr: 0.000100  iter-time: 1.5374\n",
            "[08:19:42.370175] Epoch: [34]  [10/72]  eta: 0:00:21  loss: 1.4810 (1.4483)  Accuracy: 0.5625 (0.5767)  Top 5 accuracy: 0.8750 (0.8778)  lr: 0.000100  iter-time: 0.3401\n",
            "[08:19:44.464096] Epoch: [34]  [20/72]  eta: 0:00:14  loss: 1.4810 (1.5021)  Accuracy: 0.5625 (0.5506)  Top 5 accuracy: 0.8750 (0.8705)  lr: 0.000100  iter-time: 0.2148\n",
            "[08:19:46.567693] Epoch: [34]  [30/72]  eta: 0:00:10  loss: 1.4622 (1.5040)  Accuracy: 0.5625 (0.5554)  Top 5 accuracy: 0.8750 (0.8740)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:19:48.668136] Epoch: [34]  [40/72]  eta: 0:00:07  loss: 1.3923 (1.4871)  Accuracy: 0.5625 (0.5541)  Top 5 accuracy: 0.8750 (0.8773)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:19:50.772231] Epoch: [34]  [50/72]  eta: 0:00:05  loss: 1.3512 (1.4822)  Accuracy: 0.5625 (0.5539)  Top 5 accuracy: 0.9062 (0.8824)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:19:52.979540] Epoch: [34]  [60/72]  eta: 0:00:02  loss: 1.3512 (1.4662)  Accuracy: 0.5938 (0.5610)  Top 5 accuracy: 0.8750 (0.8817)  lr: 0.000100  iter-time: 0.2154\n",
            "[08:19:55.088324] Epoch: [34]  [70/72]  eta: 0:00:00  loss: 1.4743 (1.4771)  Accuracy: 0.5625 (0.5577)  Top 5 accuracy: 0.8750 (0.8803)  lr: 0.000100  iter-time: 0.2157\n",
            "[08:19:55.252464] Epoch: [34]  [71/72]  eta: 0:00:00  loss: 1.4758 (1.4775)  Accuracy: 0.5625 (0.5578)  Top 5 accuracy: 0.8750 (0.8801)  lr: 0.000100  iter-time: 0.2127\n",
            "[08:19:55.351542] Epoch: [34] Total time: 0:00:16 (0.2324 s / it)\n",
            "[08:19:55.351917] [Train] averaged stats: loss: 1.4758 (1.4775)  Accuracy: 0.5625 (0.5578)  Top 5 accuracy: 0.8750 (0.8801)  lr: 0.000100\n",
            "[08:19:56.015254] Epoch: [34]  [0/8]  eta: 0:00:05  loss: 2.0633 (2.0633)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.6608\n",
            "[08:19:56.469918] Epoch: [34]  [7/8]  eta: 0:00:00  loss: 2.0369 (2.1660)  Accuracy: 0.4194 (0.4157)  Top 5 accuracy: 0.7500 (0.7571)  iter-time: 0.1393\n",
            "[08:19:56.565174] Epoch: [34] Total time: 0:00:01 (0.1514 s / it)\n",
            "[08:19:56.565242] [Val] averaged stats: loss: 2.0369 (2.1660)  Accuracy: 0.4194 (0.4157)  Top 5 accuracy: 0.7500 (0.7571)\n",
            "[08:19:56.565697] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[08:19:56.566497] [Time] 18.0s 11.2m/31.3m\n",
            "\n",
            "[08:19:56.566542] ~~~ Epoch 35/100 ~~~\n",
            "\n",
            "[08:19:57.622520] Epoch: [35]  [ 0/72]  eta: 0:01:15  loss: 1.6806 (1.6806)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8125 (0.8125)  lr: 0.000100  iter-time: 1.0522\n",
            "[08:19:59.730044] Epoch: [35]  [10/72]  eta: 0:00:17  loss: 1.1986 (1.2683)  Accuracy: 0.5938 (0.5966)  Top 5 accuracy: 0.9375 (0.9148)  lr: 0.000100  iter-time: 0.2871\n",
            "[08:20:01.827153] Epoch: [35]  [20/72]  eta: 0:00:13  loss: 1.3033 (1.4288)  Accuracy: 0.5938 (0.5818)  Top 5 accuracy: 0.9062 (0.8929)  lr: 0.000100  iter-time: 0.2101\n",
            "[08:20:03.936890] Epoch: [35]  [30/72]  eta: 0:00:09  loss: 1.5643 (1.4244)  Accuracy: 0.5625 (0.5857)  Top 5 accuracy: 0.8750 (0.8942)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:20:06.141288] Epoch: [35]  [40/72]  eta: 0:00:07  loss: 1.3391 (1.3965)  Accuracy: 0.6250 (0.6014)  Top 5 accuracy: 0.9062 (0.8956)  lr: 0.000100  iter-time: 0.2155\n",
            "[08:20:08.290064] Epoch: [35]  [50/72]  eta: 0:00:05  loss: 1.3885 (1.4096)  Accuracy: 0.6250 (0.5938)  Top 5 accuracy: 0.9062 (0.8946)  lr: 0.000100  iter-time: 0.2174\n",
            "[08:20:10.390751] Epoch: [35]  [60/72]  eta: 0:00:02  loss: 1.4539 (1.4439)  Accuracy: 0.5625 (0.5799)  Top 5 accuracy: 0.8750 (0.8904)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:20:12.486244] Epoch: [35]  [70/72]  eta: 0:00:00  loss: 1.6074 (1.4712)  Accuracy: 0.5312 (0.5735)  Top 5 accuracy: 0.8438 (0.8812)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:20:12.645500] Epoch: [35]  [71/72]  eta: 0:00:00  loss: 1.6074 (1.4696)  Accuracy: 0.5312 (0.5746)  Top 5 accuracy: 0.8438 (0.8816)  lr: 0.000100  iter-time: 0.2070\n",
            "[08:20:12.744505] Epoch: [35] Total time: 0:00:16 (0.2247 s / it)\n",
            "[08:20:12.744895] [Train] averaged stats: loss: 1.6074 (1.4696)  Accuracy: 0.5312 (0.5746)  Top 5 accuracy: 0.8438 (0.8816)  lr: 0.000100\n",
            "[08:20:13.270266] Epoch: [35]  [0/8]  eta: 0:00:04  loss: 1.3209 (1.3209)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.5186\n",
            "[08:20:13.764025] Epoch: [35]  [7/8]  eta: 0:00:00  loss: 2.2140 (2.1962)  Accuracy: 0.3438 (0.3992)  Top 5 accuracy: 0.7812 (0.7722)  iter-time: 0.1263\n",
            "[08:20:13.857849] Epoch: [35] Total time: 0:00:01 (0.1389 s / it)\n",
            "[08:20:13.857958] [Val] averaged stats: loss: 2.2140 (2.1962)  Accuracy: 0.3438 (0.3992)  Top 5 accuracy: 0.7812 (0.7722)\n",
            "[08:20:13.858402] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "[08:20:13.859662] Creating training plots . . .\n",
            "EarlyStopping counter: 10 out of 20\n",
            "[08:20:14.193535] [Time] 17.6s 11.5m/30.9m\n",
            "\n",
            "[08:20:14.193585] ~~~ Epoch 36/100 ~~~\n",
            "\n",
            "[08:20:15.238830] Epoch: [36]  [ 0/72]  eta: 0:01:14  loss: 1.8962 (1.8962)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.7812 (0.7812)  lr: 0.000100  iter-time: 1.0371\n",
            "[08:20:17.392873] Epoch: [36]  [10/72]  eta: 0:00:17  loss: 1.4303 (1.4982)  Accuracy: 0.5625 (0.5568)  Top 5 accuracy: 0.8750 (0.8807)  lr: 0.000100  iter-time: 0.2896\n",
            "[08:20:19.618134] Epoch: [36]  [20/72]  eta: 0:00:13  loss: 1.4303 (1.4732)  Accuracy: 0.5625 (0.5610)  Top 5 accuracy: 0.8750 (0.8824)  lr: 0.000100  iter-time: 0.2186\n",
            "[08:20:21.739065] Epoch: [36]  [30/72]  eta: 0:00:10  loss: 1.3389 (1.4033)  Accuracy: 0.6250 (0.5877)  Top 5 accuracy: 0.9062 (0.8921)  lr: 0.000100  iter-time: 0.2172\n",
            "[08:20:23.848338] Epoch: [36]  [40/72]  eta: 0:00:07  loss: 1.3588 (1.4143)  Accuracy: 0.6250 (0.5831)  Top 5 accuracy: 0.9062 (0.8895)  lr: 0.000100  iter-time: 0.2114\n",
            "[08:20:25.952301] Epoch: [36]  [50/72]  eta: 0:00:05  loss: 1.3833 (1.4396)  Accuracy: 0.5625 (0.5790)  Top 5 accuracy: 0.9062 (0.8909)  lr: 0.000100  iter-time: 0.2105\n",
            "[08:20:28.063991] Epoch: [36]  [60/72]  eta: 0:00:02  loss: 1.3992 (1.4451)  Accuracy: 0.5312 (0.5717)  Top 5 accuracy: 0.8750 (0.8863)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:20:30.180402] Epoch: [36]  [70/72]  eta: 0:00:00  loss: 1.5225 (1.4411)  Accuracy: 0.5625 (0.5766)  Top 5 accuracy: 0.8750 (0.8895)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:20:30.335939] Epoch: [36]  [71/72]  eta: 0:00:00  loss: 1.5225 (1.4395)  Accuracy: 0.5625 (0.5776)  Top 5 accuracy: 0.8750 (0.8899)  lr: 0.000100  iter-time: 0.2085\n",
            "[08:20:30.483846] Epoch: [36] Total time: 0:00:16 (0.2262 s / it)\n",
            "[08:20:30.484020] [Train] averaged stats: loss: 1.5225 (1.4395)  Accuracy: 0.5625 (0.5776)  Top 5 accuracy: 0.8750 (0.8899)  lr: 0.000100\n",
            "[08:20:31.411054] Epoch: [36]  [0/8]  eta: 0:00:07  loss: 1.6256 (1.6256)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.9179\n",
            "[08:20:31.866817] Epoch: [36]  [7/8]  eta: 0:00:00  loss: 2.2523 (2.3675)  Accuracy: 0.4062 (0.4157)  Top 5 accuracy: 0.7500 (0.7297)  iter-time: 0.1715\n",
            "[08:20:31.965331] Epoch: [36] Total time: 0:00:01 (0.1848 s / it)\n",
            "[08:20:31.965405] [Val] averaged stats: loss: 2.2523 (2.3675)  Accuracy: 0.4062 (0.4157)  Top 5 accuracy: 0.7500 (0.7297)\n",
            "[08:20:31.965993] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 11 out of 20\n",
            "[08:20:31.967247] [Time] 17.8s 11.8m/31.1m\n",
            "\n",
            "[08:20:31.967276] ~~~ Epoch 37/100 ~~~\n",
            "\n",
            "[08:20:32.961541] Epoch: [37]  [ 0/72]  eta: 0:01:11  loss: 1.3868 (1.3868)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 0.9918\n",
            "[08:20:35.111626] Epoch: [37]  [10/72]  eta: 0:00:17  loss: 1.3915 (1.3855)  Accuracy: 0.5938 (0.5739)  Top 5 accuracy: 0.8750 (0.8920)  lr: 0.000100  iter-time: 0.2855\n",
            "[08:20:37.226933] Epoch: [37]  [20/72]  eta: 0:00:13  loss: 1.2756 (1.3627)  Accuracy: 0.5625 (0.5744)  Top 5 accuracy: 0.9062 (0.8958)  lr: 0.000100  iter-time: 0.2131\n",
            "[08:20:39.353065] Epoch: [37]  [30/72]  eta: 0:00:09  loss: 1.2567 (1.3562)  Accuracy: 0.5625 (0.5857)  Top 5 accuracy: 0.9062 (0.8942)  lr: 0.000100  iter-time: 0.2119\n",
            "[08:20:41.476280] Epoch: [37]  [40/72]  eta: 0:00:07  loss: 1.3894 (1.3748)  Accuracy: 0.5625 (0.5816)  Top 5 accuracy: 0.9062 (0.8864)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:20:43.670614] Epoch: [37]  [50/72]  eta: 0:00:05  loss: 1.4573 (1.3974)  Accuracy: 0.5625 (0.5729)  Top 5 accuracy: 0.8750 (0.8854)  lr: 0.000100  iter-time: 0.2158\n",
            "[08:20:45.882225] Epoch: [37]  [60/72]  eta: 0:00:02  loss: 1.4716 (1.4108)  Accuracy: 0.5312 (0.5743)  Top 5 accuracy: 0.8750 (0.8837)  lr: 0.000100  iter-time: 0.2202\n",
            "[08:20:47.988230] Epoch: [37]  [70/72]  eta: 0:00:00  loss: 1.4315 (1.4263)  Accuracy: 0.5312 (0.5744)  Top 5 accuracy: 0.8750 (0.8812)  lr: 0.000100  iter-time: 0.2158\n",
            "[08:20:48.151567] Epoch: [37]  [71/72]  eta: 0:00:00  loss: 1.4315 (1.4265)  Accuracy: 0.5625 (0.5767)  Top 5 accuracy: 0.8750 (0.8810)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:20:48.263813] Epoch: [37] Total time: 0:00:16 (0.2263 s / it)\n",
            "[08:20:48.264322] [Train] averaged stats: loss: 1.4315 (1.4265)  Accuracy: 0.5625 (0.5767)  Top 5 accuracy: 0.8750 (0.8810)  lr: 0.000100\n",
            "[08:20:48.719556] Epoch: [37]  [0/8]  eta: 0:00:03  loss: 2.0078 (2.0078)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.7188 (0.7187)  iter-time: 0.4523\n",
            "[08:20:49.338717] Epoch: [37]  [7/8]  eta: 0:00:00  loss: 2.3989 (2.2888)  Accuracy: 0.3750 (0.4034)  Top 5 accuracy: 0.7188 (0.7373)  iter-time: 0.1338\n",
            "[08:20:49.433806] Epoch: [37] Total time: 0:00:01 (0.1459 s / it)\n",
            "[08:20:49.433882] [Val] averaged stats: loss: 2.3989 (2.2888)  Accuracy: 0.3750 (0.4034)  Top 5 accuracy: 0.7188 (0.7373)\n",
            "[08:20:49.434301] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 12 out of 20\n",
            "[08:20:49.435543] [Time] 17.5s 12.1m/30.7m\n",
            "\n",
            "[08:20:49.435575] ~~~ Epoch 38/100 ~~~\n",
            "\n",
            "[08:20:50.236577] Epoch: [38]  [ 0/72]  eta: 0:00:57  loss: 0.9997 (0.9997)  Accuracy: 0.7188 (0.7187)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.7934\n",
            "[08:20:52.434364] Epoch: [38]  [10/72]  eta: 0:00:16  loss: 1.2277 (1.2943)  Accuracy: 0.6875 (0.6619)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 0.2717\n",
            "[08:20:54.554451] Epoch: [38]  [20/72]  eta: 0:00:12  loss: 1.4006 (1.3786)  Accuracy: 0.6250 (0.6161)  Top 5 accuracy: 0.8750 (0.8854)  lr: 0.000100  iter-time: 0.2157\n",
            "[08:20:56.744897] Epoch: [38]  [30/72]  eta: 0:00:09  loss: 1.4675 (1.3988)  Accuracy: 0.5312 (0.5958)  Top 5 accuracy: 0.8750 (0.8841)  lr: 0.000100  iter-time: 0.2154\n",
            "[08:20:58.932034] Epoch: [38]  [40/72]  eta: 0:00:07  loss: 1.3672 (1.3594)  Accuracy: 0.5625 (0.6006)  Top 5 accuracy: 0.9062 (0.8941)  lr: 0.000100  iter-time: 0.2187\n",
            "[08:21:01.054086] Epoch: [38]  [50/72]  eta: 0:00:05  loss: 1.3672 (1.3811)  Accuracy: 0.5625 (0.5956)  Top 5 accuracy: 0.9062 (0.8909)  lr: 0.000100  iter-time: 0.2153\n",
            "[08:21:03.180078] Epoch: [38]  [60/72]  eta: 0:00:02  loss: 1.4005 (1.3766)  Accuracy: 0.5625 (0.5897)  Top 5 accuracy: 0.8750 (0.8914)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:21:05.291460] Epoch: [38]  [70/72]  eta: 0:00:00  loss: 1.3874 (1.3817)  Accuracy: 0.5625 (0.5849)  Top 5 accuracy: 0.8750 (0.8908)  lr: 0.000100  iter-time: 0.2118\n",
            "[08:21:05.452698] Epoch: [38]  [71/72]  eta: 0:00:00  loss: 1.3728 (1.3796)  Accuracy: 0.5625 (0.5841)  Top 5 accuracy: 0.9062 (0.8918)  lr: 0.000100  iter-time: 0.2091\n",
            "[08:21:05.561583] Epoch: [38] Total time: 0:00:16 (0.2240 s / it)\n",
            "[08:21:05.562044] [Train] averaged stats: loss: 1.3728 (1.3796)  Accuracy: 0.5625 (0.5841)  Top 5 accuracy: 0.9062 (0.8918)  lr: 0.000100\n",
            "[08:21:06.078856] Epoch: [38]  [0/8]  eta: 0:00:04  loss: 1.8358 (1.8358)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.5138\n",
            "[08:21:06.635296] Epoch: [38]  [7/8]  eta: 0:00:00  loss: 2.0857 (2.2914)  Accuracy: 0.3438 (0.4078)  Top 5 accuracy: 0.7188 (0.7216)  iter-time: 0.1326\n",
            "[08:21:06.728239] Epoch: [38] Total time: 0:00:01 (0.1455 s / it)\n",
            "[08:21:06.728313] [Val] averaged stats: loss: 2.0857 (2.2914)  Accuracy: 0.3438 (0.4078)  Top 5 accuracy: 0.7188 (0.7216)\n",
            "[08:21:06.728810] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 13 out of 20\n",
            "[08:21:06.730154] [Time] 17.3s 12.4m/30.6m\n",
            "\n",
            "[08:21:06.730192] ~~~ Epoch 39/100 ~~~\n",
            "\n",
            "[08:21:07.670464] Epoch: [39]  [ 0/72]  eta: 0:01:07  loss: 1.8763 (1.8763)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7812 (0.7812)  lr: 0.000100  iter-time: 0.9379\n",
            "[08:21:10.007559] Epoch: [39]  [10/72]  eta: 0:00:18  loss: 1.2778 (1.3475)  Accuracy: 0.5625 (0.5682)  Top 5 accuracy: 0.9062 (0.8977)  lr: 0.000100  iter-time: 0.2975\n",
            "[08:21:12.229931] Epoch: [39]  [20/72]  eta: 0:00:13  loss: 1.2874 (1.3636)  Accuracy: 0.5938 (0.5818)  Top 5 accuracy: 0.9062 (0.8943)  lr: 0.000100  iter-time: 0.2278\n",
            "[08:21:14.342871] Epoch: [39]  [30/72]  eta: 0:00:10  loss: 1.3236 (1.3466)  Accuracy: 0.6250 (0.5847)  Top 5 accuracy: 0.9062 (0.9022)  lr: 0.000100  iter-time: 0.2166\n",
            "[08:21:16.445330] Epoch: [39]  [40/72]  eta: 0:00:07  loss: 1.2659 (1.3432)  Accuracy: 0.5938 (0.5861)  Top 5 accuracy: 0.9062 (0.9024)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:21:18.548931] Epoch: [39]  [50/72]  eta: 0:00:05  loss: 1.3497 (1.3438)  Accuracy: 0.6250 (0.5968)  Top 5 accuracy: 0.9062 (0.9013)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:21:20.661980] Epoch: [39]  [60/72]  eta: 0:00:02  loss: 1.3646 (1.3590)  Accuracy: 0.6250 (0.5948)  Top 5 accuracy: 0.8438 (0.8909)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:21:22.777180] Epoch: [39]  [70/72]  eta: 0:00:00  loss: 1.3873 (1.3700)  Accuracy: 0.5938 (0.5924)  Top 5 accuracy: 0.8438 (0.8873)  lr: 0.000100  iter-time: 0.2110\n",
            "[08:21:22.940632] Epoch: [39]  [71/72]  eta: 0:00:00  loss: 1.3873 (1.3697)  Accuracy: 0.5652 (0.5921)  Top 5 accuracy: 0.8438 (0.8877)  lr: 0.000100  iter-time: 0.2084\n",
            "[08:21:23.039579] Epoch: [39] Total time: 0:00:16 (0.2265 s / it)\n",
            "[08:21:23.039970] [Train] averaged stats: loss: 1.3873 (1.3697)  Accuracy: 0.5652 (0.5921)  Top 5 accuracy: 0.8438 (0.8877)  lr: 0.000100\n",
            "[08:21:23.536464] Epoch: [39]  [0/8]  eta: 0:00:03  loss: 1.9034 (1.9034)  Accuracy: 0.4688 (0.4687)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.4851\n",
            "[08:21:24.104122] Epoch: [39]  [7/8]  eta: 0:00:00  loss: 2.0172 (2.2521)  Accuracy: 0.4375 (0.4115)  Top 5 accuracy: 0.7500 (0.7646)  iter-time: 0.1309\n",
            "[08:21:24.198528] Epoch: [39] Total time: 0:00:01 (0.1446 s / it)\n",
            "[08:21:24.198607] [Val] averaged stats: loss: 2.0172 (2.2521)  Accuracy: 0.4375 (0.4115)  Top 5 accuracy: 0.7500 (0.7646)\n",
            "[08:21:24.199124] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 14 out of 20\n",
            "[08:21:24.200482] [Time] 17.5s 12.7m/30.7m\n",
            "\n",
            "[08:21:24.200512] ~~~ Epoch 40/100 ~~~\n",
            "\n",
            "[08:21:25.019307] Epoch: [40]  [ 0/72]  eta: 0:00:58  loss: 1.5289 (1.5289)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.8125 (0.8125)  lr: 0.000100  iter-time: 0.8166\n",
            "[08:21:27.220935] Epoch: [40]  [10/72]  eta: 0:00:17  loss: 1.3301 (1.3228)  Accuracy: 0.6250 (0.6392)  Top 5 accuracy: 0.9062 (0.8949)  lr: 0.000100  iter-time: 0.2742\n",
            "[08:21:29.313335] Epoch: [40]  [20/72]  eta: 0:00:12  loss: 1.2150 (1.2899)  Accuracy: 0.6250 (0.6429)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 0.2145\n",
            "[08:21:31.417428] Epoch: [40]  [30/72]  eta: 0:00:09  loss: 1.2150 (1.3189)  Accuracy: 0.6250 (0.6310)  Top 5 accuracy: 0.9062 (0.8992)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:21:33.531252] Epoch: [40]  [40/72]  eta: 0:00:07  loss: 1.2923 (1.3237)  Accuracy: 0.6250 (0.6341)  Top 5 accuracy: 0.9062 (0.9009)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:21:35.726062] Epoch: [40]  [50/72]  eta: 0:00:04  loss: 1.3517 (1.3335)  Accuracy: 0.5938 (0.6275)  Top 5 accuracy: 0.9062 (0.8995)  lr: 0.000100  iter-time: 0.2150\n",
            "[08:21:37.835842] Epoch: [40]  [60/72]  eta: 0:00:02  loss: 1.3286 (1.3239)  Accuracy: 0.5938 (0.6230)  Top 5 accuracy: 0.9062 (0.9022)  lr: 0.000100  iter-time: 0.2148\n",
            "[08:21:39.937470] Epoch: [40]  [70/72]  eta: 0:00:00  loss: 1.2557 (1.3174)  Accuracy: 0.6250 (0.6210)  Top 5 accuracy: 0.9062 (0.9032)  lr: 0.000100  iter-time: 0.2105\n",
            "[08:21:40.102112] Epoch: [40]  [71/72]  eta: 0:00:00  loss: 1.2739 (1.3207)  Accuracy: 0.5938 (0.6191)  Top 5 accuracy: 0.9062 (0.9027)  lr: 0.000100  iter-time: 0.2082\n",
            "[08:21:40.201186] Epoch: [40] Total time: 0:00:15 (0.2222 s / it)\n",
            "[08:21:40.201547] [Train] averaged stats: loss: 1.2739 (1.3207)  Accuracy: 0.5938 (0.6191)  Top 5 accuracy: 0.9062 (0.9027)  lr: 0.000100\n",
            "[08:21:40.672782] Epoch: [40]  [0/8]  eta: 0:00:03  loss: 1.7369 (1.7369)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.4686\n",
            "[08:21:41.241575] Epoch: [40]  [7/8]  eta: 0:00:00  loss: 1.9430 (2.2338)  Accuracy: 0.4062 (0.4233)  Top 5 accuracy: 0.7500 (0.7413)  iter-time: 0.1295\n",
            "[08:21:41.340173] Epoch: [40] Total time: 0:00:01 (0.1421 s / it)\n",
            "[08:21:41.340250] [Val] averaged stats: loss: 1.9430 (2.2338)  Accuracy: 0.4062 (0.4233)  Top 5 accuracy: 0.7500 (0.7413)\n",
            "[08:21:41.340837] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "[08:21:41.342183] Creating training plots . . .\n",
            "EarlyStopping counter: 15 out of 20\n",
            "[08:21:41.669515] [Time] 17.5s 13.0m/30.7m\n",
            "\n",
            "[08:21:41.669550] ~~~ Epoch 41/100 ~~~\n",
            "\n",
            "[08:21:42.495506] Epoch: [41]  [ 0/72]  eta: 0:00:59  loss: 1.1521 (1.1521)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 0.8233\n",
            "[08:21:44.645231] Epoch: [41]  [10/72]  eta: 0:00:16  loss: 1.3370 (1.3103)  Accuracy: 0.5938 (0.5994)  Top 5 accuracy: 0.9375 (0.9148)  lr: 0.000100  iter-time: 0.2694\n",
            "[08:21:46.779868] Epoch: [41]  [20/72]  eta: 0:00:12  loss: 1.3122 (1.3128)  Accuracy: 0.5938 (0.5997)  Top 5 accuracy: 0.9062 (0.9107)  lr: 0.000100  iter-time: 0.2137\n",
            "[08:21:48.978368] Epoch: [41]  [30/72]  eta: 0:00:09  loss: 1.1812 (1.2981)  Accuracy: 0.6250 (0.6200)  Top 5 accuracy: 0.9062 (0.9042)  lr: 0.000100  iter-time: 0.2164\n",
            "[08:21:51.101294] Epoch: [41]  [40/72]  eta: 0:00:07  loss: 1.2096 (1.3005)  Accuracy: 0.6562 (0.6280)  Top 5 accuracy: 0.9062 (0.8994)  lr: 0.000100  iter-time: 0.2158\n",
            "[08:21:53.202676] Epoch: [41]  [50/72]  eta: 0:00:04  loss: 1.3379 (1.3226)  Accuracy: 0.5938 (0.6183)  Top 5 accuracy: 0.9062 (0.9020)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:21:55.307702] Epoch: [41]  [60/72]  eta: 0:00:02  loss: 1.4055 (1.3655)  Accuracy: 0.5625 (0.6066)  Top 5 accuracy: 0.9062 (0.8950)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:21:57.404878] Epoch: [41]  [70/72]  eta: 0:00:00  loss: 1.4175 (1.3809)  Accuracy: 0.5625 (0.6021)  Top 5 accuracy: 0.8750 (0.8930)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:21:57.568625] Epoch: [41]  [71/72]  eta: 0:00:00  loss: 1.4073 (1.3792)  Accuracy: 0.5625 (0.6022)  Top 5 accuracy: 0.8750 (0.8939)  lr: 0.000100  iter-time: 0.2077\n",
            "[08:21:57.668175] Epoch: [41] Total time: 0:00:15 (0.2222 s / it)\n",
            "[08:21:57.668537] [Train] averaged stats: loss: 1.4073 (1.3792)  Accuracy: 0.5625 (0.6022)  Top 5 accuracy: 0.8750 (0.8939)  lr: 0.000100\n",
            "[08:21:58.272096] Epoch: [41]  [0/8]  eta: 0:00:04  loss: 1.8617 (1.8617)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.6010\n",
            "[08:21:58.718803] Epoch: [41]  [7/8]  eta: 0:00:00  loss: 2.4009 (2.4649)  Accuracy: 0.4062 (0.4114)  Top 5 accuracy: 0.7500 (0.7181)  iter-time: 0.1307\n",
            "[08:21:58.880290] Epoch: [41] Total time: 0:00:01 (0.1512 s / it)\n",
            "[08:21:58.880387] [Val] averaged stats: loss: 2.4009 (2.4649)  Accuracy: 0.4062 (0.4114)  Top 5 accuracy: 0.7500 (0.7181)\n",
            "[08:21:58.881002] [Val] best loss: 2.1490 best  Accuracy: 0.3959 Top 5 accuracy: 0.7492 \n",
            "EarlyStopping counter: 16 out of 20\n",
            "[08:21:58.881774] [Time] 17.2s 13.3m/30.5m\n",
            "\n",
            "[08:21:58.881818] ~~~ Epoch 42/100 ~~~\n",
            "\n",
            "[08:22:00.468019] Epoch: [42]  [ 0/72]  eta: 0:01:53  loss: 0.9814 (0.9814)  Accuracy: 0.7188 (0.7187)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 1.5778\n",
            "[08:22:02.674583] Epoch: [42]  [10/72]  eta: 0:00:21  loss: 1.2671 (1.2575)  Accuracy: 0.6562 (0.6364)  Top 5 accuracy: 0.8750 (0.8864)  lr: 0.000100  iter-time: 0.3436\n",
            "[08:22:04.787640] Epoch: [42]  [20/72]  eta: 0:00:14  loss: 1.2363 (1.2123)  Accuracy: 0.6562 (0.6458)  Top 5 accuracy: 0.9062 (0.9077)  lr: 0.000100  iter-time: 0.2157\n",
            "[08:22:06.890659] Epoch: [42]  [30/72]  eta: 0:00:10  loss: 1.2256 (1.2460)  Accuracy: 0.6250 (0.6331)  Top 5 accuracy: 0.9062 (0.9052)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:22:09.003244] Epoch: [42]  [40/72]  eta: 0:00:07  loss: 1.2073 (1.2597)  Accuracy: 0.6250 (0.6387)  Top 5 accuracy: 0.9062 (0.9047)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:22:11.121093] Epoch: [42]  [50/72]  eta: 0:00:05  loss: 1.2791 (1.2714)  Accuracy: 0.6250 (0.6256)  Top 5 accuracy: 0.9062 (0.9038)  lr: 0.000100  iter-time: 0.2114\n",
            "[08:22:13.337289] Epoch: [42]  [60/72]  eta: 0:00:02  loss: 1.2991 (1.2983)  Accuracy: 0.6250 (0.6255)  Top 5 accuracy: 0.9062 (0.8991)  lr: 0.000100  iter-time: 0.2166\n",
            "[08:22:15.491210] Epoch: [42]  [70/72]  eta: 0:00:00  loss: 1.2494 (1.2946)  Accuracy: 0.6250 (0.6272)  Top 5 accuracy: 0.9062 (0.8988)  lr: 0.000100  iter-time: 0.2184\n",
            "[08:22:15.652714] Epoch: [42]  [71/72]  eta: 0:00:00  loss: 1.2494 (1.2932)  Accuracy: 0.6250 (0.6275)  Top 5 accuracy: 0.9062 (0.8990)  lr: 0.000100  iter-time: 0.2160\n",
            "[08:22:15.756235] Epoch: [42] Total time: 0:00:16 (0.2343 s / it)\n",
            "[08:22:15.756621] [Train] averaged stats: loss: 1.2494 (1.2932)  Accuracy: 0.6250 (0.6275)  Top 5 accuracy: 0.9062 (0.8990)  lr: 0.000100\n",
            "[08:22:16.386515] Epoch: [42]  [0/8]  eta: 0:00:05  loss: 1.6073 (1.6073)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.6272\n",
            "[08:22:16.854139] Epoch: [42]  [7/8]  eta: 0:00:00  loss: 2.0638 (2.0684)  Accuracy: 0.4688 (0.4779)  Top 5 accuracy: 0.7500 (0.7610)  iter-time: 0.1359\n",
            "[08:22:16.946885] Epoch: [42] Total time: 0:00:01 (0.1485 s / it)\n",
            "[08:22:16.946961] [Val] averaged stats: loss: 2.0638 (2.0684)  Accuracy: 0.4688 (0.4779)  Top 5 accuracy: 0.7500 (0.7610)\n",
            "[08:22:16.947594] Val loss improved from 2.1489836424589157 to 2.0684173852205276, saving model to /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:22:21.930033] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "[08:22:21.931900] [Time] 23.1s 13.7m/36.3m\n",
            "\n",
            "[08:22:21.931972] ~~~ Epoch 43/100 ~~~\n",
            "\n",
            "[08:22:22.901167] Epoch: [43]  [ 0/72]  eta: 0:01:09  loss: 0.7931 (0.7931)  Accuracy: 0.8125 (0.8125)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.9646\n",
            "[08:22:25.095759] Epoch: [43]  [10/72]  eta: 0:00:17  loss: 1.1487 (1.1690)  Accuracy: 0.6250 (0.6420)  Top 5 accuracy: 0.9375 (0.9233)  lr: 0.000100  iter-time: 0.2867\n",
            "[08:22:27.360959] Epoch: [43]  [20/72]  eta: 0:00:13  loss: 1.2912 (1.2764)  Accuracy: 0.6250 (0.6190)  Top 5 accuracy: 0.9062 (0.9048)  lr: 0.000100  iter-time: 0.2226\n",
            "[08:22:29.460906] Epoch: [43]  [30/72]  eta: 0:00:10  loss: 1.2300 (1.2884)  Accuracy: 0.6250 (0.6210)  Top 5 accuracy: 0.9062 (0.8992)  lr: 0.000100  iter-time: 0.2181\n",
            "[08:22:31.571445] Epoch: [43]  [40/72]  eta: 0:00:07  loss: 1.1766 (1.2757)  Accuracy: 0.6250 (0.6212)  Top 5 accuracy: 0.9062 (0.9002)  lr: 0.000100  iter-time: 0.2104\n",
            "[08:22:33.688145] Epoch: [43]  [50/72]  eta: 0:00:05  loss: 1.1922 (1.2621)  Accuracy: 0.6250 (0.6201)  Top 5 accuracy: 0.9062 (0.9075)  lr: 0.000100  iter-time: 0.2112\n",
            "[08:22:35.811866] Epoch: [43]  [60/72]  eta: 0:00:02  loss: 1.3257 (1.2925)  Accuracy: 0.5625 (0.6127)  Top 5 accuracy: 0.9062 (0.9022)  lr: 0.000100  iter-time: 0.2119\n",
            "[08:22:37.938277] Epoch: [43]  [70/72]  eta: 0:00:00  loss: 1.3257 (1.2856)  Accuracy: 0.6250 (0.6162)  Top 5 accuracy: 0.8750 (0.9027)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:22:38.104305] Epoch: [43]  [71/72]  eta: 0:00:00  loss: 1.3175 (1.2787)  Accuracy: 0.6250 (0.6185)  Top 5 accuracy: 0.8750 (0.9041)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:22:38.271443] Epoch: [43] Total time: 0:00:16 (0.2269 s / it)\n",
            "[08:22:38.272362] [Train] averaged stats: loss: 1.3175 (1.2787)  Accuracy: 0.6250 (0.6185)  Top 5 accuracy: 0.8750 (0.9041)  lr: 0.000100\n",
            "[08:22:39.205131] Epoch: [43]  [0/8]  eta: 0:00:07  loss: 1.8853 (1.8853)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.9231\n",
            "[08:22:39.682075] Epoch: [43]  [7/8]  eta: 0:00:00  loss: 2.0960 (2.1778)  Accuracy: 0.4688 (0.4425)  Top 5 accuracy: 0.8125 (0.8039)  iter-time: 0.1748\n",
            "[08:22:39.791984] Epoch: [43] Total time: 0:00:01 (0.1896 s / it)\n",
            "[08:22:39.792058] [Val] averaged stats: loss: 2.0960 (2.1778)  Accuracy: 0.4688 (0.4425)  Top 5 accuracy: 0.8125 (0.8039)\n",
            "[08:22:39.792510] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[08:22:39.793717] [Time] 17.9s 14.0m/31.2m\n",
            "\n",
            "[08:22:39.793783] ~~~ Epoch 44/100 ~~~\n",
            "\n",
            "[08:22:40.691178] Epoch: [44]  [ 0/72]  eta: 0:01:04  loss: 0.9608 (0.9608)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 0.8927\n",
            "[08:22:42.856142] Epoch: [44]  [10/72]  eta: 0:00:17  loss: 1.2131 (1.2183)  Accuracy: 0.6250 (0.6335)  Top 5 accuracy: 0.9375 (0.9119)  lr: 0.000100  iter-time: 0.2775\n",
            "[08:22:45.003098] Epoch: [44]  [20/72]  eta: 0:00:12  loss: 1.2123 (1.2184)  Accuracy: 0.6250 (0.6369)  Top 5 accuracy: 0.9375 (0.9301)  lr: 0.000100  iter-time: 0.2153\n",
            "[08:22:47.149717] Epoch: [44]  [30/72]  eta: 0:00:09  loss: 1.1170 (1.1725)  Accuracy: 0.6562 (0.6502)  Top 5 accuracy: 0.9375 (0.9304)  lr: 0.000100  iter-time: 0.2146\n",
            "[08:22:49.281224] Epoch: [44]  [40/72]  eta: 0:00:07  loss: 1.0372 (1.1617)  Accuracy: 0.6875 (0.6524)  Top 5 accuracy: 0.9375 (0.9306)  lr: 0.000100  iter-time: 0.2138\n",
            "[08:22:51.514000] Epoch: [44]  [50/72]  eta: 0:00:05  loss: 1.1755 (1.1949)  Accuracy: 0.6250 (0.6440)  Top 5 accuracy: 0.9375 (0.9216)  lr: 0.000100  iter-time: 0.2181\n",
            "[08:22:53.730944] Epoch: [44]  [60/72]  eta: 0:00:02  loss: 1.4003 (1.2287)  Accuracy: 0.5938 (0.6342)  Top 5 accuracy: 0.8438 (0.9129)  lr: 0.000100  iter-time: 0.2224\n",
            "[08:22:55.856024] Epoch: [44]  [70/72]  eta: 0:00:00  loss: 1.4003 (1.2495)  Accuracy: 0.5625 (0.6263)  Top 5 accuracy: 0.8750 (0.9085)  lr: 0.000100  iter-time: 0.2170\n",
            "[08:22:56.019255] Epoch: [44]  [71/72]  eta: 0:00:00  loss: 1.3262 (1.2439)  Accuracy: 0.5938 (0.6273)  Top 5 accuracy: 0.8750 (0.9091)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:22:56.122719] Epoch: [44] Total time: 0:00:16 (0.2268 s / it)\n",
            "[08:22:56.123173] [Train] averaged stats: loss: 1.3262 (1.2439)  Accuracy: 0.5938 (0.6273)  Top 5 accuracy: 0.8750 (0.9091)  lr: 0.000100\n",
            "[08:22:56.654895] Epoch: [44]  [0/8]  eta: 0:00:04  loss: 1.7449 (1.7449)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.5290\n",
            "[08:22:57.197566] Epoch: [44]  [7/8]  eta: 0:00:00  loss: 2.5095 (2.4847)  Accuracy: 0.3226 (0.3997)  Top 5 accuracy: 0.6562 (0.7016)  iter-time: 0.1337\n",
            "[08:22:57.290273] Epoch: [44] Total time: 0:00:01 (0.1456 s / it)\n",
            "[08:22:57.290344] [Val] averaged stats: loss: 2.5095 (2.4847)  Accuracy: 0.3226 (0.3997)  Top 5 accuracy: 0.6562 (0.7016)\n",
            "[08:22:57.290865] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[08:22:57.292225] [Time] 17.5s 14.2m/30.9m\n",
            "\n",
            "[08:22:57.292256] ~~~ Epoch 45/100 ~~~\n",
            "\n",
            "[08:22:58.363218] Epoch: [45]  [ 0/72]  eta: 0:01:16  loss: 1.4912 (1.4912)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8438 (0.8437)  lr: 0.000100  iter-time: 1.0616\n",
            "[08:23:00.519594] Epoch: [45]  [10/72]  eta: 0:00:18  loss: 1.1314 (1.1021)  Accuracy: 0.6562 (0.6847)  Top 5 accuracy: 0.9375 (0.9318)  lr: 0.000100  iter-time: 0.2924\n",
            "[08:23:02.653152] Epoch: [45]  [20/72]  eta: 0:00:13  loss: 1.1533 (1.1877)  Accuracy: 0.6562 (0.6533)  Top 5 accuracy: 0.9375 (0.9286)  lr: 0.000100  iter-time: 0.2143\n",
            "[08:23:04.858880] Epoch: [45]  [30/72]  eta: 0:00:10  loss: 1.2126 (1.1996)  Accuracy: 0.6250 (0.6462)  Top 5 accuracy: 0.9375 (0.9284)  lr: 0.000100  iter-time: 0.2168\n",
            "[08:23:07.002502] Epoch: [45]  [40/72]  eta: 0:00:07  loss: 1.2126 (1.2200)  Accuracy: 0.6250 (0.6456)  Top 5 accuracy: 0.9062 (0.9200)  lr: 0.000100  iter-time: 0.2173\n",
            "[08:23:09.108339] Epoch: [45]  [50/72]  eta: 0:00:05  loss: 1.1423 (1.2104)  Accuracy: 0.6562 (0.6458)  Top 5 accuracy: 0.9062 (0.9197)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:23:11.234468] Epoch: [45]  [60/72]  eta: 0:00:02  loss: 1.1497 (1.2109)  Accuracy: 0.6562 (0.6460)  Top 5 accuracy: 0.9062 (0.9206)  lr: 0.000100  iter-time: 0.2115\n",
            "[08:23:13.335078] Epoch: [45]  [70/72]  eta: 0:00:00  loss: 1.1106 (1.1877)  Accuracy: 0.6562 (0.6527)  Top 5 accuracy: 0.9375 (0.9212)  lr: 0.000100  iter-time: 0.2112\n",
            "[08:23:13.498566] Epoch: [45]  [71/72]  eta: 0:00:00  loss: 1.1142 (1.1869)  Accuracy: 0.6562 (0.6515)  Top 5 accuracy: 0.9375 (0.9217)  lr: 0.000100  iter-time: 0.2088\n",
            "[08:23:13.596966] Epoch: [45] Total time: 0:00:16 (0.2264 s / it)\n",
            "[08:23:13.597342] [Train] averaged stats: loss: 1.1142 (1.1869)  Accuracy: 0.6562 (0.6515)  Top 5 accuracy: 0.9375 (0.9217)  lr: 0.000100\n",
            "[08:23:14.211927] Epoch: [45]  [0/8]  eta: 0:00:04  loss: 1.6543 (1.6543)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.8750 (0.8750)  iter-time: 0.6120\n",
            "[08:23:14.666594] Epoch: [45]  [7/8]  eta: 0:00:00  loss: 2.0984 (2.1761)  Accuracy: 0.4062 (0.4235)  Top 5 accuracy: 0.7812 (0.7729)  iter-time: 0.1332\n",
            "[08:23:14.759245] Epoch: [45] Total time: 0:00:01 (0.1450 s / it)\n",
            "[08:23:14.759321] [Val] averaged stats: loss: 2.0984 (2.1761)  Accuracy: 0.4062 (0.4235)  Top 5 accuracy: 0.7812 (0.7729)\n",
            "[08:23:14.759965] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "[08:23:14.761129] Creating training plots . . .\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[08:23:15.070726] [Time] 17.8s 14.5m/31.1m\n",
            "\n",
            "[08:23:15.070771] ~~~ Epoch 46/100 ~~~\n",
            "\n",
            "[08:23:16.319906] Epoch: [46]  [ 0/72]  eta: 0:01:29  loss: 1.3730 (1.3730)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 1.2473\n",
            "[08:23:18.596806] Epoch: [46]  [10/72]  eta: 0:00:19  loss: 1.0911 (1.1238)  Accuracy: 0.6562 (0.6733)  Top 5 accuracy: 0.9375 (0.9205)  lr: 0.000100  iter-time: 0.3192\n",
            "[08:23:20.718983] Epoch: [46]  [20/72]  eta: 0:00:13  loss: 1.0788 (1.1539)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.9375 (0.9241)  lr: 0.000100  iter-time: 0.2193\n",
            "[08:23:22.810055] Epoch: [46]  [30/72]  eta: 0:00:10  loss: 1.1733 (1.1806)  Accuracy: 0.6250 (0.6552)  Top 5 accuracy: 0.9375 (0.9234)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:23:24.896568] Epoch: [46]  [40/72]  eta: 0:00:07  loss: 1.1742 (1.1768)  Accuracy: 0.6250 (0.6540)  Top 5 accuracy: 0.9062 (0.9223)  lr: 0.000100  iter-time: 0.2088\n",
            "[08:23:26.992763] Epoch: [46]  [50/72]  eta: 0:00:05  loss: 1.1479 (1.1935)  Accuracy: 0.6250 (0.6489)  Top 5 accuracy: 0.9062 (0.9179)  lr: 0.000100  iter-time: 0.2090\n",
            "[08:23:29.104257] Epoch: [46]  [60/72]  eta: 0:00:02  loss: 1.1953 (1.1864)  Accuracy: 0.6250 (0.6496)  Top 5 accuracy: 0.9062 (0.9196)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:23:31.209974] Epoch: [46]  [70/72]  eta: 0:00:00  loss: 1.2185 (1.2019)  Accuracy: 0.6250 (0.6448)  Top 5 accuracy: 0.9062 (0.9173)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:23:31.372513] Epoch: [46]  [71/72]  eta: 0:00:00  loss: 1.1667 (1.1978)  Accuracy: 0.6250 (0.6455)  Top 5 accuracy: 0.9062 (0.9184)  lr: 0.000100  iter-time: 0.2086\n",
            "[08:23:31.468880] Epoch: [46] Total time: 0:00:16 (0.2277 s / it)\n",
            "[08:23:31.469229] [Train] averaged stats: loss: 1.1667 (1.1978)  Accuracy: 0.6250 (0.6455)  Top 5 accuracy: 0.9062 (0.9184)  lr: 0.000100\n",
            "[08:23:31.842664] Epoch: [46]  [0/8]  eta: 0:00:02  loss: 1.6500 (1.6500)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8750 (0.8750)  iter-time: 0.3708\n",
            "[08:23:32.557381] Epoch: [46]  [7/8]  eta: 0:00:00  loss: 2.1306 (2.2556)  Accuracy: 0.4062 (0.4312)  Top 5 accuracy: 0.7500 (0.7453)  iter-time: 0.1352\n",
            "[08:23:32.649521] Epoch: [46] Total time: 0:00:01 (0.1473 s / it)\n",
            "[08:23:32.649597] [Val] averaged stats: loss: 2.1306 (2.2556)  Accuracy: 0.4062 (0.4312)  Top 5 accuracy: 0.7500 (0.7453)\n",
            "[08:23:32.650128] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[08:23:32.651446] [Time] 17.6s 14.8m/30.9m\n",
            "\n",
            "[08:23:32.651478] ~~~ Epoch 47/100 ~~~\n",
            "\n",
            "[08:23:33.568932] Epoch: [47]  [ 0/72]  eta: 0:01:05  loss: 1.0586 (1.0586)  Accuracy: 0.7188 (0.7187)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.9107\n",
            "[08:23:35.702497] Epoch: [47]  [10/72]  eta: 0:00:17  loss: 1.0490 (1.0937)  Accuracy: 0.6250 (0.6534)  Top 5 accuracy: 0.9375 (0.9489)  lr: 0.000100  iter-time: 0.2766\n",
            "[08:23:37.793482] Epoch: [47]  [20/72]  eta: 0:00:12  loss: 1.1890 (1.1932)  Accuracy: 0.6250 (0.6384)  Top 5 accuracy: 0.9375 (0.9315)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:23:39.881793] Epoch: [47]  [30/72]  eta: 0:00:09  loss: 1.2109 (1.1886)  Accuracy: 0.6250 (0.6381)  Top 5 accuracy: 0.9062 (0.9254)  lr: 0.000100  iter-time: 0.2089\n",
            "[08:23:42.026847] Epoch: [47]  [40/72]  eta: 0:00:07  loss: 1.2004 (1.2011)  Accuracy: 0.6250 (0.6296)  Top 5 accuracy: 0.9062 (0.9276)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:23:44.219238] Epoch: [47]  [50/72]  eta: 0:00:04  loss: 1.0631 (1.1685)  Accuracy: 0.6250 (0.6397)  Top 5 accuracy: 0.9375 (0.9314)  lr: 0.000100  iter-time: 0.2166\n",
            "[08:23:46.330334] Epoch: [47]  [60/72]  eta: 0:00:02  loss: 1.0626 (1.1576)  Accuracy: 0.6875 (0.6481)  Top 5 accuracy: 0.9375 (0.9339)  lr: 0.000100  iter-time: 0.2149\n",
            "[08:23:48.433651] Epoch: [47]  [70/72]  eta: 0:00:00  loss: 1.1557 (1.1649)  Accuracy: 0.6875 (0.6474)  Top 5 accuracy: 0.9375 (0.9335)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:23:48.596825] Epoch: [47]  [71/72]  eta: 0:00:00  loss: 1.1509 (1.1642)  Accuracy: 0.6875 (0.6469)  Top 5 accuracy: 0.9375 (0.9339)  lr: 0.000100  iter-time: 0.2081\n",
            "[08:23:48.694004] Epoch: [47] Total time: 0:00:16 (0.2228 s / it)\n",
            "[08:23:48.694378] [Train] averaged stats: loss: 1.1509 (1.1642)  Accuracy: 0.6875 (0.6469)  Top 5 accuracy: 0.9375 (0.9339)  lr: 0.000100\n",
            "[08:23:49.209721] Epoch: [47]  [0/8]  eta: 0:00:04  loss: 1.6291 (1.6291)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.5118\n",
            "[08:23:49.752587] Epoch: [47]  [7/8]  eta: 0:00:00  loss: 2.2362 (2.1884)  Accuracy: 0.3750 (0.4079)  Top 5 accuracy: 0.7812 (0.7841)  iter-time: 0.1311\n",
            "[08:23:49.843646] Epoch: [47] Total time: 0:00:01 (0.1433 s / it)\n",
            "[08:23:49.843724] [Val] averaged stats: loss: 2.2362 (2.1884)  Accuracy: 0.3750 (0.4079)  Top 5 accuracy: 0.7812 (0.7841)\n",
            "[08:23:49.844201] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[08:23:49.845525] [Time] 17.2s 15.1m/30.6m\n",
            "\n",
            "[08:23:49.845558] ~~~ Epoch 48/100 ~~~\n",
            "\n",
            "[08:23:50.903577] Epoch: [48]  [ 0/72]  eta: 0:01:15  loss: 0.7937 (0.7937)  Accuracy: 0.7812 (0.7812)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 1.0554\n",
            "[08:23:53.028112] Epoch: [48]  [10/72]  eta: 0:00:17  loss: 1.0156 (1.0796)  Accuracy: 0.7500 (0.7017)  Top 5 accuracy: 0.9375 (0.9233)  lr: 0.000100  iter-time: 0.2890\n",
            "[08:23:55.177729] Epoch: [48]  [20/72]  eta: 0:00:13  loss: 1.0494 (1.0775)  Accuracy: 0.6562 (0.6771)  Top 5 accuracy: 0.9375 (0.9286)  lr: 0.000100  iter-time: 0.2136\n",
            "[08:23:57.402156] Epoch: [48]  [30/72]  eta: 0:00:10  loss: 1.0494 (1.0900)  Accuracy: 0.6250 (0.6683)  Top 5 accuracy: 0.9375 (0.9315)  lr: 0.000100  iter-time: 0.2182\n",
            "[08:23:59.532846] Epoch: [48]  [40/72]  eta: 0:00:07  loss: 1.0640 (1.1184)  Accuracy: 0.6562 (0.6608)  Top 5 accuracy: 0.9375 (0.9261)  lr: 0.000100  iter-time: 0.2173\n",
            "[08:24:01.647066] Epoch: [48]  [50/72]  eta: 0:00:05  loss: 1.1611 (1.1504)  Accuracy: 0.6250 (0.6501)  Top 5 accuracy: 0.9062 (0.9210)  lr: 0.000100  iter-time: 0.2121\n",
            "[08:24:03.762034] Epoch: [48]  [60/72]  eta: 0:00:02  loss: 1.1611 (1.1505)  Accuracy: 0.6562 (0.6542)  Top 5 accuracy: 0.9062 (0.9201)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:24:05.885833] Epoch: [48]  [70/72]  eta: 0:00:00  loss: 1.1711 (1.1633)  Accuracy: 0.6250 (0.6492)  Top 5 accuracy: 0.9062 (0.9203)  lr: 0.000100  iter-time: 0.2118\n",
            "[08:24:06.050648] Epoch: [48]  [71/72]  eta: 0:00:00  loss: 1.1572 (1.1627)  Accuracy: 0.6250 (0.6480)  Top 5 accuracy: 0.9062 (0.9208)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:24:06.151219] Epoch: [48] Total time: 0:00:16 (0.2264 s / it)\n",
            "[08:24:06.151597] [Train] averaged stats: loss: 1.1572 (1.1627)  Accuracy: 0.6250 (0.6480)  Top 5 accuracy: 0.9062 (0.9208)  lr: 0.000100\n",
            "[08:24:06.770563] Epoch: [48]  [0/8]  eta: 0:00:04  loss: 1.4711 (1.4711)  Accuracy: 0.6875 (0.6875)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.6051\n",
            "[08:24:07.310929] Epoch: [48]  [7/8]  eta: 0:00:00  loss: 2.0938 (2.2484)  Accuracy: 0.3438 (0.4270)  Top 5 accuracy: 0.7419 (0.7451)  iter-time: 0.1427\n",
            "[08:24:07.458502] Epoch: [48] Total time: 0:00:01 (0.1631 s / it)\n",
            "[08:24:07.458596] [Val] averaged stats: loss: 2.0938 (2.2484)  Accuracy: 0.3438 (0.4270)  Top 5 accuracy: 0.7419 (0.7451)\n",
            "[08:24:07.459715] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[08:24:07.460543] [Time] 17.6s 15.4m/31.0m\n",
            "\n",
            "[08:24:07.460587] ~~~ Epoch 49/100 ~~~\n",
            "\n",
            "[08:24:08.828353] Epoch: [49]  [ 0/72]  eta: 0:01:38  loss: 1.2450 (1.2450)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 1.3634\n",
            "[08:24:11.041844] Epoch: [49]  [10/72]  eta: 0:00:20  loss: 1.1194 (1.1501)  Accuracy: 0.6875 (0.6648)  Top 5 accuracy: 0.9375 (0.9205)  lr: 0.000100  iter-time: 0.3244\n",
            "[08:24:13.177200] Epoch: [49]  [20/72]  eta: 0:00:14  loss: 1.1194 (1.1516)  Accuracy: 0.6875 (0.6667)  Top 5 accuracy: 0.9375 (0.9196)  lr: 0.000100  iter-time: 0.2169\n",
            "[08:24:15.286634] Epoch: [49]  [30/72]  eta: 0:00:10  loss: 1.1602 (1.1527)  Accuracy: 0.6562 (0.6593)  Top 5 accuracy: 0.9375 (0.9133)  lr: 0.000100  iter-time: 0.2121\n",
            "[08:24:17.391539] Epoch: [49]  [40/72]  eta: 0:00:07  loss: 1.0152 (1.1327)  Accuracy: 0.6562 (0.6692)  Top 5 accuracy: 0.9375 (0.9184)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:24:19.510321] Epoch: [49]  [50/72]  eta: 0:00:05  loss: 1.0609 (1.1439)  Accuracy: 0.6562 (0.6654)  Top 5 accuracy: 0.9375 (0.9179)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:24:21.707963] Epoch: [49]  [60/72]  eta: 0:00:02  loss: 1.1862 (1.1584)  Accuracy: 0.6250 (0.6603)  Top 5 accuracy: 0.9375 (0.9201)  lr: 0.000100  iter-time: 0.2157\n",
            "[08:24:23.827242] Epoch: [49]  [70/72]  eta: 0:00:00  loss: 1.2406 (1.1794)  Accuracy: 0.6250 (0.6554)  Top 5 accuracy: 0.9375 (0.9195)  lr: 0.000100  iter-time: 0.2157\n",
            "[08:24:23.986871] Epoch: [49]  [71/72]  eta: 0:00:00  loss: 1.2406 (1.1822)  Accuracy: 0.6250 (0.6535)  Top 5 accuracy: 0.9375 (0.9194)  lr: 0.000100  iter-time: 0.2131\n",
            "[08:24:24.086510] Epoch: [49] Total time: 0:00:16 (0.2309 s / it)\n",
            "[08:24:24.086926] [Train] averaged stats: loss: 1.2406 (1.1822)  Accuracy: 0.6250 (0.6535)  Top 5 accuracy: 0.9375 (0.9194)  lr: 0.000100\n",
            "[08:24:24.671134] Epoch: [49]  [0/8]  eta: 0:00:04  loss: 2.1989 (2.1989)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.5804\n",
            "[08:24:25.132466] Epoch: [49]  [7/8]  eta: 0:00:00  loss: 2.1989 (2.3171)  Accuracy: 0.4375 (0.4347)  Top 5 accuracy: 0.7500 (0.7371)  iter-time: 0.1301\n",
            "[08:24:25.230359] Epoch: [49] Total time: 0:00:01 (0.1427 s / it)\n",
            "[08:24:25.230440] [Val] averaged stats: loss: 2.1989 (2.3171)  Accuracy: 0.4375 (0.4347)  Top 5 accuracy: 0.7500 (0.7371)\n",
            "[08:24:25.230974] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[08:24:25.232283] [Time] 17.8s 15.7m/31.1m\n",
            "\n",
            "[08:24:25.232315] ~~~ Epoch 50/100 ~~~\n",
            "\n",
            "[08:24:26.216370] Epoch: [50]  [ 0/72]  eta: 0:01:10  loss: 1.1515 (1.1515)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 0.9796\n",
            "[08:24:28.352468] Epoch: [50]  [10/72]  eta: 0:00:17  loss: 0.9704 (1.0189)  Accuracy: 0.7500 (0.7102)  Top 5 accuracy: 0.9375 (0.9347)  lr: 0.000100  iter-time: 0.2831\n",
            "[08:24:30.456325] Epoch: [50]  [20/72]  eta: 0:00:12  loss: 1.0173 (1.0645)  Accuracy: 0.6875 (0.6845)  Top 5 accuracy: 0.9375 (0.9330)  lr: 0.000100  iter-time: 0.2119\n",
            "[08:24:32.574465] Epoch: [50]  [30/72]  eta: 0:00:09  loss: 1.2038 (1.1270)  Accuracy: 0.6562 (0.6643)  Top 5 accuracy: 0.9375 (0.9294)  lr: 0.000100  iter-time: 0.2110\n",
            "[08:24:34.819385] Epoch: [50]  [40/72]  eta: 0:00:07  loss: 1.0146 (1.0838)  Accuracy: 0.6875 (0.6799)  Top 5 accuracy: 0.9375 (0.9360)  lr: 0.000100  iter-time: 0.2178\n",
            "[08:24:36.950909] Epoch: [50]  [50/72]  eta: 0:00:05  loss: 1.0146 (1.0956)  Accuracy: 0.6875 (0.6777)  Top 5 accuracy: 0.9375 (0.9332)  lr: 0.000100  iter-time: 0.2182\n",
            "[08:24:39.048753] Epoch: [50]  [60/72]  eta: 0:00:02  loss: 1.0486 (1.0845)  Accuracy: 0.7188 (0.6839)  Top 5 accuracy: 0.9062 (0.9314)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:24:41.151507] Epoch: [50]  [70/72]  eta: 0:00:00  loss: 1.0798 (1.1011)  Accuracy: 0.6875 (0.6783)  Top 5 accuracy: 0.9375 (0.9300)  lr: 0.000100  iter-time: 0.2099\n",
            "[08:24:41.310693] Epoch: [50]  [71/72]  eta: 0:00:00  loss: 1.1021 (1.1019)  Accuracy: 0.6562 (0.6773)  Top 5 accuracy: 0.9375 (0.9310)  lr: 0.000100  iter-time: 0.2074\n",
            "[08:24:41.408054] Epoch: [50] Total time: 0:00:16 (0.2246 s / it)\n",
            "[08:24:41.408408] [Train] averaged stats: loss: 1.1021 (1.1019)  Accuracy: 0.6562 (0.6773)  Top 5 accuracy: 0.9375 (0.9310)  lr: 0.000100\n",
            "[08:24:42.167096] Epoch: [50]  [0/8]  eta: 0:00:06  loss: 1.5068 (1.5068)  Accuracy: 0.6250 (0.6250)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.7561\n",
            "[08:24:42.610063] Epoch: [50]  [7/8]  eta: 0:00:00  loss: 2.2338 (2.3334)  Accuracy: 0.4062 (0.4117)  Top 5 accuracy: 0.7500 (0.7409)  iter-time: 0.1497\n",
            "[08:24:42.714575] Epoch: [50] Total time: 0:00:01 (0.1630 s / it)\n",
            "[08:24:42.714648] [Val] averaged stats: loss: 2.2338 (2.3334)  Accuracy: 0.4062 (0.4117)  Top 5 accuracy: 0.7500 (0.7409)\n",
            "[08:24:42.715137] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "[08:24:42.716523] Creating training plots . . .\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[08:24:43.025556] [Time] 17.8s 16.0m/31.1m\n",
            "\n",
            "[08:24:43.025605] ~~~ Epoch 51/100 ~~~\n",
            "\n",
            "[08:24:43.939710] Epoch: [51]  [ 0/72]  eta: 0:01:05  loss: 0.7587 (0.7587)  Accuracy: 0.7500 (0.7500)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 0.9115\n",
            "[08:24:46.144717] Epoch: [51]  [10/72]  eta: 0:00:17  loss: 0.9380 (0.9613)  Accuracy: 0.7188 (0.7074)  Top 5 accuracy: 0.9688 (0.9460)  lr: 0.000100  iter-time: 0.2832\n",
            "[08:24:48.354380] Epoch: [51]  [20/72]  eta: 0:00:13  loss: 0.9059 (0.9213)  Accuracy: 0.7188 (0.7188)  Top 5 accuracy: 0.9375 (0.9479)  lr: 0.000100  iter-time: 0.2204\n",
            "[08:24:50.467273] Epoch: [51]  [30/72]  eta: 0:00:10  loss: 1.0879 (0.9991)  Accuracy: 0.6875 (0.6996)  Top 5 accuracy: 0.9375 (0.9395)  lr: 0.000100  iter-time: 0.2158\n",
            "[08:24:52.573852] Epoch: [51]  [40/72]  eta: 0:00:07  loss: 1.1533 (1.0464)  Accuracy: 0.6250 (0.6799)  Top 5 accuracy: 0.9375 (0.9383)  lr: 0.000100  iter-time: 0.2108\n",
            "[08:24:54.675604] Epoch: [51]  [50/72]  eta: 0:00:05  loss: 1.0847 (1.0350)  Accuracy: 0.6562 (0.6906)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.2103\n",
            "[08:24:56.770597] Epoch: [51]  [60/72]  eta: 0:00:02  loss: 1.1134 (1.0525)  Accuracy: 0.7188 (0.6855)  Top 5 accuracy: 0.9375 (0.9349)  lr: 0.000100  iter-time: 0.2097\n",
            "[08:24:58.868155] Epoch: [51]  [70/72]  eta: 0:00:00  loss: 1.1798 (1.0729)  Accuracy: 0.6562 (0.6769)  Top 5 accuracy: 0.9062 (0.9349)  lr: 0.000100  iter-time: 0.2095\n",
            "[08:24:59.030280] Epoch: [51]  [71/72]  eta: 0:00:00  loss: 1.1290 (1.0723)  Accuracy: 0.6562 (0.6778)  Top 5 accuracy: 0.9375 (0.9358)  lr: 0.000100  iter-time: 0.2072\n",
            "[08:24:59.191248] Epoch: [51] Total time: 0:00:16 (0.2245 s / it)\n",
            "[08:24:59.193394] [Train] averaged stats: loss: 1.1290 (1.0723)  Accuracy: 0.6562 (0.6778)  Top 5 accuracy: 0.9375 (0.9358)  lr: 0.000100\n",
            "[08:25:00.149499] Epoch: [51]  [0/8]  eta: 0:00:07  loss: 1.9266 (1.9266)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.9523\n",
            "[08:25:00.596910] Epoch: [51]  [7/8]  eta: 0:00:00  loss: 1.9266 (2.0969)  Accuracy: 0.4516 (0.4627)  Top 5 accuracy: 0.8125 (0.7886)  iter-time: 0.1736\n",
            "[08:25:00.693906] Epoch: [51] Total time: 0:00:01 (0.1872 s / it)\n",
            "[08:25:00.694008] [Val] averaged stats: loss: 1.9266 (2.0969)  Accuracy: 0.4516 (0.4627)  Top 5 accuracy: 0.8125 (0.7886)\n",
            "[08:25:00.694537] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[08:25:00.695971] [Time] 17.7s 16.3m/31.0m\n",
            "\n",
            "[08:25:00.696001] ~~~ Epoch 52/100 ~~~\n",
            "\n",
            "[08:25:01.555378] Epoch: [52]  [ 0/72]  eta: 0:01:00  loss: 1.3050 (1.3050)  Accuracy: 0.6562 (0.6562)  Top 5 accuracy: 0.8750 (0.8750)  lr: 0.000100  iter-time: 0.8462\n",
            "[08:25:03.739138] Epoch: [52]  [10/72]  eta: 0:00:17  loss: 0.9324 (1.0248)  Accuracy: 0.7188 (0.7131)  Top 5 accuracy: 0.9375 (0.9403)  lr: 0.000100  iter-time: 0.2753\n",
            "[08:25:05.835516] Epoch: [52]  [20/72]  eta: 0:00:12  loss: 0.9557 (1.0542)  Accuracy: 0.6875 (0.6801)  Top 5 accuracy: 0.9375 (0.9390)  lr: 0.000100  iter-time: 0.2139\n",
            "[08:25:07.938186] Epoch: [52]  [30/72]  eta: 0:00:09  loss: 0.9557 (1.0096)  Accuracy: 0.6875 (0.6976)  Top 5 accuracy: 0.9688 (0.9446)  lr: 0.000100  iter-time: 0.2098\n",
            "[08:25:10.039710] Epoch: [52]  [40/72]  eta: 0:00:07  loss: 0.8660 (0.9951)  Accuracy: 0.7500 (0.7058)  Top 5 accuracy: 0.9375 (0.9413)  lr: 0.000100  iter-time: 0.2101\n",
            "[08:25:12.248044] Epoch: [52]  [50/72]  eta: 0:00:04  loss: 0.8990 (1.0034)  Accuracy: 0.7188 (0.6991)  Top 5 accuracy: 0.9375 (0.9449)  lr: 0.000100  iter-time: 0.2154\n",
            "[08:25:14.456934] Epoch: [52]  [60/72]  eta: 0:00:02  loss: 1.1170 (1.0174)  Accuracy: 0.6562 (0.6972)  Top 5 accuracy: 0.9375 (0.9421)  lr: 0.000100  iter-time: 0.2207\n",
            "[08:25:16.568237] Epoch: [52]  [70/72]  eta: 0:00:00  loss: 1.0763 (1.0246)  Accuracy: 0.6562 (0.6915)  Top 5 accuracy: 0.9375 (0.9410)  lr: 0.000100  iter-time: 0.2159\n",
            "[08:25:16.732222] Epoch: [52]  [71/72]  eta: 0:00:00  loss: 1.0763 (1.0190)  Accuracy: 0.6875 (0.6939)  Top 5 accuracy: 0.9375 (0.9418)  lr: 0.000100  iter-time: 0.2134\n",
            "[08:25:16.830492] Epoch: [52] Total time: 0:00:16 (0.2241 s / it)\n",
            "[08:25:16.830848] [Train] averaged stats: loss: 1.0763 (1.0190)  Accuracy: 0.6875 (0.6939)  Top 5 accuracy: 0.9375 (0.9418)  lr: 0.000100\n",
            "[08:25:17.293480] Epoch: [52]  [0/8]  eta: 0:00:03  loss: 1.8915 (1.8915)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.4602\n",
            "[08:25:17.862405] Epoch: [52]  [7/8]  eta: 0:00:00  loss: 2.1981 (2.2730)  Accuracy: 0.3548 (0.4272)  Top 5 accuracy: 0.7188 (0.7533)  iter-time: 0.1286\n",
            "[08:25:17.958063] Epoch: [52] Total time: 0:00:01 (0.1407 s / it)\n",
            "[08:25:17.958140] [Val] averaged stats: loss: 2.1981 (2.2730)  Accuracy: 0.3548 (0.4272)  Top 5 accuracy: 0.7188 (0.7533)\n",
            "[08:25:17.958581] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[08:25:17.959971] [Time] 17.3s 16.6m/30.7m\n",
            "\n",
            "[08:25:17.960004] ~~~ Epoch 53/100 ~~~\n",
            "\n",
            "[08:25:18.943358] Epoch: [53]  [ 0/72]  eta: 0:01:10  loss: 0.7717 (0.7717)  Accuracy: 0.7500 (0.7500)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.9809\n",
            "[08:25:21.096415] Epoch: [53]  [10/72]  eta: 0:00:17  loss: 0.9434 (0.9148)  Accuracy: 0.7188 (0.7330)  Top 5 accuracy: 0.9375 (0.9432)  lr: 0.000100  iter-time: 0.2848\n",
            "[08:25:23.198475] Epoch: [53]  [20/72]  eta: 0:00:12  loss: 0.8945 (0.9171)  Accuracy: 0.7188 (0.7292)  Top 5 accuracy: 0.9375 (0.9494)  lr: 0.000100  iter-time: 0.2126\n",
            "[08:25:25.365988] Epoch: [53]  [30/72]  eta: 0:00:10  loss: 0.8775 (0.9234)  Accuracy: 0.7188 (0.7308)  Top 5 accuracy: 0.9375 (0.9446)  lr: 0.000100  iter-time: 0.2134\n",
            "[08:25:27.556840] Epoch: [53]  [40/72]  eta: 0:00:07  loss: 0.9459 (0.9372)  Accuracy: 0.6875 (0.7248)  Top 5 accuracy: 0.9375 (0.9398)  lr: 0.000100  iter-time: 0.2178\n",
            "[08:25:29.670766] Epoch: [53]  [50/72]  eta: 0:00:05  loss: 0.9491 (0.9582)  Accuracy: 0.6562 (0.7175)  Top 5 accuracy: 0.9375 (0.9387)  lr: 0.000100  iter-time: 0.2151\n",
            "[08:25:31.788388] Epoch: [53]  [60/72]  eta: 0:00:02  loss: 1.0377 (0.9752)  Accuracy: 0.6562 (0.7116)  Top 5 accuracy: 0.9375 (0.9385)  lr: 0.000100  iter-time: 0.2115\n",
            "[08:25:33.900329] Epoch: [53]  [70/72]  eta: 0:00:00  loss: 1.0043 (0.9734)  Accuracy: 0.6875 (0.7077)  Top 5 accuracy: 0.9375 (0.9397)  lr: 0.000100  iter-time: 0.2114\n",
            "[08:25:34.064646] Epoch: [53]  [71/72]  eta: 0:00:00  loss: 1.0043 (0.9745)  Accuracy: 0.6875 (0.7082)  Top 5 accuracy: 0.9375 (0.9405)  lr: 0.000100  iter-time: 0.2089\n",
            "[08:25:34.180775] Epoch: [53] Total time: 0:00:16 (0.2253 s / it)\n",
            "[08:25:34.181137] [Train] averaged stats: loss: 1.0043 (0.9745)  Accuracy: 0.6875 (0.7082)  Top 5 accuracy: 0.9375 (0.9405)  lr: 0.000100\n",
            "[08:25:34.631920] Epoch: [53]  [0/8]  eta: 0:00:03  loss: 2.2930 (2.2930)  Accuracy: 0.4375 (0.4375)  Top 5 accuracy: 0.7812 (0.7812)  iter-time: 0.4481\n",
            "[08:25:35.209501] Epoch: [53]  [7/8]  eta: 0:00:00  loss: 2.2924 (2.3493)  Accuracy: 0.3871 (0.4039)  Top 5 accuracy: 0.7188 (0.7494)  iter-time: 0.1271\n",
            "[08:25:35.308470] Epoch: [53] Total time: 0:00:01 (0.1407 s / it)\n",
            "[08:25:35.308548] [Val] averaged stats: loss: 2.2924 (2.3493)  Accuracy: 0.3871 (0.4039)  Top 5 accuracy: 0.7188 (0.7494)\n",
            "[08:25:35.309075] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 11 out of 20\n",
            "[08:25:35.310343] [Time] 17.4s 16.9m/30.8m\n",
            "\n",
            "[08:25:35.310376] ~~~ Epoch 54/100 ~~~\n",
            "\n",
            "[08:25:36.241618] Epoch: [54]  [ 0/72]  eta: 0:01:06  loss: 1.1231 (1.1231)  Accuracy: 0.6875 (0.6875)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 0.9285\n",
            "[08:25:38.591551] Epoch: [54]  [10/72]  eta: 0:00:18  loss: 0.9663 (0.9658)  Accuracy: 0.7188 (0.7358)  Top 5 accuracy: 0.9375 (0.9460)  lr: 0.000100  iter-time: 0.2977\n",
            "[08:25:40.830803] Epoch: [54]  [20/72]  eta: 0:00:13  loss: 0.9602 (1.0165)  Accuracy: 0.6875 (0.7039)  Top 5 accuracy: 0.9688 (0.9464)  lr: 0.000100  iter-time: 0.2292\n",
            "[08:25:42.946604] Epoch: [54]  [30/72]  eta: 0:00:10  loss: 1.0821 (1.0214)  Accuracy: 0.6562 (0.6946)  Top 5 accuracy: 0.9688 (0.9486)  lr: 0.000100  iter-time: 0.2177\n",
            "[08:25:45.075485] Epoch: [54]  [40/72]  eta: 0:00:07  loss: 1.0885 (1.0399)  Accuracy: 0.6250 (0.6837)  Top 5 accuracy: 0.9375 (0.9444)  lr: 0.000100  iter-time: 0.2121\n",
            "[08:25:47.196118] Epoch: [54]  [50/72]  eta: 0:00:05  loss: 1.1344 (1.0633)  Accuracy: 0.6250 (0.6716)  Top 5 accuracy: 0.9375 (0.9412)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:25:49.319301] Epoch: [54]  [60/72]  eta: 0:00:02  loss: 1.1938 (1.0890)  Accuracy: 0.6250 (0.6644)  Top 5 accuracy: 0.9375 (0.9344)  lr: 0.000100  iter-time: 0.2121\n",
            "[08:25:51.427042] Epoch: [54]  [70/72]  eta: 0:00:00  loss: 1.2218 (1.0902)  Accuracy: 0.6875 (0.6651)  Top 5 accuracy: 0.9375 (0.9344)  lr: 0.000100  iter-time: 0.2114\n",
            "[08:25:51.591312] Epoch: [54]  [71/72]  eta: 0:00:00  loss: 1.1708 (1.0869)  Accuracy: 0.6875 (0.6655)  Top 5 accuracy: 0.9375 (0.9347)  lr: 0.000100  iter-time: 0.2089\n",
            "[08:25:51.694192] Epoch: [54] Total time: 0:00:16 (0.2275 s / it)\n",
            "[08:25:51.694618] [Train] averaged stats: loss: 1.1708 (1.0869)  Accuracy: 0.6875 (0.6655)  Top 5 accuracy: 0.9375 (0.9347)  lr: 0.000100\n",
            "[08:25:52.126203] Epoch: [54]  [0/8]  eta: 0:00:03  loss: 1.8173 (1.8173)  Accuracy: 0.5938 (0.5937)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.4289\n",
            "[08:25:52.800980] Epoch: [54]  [7/8]  eta: 0:00:00  loss: 2.3025 (2.3505)  Accuracy: 0.4375 (0.4236)  Top 5 accuracy: 0.7500 (0.7413)  iter-time: 0.1378\n",
            "[08:25:52.894946] Epoch: [54] Total time: 0:00:01 (0.1498 s / it)\n",
            "[08:25:52.895022] [Val] averaged stats: loss: 2.3025 (2.3505)  Accuracy: 0.4375 (0.4236)  Top 5 accuracy: 0.7500 (0.7413)\n",
            "[08:25:52.895725] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 12 out of 20\n",
            "[08:25:52.896962] [Time] 17.6s 17.2m/30.9m\n",
            "\n",
            "[08:25:52.896993] ~~~ Epoch 55/100 ~~~\n",
            "\n",
            "[08:25:53.884161] Epoch: [55]  [ 0/72]  eta: 0:01:10  loss: 1.0439 (1.0439)  Accuracy: 0.6875 (0.6875)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 0.9754\n",
            "[08:25:56.044427] Epoch: [55]  [10/72]  eta: 0:00:17  loss: 0.9207 (0.9598)  Accuracy: 0.6875 (0.7017)  Top 5 accuracy: 0.9688 (0.9688)  lr: 0.000100  iter-time: 0.2849\n",
            "[08:25:58.149375] Epoch: [55]  [20/72]  eta: 0:00:12  loss: 1.0144 (0.9933)  Accuracy: 0.6562 (0.6949)  Top 5 accuracy: 0.9688 (0.9583)  lr: 0.000100  iter-time: 0.2131\n",
            "[08:26:00.259975] Epoch: [55]  [30/72]  eta: 0:00:09  loss: 0.9785 (0.9750)  Accuracy: 0.7188 (0.7056)  Top 5 accuracy: 0.9375 (0.9587)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:26:02.431974] Epoch: [55]  [40/72]  eta: 0:00:07  loss: 0.9229 (0.9793)  Accuracy: 0.7188 (0.7027)  Top 5 accuracy: 0.9688 (0.9581)  lr: 0.000100  iter-time: 0.2140\n",
            "[08:26:04.643508] Epoch: [55]  [50/72]  eta: 0:00:05  loss: 0.9782 (0.9947)  Accuracy: 0.6875 (0.7004)  Top 5 accuracy: 0.9375 (0.9522)  lr: 0.000100  iter-time: 0.2190\n",
            "[08:26:06.763663] Epoch: [55]  [60/72]  eta: 0:00:02  loss: 0.9782 (0.9927)  Accuracy: 0.6875 (0.7013)  Top 5 accuracy: 0.9375 (0.9498)  lr: 0.000100  iter-time: 0.2164\n",
            "[08:26:08.868577] Epoch: [55]  [70/72]  eta: 0:00:00  loss: 1.0489 (1.0151)  Accuracy: 0.6562 (0.6945)  Top 5 accuracy: 0.9375 (0.9472)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:26:09.031383] Epoch: [55]  [71/72]  eta: 0:00:00  loss: 1.0801 (1.0163)  Accuracy: 0.6562 (0.6940)  Top 5 accuracy: 0.9375 (0.9467)  lr: 0.000100  iter-time: 0.2084\n",
            "[08:26:09.129458] Epoch: [55] Total time: 0:00:16 (0.2254 s / it)\n",
            "[08:26:09.130074] [Train] averaged stats: loss: 1.0801 (1.0163)  Accuracy: 0.6562 (0.6940)  Top 5 accuracy: 0.9375 (0.9467)  lr: 0.000100\n",
            "[08:26:09.706358] Epoch: [55]  [0/8]  eta: 0:00:04  loss: 1.3664 (1.3664)  Accuracy: 0.5625 (0.5625)  Top 5 accuracy: 0.8438 (0.8437)  iter-time: 0.5738\n",
            "[08:26:10.152794] Epoch: [55]  [7/8]  eta: 0:00:00  loss: 2.1834 (2.2293)  Accuracy: 0.4688 (0.4821)  Top 5 accuracy: 0.7812 (0.7688)  iter-time: 0.1268\n",
            "[08:26:10.247098] Epoch: [55] Total time: 0:00:01 (0.1394 s / it)\n",
            "[08:26:10.247184] [Val] averaged stats: loss: 2.1834 (2.2293)  Accuracy: 0.4688 (0.4821)  Top 5 accuracy: 0.7812 (0.7688)\n",
            "[08:26:10.247623] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "[08:26:10.248907] Creating training plots . . .\n",
            "EarlyStopping counter: 13 out of 20\n",
            "[08:26:10.563235] [Time] 17.7s 17.5m/31.0m\n",
            "\n",
            "[08:26:10.563270] ~~~ Epoch 56/100 ~~~\n",
            "\n",
            "[08:26:11.525224] Epoch: [56]  [ 0/72]  eta: 0:01:09  loss: 0.6584 (0.6584)  Accuracy: 0.8125 (0.8125)  Top 5 accuracy: 1.0000 (1.0000)  lr: 0.000100  iter-time: 0.9584\n",
            "[08:26:13.666383] Epoch: [56]  [10/72]  eta: 0:00:17  loss: 0.8839 (0.9155)  Accuracy: 0.7188 (0.7273)  Top 5 accuracy: 0.9375 (0.9517)  lr: 0.000100  iter-time: 0.2817\n",
            "[08:26:15.836833] Epoch: [56]  [20/72]  eta: 0:00:13  loss: 0.9871 (0.9580)  Accuracy: 0.7188 (0.7232)  Top 5 accuracy: 0.9375 (0.9479)  lr: 0.000100  iter-time: 0.2154\n",
            "[08:26:18.058852] Epoch: [56]  [30/72]  eta: 0:00:10  loss: 0.8708 (0.9176)  Accuracy: 0.7188 (0.7298)  Top 5 accuracy: 0.9688 (0.9506)  lr: 0.000100  iter-time: 0.2195\n",
            "[08:26:20.158376] Epoch: [56]  [40/72]  eta: 0:00:07  loss: 0.8708 (0.9237)  Accuracy: 0.7188 (0.7271)  Top 5 accuracy: 0.9688 (0.9505)  lr: 0.000100  iter-time: 0.2160\n",
            "[08:26:22.267707] Epoch: [56]  [50/72]  eta: 0:00:05  loss: 0.9042 (0.9396)  Accuracy: 0.7188 (0.7292)  Top 5 accuracy: 0.9375 (0.9455)  lr: 0.000100  iter-time: 0.2103\n",
            "[08:26:24.383052] Epoch: [56]  [60/72]  eta: 0:00:02  loss: 0.9442 (0.9567)  Accuracy: 0.7188 (0.7203)  Top 5 accuracy: 0.9375 (0.9447)  lr: 0.000100  iter-time: 0.2111\n",
            "[08:26:26.487560] Epoch: [56]  [70/72]  eta: 0:00:00  loss: 0.8822 (0.9556)  Accuracy: 0.6875 (0.7165)  Top 5 accuracy: 0.9375 (0.9467)  lr: 0.000100  iter-time: 0.2109\n",
            "[08:26:26.648019] Epoch: [56]  [71/72]  eta: 0:00:00  loss: 0.8822 (0.9583)  Accuracy: 0.6875 (0.7138)  Top 5 accuracy: 0.9375 (0.9463)  lr: 0.000100  iter-time: 0.2083\n",
            "[08:26:26.766346] Epoch: [56] Total time: 0:00:16 (0.2250 s / it)\n",
            "[08:26:26.767031] [Train] averaged stats: loss: 0.8822 (0.9583)  Accuracy: 0.6875 (0.7138)  Top 5 accuracy: 0.9375 (0.9463)  lr: 0.000100\n",
            "[08:26:27.337003] Epoch: [56]  [0/8]  eta: 0:00:04  loss: 1.7901 (1.7901)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.5674\n",
            "[08:26:27.807150] Epoch: [56]  [7/8]  eta: 0:00:00  loss: 2.2084 (2.2717)  Accuracy: 0.4062 (0.4240)  Top 5 accuracy: 0.7500 (0.7571)  iter-time: 0.1296\n",
            "[08:26:27.932712] Epoch: [56] Total time: 0:00:01 (0.1455 s / it)\n",
            "[08:26:27.932882] [Val] averaged stats: loss: 2.2084 (2.2717)  Accuracy: 0.4062 (0.4240)  Top 5 accuracy: 0.7500 (0.7571)\n",
            "[08:26:27.933511] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 14 out of 20\n",
            "[08:26:27.934322] [Time] 17.4s 17.8m/30.8m\n",
            "\n",
            "[08:26:27.934364] ~~~ Epoch 57/100 ~~~\n",
            "\n",
            "[08:26:29.494214] Epoch: [57]  [ 0/72]  eta: 0:01:51  loss: 1.0357 (1.0357)  Accuracy: 0.7188 (0.7187)  Top 5 accuracy: 0.9062 (0.9062)  lr: 0.000100  iter-time: 1.5539\n",
            "[08:26:31.719767] Epoch: [57]  [10/72]  eta: 0:00:21  loss: 1.0971 (1.0672)  Accuracy: 0.7188 (0.6989)  Top 5 accuracy: 0.9375 (0.9261)  lr: 0.000100  iter-time: 0.3432\n",
            "[08:26:33.826279] Epoch: [57]  [20/72]  eta: 0:00:14  loss: 0.9857 (0.9968)  Accuracy: 0.7188 (0.7188)  Top 5 accuracy: 0.9375 (0.9271)  lr: 0.000100  iter-time: 0.2163\n",
            "[08:26:35.942256] Epoch: [57]  [30/72]  eta: 0:00:10  loss: 0.9127 (0.9685)  Accuracy: 0.7500 (0.7238)  Top 5 accuracy: 0.9375 (0.9325)  lr: 0.000100  iter-time: 0.2110\n",
            "[08:26:38.042828] Epoch: [57]  [40/72]  eta: 0:00:07  loss: 0.9789 (0.9963)  Accuracy: 0.7188 (0.7096)  Top 5 accuracy: 0.9375 (0.9306)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:26:40.148847] Epoch: [57]  [50/72]  eta: 0:00:05  loss: 1.0060 (1.0191)  Accuracy: 0.6562 (0.7004)  Top 5 accuracy: 0.9375 (0.9271)  lr: 0.000100  iter-time: 0.2100\n",
            "[08:26:42.331438] Epoch: [57]  [60/72]  eta: 0:00:02  loss: 1.0039 (1.0055)  Accuracy: 0.6562 (0.7013)  Top 5 accuracy: 0.9375 (0.9324)  lr: 0.000100  iter-time: 0.2141\n",
            "[08:26:44.453486] Epoch: [57]  [70/72]  eta: 0:00:00  loss: 0.8921 (1.0099)  Accuracy: 0.6875 (0.7025)  Top 5 accuracy: 0.9688 (0.9335)  lr: 0.000100  iter-time: 0.2151\n",
            "[08:26:44.618107] Epoch: [57]  [71/72]  eta: 0:00:00  loss: 0.8782 (1.0024)  Accuracy: 0.7500 (0.7048)  Top 5 accuracy: 0.9688 (0.9345)  lr: 0.000100  iter-time: 0.2125\n",
            "[08:26:44.734073] Epoch: [57] Total time: 0:00:16 (0.2333 s / it)\n",
            "[08:26:44.734475] [Train] averaged stats: loss: 0.8782 (1.0024)  Accuracy: 0.7500 (0.7048)  Top 5 accuracy: 0.9688 (0.9345)  lr: 0.000100\n",
            "[08:26:45.309057] Epoch: [57]  [0/8]  eta: 0:00:04  loss: 1.7608 (1.7608)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.5719\n",
            "[08:26:45.786450] Epoch: [57]  [7/8]  eta: 0:00:00  loss: 2.1038 (2.3413)  Accuracy: 0.4062 (0.3889)  Top 5 accuracy: 0.7188 (0.7419)  iter-time: 0.1311\n",
            "[08:26:45.878783] Epoch: [57] Total time: 0:00:01 (0.1428 s / it)\n",
            "[08:26:45.878869] [Val] averaged stats: loss: 2.1038 (2.3413)  Accuracy: 0.4062 (0.3889)  Top 5 accuracy: 0.7188 (0.7419)\n",
            "[08:26:45.879558] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 15 out of 20\n",
            "[08:26:45.880807] [Time] 17.9s 18.1m/31.2m\n",
            "\n",
            "[08:26:45.880855] ~~~ Epoch 58/100 ~~~\n",
            "\n",
            "[08:26:46.840175] Epoch: [58]  [ 0/72]  eta: 0:01:08  loss: 0.9769 (0.9769)  Accuracy: 0.7812 (0.7812)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 0.9553\n",
            "[08:26:48.975239] Epoch: [58]  [10/72]  eta: 0:00:17  loss: 0.9769 (1.0040)  Accuracy: 0.7188 (0.7102)  Top 5 accuracy: 0.9688 (0.9489)  lr: 0.000100  iter-time: 0.2808\n",
            "[08:26:51.089260] Epoch: [58]  [20/72]  eta: 0:00:12  loss: 0.9361 (1.0044)  Accuracy: 0.7188 (0.7217)  Top 5 accuracy: 0.9375 (0.9330)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:26:53.215998] Epoch: [58]  [30/72]  eta: 0:00:09  loss: 0.9459 (1.0149)  Accuracy: 0.6875 (0.7067)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.2115\n",
            "[08:26:55.404258] Epoch: [58]  [40/72]  eta: 0:00:07  loss: 0.9520 (1.0174)  Accuracy: 0.6562 (0.6997)  Top 5 accuracy: 0.9375 (0.9367)  lr: 0.000100  iter-time: 0.2150\n",
            "[08:26:57.536225] Epoch: [58]  [50/72]  eta: 0:00:05  loss: 0.9624 (1.0242)  Accuracy: 0.6875 (0.6961)  Top 5 accuracy: 0.9375 (0.9357)  lr: 0.000100  iter-time: 0.2157\n",
            "[08:26:59.652228] Epoch: [58]  [60/72]  eta: 0:00:02  loss: 1.0292 (1.0209)  Accuracy: 0.6875 (0.6957)  Top 5 accuracy: 0.9375 (0.9365)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:27:01.768088] Epoch: [58]  [70/72]  eta: 0:00:00  loss: 1.0057 (1.0161)  Accuracy: 0.6875 (0.6972)  Top 5 accuracy: 0.9375 (0.9393)  lr: 0.000100  iter-time: 0.2115\n",
            "[08:27:01.928724] Epoch: [58]  [71/72]  eta: 0:00:00  loss: 0.9749 (1.0143)  Accuracy: 0.6875 (0.6972)  Top 5 accuracy: 0.9688 (0.9401)  lr: 0.000100  iter-time: 0.2090\n",
            "[08:27:02.024813] Epoch: [58] Total time: 0:00:16 (0.2242 s / it)\n",
            "[08:27:02.025199] [Train] averaged stats: loss: 0.9749 (1.0143)  Accuracy: 0.6875 (0.6972)  Top 5 accuracy: 0.9688 (0.9401)  lr: 0.000100\n",
            "[08:27:02.512701] Epoch: [58]  [0/8]  eta: 0:00:03  loss: 1.6331 (1.6331)  Accuracy: 0.5938 (0.5937)  Top 5 accuracy: 0.8750 (0.8750)  iter-time: 0.4847\n",
            "[08:27:03.102863] Epoch: [58]  [7/8]  eta: 0:00:00  loss: 2.4612 (2.3459)  Accuracy: 0.3125 (0.3881)  Top 5 accuracy: 0.6875 (0.7455)  iter-time: 0.1342\n",
            "[08:27:03.195284] Epoch: [58] Total time: 0:00:01 (0.1460 s / it)\n",
            "[08:27:03.195358] [Val] averaged stats: loss: 2.4612 (2.3459)  Accuracy: 0.3125 (0.3881)  Top 5 accuracy: 0.6875 (0.7455)\n",
            "[08:27:03.195871] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 16 out of 20\n",
            "[08:27:03.197272] [Time] 17.3s 18.3m/30.8m\n",
            "\n",
            "[08:27:03.197304] ~~~ Epoch 59/100 ~~~\n",
            "\n",
            "[08:27:04.074914] Epoch: [59]  [ 0/72]  eta: 0:01:02  loss: 0.7301 (0.7301)  Accuracy: 0.8125 (0.8125)  Top 5 accuracy: 0.9688 (0.9687)  lr: 0.000100  iter-time: 0.8658\n",
            "[08:27:06.262272] Epoch: [59]  [10/72]  eta: 0:00:17  loss: 0.7566 (0.8201)  Accuracy: 0.7812 (0.7727)  Top 5 accuracy: 0.9688 (0.9631)  lr: 0.000100  iter-time: 0.2774\n",
            "[08:27:08.481121] Epoch: [59]  [20/72]  eta: 0:00:13  loss: 0.8130 (0.8435)  Accuracy: 0.7500 (0.7589)  Top 5 accuracy: 0.9688 (0.9583)  lr: 0.000100  iter-time: 0.2198\n",
            "[08:27:10.616134] Epoch: [59]  [30/72]  eta: 0:00:10  loss: 0.9408 (0.8826)  Accuracy: 0.7188 (0.7440)  Top 5 accuracy: 0.9375 (0.9526)  lr: 0.000100  iter-time: 0.2172\n",
            "[08:27:12.731707] Epoch: [59]  [40/72]  eta: 0:00:07  loss: 0.9408 (0.9030)  Accuracy: 0.7188 (0.7370)  Top 5 accuracy: 0.9375 (0.9466)  lr: 0.000100  iter-time: 0.2124\n",
            "[08:27:14.845104] Epoch: [59]  [50/72]  eta: 0:00:05  loss: 0.9229 (0.9183)  Accuracy: 0.7188 (0.7310)  Top 5 accuracy: 0.9375 (0.9485)  lr: 0.000100  iter-time: 0.2113\n",
            "[08:27:16.967039] Epoch: [59]  [60/72]  eta: 0:00:02  loss: 0.9173 (0.9351)  Accuracy: 0.6875 (0.7228)  Top 5 accuracy: 0.9375 (0.9467)  lr: 0.000100  iter-time: 0.2116\n",
            "[08:27:19.070779] Epoch: [59]  [70/72]  eta: 0:00:00  loss: 1.0753 (0.9484)  Accuracy: 0.6875 (0.7214)  Top 5 accuracy: 0.9375 (0.9437)  lr: 0.000100  iter-time: 0.2112\n",
            "[08:27:19.235715] Epoch: [59]  [71/72]  eta: 0:00:00  loss: 1.0753 (0.9525)  Accuracy: 0.6875 (0.7198)  Top 5 accuracy: 0.9375 (0.9438)  lr: 0.000100  iter-time: 0.2088\n",
            "[08:27:19.398561] Epoch: [59] Total time: 0:00:16 (0.2250 s / it)\n",
            "[08:27:19.398778] [Train] averaged stats: loss: 1.0753 (0.9525)  Accuracy: 0.6875 (0.7198)  Top 5 accuracy: 0.9375 (0.9438)  lr: 0.000100\n",
            "[08:27:20.431277] Epoch: [59]  [0/8]  eta: 0:00:08  loss: 1.9850 (1.9850)  Accuracy: 0.5000 (0.5000)  Top 5 accuracy: 0.7812 (0.7812)  iter-time: 1.0170\n",
            "[08:27:20.912044] Epoch: [59]  [7/8]  eta: 0:00:00  loss: 2.2287 (2.2766)  Accuracy: 0.4194 (0.4430)  Top 5 accuracy: 0.7812 (0.7727)  iter-time: 0.1871\n",
            "[08:27:21.053102] Epoch: [59] Total time: 0:00:01 (0.2064 s / it)\n",
            "[08:27:21.053210] [Val] averaged stats: loss: 2.2287 (2.2766)  Accuracy: 0.4194 (0.4430)  Top 5 accuracy: 0.7812 (0.7727)\n",
            "[08:27:21.053919] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 17 out of 20\n",
            "[08:27:21.054796] [Time] 17.9s 18.6m/31.1m\n",
            "\n",
            "[08:27:21.054851] ~~~ Epoch 60/100 ~~~\n",
            "\n",
            "[08:27:22.054167] Epoch: [60]  [ 0/72]  eta: 0:01:11  loss: 0.9705 (0.9705)  Accuracy: 0.6875 (0.6875)  Top 5 accuracy: 1.0000 (1.0000)  lr: 0.000100  iter-time: 0.9908\n",
            "[08:27:24.197189] Epoch: [60]  [10/72]  eta: 0:00:17  loss: 0.8466 (0.8197)  Accuracy: 0.7500 (0.7415)  Top 5 accuracy: 0.9688 (0.9716)  lr: 0.000100  iter-time: 0.2848\n",
            "[08:27:26.300481] Epoch: [60]  [20/72]  eta: 0:00:12  loss: 0.8466 (0.8895)  Accuracy: 0.7500 (0.7321)  Top 5 accuracy: 0.9688 (0.9554)  lr: 0.000100  iter-time: 0.2122\n",
            "[08:27:28.411378] Epoch: [60]  [30/72]  eta: 0:00:09  loss: 0.8552 (0.8837)  Accuracy: 0.7500 (0.7369)  Top 5 accuracy: 0.9375 (0.9546)  lr: 0.000100  iter-time: 0.2106\n",
            "[08:27:30.516300] Epoch: [60]  [40/72]  eta: 0:00:07  loss: 0.8047 (0.8716)  Accuracy: 0.7188 (0.7363)  Top 5 accuracy: 0.9375 (0.9543)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:27:32.664490] Epoch: [60]  [50/72]  eta: 0:00:05  loss: 0.9120 (0.9135)  Accuracy: 0.6875 (0.7249)  Top 5 accuracy: 0.9375 (0.9491)  lr: 0.000100  iter-time: 0.2126\n",
            "[08:27:34.858377] Epoch: [60]  [60/72]  eta: 0:00:02  loss: 0.9514 (0.9238)  Accuracy: 0.6875 (0.7198)  Top 5 accuracy: 0.9375 (0.9467)  lr: 0.000100  iter-time: 0.2170\n",
            "[08:27:36.963397] Epoch: [60]  [70/72]  eta: 0:00:00  loss: 1.0168 (0.9498)  Accuracy: 0.6875 (0.7113)  Top 5 accuracy: 0.9375 (0.9437)  lr: 0.000100  iter-time: 0.2148\n",
            "[08:27:37.124398] Epoch: [60]  [71/72]  eta: 0:00:00  loss: 1.0168 (0.9478)  Accuracy: 0.6875 (0.7135)  Top 5 accuracy: 0.9130 (0.9432)  lr: 0.000100  iter-time: 0.2120\n",
            "[08:27:37.224234] Epoch: [60] Total time: 0:00:16 (0.2245 s / it)\n",
            "[08:27:37.224679] [Train] averaged stats: loss: 1.0168 (0.9478)  Accuracy: 0.6875 (0.7135)  Top 5 accuracy: 0.9130 (0.9432)  lr: 0.000100\n",
            "[08:27:37.656913] Epoch: [60]  [0/8]  eta: 0:00:03  loss: 1.5810 (1.5810)  Accuracy: 0.5938 (0.5937)  Top 5 accuracy: 0.8125 (0.8125)  iter-time: 0.4297\n",
            "[08:27:38.295260] Epoch: [60]  [7/8]  eta: 0:00:00  loss: 2.2323 (2.2563)  Accuracy: 0.4375 (0.4351)  Top 5 accuracy: 0.7500 (0.7767)  iter-time: 0.1327\n",
            "[08:27:38.391846] Epoch: [60] Total time: 0:00:01 (0.1457 s / it)\n",
            "[08:27:38.391930] [Val] averaged stats: loss: 2.2323 (2.2563)  Accuracy: 0.4375 (0.4351)  Top 5 accuracy: 0.7500 (0.7767)\n",
            "[08:27:38.392389] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "[08:27:38.393718] Creating training plots . . .\n",
            "EarlyStopping counter: 18 out of 20\n",
            "[08:27:38.715482] [Time] 17.7s 18.9m/31.0m\n",
            "\n",
            "[08:27:38.715518] ~~~ Epoch 61/100 ~~~\n",
            "\n",
            "[08:27:39.473502] Epoch: [61]  [ 0/72]  eta: 0:00:54  loss: 0.5697 (0.5697)  Accuracy: 0.8750 (0.8750)  Top 5 accuracy: 1.0000 (1.0000)  lr: 0.000100  iter-time: 0.7552\n",
            "[08:27:41.699298] Epoch: [61]  [10/72]  eta: 0:00:16  loss: 0.8897 (0.8412)  Accuracy: 0.7500 (0.7727)  Top 5 accuracy: 0.9375 (0.9432)  lr: 0.000100  iter-time: 0.2708\n",
            "[08:27:43.808514] Epoch: [61]  [20/72]  eta: 0:00:12  loss: 0.8636 (0.8339)  Accuracy: 0.7500 (0.7634)  Top 5 accuracy: 0.9375 (0.9524)  lr: 0.000100  iter-time: 0.2166\n",
            "[08:27:45.948523] Epoch: [61]  [30/72]  eta: 0:00:09  loss: 0.9199 (0.9038)  Accuracy: 0.7500 (0.7429)  Top 5 accuracy: 0.9375 (0.9486)  lr: 0.000100  iter-time: 0.2123\n",
            "[08:27:48.158553] Epoch: [61]  [40/72]  eta: 0:00:07  loss: 0.9866 (0.9113)  Accuracy: 0.7188 (0.7348)  Top 5 accuracy: 0.9375 (0.9482)  lr: 0.000100  iter-time: 0.2174\n",
            "[08:27:50.263216] Epoch: [61]  [50/72]  eta: 0:00:04  loss: 0.8810 (0.9071)  Accuracy: 0.7188 (0.7267)  Top 5 accuracy: 0.9688 (0.9498)  lr: 0.000100  iter-time: 0.2156\n",
            "[08:27:52.366249] Epoch: [61]  [60/72]  eta: 0:00:02  loss: 0.9223 (0.9301)  Accuracy: 0.6875 (0.7157)  Top 5 accuracy: 0.9688 (0.9498)  lr: 0.000100  iter-time: 0.2103\n",
            "[08:27:54.479091] Epoch: [61]  [70/72]  eta: 0:00:00  loss: 0.9729 (0.9395)  Accuracy: 0.6875 (0.7157)  Top 5 accuracy: 0.9375 (0.9467)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:27:54.642679] Epoch: [61]  [71/72]  eta: 0:00:00  loss: 0.9729 (0.9427)  Accuracy: 0.7188 (0.7160)  Top 5 accuracy: 0.9375 (0.9457)  lr: 0.000100  iter-time: 0.2084\n",
            "[08:27:54.744429] Epoch: [61] Total time: 0:00:16 (0.2226 s / it)\n",
            "[08:27:54.744841] [Train] averaged stats: loss: 0.9729 (0.9427)  Accuracy: 0.7188 (0.7160)  Top 5 accuracy: 0.9375 (0.9457)  lr: 0.000100\n",
            "[08:27:55.357469] Epoch: [61]  [0/8]  eta: 0:00:04  loss: 1.7741 (1.7741)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7500 (0.7500)  iter-time: 0.6102\n",
            "[08:27:55.812289] Epoch: [61]  [7/8]  eta: 0:00:00  loss: 1.9244 (2.1578)  Accuracy: 0.4062 (0.4475)  Top 5 accuracy: 0.7188 (0.7457)  iter-time: 0.1326\n",
            "[08:27:55.904123] Epoch: [61] Total time: 0:00:01 (0.1447 s / it)\n",
            "[08:27:55.904197] [Val] averaged stats: loss: 1.9244 (2.1578)  Accuracy: 0.4062 (0.4475)  Top 5 accuracy: 0.7188 (0.7457)\n",
            "[08:27:55.904637] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 19 out of 20\n",
            "[08:27:55.905873] [Time] 17.2s 19.2m/30.7m\n",
            "\n",
            "[08:27:55.905906] ~~~ Epoch 62/100 ~~~\n",
            "\n",
            "[08:27:56.715063] Epoch: [62]  [ 0/72]  eta: 0:00:57  loss: 1.0699 (1.0699)  Accuracy: 0.7188 (0.7187)  Top 5 accuracy: 0.9375 (0.9375)  lr: 0.000100  iter-time: 0.8031\n",
            "[08:27:58.949976] Epoch: [62]  [10/72]  eta: 0:00:17  loss: 0.9214 (0.9619)  Accuracy: 0.7188 (0.7188)  Top 5 accuracy: 0.9375 (0.9318)  lr: 0.000100  iter-time: 0.2752\n",
            "[08:28:01.221788] Epoch: [62]  [20/72]  eta: 0:00:13  loss: 0.9009 (0.9117)  Accuracy: 0.7188 (0.7247)  Top 5 accuracy: 0.9688 (0.9509)  lr: 0.000100  iter-time: 0.2247\n",
            "[08:28:03.337458] Epoch: [62]  [30/72]  eta: 0:00:10  loss: 0.9009 (0.9004)  Accuracy: 0.6875 (0.7228)  Top 5 accuracy: 0.9688 (0.9506)  lr: 0.000100  iter-time: 0.2193\n",
            "[08:28:05.438877] Epoch: [62]  [40/72]  eta: 0:00:07  loss: 0.9497 (0.9438)  Accuracy: 0.6875 (0.7180)  Top 5 accuracy: 0.9688 (0.9466)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:28:07.555036] Epoch: [62]  [50/72]  eta: 0:00:05  loss: 0.9497 (0.9387)  Accuracy: 0.7188 (0.7169)  Top 5 accuracy: 0.9688 (0.9491)  lr: 0.000100  iter-time: 0.2107\n",
            "[08:28:09.660581] Epoch: [62]  [60/72]  eta: 0:00:02  loss: 0.9009 (0.9382)  Accuracy: 0.7188 (0.7182)  Top 5 accuracy: 0.9375 (0.9483)  lr: 0.000100  iter-time: 0.2110\n",
            "[08:28:11.761040] Epoch: [62]  [70/72]  eta: 0:00:00  loss: 1.0304 (0.9494)  Accuracy: 0.6875 (0.7126)  Top 5 accuracy: 0.9375 (0.9454)  lr: 0.000100  iter-time: 0.2102\n",
            "[08:28:11.923838] Epoch: [62]  [71/72]  eta: 0:00:00  loss: 1.0304 (0.9493)  Accuracy: 0.6875 (0.7117)  Top 5 accuracy: 0.9375 (0.9462)  lr: 0.000100  iter-time: 0.2078\n",
            "[08:28:12.092317] Epoch: [62] Total time: 0:00:16 (0.2248 s / it)\n",
            "[08:28:12.092516] [Train] averaged stats: loss: 1.0304 (0.9493)  Accuracy: 0.6875 (0.7117)  Top 5 accuracy: 0.9375 (0.9462)  lr: 0.000100\n",
            "[08:28:13.021819] Epoch: [62]  [0/8]  eta: 0:00:07  loss: 1.8360 (1.8360)  Accuracy: 0.5312 (0.5312)  Top 5 accuracy: 0.7812 (0.7812)  iter-time: 0.9258\n",
            "[08:28:13.467572] Epoch: [62]  [7/8]  eta: 0:00:00  loss: 2.3412 (2.3294)  Accuracy: 0.4062 (0.4429)  Top 5 accuracy: 0.7500 (0.7254)  iter-time: 0.1705\n",
            "[08:28:13.561535] Epoch: [62] Total time: 0:00:01 (0.1833 s / it)\n",
            "[08:28:13.561609] [Val] averaged stats: loss: 2.3412 (2.3294)  Accuracy: 0.4062 (0.4429)  Top 5 accuracy: 0.7500 (0.7254)\n",
            "[08:28:13.562096] [Val] best loss: 2.0684 best  Accuracy: 0.4779 Top 5 accuracy: 0.7610 \n",
            "EarlyStopping counter: 20 out of 20\n",
            "[08:28:13.563376] Early stopping\n",
            "[08:28:13.563424] Training time: 0:19:30\n",
            "[08:28:13.563446] Train loss: 0.9492698237299919\n",
            "[08:28:13.563469] Train Accuracy: 0.7117489435606532\n",
            "[08:28:13.563488] Train Top 5 accuracy: 0.9461805555555556\n",
            "[08:28:13.563513] Validation loss: 2.0684173852205276\n",
            "[08:28:13.563549] Validation Accuracy: 0.4779485762119293\n",
            "[08:28:13.563568] Validation Top 5 accuracy: 0.760962724685669\n",
            "[08:28:13.563584] Finished Training\n",
            "[08:28:13.564820] Loading checkpoint from file /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:28:14.493544] Model weights loaded!\n",
            "[08:28:14.514245] Releasing memory . . .\n",
            "[08:28:14.514370] ######################\n",
            "[08:28:14.514392] #   LOAD TEST DATA   #\n",
            "[08:28:14.514408] ######################\n",
            "[08:28:14.514456] ### LOAD ###\n",
            "[08:28:14.514652] Found 75 classes\n",
            "[08:28:15.849211] ############################\n",
            "[08:28:15.849324] #  PREPARE TEST GENERATOR  #\n",
            "[08:28:15.849347] ############################\n",
            "[08:28:15.854006] Loading checkpoint from file /content/output/my_2d_classification_butterfly/checkpoints/my_2d_classification_butterfly_1-checkpoint-best.pth\n",
            "[08:28:16.578069] Model weights loaded!\n",
            "[08:28:16.579798] ###############\n",
            "[08:28:16.579852] #  INFERENCE  #\n",
            "[08:28:16.579869] ###############\n",
            "[08:28:16.579885] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[08:28:30.389180] Releasing memory . . .\n",
            "[08:28:30.433650] #############\n",
            "[08:28:30.433691] #  RESULTS  #\n",
            "[08:28:30.433709] #############\n",
            "[08:28:30.433725] The values below represent the averages across all test samples\n",
            "[08:28:30.433780] Epoch number: 62\n",
            "[08:28:30.433799] Train time (s): 0:19:30\n",
            "[08:28:30.433866] Train loss: 0.9427123769289918\n",
            "[08:28:30.433913] Train Accuracy: 0.7198256336980395\n",
            "[08:28:30.433951] Train Top 5 accuracy: 0.9467089374860128\n",
            "[08:28:30.433970] Validation loss: 2.0684173852205276\n",
            "[08:28:30.433994] Validation Accuracy: 0.4779485762119293\n",
            "[08:28:30.434012] Validation Top 5 accuracy: 0.760962724685669\n",
            "[08:28:30.434053] Test Accuracy: 0.524\n",
            "[08:28:30.434074] Confusion matrix: \n",
            "[08:28:30.434091] [[9 0 0 ... 0 0 0]\n",
            " [0 8 0 ... 0 0 0]\n",
            " [0 0 5 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 5 0]\n",
            " [0 0 0 ... 0 0 9]]\n",
            "[08:28:30.441921] \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Category 0       0.60      0.90      0.72        10\n",
            "  Category 1       0.57      0.80      0.67        10\n",
            "  Category 2       0.56      0.50      0.53        10\n",
            "  Category 3       0.50      1.00      0.67        10\n",
            "  Category 4       0.57      0.80      0.67        10\n",
            "  Category 5       1.00      0.50      0.67        10\n",
            "  Category 6       0.60      0.30      0.40        10\n",
            "  Category 7       0.58      0.70      0.64        10\n",
            "  Category 8       0.56      0.50      0.53        10\n",
            "  Category 9       0.64      0.70      0.67        10\n",
            " Category 10       0.33      0.30      0.32        10\n",
            " Category 11       0.57      0.40      0.47        10\n",
            " Category 12       0.40      0.20      0.27        10\n",
            " Category 13       0.50      0.50      0.50        10\n",
            " Category 14       0.78      0.70      0.74        10\n",
            " Category 15       0.30      0.60      0.40        10\n",
            " Category 16       0.50      0.80      0.62        10\n",
            " Category 17       0.78      0.70      0.74        10\n",
            " Category 18       0.75      0.30      0.43        10\n",
            " Category 19       0.50      0.10      0.17        10\n",
            " Category 20       0.50      0.40      0.44        10\n",
            " Category 21       0.23      0.30      0.26        10\n",
            " Category 22       0.38      0.50      0.43        10\n",
            " Category 23       0.56      0.50      0.53        10\n",
            " Category 24       0.89      0.80      0.84        10\n",
            " Category 25       0.75      0.30      0.43        10\n",
            " Category 26       0.43      0.30      0.35        10\n",
            " Category 27       0.44      0.70      0.54        10\n",
            " Category 28       0.71      1.00      0.83        10\n",
            " Category 29       0.82      0.90      0.86        10\n",
            " Category 30       0.38      0.30      0.33        10\n",
            " Category 31       0.25      0.20      0.22        10\n",
            " Category 32       0.78      0.70      0.74        10\n",
            " Category 33       0.83      0.50      0.62        10\n",
            " Category 34       0.67      0.40      0.50        10\n",
            " Category 35       0.73      0.80      0.76        10\n",
            " Category 36       0.38      0.60      0.46        10\n",
            " Category 37       0.67      0.60      0.63        10\n",
            " Category 38       0.50      0.20      0.29        10\n",
            " Category 39       0.53      0.80      0.64        10\n",
            " Category 40       0.57      0.40      0.47        10\n",
            " Category 41       0.71      0.50      0.59        10\n",
            " Category 42       0.78      0.70      0.74        10\n",
            " Category 43       0.38      0.30      0.33        10\n",
            " Category 44       0.42      0.50      0.45        10\n",
            " Category 45       0.41      0.70      0.52        10\n",
            " Category 46       0.12      0.10      0.11        10\n",
            " Category 47       0.60      0.30      0.40        10\n",
            " Category 48       0.53      0.80      0.64        10\n",
            " Category 49       0.44      0.40      0.42        10\n",
            " Category 50       0.78      0.70      0.74        10\n",
            " Category 51       0.89      0.80      0.84        10\n",
            " Category 52       0.47      0.80      0.59        10\n",
            " Category 53       0.50      0.60      0.55        10\n",
            " Category 54       0.40      0.80      0.53        10\n",
            " Category 55       0.50      0.60      0.55        10\n",
            " Category 56       0.23      0.30      0.26        10\n",
            " Category 57       0.27      0.30      0.29        10\n",
            " Category 58       0.50      0.60      0.55        10\n",
            " Category 59       0.47      0.70      0.56        10\n",
            " Category 60       0.50      0.10      0.17        10\n",
            " Category 61       0.17      0.10      0.12        10\n",
            " Category 62       0.57      0.80      0.67        10\n",
            " Category 63       0.75      0.30      0.43        10\n",
            " Category 64       0.45      0.50      0.48        10\n",
            " Category 65       0.33      0.10      0.15        10\n",
            " Category 66       0.50      0.70      0.58        10\n",
            " Category 67       0.86      0.60      0.71        10\n",
            " Category 68       0.00      0.00      0.00        10\n",
            " Category 69       0.44      0.40      0.42        10\n",
            " Category 70       0.53      0.90      0.67        10\n",
            " Category 71       0.43      0.30      0.35        10\n",
            " Category 72       0.17      0.10      0.12        10\n",
            " Category 73       0.83      0.50      0.62        10\n",
            " Category 74       0.69      0.90      0.78        10\n",
            "\n",
            "    accuracy                           0.52       750\n",
            "   macro avg       0.54      0.52      0.51       750\n",
            "weighted avg       0.54      0.52      0.51       750\n",
            "\n",
            "[08:28:30.442000] FINISHED JOB my_2d_classification_butterfly_1 !!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play to train the model\n",
        "import os\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# remove template file it is exists\n",
        "template_file = '2d_classification.yaml'\n",
        "if os.path.exists( template_file ):\n",
        "    os.remove( template_file )\n",
        "\n",
        "# Download template file\n",
        "!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/classification/2d_classification.yaml &> /dev/null\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(train_data_path))\n",
        "\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[1])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No folders found in dir {}\".format(test_data_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( template_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "#DATA.NORMALIZATION.TYPE\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size)+', '+ str(patch_size)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding = patch_size // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding)+', '+ str(padding)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# Data augmentation\n",
        "if aggressive_data_augmentation == True:\n",
        "    biapy_config['AUGMENTOR']['DROPOUT'] = True\n",
        "    biapy_config['AUGMENTOR']['GRIDMASK'] = True\n",
        "    biapy_config['AUGMENTOR']['CUTBLUR'] = True\n",
        "    biapy_config['AUGMENTOR']['CUTNOISE'] = True\n",
        "    biapy_config['AUGMENTOR']['MOTION_BLUR'] = True\n",
        "    #biapy_config['AUGMENTOR']['ELASTIC'] = True\n",
        "    #biapy_config['AUGMENTOR']['CUTOUT'] = True\n",
        "    #biapy_config['AUGMENTOR']['BRIGHTNESS'] = True\n",
        "    #biapy_config['AUGMENTOR']['CONTRAST'] = True\n",
        "\n",
        "# learning rate scheduler\n",
        "if learning_rate_scheduler == 'One cycle':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'onecycle'\n",
        "elif learning_rate_scheduler == 'Warm-up cosine decay':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'warmupcosine'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.0\n",
        "    warmup_epochs = round( number_of_epochs * 0.05 )\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['WARMUP_COSINE_DECAY_EPOCHS'] = warmup_epochs\n",
        "elif learning_rate_scheduler == 'Reduce on plateau':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'reduceonplateau'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_FACTOR'] = 0.5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_PATIENCE'] = 5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.00001\n",
        "\n",
        "# change source to build model - biapy, torchvision or bmz\n",
        "if changed_source:\n",
        "    if source.value == \"BiaPy\":\n",
        "        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "    elif source.value == 'Torchvision':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"torchvision\"\n",
        "        biapy_config['MODEL']['TORCHVISION_MODEL_NAME'] = t_vision.value\n",
        "    elif source.value == 'BioImage Model Zoo':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n",
        "        biapy_config['MODEL']['BMZ'] = {}\n",
        "        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_ID'] = str(bmz.value).strip()\n",
        "else:\n",
        "    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"ViT\", \"EfficientNetB0\", \"EfficientNetB1\", \"EfficientNetB2\",\n",
        "# \"EfficientNetB3\", \"EfficientNetB4\", \"EfficientNetB5\", \"EfficientNetB6\",\n",
        "#  \"EfficientNetB7\", \"simple_cnn\"\n",
        "architecture = \"simple_cnn\"\n",
        "if model_architecture == \"simple_cnn\":\n",
        "    architecture = 'simple_cnn'\n",
        "elif model_architecture == \"ViT\":\n",
        "    architecture = 'ViT'\n",
        "elif \"EfficientNet\" in model_architecture:\n",
        "    architecture = model_architecture.replace(\"B\", \"_b\").lower()\n",
        "biapy_config['MODEL']['N_CLASSES'] = number_of_classes\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "# model weights\n",
        "if checkpoint_path != '':\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4i0N2vOWUes"
      },
      "source": [
        "## **Inspection of the Loss Function and Accuracy**\n",
        "---\n",
        "\n",
        "Before proceeding with interpretations, it's pivotal to gauge the training evolution by juxtaposing the training loss against the validation loss. The validation loss casts light on the model's efficacy over a reserved subset of data unseen during training. A deeper understanding can be garnered from [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n",
        "\n",
        "- **Training Loss**: This captures the discrepancy between the model's predictions and the actual ground-truth after each epoch.\n",
        "\n",
        "- **Validation Loss**: This signifies the error between the model's estimates on validation images and their actual counterparts.\n",
        "\n",
        "As training unfurls, these metrics are expected to wane, eventually plateauing at an optimal, minimal value. Contrasting the trajectories of these losses can yield vital information about the model's adaptability.\n",
        "\n",
        "- **Decreasing Training and Validation Losses**: This trend is indicative of potential model improvements with further training. Elevating the `number_of_epochs` is advised in such scenarios. Notably, even if the loss curves seem to stabilize towards the tail end, it might be a mere visual effect due to y-axis scaling. The model is considered convergent once the curves genuinely flatten, marking the end of required training.\n",
        "\n",
        "- **Divergent Losses**: An upward tick in validation loss while training loss gravitates towards zero hints at overfitting. It suggests that the model is intricately memorizing training patterns at the cost of broader applicability. A more substantial training dataset can alleviate this.\n",
        "\n",
        "\n",
        "The **Accuracy** metric evaluates the model's performance across all classes by contrasting the target class against the predicted output. **A value gravitating towards 1 denotes peak performance.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "ur21krhZVwX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "20ccddaa-96d7-498a-8d30-8195ea487bfc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play the cell to show a plot of training error vs. epoch number and accuracy vs epoch number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n",
        "\n",
        "iou_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_Accuracy.png' )\n",
        "\n",
        "fig = plt.figure( figsize = (20,10))\n",
        "ax1 = plt.subplot( 1, 2, 1 )\n",
        "_ = plt.imshow( loss_plot )\n",
        "_ = plt.axis('off')\n",
        "ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n",
        "\n",
        "ax2 = plt.subplot( 1, 2, 2 )\n",
        "_ = plt.imshow( iou_plot )\n",
        "_ = plt.axis('off')\n",
        "_= ax2.set_title( 'Accuracy vs epoch number', fontdict = {'fontsize':22})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iqPSdEw-g4qs"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Visualize predictions (from the test set)\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "predictions_df = pd.read_csv('/content/output/'+str(job_name)+'/results/'+str(job_name)+'_1/predictions.csv')\n",
        "#labels = sorted([folder for folder in os.listdir(test_data_path) if os.path.isdir(os.path.join(test_data_path, folder))])\n",
        "\n",
        "# Reading class names dynamically from folder names\n",
        "labels = sorted([folder for folder in os.listdir(train_data_path) if os.path.isdir(os.path.join(train_data_path, folder))])\n",
        "\n",
        "def find_original_class(filename, labels):\n",
        "    for index, label in enumerate(labels):\n",
        "        if filename in os.listdir(os.path.join(test_data_path, label)):\n",
        "            return index\n",
        "    return None\n",
        "\n",
        "def display_predictions(predictions_df, labels, num_image):\n",
        "    random_samples = predictions_df.sample(n=num_image)\n",
        "    fig = plt.figure(figsize=(25, 25 * num_image))\n",
        "\n",
        "    for index, (idx, row) in enumerate(random_samples.iterrows()):\n",
        "        original_class = find_original_class(os.path.basename( row['filename'] ), labels)\n",
        "        image_path = os.path.join(test_data_path, labels[original_class], row['filename'])\n",
        "        image = plt.imread(image_path)\n",
        "\n",
        "        ax = plt.subplot(1, num_image, index + 1)\n",
        "        if image.shape[-1] == 1 or image.ndim == 2:\n",
        "            ax.imshow(image, cmap='gray')\n",
        "        else:\n",
        "            ax.imshow(image)\n",
        "\n",
        "        predicted_label_name = row['class']\n",
        "        original_label_name = original_class\n",
        "\n",
        "        if test_ground_truth:\n",
        "            ax.set_title(f\"Predicted label: {predicted_label_name}\\nGT label: {original_label_name}\", fontsize=11)\n",
        "        else:\n",
        "            ax.set_title(f\"Predicted label: {predicted_label_name}\", fontsize=11)\n",
        "\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
        "    plt.show()\n",
        "\n",
        "display_predictions(predictions_df, labels, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mlQnAH6uAawl"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Play to display the path to the output CSV file\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "class_results = os.path.join(final_results, \"predictions.csv\")\n",
        "\n",
        "print(\"Output paths:\")\n",
        "print(\"    Predicted test classes are in {}\".format(class_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdCIYo4ohcAw"
      },
      "source": [
        "## **Download classification results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gnRa9DOUP0FM",
        "outputId": "9ef5d488-29ac-4922-c3c3-f603271803e9"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_afdb5617-8632-4a06-876f-1ca4aedea24b\", \"predictions.csv\", 32990)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download the CSV file with all classification results in test.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(class_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwt72WYddVgl"
      },
      "source": [
        "## **Download train model (weights and configuration file)**\n",
        "---\n",
        "If you want to **reuse the train model in the future**, you can download both the model weights and its configuration file (.YAML) by running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XoFclBfEduZC",
        "outputId": "1dc405d6-c012-403b-d561-3f80def59dfc"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_5330622b-cd48-4857-859a-149237f96e9a\", \"model_weights_my_2d_classification_VIT_1.h5\", 342858352)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "#@markdown ###Play to download the model weights\n",
        "\n",
        "checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n",
        "\n",
        "weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n",
        "\n",
        "files.download( os.path.join( checkpoints_path, weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "raDdSsz1dujE",
        "outputId": "6f363718-12c4-41b4-c142-be79b16010d6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b20676ea-8a36-4641-856e-c1addaa43ed7\", \"my_2d_classification_VIT.yaml\", 752)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download the model configuration file (.YAML)\n",
        "\n",
        "config_path = os.path.join(output_path, job_name, 'config_files')\n",
        "\n",
        "files.download( os.path.join( config_path, yaml_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KraUMXqJdoSU"
      },
      "source": [
        "## **Export your model to BioImage Model Zoo format**\n",
        "---\n",
        "If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWHr_sQK_-qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##Construct model's metadata to export it to the BioImage Model Zoo format. Choose just one option:\n",
        "\n",
        "#@markdown **Option 1: Reuse previous BioImage Model Zoo model configuration**\n",
        "\n",
        "#@markdown With this option, if you were using a model from BioImage Model Zoo you can select this option to reuse its configuration instead of provide all fields manually. If that's not the case and you try to use this option an error will be thrown.\n",
        "reuse_previous_BMZ_model_config = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Option 2: Manual export fields**\n",
        "\n",
        "#@markdown With this option you need to introduce manually the metadata of the model.\n",
        "\n",
        "# ------------- User input ------------\n",
        "# information about the model\n",
        "trained_model_name    = \"\" #@param {type:\"string\"}\n",
        "trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n",
        "trained_model_authors_github_user =  \"[First Author Github User, Second Author Github User, Third Author Github User]\" #@param {type:\"string\"}\n",
        "trained_model_description = \"\" #@param {type:\"string\"}\n",
        "trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n",
        "trained_model_references = [\"Ronneberger et al. arXiv in 2015\", \"Franco-Barranco, Daniel, et al. ISBI in 2023\"] #@param {type:\"string\"}\n",
        "trained_model_references_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n",
        "trained_model_tags = \"[\\\"tag-1\\\", \\\"tag-2\\\"]\" #@param {type:\"string\"}\n",
        "trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KH8UuC_CgpH2"
      },
      "outputs": [],
      "source": [
        "# @markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "bmz_results = os.path.join(final_results, \"bmz_model\")\n",
        "\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "\n",
        "    # create the author spec input\n",
        "    auth_names = trained_model_authors[1:-1].split(\",\")\n",
        "    auth_githubusers = trained_model_authors_github_user[1:-1].split(\",\")\n",
        "    assert len(auth_names) == len(auth_githubusers)\n",
        "    authors = [{\"name\": auth_name, \"github_user\": auth_guser} for auth_name, auth_guser in zip(auth_names, auth_githubusers)]\n",
        "\n",
        "    # create the citation input spec\n",
        "    assert len(trained_model_references_DOI) == len(trained_model_references)\n",
        "    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_references_DOI)]\n",
        "\n",
        "    tags = [t for t in trained_model_tags.split(\",\")]\n",
        "\n",
        "    with open(trained_model_documentation, \"w\") as f:\n",
        "        f.write(\"### **Description**\\n\")\n",
        "        f.write(f\"{trained_model_description}\\n\\n\")\n",
        "        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n",
        "\n",
        "    bmz_cfg = {}\n",
        "    # Description of the model\n",
        "    bmz_cfg['description'] = trained_model_description\n",
        "    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Daniel\", \"github_user\": \"danifranco\"}]\n",
        "    bmz_cfg['authors'] = authors\n",
        "    # License of the model. E.g. \"CC-BY-4.0\"\n",
        "    bmz_cfg['license'] = trained_model_license\n",
        "    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n",
        "    bmz_cfg['tags'] = tags\n",
        "    # Tags to make models more findable on the website, e.g. tags=[\"electron-microscopy\", \"mitochondria\"]\n",
        "    bmz_cfg['cite'] = citations\n",
        "    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n",
        "    bmz_cfg['doc'] = trained_model_documentation\n",
        "    # Name of the model\n",
        "    bmz_cfg[\"model_name\"] = trained_model_name\n",
        "    biapy.export_model_to_bmz(bmz_results, bmz_cfg)\n",
        "else:\n",
        "    try:\n",
        "        biapy.export_model_to_bmz(bmz_results, reuse_original_bmz_config=True)\n",
        "    except:\n",
        "        print(\"Seems that the was a problem reusing BMZ model specs. Please uncheck 'reuse_previous_BMZ_model_config' and do it manually\")\n",
        "\n",
        "download = True\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "    bmz_zip_path = f\"/{bmz_results}/{trained_model_name}.zip\"\n",
        "else:\n",
        "    ids = sorted(next(os.walk(bmz_results))[2])\n",
        "    ids = [x for x in ids if x.endswith(\".zip\")]\n",
        "    if len(ids) > 1:\n",
        "        print(f\"There are more than one ZIP files in {bmz_results} folder. Please check which one you want you want to download and do it manually.\")\n",
        "        download = False\n",
        "    elif len(ids) == 0:\n",
        "        print(f\"BMZ zip file could not be found.\")\n",
        "        download = False\n",
        "    else: # only one zip\n",
        "        ids = ids[0]\n",
        "    bmz_zip_path = f\"/{bmz_results}/{ids}\"\n",
        "\n",
        "if download and os.path.exists(bmz_zip_path):\n",
        "    files.download(bmz_zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFVjWbF8GZ2z"
      },
      "source": [
        "## **How to use the trained model with new data**\n",
        "---\n",
        "To directly infer new data to the trained model, you can use [this notebook](https://github.com/BiaPyX/BiaPy/blob/master/notebooks/BiaPy_Inference.ipynb). It will be necessary to upload the downloaded YAML configuration file and model weights to that notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjSgLwe0x-P0"
      },
      "source": [
        "## **Acknowledgments**\n",
        "---\n",
        "We would like to acknowledge the inspiration provided by the excellent [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki). In particular, we have reused some of their descriptions of metrics and parameters."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}