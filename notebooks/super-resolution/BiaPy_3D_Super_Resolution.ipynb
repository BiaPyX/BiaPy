{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj4fyEhgM1EW"
      },
      "source": [
        "# **3D Super-resolution / Image restoration pipeline**\n",
        "___\n",
        "In this notebook, we demonstrate the use of the [BiaPy](https://biapyx.github.io/) pipeline for **3D super-resolution / image restoration**, for reconstructing (or restoring) high-resolution (HR) images from low-resolution (LR).\n",
        "\n",
        "<figure>\n",
        "  <center>\n",
        "    <table>\n",
        "    <tr>\n",
        "        <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_1_LR.png' width='100px'/>\n",
        "        </td>\n",
        "      <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_2_LR.png' width='100px'/>\n",
        "      </td>\n",
        "      <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_3_LR.png' width='100px'/>\n",
        "      </td>\n",
        "      <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_4_LR.png' width='100px'/>\n",
        "      </td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "        <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_1_HR.png' width='100px'/>\n",
        "        </td>\n",
        "      <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_2_HR.png' width='100px'/>\n",
        "      </td>\n",
        "      <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_3_HR.png' width='100px'/>\n",
        "      </td>\n",
        "      <td>\n",
        "        <img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/super-resolution/SR_3D_cardiomyoblast_sample_4_HR.png' width='100px'/>\n",
        "      </td>\n",
        "    </tr>\n",
        "    </table>\n",
        "    <figcaption>Illustrative demonstration of a 3D Super-resolution problem. The images presented in the first row correspond to in low resolution cardiomyoblasts images, while their corresponding high-resolution counterparts are depicted in the second row.</figcaption>\n",
        "  </center>\n",
        "</figure>\n",
        "\n",
        "\n",
        "Without any coding, we'll guide you step-by-step through the process to:\n",
        "1. **Upload a set of training and test images** along with their corresponding instance label images.\n",
        "2. **Train a Deep Neural Network (DNN)** model using the training set.\n",
        "3. **Apply the model** to the test images.\n",
        "4. **Download the segmentation results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired by the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus), [Lenka Backov\u00e1](mailto:lenka.backova@ehu.eus) [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org) and [Ane Paniagua](mailto:anepaniagua@gmail.com). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THPAvyG3JD33"
      },
      "source": [
        "## **Expected inputs and outputs**\n",
        "___\n",
        "### **Inputs**\n",
        "\n",
        "This notebook expects five folders as input:\n",
        "* **Training LR images**: with the low resolution 3D images to train the model.\n",
        "* **Training HR images**: with the high resolution 3D images to train the model. Their number and sizes must match those of the training raw images.\n",
        "* **Test LR images**: with the raw 3D images to test the model.\n",
        "* **Test HR images**: with the high resolution 3D images to test the model. Their number and sizes must match those of the validation raw images.\n",
        "* **Output folder**: a path to store the super-resolution results.\n",
        "\n",
        "**Outputs**\n",
        "\n",
        "Upon successful execution, a new folder will be generated containing one result **TIFF image** for every test image. These result images will showcase the instances of the objects of interest as determined by our pipeline.\n",
        "\n",
        "<font color='red'><b>Note:</b></font> For testing, this notebook can be executed using the **example datasets found under 'Manage file(s) source > Option 3'**.\n",
        "\n",
        "**Data structure**\n",
        "\n",
        "To ensure the proper operation of the library the data directory tree should be something like this:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "\u251c\u2500\u2500 train\n",
        "\u2502   \u251c\u2500\u2500 LR\n",
        "\u2502   \u2502   \u251c\u2500\u2500 training-0001.tif\n",
        "\u2502   \u2502   \u251c\u2500\u2500 training-0002.tif\n",
        "\u2502   \u2502   \u251c\u2500\u2500 . . .\n",
        "\u2502   \u2502   \u2514\u2500\u2500 training-9999.tif\n",
        "\u2502   \u2514\u2500\u2500 HR\n",
        "\u2502       \u251c\u2500\u2500 training_groundtruth-0001.tif\n",
        "\u2502       \u251c\u2500\u2500 training_groundtruth-0002.tif\n",
        "\u2502       \u251c\u2500\u2500 . . .\n",
        "\u2502       \u2514\u2500\u2500 training_groundtruth-9999.tif\n",
        "\u2514\u2500\u2500 test\n",
        "    \u251c\u2500\u2500 LR\n",
        "    \u2502   \u251c\u2500\u2500 testing-0001.tif\n",
        "    \u2502   \u251c\u2500\u2500 testing-0002.tif\n",
        "    \u2502   \u251c\u2500\u2500 . . .\n",
        "    \u2502   \u2514\u2500\u2500 testing-9999.tif\n",
        "    \u2514\u2500\u2500 HR\n",
        "        \u251c\u2500\u2500 testing_groundtruth-0001.tif\n",
        "        \u251c\u2500\u2500 testing_groundtruth-0002.tif\n",
        "        \u251c\u2500\u2500 . . .\n",
        "        \u2514\u2500\u2500 testing_groundtruth-9999.tif\n",
        "```\n",
        "\n",
        "**\u26a0\ufe0f Warning:** Ensure that low-resolution images and their corresponding high-resolution images are sorted in the same way. A common approach is to fill with zeros the image number added to the filenames (as in the example).\n",
        "\n",
        "**Input Format Support**\n",
        "\n",
        "This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.npy` (every extension for 3D images supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZvMhqxZJMqk"
      },
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFh72ny0Y9dO"
      },
      "source": [
        "## **Check for GPU Access**\n",
        "---\n",
        "\n",
        "By default, the session is configured to use Python 3 with GPU acceleration. However, it's a good practice to double-check these settings:\n",
        "\n",
        "1. Navigate to **Runtime** in the top menu and select **Change the Runtime type**.\n",
        "2. Ensure the following settings:\n",
        "   - **Runtime type:** Python 3 (This program is written in the Python 3 programming language.)\n",
        "   - **Accelerator:** GPU (Graphics Processing Unit)\n",
        "\n",
        "This will ensure that you're using Python 3 and taking advantage of GPU acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLYsqrDALpVN"
      },
      "source": [
        "## **Install BiaPy**\n",
        "---\n",
        "This might take some minutes depending on the current installed libraries in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p33UIUUWLm3V",
        "outputId": "4dab9c0f-6c01-4eed-ef98-547d2492a139",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biapy==3.5.12\n",
            "  Downloading biapy-3.5.12-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.6.1)\n",
            "Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.0.4)\n",
            "Collecting yacs>=0.1.8 (from biapy==3.5.12)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (0.25.2)\n",
            "Collecting edt>=2.3.2 (from biapy==3.5.12)\n",
            "  Downloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting fill-voids>=2.0.6 (from biapy==3.5.12)\n",
            "  Downloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.76 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.2.2)\n",
            "Collecting torchinfo>=1.8.0 (from biapy==3.5.12)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.6.2.2 (from biapy==3.5.12)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: h5py>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.13.0)\n",
            "Requirement already satisfied: zarr>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.18.4)\n",
            "Collecting bioimageio.core==0.7.0 (from biapy==3.5.12)\n",
            "  Downloading bioimageio.core-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting imagecodecs>=2024.1.1 (from biapy==3.5.12)\n",
            "  Downloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.26.4)\n",
            "Collecting imgaug>=0.4.0 (from biapy==3.5.12)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pooch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.8.2)\n",
            "Collecting diplib>=3.5.1 (from biapy==3.5.12)\n",
            "  Downloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting pydantic<2.10,>=2.7.0 (from biapy==3.5.12)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray==2025.1.* in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2025.1.2)\n",
            "Collecting bioimageio.spec==0.5.3.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading bioimageio.spec-0.5.3.5-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: imageio>=2.10 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.37.0)\n",
            "Collecting loguru (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic-settings>=2.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.32.3)\n",
            "Collecting ruyaml (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading ruyaml-0.91.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (4.12.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray==2025.1.*->biapy==3.5.12) (24.2)\n",
            "Requirement already satisfied: annotated-types<1,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.7.0)\n",
            "Collecting email-validator (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.8.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (13.9.4)\n",
            "Requirement already satisfied: tifffile>=2020.7.4 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2025.3.13)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.21.0)\n",
            "Collecting fastremap (from fill-voids>=2.0.6->biapy==3.5.12)\n",
            "  Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (11.1.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (2.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.8.1->biapy==3.5.12) (4.3.7)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<2.10,>=2.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (3.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.5.12) (5.29.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8->biapy==3.5.12) (6.0.2)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.3.3)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.19)\n",
            "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.15.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.2.18)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2025.1.31)\n",
            "Requirement already satisfied: distro>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=39.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (75.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.1.2)\n",
            "Downloading biapy-3.5.12-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.core-0.7.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.spec-0.5.3.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruyaml-0.91.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yacs, torchinfo, tensorboardX, ruyaml, python-dotenv, pydantic-core, loguru, imagecodecs, fastremap, edt, dnspython, diplib, pydantic, fill-voids, email-validator, pydantic-settings, imgaug, bioimageio.spec, bioimageio.core, biapy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "Successfully installed biapy-3.5.12 bioimageio.core-0.7.0 bioimageio.spec-0.5.3.5 diplib-3.5.2 dnspython-2.7.0 edt-3.0.0 email-validator-2.2.0 fastremap-1.15.1 fill-voids-2.0.8 imagecodecs-2024.12.30 imgaug-0.4.0 loguru-0.7.3 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.8.1 python-dotenv-1.1.0 ruyaml-0.91.0 tensorboardX-2.6.2.2 torchinfo-1.8.0 yacs-0.1.8\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting torchmetrics==1.4.* (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (24.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.4.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (0.19.0+cu118)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.86)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-msssim, torch-fidelity\n",
            "Successfully installed lightning-utilities-0.14.2 pytorch-msssim-1.0.0 torch-fidelity-0.3.0 torchmetrics-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "# Install latest release of BiaPy\n",
        "!pip install biapy==3.6.0\n",
        "\n",
        "# Then install Pytorch + CUDA 11.8\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Finally install some packages that rely on the Pytorch installation\n",
        "!pip install timm==1.0.14 pytorch-msssim torchmetrics[image]==1.4.*\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "from biapy import BiaPy\n",
        "\n",
        "changed_source = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbwGjEZ_gHzU"
      },
      "source": [
        "## **Manage File(s) Source**\n",
        "---\n",
        "\n",
        "The input folder can be provided using three different options:\n",
        "1. **Direct Upload**: Directly upload the desired folder.\n",
        "2. **Google Drive**: Use a folder stored in your Google Drive.\n",
        "3. **Sample Data**: Use a sample dataset provided by us.\n",
        "\n",
        "The steps you'll need to follow vary depending on your chosen option. These steps are detailed in the subsequent sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlqK-re2T-gu"
      },
      "source": [
        "### **Option 1: Upload Files from Your Local Machine**\n",
        "---\n",
        "\n",
        "When you select this option, you'll be prompted to upload your files to Colab. Once uploaded, they will be stored in the `/content/input/` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xGS5LCaHPWR8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train LR images)\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/LR\n",
        "%cd /content/input/train/LR\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qyvRptgjXMMN"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train HR images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/HR\n",
        "%cd /content/input/train/HR\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PafWC0U3XYjd"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (test LR images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test/LR\n",
        "%cd /content/input/test/LR\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Tl1qtfeJXYp1"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (test HR images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test/HR\n",
        "%cd /content/input/test/HR\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-xIgKMDUkv1"
      },
      "source": [
        "### **Option 2: Mount Your Google Drive**\n",
        "---\n",
        "\n",
        "If you wish to use this notebook with data from your Google Drive, you'll first need to mount the drive to this notebook.\n",
        "\n",
        "Execute the cell below to initiate the Google Drive mounting process. A link will be displayed click on it. In the new browser window that opens, choose your drive and click 'Allow'. Copy the code that appears, return to this notebook, paste the code into the cell, and press 'Enter'. This action grants Colab access to your Google Drive data.\n",
        "\n",
        "After this process, you can access your data via the **Files** tab, located on the top left of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fznVLfygUnb2"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL.\n",
        "\n",
        "#@markdown * Sign in your Google Account.\n",
        "\n",
        "#@markdown * Copy the authorization code.\n",
        "\n",
        "#@markdown * Enter the authorization code.\n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaaq51GGUre1"
      },
      "source": [
        "### **Option 3: Download an Example Dataset**\n",
        "---\n",
        "Don't have data readily available but still want to test the notebook? No problem! Simply execute the following cell to download a sample dataset.\n",
        "\n",
        "Specifically, we'll use the [\"Confocal 2 STED - Nuclear Pore complex\" dataset](https://zenodo.org/records/4624364#.YF3jsa9Kibg) released in [Chen, J., Sasaki, H., Lai, H. et al. Three-dimensional residual channel attention networks denoise and sharpen fluorescence microscopy image volumes. Nat Methods 18, 678\u2013687 (2021).](https://www.nature.com/articles/s41597-022-01207-7)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ws5Yw8fUUqzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f3ae33-1b5a-4282-aa0a-90ff2c7437a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "!pip install gdown==5.1.0 --quiet\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "gdown.download(\"https://drive.google.com/uc?id=1TfQVK7arJiRAVmKHRebsfi8NEas8ni4s\", \"data.zip\", quiet=True)\n",
        "\n",
        "!unzip -q data.zip\n",
        "!rm data.zip\n",
        "\n",
        "print('Dataset downloaded and unzipped under /content/data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzgl3nt0ZuC2"
      },
      "source": [
        "## **Paths for Input Images and Output Files**\n",
        "___\n",
        "\n",
        "Depending on the option you chose for managing file sources, you'll set your paths differently:\n",
        "\n",
        "- **Option 1 (Upload from Local Machine)**:\n",
        "  - Set `train_lr_data_path` to `/content/input/train/LR`\n",
        "  - Set `train_hr_data_path` to `/content/input/train/HR`\n",
        "  - Set `test_lr_data_path` to `/content/input/test/LR`\n",
        "  - Set `test_hr_data_path` to `/content/input/test/HR`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "- **Option 2 (Use Google Drive Data)**:\n",
        "  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n",
        "  \n",
        "- **Option 3 (Use Our Sample Data)**:\n",
        "  - Set `train_lr_data_path` to `/content/data/train/LR`\n",
        "  - Set `train_hr_data_path` to `/content/data/train/HR`\n",
        "  - Set `test_lr_data_path` to `/content/data/test/LR`\n",
        "  - Set `test_hr_data_path` to `/content/data/test/HR`\n",
        "  - Set `output_path` to `/content/out`\n",
        "\n",
        "  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n",
        "\n",
        "**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMPZ8raKZuZm",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e20b08-36ce-440b-a0fd-5beec7aeafde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training LR images: 26\n",
            "Number of training HR images: 26\n",
            "Number of test LR images: 6\n",
            "Number of test HR images: 6\n"
          ]
        }
      ],
      "source": [
        "#@markdown #####Path to train LR images\n",
        "train_lr_data_path = '/content/data/train/LR' #@param {type:\"string\"}\n",
        "#@markdown #####Path to train HR images\n",
        "train_hr_data_path = '/content/data/train/HR' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test LR images\n",
        "test_lr_data_path = '/content/data/test/LR' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test HR images\n",
        "test_hr_data_path = '/content/data/test/HR' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def count_image_files(directory):\n",
        "    if not directory or not os.path.exists(directory):\n",
        "        return 0\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.tif', '.npy', '.tiff', '.h5', '.hd5', '.zarr'}\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in image_extensions:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "num_train_images = count_image_files(train_lr_data_path)\n",
        "num_train_labels = count_image_files(train_hr_data_path)\n",
        "\n",
        "num_test_images = count_image_files(test_lr_data_path)\n",
        "num_test_labels = count_image_files(test_hr_data_path)\n",
        "\n",
        "print(f\"Number of training LR images: {num_train_images}\")\n",
        "print(f\"Number of training HR images: {num_train_labels}\")\n",
        "print(f\"Number of test LR images: {num_test_images}\")\n",
        "if test_hr_data_path != \"\":\n",
        "    print(f\"Number of test HR images: {num_test_labels}\")\n",
        "\n",
        "if num_train_images != num_train_labels:\n",
        "    print(\"Error: The number of training LR images does not match the number of training HR images.\")\n",
        "if test_hr_data_path != \"\" and num_test_images != num_test_labels:\n",
        "    print(\"Error: The number of test LR images does not match the number of test LR images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "i1bGcFh1i8Zq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## Play to visualize some data samples\n",
        "# @markdown Select the *Set* (training or test) to visualize samples from, and use the *Image index* and *Z value* scrolls to navigate among volumes and slices.\n",
        "\n",
        "# @markdown **Note**: it might take a few seconds to refresh the images.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread\n",
        "import os\n",
        "from ipywidgets import interact, IntSlider, Layout, Dropdown, VBox, Output\n",
        "\n",
        "# Initialize global attributes\n",
        "input_path = train_lr_data_path\n",
        "gt_path = train_hr_data_path\n",
        "\n",
        "instance_id = 0\n",
        "ids_input = sorted(next(os.walk(input_path))[2])\n",
        "input_img = imread(os.path.join(input_path, ids_input[0]))\n",
        "\n",
        "ids_gt = sorted(next(os.walk(gt_path))[2])\n",
        "gt_img = imread(os.path.join(gt_path, ids_gt[0]))\n",
        "\n",
        "# Initialize widgets\n",
        "\n",
        "# Dropdown widget to choose training or test set\n",
        "dropdown = Dropdown(\n",
        "    options=['training-set', 'test-set'],\n",
        "    value='training-set',\n",
        "    description='Set:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Slider widget to choose instance\n",
        "slider= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(ids_input),\n",
        "    step=1,\n",
        "    description='Image index:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "slider.style.description_width = 'initial'\n",
        "slider.style.handle_color='blue'\n",
        "\n",
        "# Slider widget to choose Z value\n",
        "sliderZ= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(input_img),\n",
        "    step=1,\n",
        "    description='Z value:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "sliderZ.style.description_width = 'initial'\n",
        "sliderZ.style.handle_color='blue'\n",
        "\n",
        "# Initialize Output instance to handle code output cell\n",
        "output = Output()\n",
        "\n",
        "# Function to update paths (input_img, gt_img) and image IDs (ids_input, ids_gt) depending on dropdown\n",
        "def update_paths(change):\n",
        "    global input_path, gt_path\n",
        "    if change.new == 'test-set':\n",
        "        input_path = test_lr_data_path\n",
        "        gt_path = test_hr_data_path\n",
        "    else:\n",
        "        input_path = train_lr_data_path\n",
        "        gt_path = train_hr_data_path\n",
        "\n",
        "    # Update image IDs based on the new paths\n",
        "    global ids_input, ids_gt\n",
        "    ids_input = sorted(next(os.walk(input_path))[2])\n",
        "    try:\n",
        "        ids_gt = sorted(next(os.walk(gt_path))[2])\n",
        "    except StopIteration:\n",
        "        ids_gt = []\n",
        "\n",
        "\n",
        "    # Reset slider value to 1 when dropdown changes\n",
        "    slider.value = 1\n",
        "    slider.max = len(ids_input)\n",
        "    update_id({'new': 1})\n",
        "\n",
        "# Function to update image and label set (input_img, gt_img, instance_id) depending on slider value\n",
        "def update_id(change):\n",
        "    index = change['new']\n",
        "\n",
        "    global instance_id\n",
        "    instance_id = index - 1\n",
        "\n",
        "    global input_path, ids_input, gt_path, ids_gt, input_img, gt_img\n",
        "\n",
        "    input_img_path = os.path.join(input_path, ids_input[instance_id])\n",
        "    input_img = imread(input_img_path)\n",
        "\n",
        "    if ids_gt != []: # If StopIteration exception was not thrown\n",
        "        gt_img_path = os.path.join(gt_path, ids_gt[instance_id])\n",
        "        gt_img = imread(gt_img_path)\n",
        "    else:\n",
        "        gt_img = None\n",
        "\n",
        "    sliderZ.value = 1\n",
        "    sliderZ.max = len(input_img)\n",
        "    display_images({'new': 1})\n",
        "\n",
        "# Function to display images depending on sliderZ value\n",
        "def display_images(change):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "        index = change['new']\n",
        "\n",
        "        global input_img, gt_img, instance_id\n",
        "\n",
        "        # Display images\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f\"Input LR image: {instance_id+1}, Z: {index}\")\n",
        "\n",
        "        if len(input_img.shape) == 4: # RGB\n",
        "            plt.imshow(input_img[index-1])\n",
        "        else:\n",
        "            plt.imshow(input_img[index-1], cmap='magma',vmin=np.percentile(input_img[index-1],0.1),vmax=np.percentile(input_img[index-1],99.9))\n",
        "        # plt.axis('off')\n",
        "\n",
        "        # # Print instance path to ensure the image displayed is correct\n",
        "        # global input_path, ids_input\n",
        "        # print(os.path.join(input_path, ids_input[instance_id]))\n",
        "\n",
        "        if gt_img is not None: # If StopIteration exception was not thrown\n",
        "            plt.subplot(1, 2, 2)\n",
        "            plt.title(\"Label HR image\")\n",
        "            if len(gt_img.shape) == 4: # RGB\n",
        "                plt.imshow(gt_img[index-1])\n",
        "            else:\n",
        "                plt.imshow(gt_img[index-1], cmap='magma',vmin=np.percentile(gt_img[index-1],0.1),vmax=np.percentile(gt_img[index-1],99.9))\n",
        "            # plt.axis('off')\n",
        "\n",
        "            # # Print label path to ensure the image displayed is correct\n",
        "            # global gt_path, ids_gt\n",
        "            # print(os.path.join(gt_path, ids_gt[instance_id]))\n",
        "        else:\n",
        "            print(\"No labels for this set.\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create a VBox to hold the dropdown and slider\n",
        "controls = VBox([dropdown, slider, sliderZ])\n",
        "display(controls, output)\n",
        "\n",
        "# Link widgets to functions\n",
        "dropdown.observe(update_paths, names='value')\n",
        "slider.observe(update_id, names='value')\n",
        "sliderZ.observe(display_images, names='value')\n",
        "\n",
        "# Initial display\n",
        "display_images({'new': slider.value})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592,
          "referenced_widgets": [
            "7bd7716f1fb14a9691980bad2aaeff80",
            "8e3a9bf74d244670a474c5f987758379",
            "89f1e0b53a7c44c99fae18a1e3b55e88",
            "d2c597a940f242c5a19831b2f30e7aa1",
            "a3a6e914b71b4d2f8308e0a2142c08b3",
            "5fd01741cb884904a4345e86ae11ad21",
            "2ef1f51a2a1547d99875ef31f154fcee",
            "f061c1d2d5a4402f81e1b9c57521c82d",
            "746db3f2fd984adf906d12a16d13be80",
            "285f211218cd4fd1bdd19e2b2ccc2390",
            "8db14c60c31044a2a869454f109468c7",
            "d0003cc741244002bb4a10f459b9aebe",
            "323b2eee041647ef88c6b71eba3031df"
          ]
        },
        "id": "_VbVVca0FaV9",
        "outputId": "bbc611aa-1fe3-4712-b13f-a138c1a47020",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Set:', options=('training-set', 'test-set'), value='training-set'), IntSl\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bd7716f1fb14a9691980bad2aaeff80"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0003cc741244002bb4a10f459b9aebe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9pIbL9NbZTe"
      },
      "source": [
        "## **Configure and train the DNN model**\n",
        "___\n",
        "[BiaPy](https://biapy.readthedocs.io/en/latest/) contains deep learning models to perform single image super-resolution.\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "57443892-0209-405b-97ce-47bb92e0c4f2",
        "cellView": "form",
        "id": "daGtIo-V_Ydt"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ###OPTIONAL: Check BioImage Model Zoo (BMZ) models compatible with BiaPy\n",
        "# @markdown Use this option to generate a full list of the available BiaPy-compatible models in the BMZ.\n",
        "\n",
        "# @markdown **Important:** To select one of the listed models (if any), you will have to run the next cell and select \"BioImage Model Zoo\" as the source of the model. Then, paste the corresponding model's nickname into the created field.\n",
        "# @markdown <div><img src=\"https://bioimage.io/static/img/bioimage-io-logo.svg\" width=\"600\"/></div>\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pooch\n",
        "import yaml\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "from biapy.models import check_bmz_model_compatibility\n",
        "from packaging.version import Version\n",
        "from typing import Optional, Dict, Tuple, List, Literal\n",
        "\n",
        "# Change pooch verbosity\n",
        "logger = pooch.get_logger()\n",
        "logger.setLevel(\"WARNING\")\n",
        "\n",
        "# Extracted from BiaPy-GUI.\n",
        "# Adapted from BiaPy commit: 284ec3838766392c9a333ac9d27b55816a267bb9 (3.5.2)\n",
        "def check_model_restrictions(\n",
        "    model_rdf,\n",
        "    workflow_specs,\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks model restrictions to be applied into the current configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_rdf : dict\n",
        "        BMZ model RDF that contains all the information of the model.\n",
        "\n",
        "    workflow_specs : dict\n",
        "        Specifications of the workflow. If not provided all possible models will be considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    option_list: dict\n",
        "        Variables and values to change in current configuration. These changes\n",
        "        are imposed by the selected model.\n",
        "    \"\"\"\n",
        "    specific_workflow = workflow_specs[\"workflow_type\"]\n",
        "\n",
        "    # Version of the model\n",
        "    model_version = Version(model_rdf[\"format_version\"])\n",
        "    opts = {}\n",
        "\n",
        "    # 1) Change PATCH_SIZE with the one stored in the model description. This differs from the code of BiaPy where\n",
        "    # get_test_inputs() is simply used as there a ModelDescr is build out of the RDF. Here we try to do it manually\n",
        "    # to avoid fetching files using the network as it may be slow.\n",
        "    input_image_shape = []\n",
        "    if \"shape\" in model_rdf[\"inputs\"][0]:\n",
        "        input_image_shape = model_rdf[\"inputs\"][0][\"shape\"]\n",
        "        # \"CebraNET Cellular Membranes in Volume SEM\" ('format_version': '0.4.10')\n",
        "        #   have: {'min': [1, 1, 64, 64, 64], 'step': [0, 0, 16, 16, 16]}\n",
        "        if isinstance(input_image_shape, dict) and \"min\" in input_image_shape:\n",
        "            input_image_shape = input_image_shape[\"min\"]\n",
        "    else:\n",
        "        # Check axes and dimension\n",
        "        input_image_shape = []\n",
        "        for axis in model_rdf[\"inputs\"][0][\"axes\"]:\n",
        "            if 'type' in axis:\n",
        "                if axis['type'] == \"batch\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif axis['type'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif 'id' in axis and 'size' in axis:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "            elif 'id' in axis:\n",
        "                if axis['id'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                else:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "    if len(input_image_shape) == 0:\n",
        "        raise ValueError(\"Couldn't load input info from BMZ model's RDF: {}\".format(model_rdf[\"inputs\"][0]))\n",
        "    opts[\"DATA.PATCH_SIZE\"] = tuple(input_image_shape[2:]) + (input_image_shape[1],)\n",
        "\n",
        "    # Capture model kwargs\n",
        "    if \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]:\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"kwargs\"]\n",
        "    elif (\n",
        "        \"architecture\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]\n",
        "        and \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"]\n",
        "    ):\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"][\"kwargs\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Couldn't extract kwargs from model description.\")\n",
        "\n",
        "    # 2) Workflow specific restrictions\n",
        "    # Classes in semantic segmentation\n",
        "    if specific_workflow in [\"SEMANTIC_SEG\"]:\n",
        "        # Check number of classes\n",
        "        classes = -1\n",
        "        if \"n_classes\" in model_kwargs: # BiaPy\n",
        "            classes = model_kwargs[\"n_classes\"]\n",
        "        elif \"out_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"out_channels\"]\n",
        "        elif \"classes\" in model_kwargs:\n",
        "            classes = model_kwargs[\"classes\"]\n",
        "\n",
        "        if isinstance(classes, list):\n",
        "            classes = classes[0]\n",
        "        if not isinstance(classes, int):\n",
        "            raise ValueError(f\"Classes not extracted correctly. Obtained {classes}\")\n",
        "\n",
        "        if specific_workflow == \"SEMANTIC_SEG\" and classes == -1:\n",
        "            raise ValueError(\"Classes not found for semantic segmentation dir. \")\n",
        "        opts[\"MODEL.N_CLASSES\"] = max(2,classes)\n",
        "    elif specific_workflow in [\"INSTANCE_SEG\"]:\n",
        "        # Assumed it's BC. This needs a more elaborated process. Still deciding this:\n",
        "        # https://github.com/bioimage-io/spec-bioimage-io/issues/621\n",
        "        channels = 2\n",
        "        if \"out_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"out_channels\"]\n",
        "        if channels == 1:\n",
        "            channel_code = \"C\"\n",
        "        elif channels == 2:\n",
        "            channel_code = \"BC\"\n",
        "        elif channels == 3:\n",
        "            channel_code = \"BCM\"\n",
        "        if channels > 3:\n",
        "            raise ValueError(f\"Not recognized number of channels for instance segmentation. Obtained {channels}\")\n",
        "\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\"] = channel_code\n",
        "\n",
        "    if \"preprocessing\" not in model_rdf[\"inputs\"][0]:\n",
        "        return opts\n",
        "\n",
        "    preproc_info = model_rdf[\"inputs\"][0][\"preprocessing\"]\n",
        "    if len(preproc_info) == 0:\n",
        "        return opts\n",
        "    preproc_info = preproc_info[0]\n",
        "\n",
        "    # 3) Change preprocessing to the one stablished by BMZ by translate BMZ keywords into BiaPy's\n",
        "    # 'zero_mean_unit_variance' and 'fixed_zero_mean_unit_variance' norms of BMZ can be translated to our 'custom' norm\n",
        "    # providing mean and std\n",
        "    key_to_find = \"id\" if model_version > Version(\"0.5.0\") else \"name\"\n",
        "    if key_to_find in preproc_info:\n",
        "        if preproc_info[key_to_find] in [\"fixed_zero_mean_unit_variance\", \"zero_mean_unit_variance\"]:\n",
        "            if (\n",
        "                \"kwargs\" in preproc_info\n",
        "                and \"mean\" in preproc_info[\"kwargs\"]\n",
        "            ):\n",
        "                mean = preproc_info[\"kwargs\"][\"mean\"]\n",
        "                std = preproc_info[\"kwargs\"][\"std\"]\n",
        "            elif \"mean\" in preproc_info:\n",
        "                mean = preproc_info[\"mean\"]\n",
        "                std = preproc_info[\"std\"]\n",
        "            else:\n",
        "                mean, std = -1., -1.\n",
        "\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"custom\"\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_MEAN\"] = mean\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_STD\"] = std\n",
        "\n",
        "        # 'scale_linear' norm of BMZ is close to our 'div' norm (TODO: we need to control the \"gain\" arg)\n",
        "        elif preproc_info[key_to_find] == \"scale_linear\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"div\"\n",
        "\n",
        "        # 'scale_range' norm of BMZ is as our PERC_CLIP + 'scale_range' norm\n",
        "        elif preproc_info[key_to_find] == \"scale_range\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"scale_range\"\n",
        "            if (\n",
        "                float(preproc_info[\"kwargs\"][\"min_percentile\"]) != 0\n",
        "                or float(preproc_info[\"kwargs\"][\"max_percentile\"]) != 100\n",
        "            ):\n",
        "                opts[\"DATA.NORMALIZATION.PERC_CLIP\"] = True\n",
        "                opts[\"DATA.NORMALIZATION.PERC_LOWER\"] = float(preproc_info[\"kwargs\"][\"min_percentile\"])\n",
        "                opts[\"DATA.NORMALIZATION.PERC_UPPER\"] = float(preproc_info[\"kwargs\"][\"max_percentile\"])\n",
        "\n",
        "    return opts\n",
        "\n",
        "# Check the models that BiaPy can consume\n",
        "COLLECTION_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/collection.json\"\n",
        "collection_path = Path(pooch.retrieve(COLLECTION_URL, known_hash=None))\n",
        "with collection_path.open() as f:\n",
        "    collection = json.load(f)\n",
        "\n",
        "model_urls = [entry[\"rdf_source\"] for entry in collection[\"collection\"] if entry[\"type\"] == \"model\"]\n",
        "\n",
        "model_rdfs = []\n",
        "for mu in model_urls:\n",
        "    with open(Path(pooch.retrieve(mu, known_hash=None)), 'rt', encoding='utf8') as stream:\n",
        "        try:\n",
        "            model_rdfs.append(yaml.safe_load(stream))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "\n",
        "# Check axes, preprocessing functions used and postprocessing.\n",
        "pytorch_models = []\n",
        "imposed_vars = []\n",
        "\n",
        "workflow_specs = {\n",
        "    \"workflow_type\": \"SUPER_RESOLUTION\",\n",
        "    \"ndim\": \"3D\",\n",
        "    \"nclasses\": \"all\",\n",
        "}\n",
        "for model_rdf in model_rdfs:\n",
        "     try:\n",
        "        (\n",
        "            preproc_info,\n",
        "            error,\n",
        "            error_message\n",
        "        ) = check_bmz_model_compatibility(model_rdf, workflow_specs=workflow_specs)\n",
        "    except:\n",
        "        error = True\n",
        "\n",
        "    if not error:\n",
        "        model_imposed_vars = check_model_restrictions(model_rdf, workflow_specs=workflow_specs)\n",
        "        imposed_vars.append(model_imposed_vars)\n",
        "        pytorch_models.append(model_rdf)\n",
        "\n",
        "# Print the possible models\n",
        "html = \"<table style='width:100%''>\"\n",
        "c = 0\n",
        "for i, model in enumerate(pytorch_models):\n",
        "\n",
        "    if 'nickname' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['nickname']\n",
        "        nickname_icon = model['config']['bioimageio']['nickname_icon']\n",
        "    elif 'id' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['id']\n",
        "        nickname_icon = model['config']['bioimageio']['id_emoji']\n",
        "    else:\n",
        "        doi = \"/\".join(model['id'].split(\"/\")[:2])\n",
        "        nickname = doi\n",
        "        nickname_icon = doi\n",
        "    cover_url = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/\"+nickname+\"/\"+str(model[\"version\"])+\"/files/\"+model['covers'][0]\n",
        "    restrictions = \"\"\n",
        "    for key, val in imposed_vars[i].items():\n",
        "        if key == 'MODEL.N_CLASSES':\n",
        "            restrictions += \"<p>number_of_classes: {}</p>\".format(val)\n",
        "        elif key == \"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\":\n",
        "            problem_channels = 'Binary mask + Contours'\n",
        "            if val == \"BC\":\n",
        "                problem_channels = \"Binary mask + Contours\"\n",
        "            elif val == 'BP':\n",
        "                problem_channels = \"Binary mask + Central points\"\n",
        "            elif val == 'BD':\n",
        "                problem_channels = \"Binary mask + Distance map\"\n",
        "            elif val == 'BCM':\n",
        "                problem_channels = \"Binary mask + Contours + Foreground mask\"\n",
        "            elif val == 'BCD':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map\"\n",
        "            elif val == 'BCDv2':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map with background\"\n",
        "            elif val == 'Dv2':\n",
        "                problem_channels = \"Distance map with background\"\n",
        "            restrictions += \"<p>problem_representation: {}</p>\".format(problem_channels)\n",
        "    if c == 0:\n",
        "        html += \"<tr>\"\n",
        "    html += \"<td style='width:33%'>\"\n",
        "    html += \"<p style='color:#2196f3'>%s</p><p>Nickname: %s (%s)</p>%s<img src='%s' height='200'></td>\"%(\n",
        "        model['name'],\n",
        "        nickname,\n",
        "        nickname_icon,\n",
        "        restrictions,\n",
        "        cover_url,\n",
        "    )\n",
        "    c +=1\n",
        "    if c == 3:\n",
        "        html += \"</tr>\"\n",
        "        c=0\n",
        "html += \"</table>\"\n",
        "if len( pytorch_models ) == 0:\n",
        "    display(HTML('<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>'))\n",
        "else:\n",
        "    display(HTML('<h1>List of models that can be used in BiaPy:</h1><br>'))\n",
        "    display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70,
          "referenced_widgets": [
            "2effac8760764be5ba6c5245b79f628c",
            "f1ccd703e45348389e9a18196b7cc284",
            "de5f36929d1a406eb90ecc4886715006"
          ]
        },
        "id": "8_tqydEKsVZY",
        "outputId": "714ca42d-7261-4004-d041-2ed1e5193b11"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='Source:', options=('BiaPy', 'BioImage Model Zoo'), tooltips=('Models created during\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2effac8760764be5ba6c5245b79f628c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ###Play to select the source to build the model (BiaPy or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown **BiaPy**: to use the models implemented in BiaPy.\n",
        "\n",
        "#@markdown **Bioimage Model Zoo (BMZ)**: to use models from the [BMZ repository](https://bioimage.io/#/). You can run the above cell to generate an updated list of the models that can be used with BiaPy. Copy the nickname from the model and paste it below.\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "\n",
        "changed_source = True\n",
        "exists_bmz = False\n",
        "# create widgets\n",
        "source = widgets.ToggleButtons(\n",
        "    options=['BiaPy', 'BioImage Model Zoo'],\n",
        "    description='Source:',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltips=['Models created during this workflow', 'BioImage Model Zoo model'],\n",
        "#     icons=['check'] * 3\n",
        ")\n",
        "\n",
        "bmz = widgets.Text(\n",
        "    # value='10.5281/zenodo.5764892',\n",
        "    placeholder='Nickname of BMZ model',\n",
        "    description='ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# display the first widget\n",
        "display(source)\n",
        "\n",
        "# intialize the output - second widget\n",
        "out = Output()\n",
        "\n",
        "def changed(change):\n",
        "    '''\n",
        "    Monitor change in the first widget\n",
        "    '''\n",
        "    global out\n",
        "    global exists_bmz\n",
        "    if source.value == 'BiaPy':\n",
        "        bmz.layout.display = 'none'\n",
        "        out.clear_output() #clear output\n",
        "        out = Output() # redefine output\n",
        "    else:\n",
        "        bmz.layout.display = 'none'\n",
        "        bmz.layout.display = 'flex'\n",
        "        if not exists_bmz:\n",
        "          out.append_display_data(bmz)\n",
        "          display(out)\n",
        "        exists_bmz = True\n",
        "\n",
        "# monitor the source widget for changes\n",
        "source.observe(changed, 'value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z75adIcIbkxe"
      },
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 20**\n",
        "\n",
        "* **`test_ground_truth`:** Select to use test data ground truth to measure the performance of the model's result. If selected, **test_data_gt_path** variable path set above will be used. **Default value: True**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 1**\n",
        "\n",
        "* **`scale_factor_XY`:** Factor by which the images will be super-resolved in X and Y. If set to 1, the model will perform image restoration. **Default value: 1**\n",
        "\n",
        "* **`scale_factor_Z`:** Factor by which the images will be super-resolved in Z. If set to 1, the model will perform image restoration. **Default value: 1**\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. **Default value: 15**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 15**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: U-Net, Residual U-Net, Attention U-Net, SEUNet, MultiResUNet, ResUNet++ and U-NeXt V1. **Default value: Residual U-Net**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 16**\n",
        "\n",
        "* **`patch_size_xy`:** Input the XY size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 128**\n",
        "\n",
        "* **`patch_size_z`:** Input the Z size of the patches use to train your model (length in pixels in Z). The value should be smaller or equal to the dimensions of the image. **Default value: 6**\n",
        "\n",
        "* **`anisotropic_data`:** Select if your image data is anisotropic (lower resolution in Z with respect to XY). The model downsampling step size will be set accordingly. **Default value: True**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization. **Default value: ADAMW**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer and no scheduler, this value should be around 10e-4. **Default value: 0.001**\n",
        "\n",
        "* **`learning_rate_scheduler`:** Select to adjust the learning rate between epochs. Options: \"None\", \"Reduce on plateau\", \"One cycle\", \"Warm-up cosine decay\". **Default value: One cycle**\n",
        "\n",
        "* **`aggressive_data_augmentation`:** Select to apply more aggressive data augmentation compatible with the task (CutOut, GridMask, etc.) during training. Otherwise, simple flips and factors of 90-degree rotations will be applied. **Default value: False**\n",
        "\n",
        "* **`test_time_augmentation`:** Select to apply augmentation (flips and rotations) at test time. It usually provides more robust results but uses more time to produce each result. **Default value: False**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyiteHVs31qK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Select your parameters**\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #### **Name of the model**\n",
        "model_name = \"my_3d_super_resolution\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown #### **Data management**\n",
        "percentage_validation = 20 #@param {type:\"number\"}\n",
        "test_ground_truth = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown #### **Basic training parameters**\n",
        "input_channels = 1 #@param {type:\"number\"}\n",
        "scale_factor_XY = 1 #@param {type:\"number\"}\n",
        "scale_factor_Z = 1 #@param {type:\"number\"}\n",
        "number_of_epochs = 15 #@param {type:\"number\"}\n",
        "patience = 15 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown #### **Advanced Parameters - experienced users only**\n",
        "model_architecture = \"Residual U-Net\" #@param [\"U-Net\", \"Residual U-Net\", \"Attention U-Net\", 'MultiResUNet', 'ResUNet++', 'SEUNet', 'U-NeXt V1']\n",
        "batch_size = 16 #@param {type:\"number\"}\n",
        "patch_size_xy = 128 # @param {type:\"number\"}\n",
        "patch_size_z = 6 # @param {type:\"number\"}\n",
        "anisotropic_data = True #@param {type:\"boolean\"}\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"ADAMW\", \"SGD\"]\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}\n",
        "learning_rate_scheduler = \"One cycle\" #@param [\"None\", \"Reduce on plateau\",\"One cycle\", \"Warm-up cosine decay\"]\n",
        "aggressive_data_augmentation = False #@param {type:\"boolean\"}\n",
        "test_time_augmentation = False #@param {type:\"boolean\"}\n",
        "\n",
        "checkpoint_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z86o1irRXUZb"
      },
      "outputs": [],
      "source": [
        "#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n",
        "#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n",
        "\n",
        "#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n",
        "from google.colab import files\n",
        "\n",
        "#s.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "checkpoint_path = '/content/' + list(uploaded.keys())[0]\n",
        "\n",
        "# open previously configured file, if exists\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# edit previous configuration file if it exists to load the checkpoint model\n",
        "if os.path.exists( yaml_file ):\n",
        "    import yaml\n",
        "    with open( yaml_file, 'r') as stream:\n",
        "        try:\n",
        "            biapy_config = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "    # save file\n",
        "    with open( yaml_file, 'w') as outfile:\n",
        "        yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Pre-trained model loaded and ready to re-train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F5jOxIdaZKQ"
      },
      "source": [
        "### **Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W3XBGA9LaZjw",
        "outputId": "f4093393-f7b5-463c-c4d9-46232e9f552f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:08:22.291699] Training configuration finished.\n",
            "[07:08:22.301866] Date: 2024-09-08 07:08:22\n",
            "[07:08:22.301984] Arguments: Namespace(config='/content/my_3d_super_resolution.yaml', result_dir='/content/output', name='my_3d_super_resolution', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "[07:08:22.303302] Job: my_3d_super_resolution_1\n",
            "[07:08:22.303372] Python       : 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "[07:08:22.303423] PyTorch:  2.4.0+cu121\n",
            "[07:08:22.306908] Not using distributed mode\n",
            "[07:08:22.310300] Configuration details:\n",
            "[07:08:22.310931] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: False\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: True\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    APPLICATION_MODE: image\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    PERC_CLIP: False\n",
            "    PERC_LOWER: -1.0\n",
            "    PERC_UPPER: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (6, 128, 128, 1)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/test/LR/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/test/HR_detection_masks\n",
            "    GT_PATH: /content/data/test/HR\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/test/LR_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/test/HR_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: True\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (2, 16, 16)\n",
            "    PATH: /content/data/test/LR\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/test/LR_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/train/HR_detection_masks\n",
            "    GT_PATH: /content/data/train/HR\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train/LR_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/train/HR_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: -1.0\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: /content/data/train/LR\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train/LR_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    DIST_EVAL: True\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SPLIT_TRAIN: 0.2\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_3d_super_resolution/train_logs\n",
            "  LOG_FILE_PREFIX: my_3d_super_resolution_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: False\n",
            "  TYPE: MAE\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: ELU\n",
            "  ARCHITECTURE: resunet\n",
            "  BMZ:\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [32, 64, 128]\n",
            "  ISOTROPY: [True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 2\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: post\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [1, 1]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/charts\n",
            "  CHECKPOINT: /content/output/my_3d_super_resolution/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/aug\n",
            "  GEN_CHECKS: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/gen_mask_check\n",
            "  LWR_X_FILE: /content/output/my_3d_super_resolution/checkpoints/lower_bound_X_perc.npy\n",
            "  LWR_Y_FILE: /content/output/my_3d_super_resolution/checkpoints/lower_bound_Y_perc.npy\n",
            "  MAE_OUT_DIR: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/MAE_checks\n",
            "  MEAN_INFO_FILE: /content/output/my_3d_super_resolution/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_3d_super_resolution/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/instance_associations\n",
            "    PATH: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1\n",
            "    PER_IMAGE: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_3d_super_resolution/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: /content/data/test/HR/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/train_BC_instance_channels\n",
            "  UPR_X_FILE: /content/output/my_3d_super_resolution/checkpoints/upper_bound_X_perc.npy\n",
            "  UPR_Y_FILE: /content/output/my_3d_super_resolution/checkpoints/upper_bound_Y_perc.npy\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [2]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 3D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1, 1)\n",
            "  TYPE: SUPER_RESOLUTION\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: 5\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    FORMAT: H5\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['psnr', 'mae', 'mse', 'ssim']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGN: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: False\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 16\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 15\n",
            "  LR: 0.001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: onecycle\n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "  METRICS: ['psnr', 'mae', 'mse', 'ssim']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 15\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[07:08:22.312516] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[07:08:22.313066] Initializing Super_resolution_Workflow\n",
            "[07:08:22.313557] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[07:08:22.319651] ##########################\n",
            "[07:08:22.320272] #   LOAD TRAINING DATA   #\n",
            "[07:08:22.320785] ##########################\n",
            "[07:08:22.321347] ### LOAD ###\n",
            "[07:08:22.321866] 0) Loading train images . . .\n",
            "[07:08:22.322366] Loading data from /content/data/train/LR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26/26 [00:03<00:00,  7.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:08:27.050287] *** Loaded data shape is (1664, 6, 128, 128, 1)\n",
            "[07:08:27.093811] 1) Loading train GT . . .\n",
            "[07:08:27.094358] Loading data from /content/data/train/HR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 26/26 [00:05<00:00,  4.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:08:33.951362] *** Loaded data shape is (1664, 6, 128, 128, 1)\n",
            "[07:08:33.991407] Creating validation data\n",
            "[07:08:36.529073] Not all samples seem to have the same shape. Number of samples: 1331\n",
            "[07:08:36.530241] *** Loaded train data shape is: (1331, 6, 128, 128, 1)\n",
            "[07:08:36.530319] *** Loaded train GT shape is: (1331, 6, 128, 128, 1)\n",
            "[07:08:36.531498] *** Loaded validation data shape is: (333, 6, 128, 128, 1)\n",
            "[07:08:36.531555] *** Loaded validation GT shape is: (333, 6, 128, 128, 1)\n",
            "[07:08:36.531598] ### END LOAD ###\n",
            "[07:08:36.531680] ###############\n",
            "[07:08:36.531720] # Build model #\n",
            "[07:08:36.531762] ###############\n",
            "[07:08:36.585432] ##############################\n",
            "[07:08:36.585507] #  PREPARE TRAIN GENERATORS  #\n",
            "[07:08:36.585552] ##############################\n",
            "[07:08:36.585832] Initializing train data generator . . .\n",
            "[07:08:36.589302] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_image', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('float32')}\n",
            "[07:08:36.590188] Normalization config used for Y: as_image\n",
            "[07:08:36.590694] Initializing val data generator . . .\n",
            "[07:08:36.592711] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_image', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('float32')}\n",
            "[07:08:36.593494] Normalization config used for Y: as_image\n",
            "[07:08:36.593786] Creating generator samples . . .\n",
            "[07:08:36.593860] 0) Creating samples of data augmentation . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/10 [00:00<?, ?it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 12.87it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:00, 11.23it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:00<00:00,  5.49it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  5.02it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  5.42it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01<00:00,  5.86it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  6.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:08:38.199220] Number of workers: 5\n",
            "[07:08:38.199306] Accumulate grad iterations: 1\n",
            "[07:08:38.199356] Effective batch size: 16\n",
            "[07:08:38.199442] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7e6b9240a650>\n",
            "[07:08:38.199745] #######################\n",
            "[07:08:38.199836] # Prepare logging tool #\n",
            "[07:08:38.199924] #######################\n",
            "[07:08:38.206929] AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.02\n",
            ")\n",
            "[07:08:38.207659] #####################\n",
            "[07:08:38.207813] #  TRAIN THE MODEL  #\n",
            "[07:08:38.207967] #####################\n",
            "[07:08:38.208124] Start training in epoch 1 - Total: 15\n",
            "[07:08:38.208271] ~~~ Epoch 1/15 ~~~\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:08:40.695682] Epoch: [1]  [ 0/84]  eta: 0:03:27  loss: 0.6179 (0.6179)  SSIM: 0.0000 (0.0000)  MAE: 0.6179 (0.6179)  MSE: 0.6559 (0.6559)  PSNR: 7.2034 (7.2034)  lr: 0.000040  iter-time: 2.4726\n",
            "[07:08:55.135766] Epoch: [1]  [10/84]  eta: 0:01:53  loss: 0.3984 (0.4328)  SSIM: 0.0000 (0.0000)  MAE: 0.3984 (0.4328)  MSE: 0.2630 (0.3295)  PSNR: 8.1083 (8.2347)  lr: 0.000042  iter-time: 1.5374\n",
            "[07:09:10.201929] Epoch: [1]  [20/84]  eta: 0:01:37  loss: 0.3230 (0.3680)  SSIM: 0.0000 (0.0000)  MAE: 0.3230 (0.3680)  MSE: 0.1859 (0.2450)  PSNR: 8.8302 (8.7940)  lr: 0.000047  iter-time: 1.4751\n",
            "[07:09:25.222301] Epoch: [1]  [30/84]  eta: 0:01:21  loss: 0.2607 (0.3205)  SSIM: 0.0000 (0.0000)  MAE: 0.2607 (0.3205)  MSE: 0.1172 (0.1940)  PSNR: 9.7943 (9.1422)  lr: 0.000056  iter-time: 1.5041\n",
            "[07:09:39.843540] Epoch: [1]  [40/84]  eta: 0:01:06  loss: 0.1962 (0.2872)  SSIM: 0.0000 (0.0000)  MAE: 0.1962 (0.2872)  MSE: 0.0690 (0.1611)  PSNR: 10.0531 (9.5506)  lr: 0.000068  iter-time: 1.4819\n",
            "[07:09:54.291677] Epoch: [1]  [50/84]  eta: 0:00:50  loss: 0.1641 (0.2598)  SSIM: 0.0000 (0.0000)  MAE: 0.1641 (0.2598)  MSE: 0.0475 (0.1370)  PSNR: 10.7392 (9.8281)  lr: 0.000083  iter-time: 1.4532\n",
            "[07:10:08.753660] Epoch: [1]  [60/84]  eta: 0:00:35  loss: 0.1317 (0.2371)  SSIM: 0.0000 (0.0000)  MAE: 0.1317 (0.2371)  MSE: 0.0303 (0.1189)  PSNR: 11.3911 (10.1727)  lr: 0.000101  iter-time: 1.4453\n",
            "[07:10:23.330520] Epoch: [1]  [70/84]  eta: 0:00:20  loss: 0.1107 (0.2181)  SSIM: 0.0000 (0.0000)  MAE: 0.1107 (0.2181)  MSE: 0.0231 (0.1050)  PSNR: 11.9638 (10.4372)  lr: 0.000122  iter-time: 1.4517\n",
            "[07:10:37.966569] Epoch: [1]  [80/84]  eta: 0:00:05  loss: 0.0968 (0.2027)  SSIM: 0.0000 (0.0000)  MAE: 0.0968 (0.2027)  MSE: 0.0175 (0.0940)  PSNR: 12.0924 (10.7355)  lr: 0.000145  iter-time: 1.4604\n",
            "[07:12:50.429347] Epoch: [1]  [83/84]  eta: 0:00:03  loss: 0.0945 (0.1989)  SSIM: 0.0000 (0.0000)  MAE: 0.0945 (0.1989)  MSE: 0.0173 (0.0913)  PSNR: 12.0644 (10.7900)  lr: 0.000153  iter-time: 7.8657\n",
            "[07:12:50.656101] Epoch: [1] Total time: 0:04:12 (3.0053 s / it)\n",
            "[07:12:50.656284] [Train] averaged stats: loss: 0.0945 (0.1989)  SSIM: 0.0000 (0.0000)  MAE: 0.0945 (0.1989)  MSE: 0.0173 (0.0913)  PSNR: 12.0644 (10.7900)  lr: 0.000153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:12:51.592190] Epoch: [1]  [ 0/21]  eta: 0:00:19  loss: 0.0918 (0.0918)  SSIM: 0.0000 (0.0000)  MAE: 0.0918 (0.0918)  MSE: 0.0157 (0.0157)  PSNR: 15.3097 (15.3097)  iter-time: 0.9338\n",
            "[07:12:56.688453] Epoch: [1]  [10/21]  eta: 0:00:06  loss: 0.0904 (0.0903)  SSIM: 0.0000 (0.0000)  MAE: 0.0904 (0.0903)  MSE: 0.0152 (0.0150)  PSNR: 15.1136 (15.0809)  iter-time: 0.5480\n",
            "[07:15:37.231327] Epoch: [1]  [20/21]  eta: 0:00:07  loss: 0.0904 (0.0905)  SSIM: 0.0000 (0.0000)  MAE: 0.0904 (0.0905)  MSE: 0.0151 (0.0150)  PSNR: 15.2186 (15.4142)  iter-time: 8.2818\n",
            "[07:15:37.585878] Epoch: [1] Total time: 0:02:46 (7.9490 s / it)\n",
            "[07:15:37.586050] [Val] averaged stats: loss: 0.0904 (0.0905)  SSIM: 0.0000 (0.0000)  MAE: 0.0904 (0.0905)  MSE: 0.0151 (0.0150)  PSNR: 15.2186 (15.4142)\n",
            "[07:15:37.589661] Val loss improved from inf to 0.09048532942930858, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:15:37.658497] [Val] best loss: 0.0905 best  SSIM: 0.0000 MAE: 0.0905 MSE: 0.0150 PSNR: 15.4142 \n",
            "[07:15:37.660788] [Time] 7.0m 7.0m/1.9h\n",
            "\n",
            "[07:15:37.661916] ~~~ Epoch 2/15 ~~~\n",
            "\n",
            "[07:15:39.650125] Epoch: [2]  [ 0/84]  eta: 0:02:46  loss: 0.0894 (0.0894)  SSIM: 0.0000 (0.0000)  MAE: 0.0894 (0.0894)  MSE: 0.0150 (0.0150)  PSNR: 14.4773 (14.4773)  lr: 0.000155  iter-time: 1.9859\n",
            "[07:15:54.497025] Epoch: [2]  [10/84]  eta: 0:01:53  loss: 0.0941 (0.0927)  SSIM: 0.0000 (0.0000)  MAE: 0.0941 (0.0927)  MSE: 0.0165 (0.0157)  PSNR: 13.6928 (13.8256)  lr: 0.000183  iter-time: 1.5301\n",
            "[07:16:09.256323] Epoch: [2]  [20/84]  eta: 0:01:36  loss: 0.0891 (0.0890)  SSIM: 0.0000 (0.0000)  MAE: 0.0891 (0.0890)  MSE: 0.0144 (0.0147)  PSNR: 13.8310 (14.0040)  lr: 0.000212  iter-time: 1.4801\n",
            "[07:16:23.839393] Epoch: [2]  [30/84]  eta: 0:01:20  loss: 0.0778 (0.0850)  SSIM: 0.0000 (0.0000)  MAE: 0.0778 (0.0850)  MSE: 0.0118 (0.0136)  PSNR: 14.8697 (14.3022)  lr: 0.000244  iter-time: 1.4669\n",
            "[07:16:38.352592] Epoch: [2]  [40/84]  eta: 0:01:05  loss: 0.0776 (0.0837)  SSIM: 0.0000 (0.0000)  MAE: 0.0776 (0.0837)  MSE: 0.0114 (0.0132)  PSNR: 15.3710 (14.6069)  lr: 0.000278  iter-time: 1.4546\n",
            "[07:16:52.879188] Epoch: [2]  [50/84]  eta: 0:00:50  loss: 0.0787 (0.0826)  SSIM: 0.0000 (0.0000)  MAE: 0.0787 (0.0826)  MSE: 0.0116 (0.0129)  PSNR: 15.4851 (14.7478)  lr: 0.000313  iter-time: 1.4517\n",
            "[07:17:07.453530] Epoch: [2]  [60/84]  eta: 0:00:35  loss: 0.0777 (0.0815)  SSIM: 0.0000 (0.0000)  MAE: 0.0777 (0.0815)  MSE: 0.0115 (0.0127)  PSNR: 15.5985 (14.9380)  lr: 0.000350  iter-time: 1.4548\n",
            "[07:17:22.062106] Epoch: [2]  [70/84]  eta: 0:00:20  loss: 0.0777 (0.0821)  SSIM: 0.0000 (0.0000)  MAE: 0.0777 (0.0821)  MSE: 0.0120 (0.0129)  PSNR: 15.6784 (14.9328)  lr: 0.000388  iter-time: 1.4589\n",
            "[07:17:36.654494] Epoch: [2]  [80/84]  eta: 0:00:05  loss: 0.0869 (0.0850)  SSIM: 0.0000 (0.0000)  MAE: 0.0869 (0.0850)  MSE: 0.0151 (0.0139)  PSNR: 14.8530 (14.7204)  lr: 0.000427  iter-time: 1.4599\n",
            "[07:17:39.843213] Epoch: [2]  [83/84]  eta: 0:00:01  loss: 0.0992 (0.0854)  SSIM: 0.0000 (0.0000)  MAE: 0.0992 (0.0854)  MSE: 0.0179 (0.0140)  PSNR: 14.8530 (14.6810)  lr: 0.000438  iter-time: 1.4004\n",
            "[07:17:40.067511] Epoch: [2] Total time: 0:02:02 (1.4572 s / it)\n",
            "[07:17:40.068665] [Train] averaged stats: loss: 0.0992 (0.0854)  SSIM: 0.0000 (0.0000)  MAE: 0.0992 (0.0854)  MSE: 0.0179 (0.0140)  PSNR: 14.8530 (14.6810)  lr: 0.000438\n",
            "[07:17:41.050221] Epoch: [2]  [ 0/21]  eta: 0:00:20  loss: 0.0849 (0.0849)  SSIM: 0.0000 (0.0000)  MAE: 0.0849 (0.0849)  MSE: 0.0137 (0.0137)  PSNR: 13.4151 (13.4151)  iter-time: 0.9763\n",
            "[07:17:46.074538] Epoch: [2]  [10/21]  eta: 0:00:05  loss: 0.0828 (0.0830)  SSIM: 0.0000 (0.0000)  MAE: 0.0828 (0.0830)  MSE: 0.0128 (0.0129)  PSNR: 13.7389 (13.6728)  iter-time: 0.5452\n",
            "[07:17:50.998641] Epoch: [2]  [20/21]  eta: 0:00:00  loss: 0.0828 (0.0838)  SSIM: 0.0000 (0.0000)  MAE: 0.0828 (0.0838)  MSE: 0.0129 (0.0131)  PSNR: 13.7697 (13.7603)  iter-time: 0.4972\n",
            "[07:17:51.402014] Epoch: [2] Total time: 0:00:11 (0.5395 s / it)\n",
            "[07:17:51.403400] [Val] averaged stats: loss: 0.0828 (0.0838)  SSIM: 0.0000 (0.0000)  MAE: 0.0828 (0.0838)  MSE: 0.0129 (0.0131)  PSNR: 13.7697 (13.7603)\n",
            "[07:17:51.405874] Val loss improved from 0.09048532942930858 to 0.0837648365469206, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:17:51.553649] [Val] best loss: 0.0838 best  SSIM: 0.0000 MAE: 0.0838 MSE: 0.0131 PSNR: 13.7603 \n",
            "[07:17:51.556745] [Time] 2.2m 9.2m/40.5m\n",
            "\n",
            "[07:17:51.557584] ~~~ Epoch 3/15 ~~~\n",
            "\n",
            "[07:17:53.899482] Epoch: [3]  [ 0/84]  eta: 0:03:16  loss: 0.0914 (0.0914)  SSIM: 0.0000 (0.0000)  MAE: 0.0914 (0.0914)  MSE: 0.0156 (0.0156)  PSNR: 13.1953 (13.1953)  lr: 0.000442  iter-time: 2.3358\n",
            "[07:18:08.502620] Epoch: [3]  [10/84]  eta: 0:01:53  loss: 0.0802 (0.0822)  SSIM: 0.0000 (0.0000)  MAE: 0.0802 (0.0822)  MSE: 0.0124 (0.0130)  PSNR: 15.5323 (15.8436)  lr: 0.000482  iter-time: 1.5396\n",
            "[07:18:23.104802] Epoch: [3]  [20/84]  eta: 0:01:36  loss: 0.0708 (0.0748)  SSIM: 0.0000 (0.0000)  MAE: 0.0708 (0.0748)  MSE: 0.0100 (0.0113)  PSNR: 15.4578 (15.7131)  lr: 0.000522  iter-time: 1.4599\n",
            "[07:18:37.696235] Epoch: [3]  [30/84]  eta: 0:01:20  loss: 0.0665 (0.0727)  SSIM: 0.0000 (0.0000)  MAE: 0.0665 (0.0727)  MSE: 0.0091 (0.0107)  PSNR: 16.0793 (16.0781)  lr: 0.000562  iter-time: 1.4594\n",
            "[07:18:52.281311] Epoch: [3]  [40/84]  eta: 0:01:05  loss: 0.0697 (0.0731)  SSIM: 0.0000 (0.0000)  MAE: 0.0697 (0.0731)  MSE: 0.0095 (0.0107)  PSNR: 16.1167 (16.1505)  lr: 0.000602  iter-time: 1.4585\n",
            "[07:19:06.874576] Epoch: [3]  [50/84]  eta: 0:00:50  loss: 0.0695 (0.0724)  SSIM: 0.0000 (0.0000)  MAE: 0.0695 (0.0724)  MSE: 0.0095 (0.0106)  PSNR: 17.1883 (16.3620)  lr: 0.000641  iter-time: 1.4587\n",
            "[07:19:21.477315] Epoch: [3]  [60/84]  eta: 0:00:35  loss: 0.0656 (0.0714)  SSIM: 0.0000 (0.0000)  MAE: 0.0656 (0.0714)  MSE: 0.0087 (0.0103)  PSNR: 18.2793 (16.5651)  lr: 0.000679  iter-time: 1.4596\n",
            "[07:19:36.046383] Epoch: [3]  [70/84]  eta: 0:00:20  loss: 0.0661 (0.0721)  SSIM: 0.0000 (0.0000)  MAE: 0.0661 (0.0721)  MSE: 0.0087 (0.0105)  PSNR: 18.2287 (16.6268)  lr: 0.000716  iter-time: 1.4583\n",
            "[07:19:50.615653] Epoch: [3]  [80/84]  eta: 0:00:05  loss: 0.0712 (0.0730)  SSIM: 0.0000 (0.0000)  MAE: 0.0712 (0.0730)  MSE: 0.0106 (0.0108)  PSNR: 18.0430 (16.5425)  lr: 0.000752  iter-time: 1.4566\n",
            "[07:19:53.801700] Epoch: [3]  [83/84]  eta: 0:00:01  loss: 0.0717 (0.0732)  SSIM: 0.0000 (0.0000)  MAE: 0.0717 (0.0732)  MSE: 0.0109 (0.0108)  PSNR: 18.0430 (16.4522)  lr: 0.000762  iter-time: 1.3977\n",
            "[07:19:54.123730] Epoch: [3] Total time: 0:02:02 (1.4591 s / it)\n",
            "[07:19:54.126863] [Train] averaged stats: loss: 0.0717 (0.0732)  SSIM: 0.0000 (0.0000)  MAE: 0.0717 (0.0732)  MSE: 0.0109 (0.0108)  PSNR: 18.0430 (16.4522)  lr: 0.000762\n",
            "[07:19:55.098810] Epoch: [3]  [ 0/21]  eta: 0:00:20  loss: 0.0947 (0.0947)  SSIM: 0.0000 (0.0000)  MAE: 0.0947 (0.0947)  MSE: 0.0144 (0.0144)  PSNR: 18.7406 (18.7406)  iter-time: 0.9682\n",
            "[07:20:00.095870] Epoch: [3]  [10/21]  eta: 0:00:05  loss: 0.0847 (0.0856)  SSIM: 0.0000 (0.0000)  MAE: 0.0847 (0.0856)  MSE: 0.0121 (0.0123)  PSNR: 18.9160 (19.0092)  iter-time: 0.5421\n",
            "[07:20:04.992039] Epoch: [3]  [20/21]  eta: 0:00:00  loss: 0.0847 (0.0858)  SSIM: 0.0000 (0.0000)  MAE: 0.0847 (0.0858)  MSE: 0.0121 (0.0125)  PSNR: 18.9160 (18.9727)  iter-time: 0.4945\n",
            "[07:20:05.329002] Epoch: [3] Total time: 0:00:11 (0.5333 s / it)\n",
            "[07:20:05.329143] [Val] averaged stats: loss: 0.0847 (0.0858)  SSIM: 0.0000 (0.0000)  MAE: 0.0847 (0.0858)  MSE: 0.0121 (0.0125)  PSNR: 18.9160 (18.9727)\n",
            "[07:20:05.333341] [Val] best loss: 0.0838 best  SSIM: 0.0000 MAE: 0.0838 MSE: 0.0131 PSNR: 13.7603 \n",
            "EarlyStopping counter: 1 out of 15\n",
            "[07:20:05.336272] [Time] 2.2m 11.5m/40.4m\n",
            "\n",
            "[07:20:05.336320] ~~~ Epoch 4/15 ~~~\n",
            "\n",
            "[07:20:07.610886] Epoch: [4]  [ 0/84]  eta: 0:03:10  loss: 0.0878 (0.0878)  SSIM: 0.0000 (0.0000)  MAE: 0.0878 (0.0878)  MSE: 0.0129 (0.0129)  PSNR: 18.3696 (18.3696)  lr: 0.000766  iter-time: 2.2715\n",
            "[07:20:22.202218] Epoch: [4]  [10/84]  eta: 0:01:53  loss: 0.0671 (0.0719)  SSIM: 0.0000 (0.0000)  MAE: 0.0671 (0.0719)  MSE: 0.0092 (0.0107)  PSNR: 15.6687 (16.0004)  lr: 0.000799  iter-time: 1.5328\n",
            "[07:20:36.784879] Epoch: [4]  [20/84]  eta: 0:01:35  loss: 0.0632 (0.0667)  SSIM: 0.0000 (0.0000)  MAE: 0.0632 (0.0667)  MSE: 0.0083 (0.0095)  PSNR: 15.9790 (16.7660)  lr: 0.000831  iter-time: 1.4585\n",
            "[07:20:51.386304] Epoch: [4]  [30/84]  eta: 0:01:20  loss: 0.0616 (0.0667)  SSIM: 0.0000 (0.0000)  MAE: 0.0616 (0.0667)  MSE: 0.0082 (0.0093)  PSNR: 17.3392 (16.8950)  lr: 0.000860  iter-time: 1.4589\n",
            "[07:21:05.983323] Epoch: [4]  [40/84]  eta: 0:01:05  loss: 0.0616 (0.0654)  SSIM: 0.0000 (0.0000)  MAE: 0.0616 (0.0654)  MSE: 0.0082 (0.0090)  PSNR: 19.4079 (17.2416)  lr: 0.000887  iter-time: 1.4597\n",
            "[07:21:20.594194] Epoch: [4]  [50/84]  eta: 0:00:50  loss: 0.0605 (0.0645)  SSIM: 0.0000 (0.0000)  MAE: 0.0605 (0.0645)  MSE: 0.0076 (0.0088)  PSNR: 19.4079 (17.5281)  lr: 0.000912  iter-time: 1.4602\n",
            "[07:21:35.207962] Epoch: [4]  [60/84]  eta: 0:00:35  loss: 0.0587 (0.0635)  SSIM: 0.0000 (0.0000)  MAE: 0.0587 (0.0635)  MSE: 0.0075 (0.0086)  PSNR: 18.9803 (17.6184)  lr: 0.000933  iter-time: 1.4609\n",
            "[07:21:49.818659] Epoch: [4]  [70/84]  eta: 0:00:20  loss: 0.0587 (0.0638)  SSIM: 0.0000 (0.0000)  MAE: 0.0587 (0.0638)  MSE: 0.0075 (0.0087)  PSNR: 19.4703 (17.6361)  lr: 0.000952  iter-time: 1.4610\n",
            "[07:22:04.437503] Epoch: [4]  [80/84]  eta: 0:00:05  loss: 0.0634 (0.0637)  SSIM: 0.0000 (0.0000)  MAE: 0.0634 (0.0637)  MSE: 0.0088 (0.0087)  PSNR: 19.4703 (17.6185)  lr: 0.000968  iter-time: 1.4613\n",
            "[07:22:07.625244] Epoch: [4]  [83/84]  eta: 0:00:01  loss: 0.0646 (0.0637)  SSIM: 0.0000 (0.0000)  MAE: 0.0646 (0.0637)  MSE: 0.0093 (0.0087)  PSNR: 18.2650 (17.5865)  lr: 0.000972  iter-time: 1.4014\n",
            "[07:22:07.842621] Epoch: [4] Total time: 0:02:02 (1.4584 s / it)\n",
            "[07:22:07.843716] [Train] averaged stats: loss: 0.0646 (0.0637)  SSIM: 0.0000 (0.0000)  MAE: 0.0646 (0.0637)  MSE: 0.0093 (0.0087)  PSNR: 18.2650 (17.5865)  lr: 0.000972\n",
            "[07:22:08.793000] Epoch: [4]  [ 0/21]  eta: 0:00:19  loss: 0.0598 (0.0598)  SSIM: 0.0000 (0.0000)  MAE: 0.0598 (0.0598)  MSE: 0.0080 (0.0080)  PSNR: 16.5156 (16.5156)  iter-time: 0.9460\n",
            "[07:22:13.841634] Epoch: [4]  [10/21]  eta: 0:00:05  loss: 0.0585 (0.0584)  SSIM: 0.0000 (0.0000)  MAE: 0.0585 (0.0584)  MSE: 0.0077 (0.0076)  PSNR: 16.5156 (16.8900)  iter-time: 0.5449\n",
            "[07:22:18.755677] Epoch: [4]  [20/21]  eta: 0:00:00  loss: 0.0585 (0.0590)  SSIM: 0.0000 (0.0000)  MAE: 0.0585 (0.0590)  MSE: 0.0076 (0.0077)  PSNR: 16.3268 (16.2566)  iter-time: 0.4980\n",
            "[07:22:18.984534] Epoch: [4] Total time: 0:00:11 (0.5304 s / it)\n",
            "[07:22:18.984665] [Val] averaged stats: loss: 0.0585 (0.0590)  SSIM: 0.0000 (0.0000)  MAE: 0.0585 (0.0590)  MSE: 0.0076 (0.0077)  PSNR: 16.3268 (16.2566)\n",
            "[07:22:18.987712] Val loss improved from 0.0837648365469206 to 0.05899338619340034, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:22:19.045244] [Val] best loss: 0.0590 best  SSIM: 0.0000 MAE: 0.0590 MSE: 0.0077 PSNR: 16.2566 \n",
            "[07:22:19.048151] [Time] 2.2m 13.7m/40.4m\n",
            "\n",
            "[07:22:19.048233] ~~~ Epoch 5/15 ~~~\n",
            "\n",
            "[07:22:21.130278] Epoch: [5]  [ 0/84]  eta: 0:02:54  loss: 0.0635 (0.0635)  SSIM: 0.0000 (0.0000)  MAE: 0.0635 (0.0635)  MSE: 0.0088 (0.0088)  PSNR: 16.2111 (16.2111)  lr: 0.000974  iter-time: 2.0795\n",
            "[07:22:35.743452] Epoch: [5]  [10/84]  eta: 0:01:52  loss: 0.0589 (0.0578)  SSIM: 0.0000 (0.0000)  MAE: 0.0589 (0.0578)  MSE: 0.0073 (0.0073)  PSNR: 19.4421 (18.2509)  lr: 0.000985  iter-time: 1.5171\n",
            "[07:22:50.348252] Epoch: [5]  [20/84]  eta: 0:01:35  loss: 0.0572 (0.0575)  SSIM: 0.0000 (0.0000)  MAE: 0.0572 (0.0575)  MSE: 0.0072 (0.0074)  PSNR: 19.4421 (18.1076)  lr: 0.000993  iter-time: 1.4605\n",
            "[07:23:04.953718] Epoch: [5]  [30/84]  eta: 0:01:19  loss: 0.0582 (0.0583)  SSIM: 0.0000 (0.0000)  MAE: 0.0582 (0.0583)  MSE: 0.0072 (0.0074)  PSNR: 19.7268 (18.1923)  lr: 0.000998  iter-time: 1.4602\n",
            "[07:23:19.566750] Epoch: [5]  [40/84]  eta: 0:01:04  loss: 0.0589 (0.0584)  SSIM: 0.0000 (0.0000)  MAE: 0.0589 (0.0584)  MSE: 0.0078 (0.0075)  PSNR: 19.0081 (18.3539)  lr: 0.001000  iter-time: 1.4607\n",
            "[07:23:34.184229] Epoch: [5]  [50/84]  eta: 0:00:50  loss: 0.0575 (0.0582)  SSIM: 0.0000 (0.0000)  MAE: 0.0575 (0.0582)  MSE: 0.0072 (0.0074)  PSNR: 19.0081 (18.5741)  lr: 0.001000  iter-time: 1.4614\n",
            "[07:23:48.795210] Epoch: [5]  [60/84]  eta: 0:00:35  loss: 0.0566 (0.0580)  SSIM: 0.0000 (0.0000)  MAE: 0.0566 (0.0580)  MSE: 0.0070 (0.0074)  PSNR: 19.0582 (18.5393)  lr: 0.000999  iter-time: 1.4613\n",
            "[07:24:03.408073] Epoch: [5]  [70/84]  eta: 0:00:20  loss: 0.0567 (0.0582)  SSIM: 0.0000 (0.0000)  MAE: 0.0567 (0.0582)  MSE: 0.0071 (0.0075)  PSNR: 19.1079 (18.5749)  lr: 0.000997  iter-time: 1.4610\n",
            "[07:24:18.024137] Epoch: [5]  [80/84]  eta: 0:00:05  loss: 0.0565 (0.0579)  SSIM: 0.0000 (0.0000)  MAE: 0.0565 (0.0579)  MSE: 0.0071 (0.0074)  PSNR: 19.5558 (18.7147)  lr: 0.000995  iter-time: 1.4612\n",
            "[07:24:21.214898] Epoch: [5]  [83/84]  eta: 0:00:01  loss: 0.0565 (0.0580)  SSIM: 0.0000 (0.0000)  MAE: 0.0565 (0.0580)  MSE: 0.0071 (0.0074)  PSNR: 18.7722 (18.6415)  lr: 0.000994  iter-time: 1.4012\n",
            "[07:24:21.588957] Epoch: [5] Total time: 0:02:02 (1.4588 s / it)\n",
            "[07:24:21.591089] [Train] averaged stats: loss: 0.0565 (0.0580)  SSIM: 0.0000 (0.0000)  MAE: 0.0565 (0.0580)  MSE: 0.0071 (0.0074)  PSNR: 18.7722 (18.6415)  lr: 0.000994\n",
            "[07:24:22.678102] Epoch: [5]  [ 0/21]  eta: 0:00:22  loss: 0.0554 (0.0554)  SSIM: 0.0000 (0.0000)  MAE: 0.0554 (0.0554)  MSE: 0.0070 (0.0070)  PSNR: 18.7653 (18.7653)  iter-time: 1.0831\n",
            "[07:24:27.695357] Epoch: [5]  [10/21]  eta: 0:00:06  loss: 0.0554 (0.0554)  SSIM: 0.0000 (0.0000)  MAE: 0.0554 (0.0554)  MSE: 0.0069 (0.0069)  PSNR: 19.5662 (19.4296)  iter-time: 0.5544\n",
            "[07:24:32.604208] Epoch: [5]  [20/21]  eta: 0:00:00  loss: 0.0550 (0.0555)  SSIM: 0.0000 (0.0000)  MAE: 0.0550 (0.0555)  MSE: 0.0067 (0.0069)  PSNR: 19.2460 (18.9699)  iter-time: 0.4962\n",
            "[07:24:32.997460] Epoch: [5] Total time: 0:00:11 (0.5430 s / it)\n",
            "[07:24:32.997607] [Val] averaged stats: loss: 0.0550 (0.0555)  SSIM: 0.0000 (0.0000)  MAE: 0.0550 (0.0555)  MSE: 0.0067 (0.0069)  PSNR: 19.2460 (18.9699)\n",
            "[07:24:33.000708] Val loss improved from 0.05899338619340034 to 0.05548743584326336, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:24:33.089931] [Val] best loss: 0.0555 best  SSIM: 0.0000 MAE: 0.0555 MSE: 0.0069 PSNR: 18.9699 \n",
            "[07:24:33.092882] Creating training plots . . .\n",
            "[07:24:34.327598] [Time] 2.3m 15.9m/40.7m\n",
            "\n",
            "[07:24:34.328914] ~~~ Epoch 6/15 ~~~\n",
            "\n",
            "[07:24:36.612241] Epoch: [6]  [ 0/84]  eta: 0:03:11  loss: 0.0595 (0.0595)  SSIM: 0.0000 (0.0000)  MAE: 0.0595 (0.0595)  MSE: 0.0078 (0.0078)  PSNR: 17.9726 (17.9726)  lr: 0.000994  iter-time: 2.2794\n",
            "[07:24:51.194977] Epoch: [6]  [10/84]  eta: 0:01:53  loss: 0.0559 (0.0561)  SSIM: 0.0000 (0.0000)  MAE: 0.0559 (0.0561)  MSE: 0.0070 (0.0070)  PSNR: 19.5381 (18.4732)  lr: 0.000991  iter-time: 1.5326\n",
            "[07:25:05.867205] Epoch: [6]  [20/84]  eta: 0:01:36  loss: 0.0552 (0.0558)  SSIM: 0.0000 (0.0000)  MAE: 0.0552 (0.0558)  MSE: 0.0070 (0.0070)  PSNR: 19.9382 (18.6951)  lr: 0.000987  iter-time: 1.4624\n",
            "[07:25:20.513222] Epoch: [6]  [30/84]  eta: 0:01:20  loss: 0.0549 (0.0551)  SSIM: 0.0000 (0.0000)  MAE: 0.0549 (0.0551)  MSE: 0.0066 (0.0068)  PSNR: 20.1569 (19.0089)  lr: 0.000983  iter-time: 1.4656\n",
            "[07:25:35.154569] Epoch: [6]  [40/84]  eta: 0:01:05  loss: 0.0549 (0.0556)  SSIM: 0.0000 (0.0000)  MAE: 0.0549 (0.0556)  MSE: 0.0066 (0.0070)  PSNR: 20.1569 (19.1298)  lr: 0.000978  iter-time: 1.4641\n",
            "[07:25:49.775895] Epoch: [6]  [50/84]  eta: 0:00:50  loss: 0.0565 (0.0558)  SSIM: 0.0000 (0.0000)  MAE: 0.0565 (0.0558)  MSE: 0.0071 (0.0069)  PSNR: 19.9094 (19.1636)  lr: 0.000972  iter-time: 1.4630\n",
            "[07:26:04.374757] Epoch: [6]  [60/84]  eta: 0:00:35  loss: 0.0554 (0.0558)  SSIM: 0.0000 (0.0000)  MAE: 0.0554 (0.0558)  MSE: 0.0067 (0.0070)  PSNR: 19.3996 (19.1810)  lr: 0.000966  iter-time: 1.4608\n",
            "[07:26:18.957648] Epoch: [6]  [70/84]  eta: 0:00:20  loss: 0.0546 (0.0556)  SSIM: 0.0000 (0.0000)  MAE: 0.0546 (0.0556)  MSE: 0.0065 (0.0069)  PSNR: 20.2569 (19.3944)  lr: 0.000959  iter-time: 1.4588\n",
            "[07:26:33.528724] Epoch: [6]  [80/84]  eta: 0:00:05  loss: 0.0546 (0.0555)  SSIM: 0.0000 (0.0000)  MAE: 0.0546 (0.0555)  MSE: 0.0065 (0.0069)  PSNR: 20.0733 (19.4062)  lr: 0.000952  iter-time: 1.4573\n",
            "[07:26:36.716883] Epoch: [6]  [83/84]  eta: 0:00:01  loss: 0.0546 (0.0557)  SSIM: 0.0000 (0.0000)  MAE: 0.0546 (0.0557)  MSE: 0.0067 (0.0069)  PSNR: 20.0208 (19.4252)  lr: 0.000950  iter-time: 1.3976\n",
            "[07:26:37.072519] Epoch: [6] Total time: 0:02:02 (1.4612 s / it)\n",
            "[07:26:37.074318] [Train] averaged stats: loss: 0.0546 (0.0557)  SSIM: 0.0000 (0.0000)  MAE: 0.0546 (0.0557)  MSE: 0.0067 (0.0069)  PSNR: 20.0208 (19.4252)  lr: 0.000950\n",
            "[07:26:38.091910] Epoch: [6]  [ 0/21]  eta: 0:00:21  loss: 0.0539 (0.0539)  SSIM: 0.0000 (0.0000)  MAE: 0.0539 (0.0539)  MSE: 0.0067 (0.0067)  PSNR: 17.5161 (17.5161)  iter-time: 1.0132\n",
            "[07:26:43.086439] Epoch: [6]  [10/21]  eta: 0:00:06  loss: 0.0549 (0.0547)  SSIM: 0.0000 (0.0000)  MAE: 0.0549 (0.0547)  MSE: 0.0067 (0.0067)  PSNR: 17.9687 (18.1646)  iter-time: 0.5459\n",
            "[07:26:47.978027] Epoch: [6]  [20/21]  eta: 0:00:00  loss: 0.0547 (0.0547)  SSIM: 0.0000 (0.0000)  MAE: 0.0547 (0.0547)  MSE: 0.0065 (0.0067)  PSNR: 17.7332 (17.8797)  iter-time: 0.4941\n",
            "[07:26:48.345675] Epoch: [6] Total time: 0:00:11 (0.5366 s / it)\n",
            "[07:26:48.345820] [Val] averaged stats: loss: 0.0547 (0.0547)  SSIM: 0.0000 (0.0000)  MAE: 0.0547 (0.0547)  MSE: 0.0065 (0.0067)  PSNR: 17.7332 (17.8797)\n",
            "[07:26:48.346559] Val loss improved from 0.05548743584326336 to 0.0547491264130388, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:26:48.435119] [Val] best loss: 0.0547 best  SSIM: 0.0000 MAE: 0.0547 MSE: 0.0067 PSNR: 17.8797 \n",
            "[07:26:48.437853] [Time] 2.2m 18.2m/40.5m\n",
            "\n",
            "[07:26:48.438662] ~~~ Epoch 7/15 ~~~\n",
            "\n",
            "[07:26:50.634035] Epoch: [7]  [ 0/84]  eta: 0:03:04  loss: 0.0607 (0.0607)  SSIM: 0.0000 (0.0000)  MAE: 0.0607 (0.0607)  MSE: 0.0081 (0.0081)  PSNR: 14.1100 (14.1100)  lr: 0.000949  iter-time: 2.1919\n",
            "[07:27:05.201061] Epoch: [7]  [10/84]  eta: 0:01:52  loss: 0.0570 (0.0564)  SSIM: 0.0000 (0.0000)  MAE: 0.0570 (0.0564)  MSE: 0.0069 (0.0069)  PSNR: 19.2823 (18.2921)  lr: 0.000941  iter-time: 1.5234\n",
            "[07:27:19.817848] Epoch: [7]  [20/84]  eta: 0:01:35  loss: 0.0569 (0.0563)  SSIM: 0.0000 (0.0000)  MAE: 0.0569 (0.0563)  MSE: 0.0069 (0.0070)  PSNR: 19.2882 (18.5335)  lr: 0.000932  iter-time: 1.4590\n",
            "[07:27:34.464181] Epoch: [7]  [30/84]  eta: 0:01:20  loss: 0.0565 (0.0556)  SSIM: 0.0000 (0.0000)  MAE: 0.0565 (0.0556)  MSE: 0.0067 (0.0069)  PSNR: 19.6933 (18.8009)  lr: 0.000923  iter-time: 1.4629\n",
            "[07:27:49.070144] Epoch: [7]  [40/84]  eta: 0:01:05  loss: 0.0571 (0.0563)  SSIM: 0.0000 (0.0000)  MAE: 0.0571 (0.0563)  MSE: 0.0070 (0.0070)  PSNR: 20.0637 (19.0940)  lr: 0.000913  iter-time: 1.4624\n",
            "[07:28:03.686074] Epoch: [7]  [50/84]  eta: 0:00:50  loss: 0.0571 (0.0562)  SSIM: 0.0000 (0.0000)  MAE: 0.0571 (0.0562)  MSE: 0.0069 (0.0069)  PSNR: 20.0637 (19.3340)  lr: 0.000903  iter-time: 1.4609\n",
            "[07:28:18.299097] Epoch: [7]  [60/84]  eta: 0:00:35  loss: 0.0555 (0.0559)  SSIM: 0.0000 (0.0000)  MAE: 0.0555 (0.0559)  MSE: 0.0066 (0.0069)  PSNR: 20.6363 (19.5255)  lr: 0.000892  iter-time: 1.4612\n",
            "[07:28:32.917015] Epoch: [7]  [70/84]  eta: 0:00:20  loss: 0.0522 (0.0555)  SSIM: 0.0000 (0.0000)  MAE: 0.0522 (0.0555)  MSE: 0.0061 (0.0068)  PSNR: 21.3303 (19.7707)  lr: 0.000881  iter-time: 1.4613\n",
            "[07:28:47.498794] Epoch: [7]  [80/84]  eta: 0:00:05  loss: 0.0522 (0.0552)  SSIM: 0.0000 (0.0000)  MAE: 0.0522 (0.0552)  MSE: 0.0061 (0.0067)  PSNR: 21.2611 (19.8944)  lr: 0.000869  iter-time: 1.4597\n",
            "[07:28:50.682494] Epoch: [7]  [83/84]  eta: 0:00:01  loss: 0.0524 (0.0553)  SSIM: 0.0000 (0.0000)  MAE: 0.0524 (0.0553)  MSE: 0.0062 (0.0068)  PSNR: 21.2205 (19.9436)  lr: 0.000865  iter-time: 1.3994\n",
            "[07:28:50.917574] Epoch: [7] Total time: 0:02:02 (1.4581 s / it)\n",
            "[07:28:50.917842] [Train] averaged stats: loss: 0.0524 (0.0553)  SSIM: 0.0000 (0.0000)  MAE: 0.0524 (0.0553)  MSE: 0.0062 (0.0068)  PSNR: 21.2205 (19.9436)  lr: 0.000865\n",
            "[07:28:51.869835] Epoch: [7]  [ 0/21]  eta: 0:00:19  loss: 0.0529 (0.0529)  SSIM: 0.0000 (0.0000)  MAE: 0.0529 (0.0529)  MSE: 0.0062 (0.0062)  PSNR: 21.9773 (21.9773)  iter-time: 0.9462\n",
            "[07:28:56.896746] Epoch: [7]  [10/21]  eta: 0:00:05  loss: 0.0532 (0.0530)  SSIM: 0.0000 (0.0000)  MAE: 0.0532 (0.0530)  MSE: 0.0060 (0.0060)  PSNR: 22.1737 (21.8488)  iter-time: 0.5429\n",
            "[07:29:01.809942] Epoch: [7]  [20/21]  eta: 0:00:00  loss: 0.0532 (0.0533)  SSIM: 0.0000 (0.0000)  MAE: 0.0532 (0.0533)  MSE: 0.0059 (0.0060)  PSNR: 22.1687 (21.8346)  iter-time: 0.4969\n",
            "[07:29:02.166365] Epoch: [7] Total time: 0:00:11 (0.5354 s / it)\n",
            "[07:29:02.166567] [Val] averaged stats: loss: 0.0532 (0.0533)  SSIM: 0.0000 (0.0000)  MAE: 0.0532 (0.0533)  MSE: 0.0059 (0.0060)  PSNR: 22.1687 (21.8346)\n",
            "[07:29:02.170084] Val loss improved from 0.0547491264130388 to 0.05328046086998213, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:29:02.246028] [Val] best loss: 0.0533 best  SSIM: 0.0000 MAE: 0.0533 MSE: 0.0060 PSNR: 21.8346 \n",
            "[07:29:02.249136] [Time] 2.2m 20.4m/40.5m\n",
            "\n",
            "[07:29:02.249912] ~~~ Epoch 8/15 ~~~\n",
            "\n",
            "[07:29:04.307405] Epoch: [8]  [ 0/84]  eta: 0:02:52  loss: 0.0573 (0.0573)  SSIM: 0.0000 (0.0000)  MAE: 0.0573 (0.0573)  MSE: 0.0069 (0.0069)  PSNR: 20.6760 (20.6760)  lr: 0.000864  iter-time: 2.0552\n",
            "[07:29:18.886279] Epoch: [8]  [10/84]  eta: 0:01:51  loss: 0.0528 (0.0537)  SSIM: 0.0000 (0.0000)  MAE: 0.0528 (0.0537)  MSE: 0.0058 (0.0062)  PSNR: 20.6760 (20.5044)  lr: 0.000852  iter-time: 1.5120\n",
            "[07:29:33.468416] Epoch: [8]  [20/84]  eta: 0:01:35  loss: 0.0521 (0.0531)  SSIM: 0.0000 (0.0000)  MAE: 0.0521 (0.0531)  MSE: 0.0059 (0.0063)  PSNR: 20.7498 (20.7185)  lr: 0.000839  iter-time: 1.4578\n",
            "[07:29:48.084112] Epoch: [8]  [30/84]  eta: 0:01:19  loss: 0.0520 (0.0529)  SSIM: 0.0000 (0.0000)  MAE: 0.0520 (0.0529)  MSE: 0.0061 (0.0062)  PSNR: 21.7420 (20.7079)  lr: 0.000825  iter-time: 1.4597\n",
            "[07:30:02.715263] Epoch: [8]  [40/84]  eta: 0:01:04  loss: 0.0540 (0.0536)  SSIM: 0.0000 (0.0000)  MAE: 0.0540 (0.0536)  MSE: 0.0063 (0.0063)  PSNR: 21.7091 (20.8950)  lr: 0.000812  iter-time: 1.4622\n",
            "[07:30:17.342446] Epoch: [8]  [50/84]  eta: 0:00:50  loss: 0.0554 (0.0538)  SSIM: 0.0000 (0.0000)  MAE: 0.0554 (0.0538)  MSE: 0.0066 (0.0063)  PSNR: 21.5837 (20.9616)  lr: 0.000798  iter-time: 1.4628\n",
            "[07:30:31.971888] Epoch: [8]  [60/84]  eta: 0:00:35  loss: 0.0541 (0.0538)  SSIM: 0.0000 (0.0000)  MAE: 0.0541 (0.0538)  MSE: 0.0062 (0.0063)  PSNR: 21.7110 (21.0616)  lr: 0.000783  iter-time: 1.4627\n",
            "[07:30:46.596947] Epoch: [8]  [70/84]  eta: 0:00:20  loss: 0.0514 (0.0536)  SSIM: 0.0000 (0.0000)  MAE: 0.0514 (0.0536)  MSE: 0.0059 (0.0063)  PSNR: 22.0268 (21.1960)  lr: 0.000768  iter-time: 1.4625\n",
            "[07:31:01.203250] Epoch: [8]  [80/84]  eta: 0:00:05  loss: 0.0516 (0.0535)  SSIM: 0.0000 (0.0000)  MAE: 0.0516 (0.0535)  MSE: 0.0059 (0.0063)  PSNR: 21.8793 (21.2536)  lr: 0.000753  iter-time: 1.4613\n",
            "[07:31:04.396087] Epoch: [8]  [83/84]  eta: 0:00:01  loss: 0.0519 (0.0537)  SSIM: 0.0000 (0.0000)  MAE: 0.0519 (0.0537)  MSE: 0.0061 (0.0063)  PSNR: 21.7405 (21.2443)  lr: 0.000748  iter-time: 1.4012\n",
            "[07:31:04.770130] Epoch: [8] Total time: 0:02:02 (1.4586 s / it)\n",
            "[07:31:04.771454] [Train] averaged stats: loss: 0.0519 (0.0537)  SSIM: 0.0000 (0.0000)  MAE: 0.0519 (0.0537)  MSE: 0.0061 (0.0063)  PSNR: 21.7405 (21.2443)  lr: 0.000748\n",
            "[07:31:05.746260] Epoch: [8]  [ 0/21]  eta: 0:00:20  loss: 0.0542 (0.0542)  SSIM: 0.0000 (0.0000)  MAE: 0.0542 (0.0542)  MSE: 0.0066 (0.0066)  PSNR: 21.9860 (21.9860)  iter-time: 0.9707\n",
            "[07:31:10.758293] Epoch: [8]  [10/21]  eta: 0:00:05  loss: 0.0534 (0.0534)  SSIM: 0.0000 (0.0000)  MAE: 0.0534 (0.0534)  MSE: 0.0061 (0.0062)  PSNR: 21.7689 (21.7999)  iter-time: 0.5438\n",
            "[07:31:15.663255] Epoch: [8]  [20/21]  eta: 0:00:00  loss: 0.0534 (0.0540)  SSIM: 0.0000 (0.0000)  MAE: 0.0534 (0.0540)  MSE: 0.0060 (0.0063)  PSNR: 21.7689 (21.8204)  iter-time: 0.4958\n",
            "[07:31:16.023438] Epoch: [8] Total time: 0:00:11 (0.5356 s / it)\n",
            "[07:31:16.026439] [Val] averaged stats: loss: 0.0534 (0.0540)  SSIM: 0.0000 (0.0000)  MAE: 0.0534 (0.0540)  MSE: 0.0060 (0.0063)  PSNR: 21.7689 (21.8204)\n",
            "[07:31:16.028647] [Val] best loss: 0.0533 best  SSIM: 0.0000 MAE: 0.0533 MSE: 0.0060 PSNR: 21.8346 \n",
            "EarlyStopping counter: 1 out of 15\n",
            "[07:31:16.031597] [Time] 2.2m 22.6m/40.5m\n",
            "\n",
            "[07:31:16.031675] ~~~ Epoch 9/15 ~~~\n",
            "\n",
            "[07:31:18.446974] Epoch: [9]  [ 0/84]  eta: 0:03:22  loss: 0.0574 (0.0574)  SSIM: 0.0000 (0.0000)  MAE: 0.0574 (0.0574)  MSE: 0.0069 (0.0069)  PSNR: 21.3221 (21.3221)  lr: 0.000747  iter-time: 2.4108\n",
            "[07:31:33.013529] Epoch: [9]  [10/84]  eta: 0:01:54  loss: 0.0537 (0.0532)  SSIM: 0.0000 (0.0000)  MAE: 0.0537 (0.0532)  MSE: 0.0059 (0.0061)  PSNR: 21.7613 (21.7179)  lr: 0.000731  iter-time: 1.5431\n",
            "[07:31:47.596351] Epoch: [9]  [20/84]  eta: 0:01:36  loss: 0.0520 (0.0524)  SSIM: 0.0000 (0.0000)  MAE: 0.0520 (0.0524)  MSE: 0.0059 (0.0060)  PSNR: 22.0699 (21.8754)  lr: 0.000715  iter-time: 1.4572\n",
            "[07:32:02.206667] Epoch: [9]  [30/84]  eta: 0:01:20  loss: 0.0509 (0.0519)  SSIM: 0.0000 (0.0000)  MAE: 0.0509 (0.0519)  MSE: 0.0059 (0.0060)  PSNR: 22.1579 (21.7498)  lr: 0.000699  iter-time: 1.4594\n",
            "[07:32:16.853175] Epoch: [9]  [40/84]  eta: 0:01:05  loss: 0.0510 (0.0524)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0524)  MSE: 0.0062 (0.0060)  PSNR: 21.9874 (21.8037)  lr: 0.000683  iter-time: 1.4625\n",
            "[07:32:31.472204] Epoch: [9]  [50/84]  eta: 0:00:50  loss: 0.0540 (0.0527)  SSIM: 0.0000 (0.0000)  MAE: 0.0540 (0.0527)  MSE: 0.0063 (0.0061)  PSNR: 21.9284 (21.8371)  lr: 0.000666  iter-time: 1.4631\n",
            "[07:32:46.096957] Epoch: [9]  [60/84]  eta: 0:00:35  loss: 0.0534 (0.0528)  SSIM: 0.0000 (0.0000)  MAE: 0.0534 (0.0528)  MSE: 0.0060 (0.0061)  PSNR: 22.0633 (21.8997)  lr: 0.000649  iter-time: 1.4620\n",
            "[07:33:00.723237] Epoch: [9]  [70/84]  eta: 0:00:20  loss: 0.0509 (0.0526)  SSIM: 0.0000 (0.0000)  MAE: 0.0509 (0.0526)  MSE: 0.0058 (0.0061)  PSNR: 22.1902 (21.9449)  lr: 0.000632  iter-time: 1.4622\n",
            "[07:33:15.331848] Epoch: [9]  [80/84]  eta: 0:00:05  loss: 0.0509 (0.0525)  SSIM: 0.0000 (0.0000)  MAE: 0.0509 (0.0525)  MSE: 0.0058 (0.0061)  PSNR: 22.1997 (21.9747)  lr: 0.000615  iter-time: 1.4614\n",
            "[07:33:18.525752] Epoch: [9]  [83/84]  eta: 0:00:01  loss: 0.0514 (0.0527)  SSIM: 0.0000 (0.0000)  MAE: 0.0514 (0.0527)  MSE: 0.0059 (0.0061)  PSNR: 22.1429 (21.9602)  lr: 0.000610  iter-time: 1.4013\n",
            "[07:33:18.747691] Epoch: [9] Total time: 0:02:02 (1.4609 s / it)\n",
            "[07:33:18.748692] [Train] averaged stats: loss: 0.0514 (0.0527)  SSIM: 0.0000 (0.0000)  MAE: 0.0514 (0.0527)  MSE: 0.0059 (0.0061)  PSNR: 22.1429 (21.9602)  lr: 0.000610\n",
            "[07:33:19.732478] Epoch: [9]  [ 0/21]  eta: 0:00:20  loss: 0.0519 (0.0519)  SSIM: 0.0000 (0.0000)  MAE: 0.0519 (0.0519)  MSE: 0.0059 (0.0059)  PSNR: 22.0864 (22.0864)  iter-time: 0.9802\n",
            "[07:33:24.806138] Epoch: [9]  [10/21]  eta: 0:00:06  loss: 0.0521 (0.0524)  SSIM: 0.0000 (0.0000)  MAE: 0.0521 (0.0524)  MSE: 0.0058 (0.0058)  PSNR: 21.8864 (21.8994)  iter-time: 0.5502\n",
            "[07:33:29.718734] Epoch: [9]  [20/21]  eta: 0:00:00  loss: 0.0521 (0.0526)  SSIM: 0.0000 (0.0000)  MAE: 0.0521 (0.0526)  MSE: 0.0057 (0.0058)  PSNR: 21.9232 (21.9357)  iter-time: 0.4992\n",
            "[07:33:29.947118] Epoch: [9] Total time: 0:00:11 (0.5331 s / it)\n",
            "[07:33:29.947240] [Val] averaged stats: loss: 0.0521 (0.0526)  SSIM: 0.0000 (0.0000)  MAE: 0.0521 (0.0526)  MSE: 0.0057 (0.0058)  PSNR: 21.9232 (21.9357)\n",
            "[07:33:29.952138] Val loss improved from 0.05328046086998213 to 0.052631307215917675, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:33:30.010011] [Val] best loss: 0.0526 best  SSIM: 0.0000 MAE: 0.0526 MSE: 0.0058 PSNR: 21.9357 \n",
            "[07:33:30.013043] [Time] 2.2m 24.9m/40.5m\n",
            "\n",
            "[07:33:30.013117] ~~~ Epoch 10/15 ~~~\n",
            "\n",
            "[07:33:32.115123] Epoch: [10]  [ 0/84]  eta: 0:02:56  loss: 0.0570 (0.0570)  SSIM: 0.0000 (0.0000)  MAE: 0.0570 (0.0570)  MSE: 0.0067 (0.0067)  PSNR: 21.1488 (21.1488)  lr: 0.000608  iter-time: 2.0985\n",
            "[07:33:46.702096] Epoch: [10]  [10/84]  eta: 0:01:52  loss: 0.0516 (0.0524)  SSIM: 0.0000 (0.0000)  MAE: 0.0516 (0.0524)  MSE: 0.0057 (0.0059)  PSNR: 22.1653 (21.9567)  lr: 0.000590  iter-time: 1.5166\n",
            "[07:34:01.288462] Epoch: [10]  [20/84]  eta: 0:01:35  loss: 0.0511 (0.0517)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0517)  MSE: 0.0057 (0.0059)  PSNR: 22.1342 (22.1179)  lr: 0.000573  iter-time: 1.4584\n",
            "[07:34:15.882416] Epoch: [10]  [30/84]  eta: 0:01:19  loss: 0.0505 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0505 (0.0513)  MSE: 0.0056 (0.0058)  PSNR: 22.1393 (22.1558)  lr: 0.000555  iter-time: 1.4588\n",
            "[07:34:30.495906] Epoch: [10]  [40/84]  eta: 0:01:04  loss: 0.0506 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0506 (0.0518)  MSE: 0.0056 (0.0059)  PSNR: 22.2707 (22.1484)  lr: 0.000537  iter-time: 1.4601\n",
            "[07:34:45.132923] Epoch: [10]  [50/84]  eta: 0:00:50  loss: 0.0532 (0.0522)  SSIM: 0.0000 (0.0000)  MAE: 0.0532 (0.0522)  MSE: 0.0062 (0.0059)  PSNR: 21.9971 (22.1315)  lr: 0.000520  iter-time: 1.4622\n",
            "[07:34:59.754744] Epoch: [10]  [60/84]  eta: 0:00:35  loss: 0.0531 (0.0523)  SSIM: 0.0000 (0.0000)  MAE: 0.0531 (0.0523)  MSE: 0.0060 (0.0060)  PSNR: 22.0842 (22.1412)  lr: 0.000502  iter-time: 1.4627\n",
            "[07:35:14.389990] Epoch: [10]  [70/84]  eta: 0:00:20  loss: 0.0503 (0.0520)  SSIM: 0.0000 (0.0000)  MAE: 0.0503 (0.0520)  MSE: 0.0056 (0.0059)  PSNR: 22.2637 (22.1748)  lr: 0.000484  iter-time: 1.4627\n",
            "[07:35:28.965992] Epoch: [10]  [80/84]  eta: 0:00:05  loss: 0.0508 (0.0520)  SSIM: 0.0000 (0.0000)  MAE: 0.0508 (0.0520)  MSE: 0.0057 (0.0059)  PSNR: 22.2637 (22.1966)  lr: 0.000466  iter-time: 1.4604\n",
            "[07:35:32.152319] Epoch: [10]  [83/84]  eta: 0:00:01  loss: 0.0510 (0.0521)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0521)  MSE: 0.0059 (0.0060)  PSNR: 22.2333 (22.1702)  lr: 0.000461  iter-time: 1.4003\n",
            "[07:35:32.378972] Epoch: [10] Total time: 0:02:02 (1.4567 s / it)\n",
            "[07:35:32.380107] [Train] averaged stats: loss: 0.0510 (0.0521)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0521)  MSE: 0.0059 (0.0060)  PSNR: 22.2333 (22.1702)  lr: 0.000461\n",
            "[07:35:33.358551] Epoch: [10]  [ 0/21]  eta: 0:00:20  loss: 0.0510 (0.0510)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0510)  MSE: 0.0058 (0.0058)  PSNR: 22.3336 (22.3336)  iter-time: 0.9751\n",
            "[07:35:38.375298] Epoch: [10]  [10/21]  eta: 0:00:05  loss: 0.0510 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0515)  MSE: 0.0057 (0.0057)  PSNR: 22.1640 (22.1036)  iter-time: 0.5446\n",
            "[07:35:43.285212] Epoch: [10]  [20/21]  eta: 0:00:00  loss: 0.0514 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0514 (0.0518)  MSE: 0.0056 (0.0057)  PSNR: 22.1640 (22.1031)  iter-time: 0.4962\n",
            "[07:35:43.609995] Epoch: [10] Total time: 0:00:11 (0.5346 s / it)\n",
            "[07:35:43.610160] [Val] averaged stats: loss: 0.0514 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0514 (0.0518)  MSE: 0.0056 (0.0057)  PSNR: 22.1640 (22.1031)\n",
            "[07:35:43.615065] Val loss improved from 0.052631307215917675 to 0.05178729267347427, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:35:43.707642] [Val] best loss: 0.0518 best  SSIM: 0.0000 MAE: 0.0518 MSE: 0.0057 PSNR: 22.1031 \n",
            "[07:35:43.711888] Creating training plots . . .\n",
            "[07:35:44.743849] [Time] 2.2m 27.1m/40.6m\n",
            "\n",
            "[07:35:44.743979] ~~~ Epoch 11/15 ~~~\n",
            "\n",
            "[07:35:46.868248] Epoch: [11]  [ 0/84]  eta: 0:02:58  loss: 0.0563 (0.0563)  SSIM: 0.0000 (0.0000)  MAE: 0.0563 (0.0563)  MSE: 0.0067 (0.0067)  PSNR: 21.3088 (21.3088)  lr: 0.000459  iter-time: 2.1216\n",
            "[07:36:01.425140] Epoch: [11]  [10/84]  eta: 0:01:52  loss: 0.0515 (0.0520)  SSIM: 0.0000 (0.0000)  MAE: 0.0515 (0.0520)  MSE: 0.0055 (0.0057)  PSNR: 22.3428 (22.2026)  lr: 0.000441  iter-time: 1.5159\n",
            "[07:36:16.036336] Epoch: [11]  [20/84]  eta: 0:01:35  loss: 0.0506 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0506 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.2804 (22.2470)  lr: 0.000424  iter-time: 1.4582\n",
            "[07:36:30.639021] Epoch: [11]  [30/84]  eta: 0:01:19  loss: 0.0494 (0.0509)  SSIM: 0.0000 (0.0000)  MAE: 0.0494 (0.0509)  MSE: 0.0055 (0.0057)  PSNR: 22.3904 (22.3370)  lr: 0.000406  iter-time: 1.4604\n",
            "[07:36:45.243713] Epoch: [11]  [40/84]  eta: 0:01:04  loss: 0.0499 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0499 (0.0513)  MSE: 0.0055 (0.0058)  PSNR: 22.3904 (22.2733)  lr: 0.000389  iter-time: 1.4601\n",
            "[07:36:59.872539] Epoch: [11]  [50/84]  eta: 0:00:50  loss: 0.0530 (0.0517)  SSIM: 0.0000 (0.0000)  MAE: 0.0530 (0.0517)  MSE: 0.0061 (0.0058)  PSNR: 21.9740 (22.2049)  lr: 0.000371  iter-time: 1.4613\n",
            "[07:37:14.445072] Epoch: [11]  [60/84]  eta: 0:00:35  loss: 0.0525 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0525 (0.0518)  MSE: 0.0059 (0.0059)  PSNR: 22.1191 (22.1871)  lr: 0.000354  iter-time: 1.4597\n",
            "[07:37:29.024118] Epoch: [11]  [70/84]  eta: 0:00:20  loss: 0.0503 (0.0516)  SSIM: 0.0000 (0.0000)  MAE: 0.0503 (0.0516)  MSE: 0.0056 (0.0059)  PSNR: 22.3599 (22.2121)  lr: 0.000337  iter-time: 1.4573\n",
            "[07:37:43.581379] Epoch: [11]  [80/84]  eta: 0:00:05  loss: 0.0502 (0.0516)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0516)  MSE: 0.0056 (0.0059)  PSNR: 22.3413 (22.2227)  lr: 0.000321  iter-time: 1.4566\n",
            "[07:37:46.770321] Epoch: [11]  [83/84]  eta: 0:00:01  loss: 0.0510 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0518)  MSE: 0.0058 (0.0059)  PSNR: 22.1648 (22.1918)  lr: 0.000316  iter-time: 1.3970\n",
            "[07:37:47.159691] Epoch: [11] Total time: 0:02:02 (1.4573 s / it)\n",
            "[07:37:47.161727] [Train] averaged stats: loss: 0.0510 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0518)  MSE: 0.0058 (0.0059)  PSNR: 22.1648 (22.1918)  lr: 0.000316\n",
            "[07:37:48.302188] Epoch: [11]  [ 0/21]  eta: 0:00:23  loss: 0.0512 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0512 (0.0512)  MSE: 0.0058 (0.0058)  PSNR: 22.3540 (22.3540)  iter-time: 1.1362\n",
            "[07:37:53.293167] Epoch: [11]  [10/21]  eta: 0:00:06  loss: 0.0512 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0512 (0.0515)  MSE: 0.0057 (0.0057)  PSNR: 22.2022 (22.1904)  iter-time: 0.5569\n",
            "[07:37:58.189549] Epoch: [11]  [20/21]  eta: 0:00:00  loss: 0.0513 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0513 (0.0518)  MSE: 0.0057 (0.0058)  PSNR: 22.2022 (22.1699)  iter-time: 0.4943\n",
            "[07:37:58.521443] Epoch: [11] Total time: 0:00:11 (0.5408 s / it)\n",
            "[07:37:58.521573] [Val] averaged stats: loss: 0.0513 (0.0518)  SSIM: 0.0000 (0.0000)  MAE: 0.0513 (0.0518)  MSE: 0.0057 (0.0058)  PSNR: 22.2022 (22.1699)\n",
            "[07:37:58.522437] Val loss improved from 0.05178729267347427 to 0.05176840030721256, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:37:58.608329] [Val] best loss: 0.0518 best  SSIM: 0.0000 MAE: 0.0518 MSE: 0.0058 PSNR: 22.1699 \n",
            "[07:37:58.611014] [Time] 2.2m 29.3m/40.5m\n",
            "\n",
            "[07:37:58.613066] ~~~ Epoch 12/15 ~~~\n",
            "\n",
            "[07:38:00.819117] Epoch: [12]  [ 0/84]  eta: 0:03:05  loss: 0.0563 (0.0563)  SSIM: 0.0000 (0.0000)  MAE: 0.0563 (0.0563)  MSE: 0.0068 (0.0068)  PSNR: 21.3051 (21.3051)  lr: 0.000314  iter-time: 2.2027\n",
            "[07:38:15.403519] Epoch: [12]  [10/84]  eta: 0:01:52  loss: 0.0512 (0.0519)  SSIM: 0.0000 (0.0000)  MAE: 0.0512 (0.0519)  MSE: 0.0055 (0.0057)  PSNR: 22.2421 (22.1684)  lr: 0.000298  iter-time: 1.5258\n",
            "[07:38:30.029813] Epoch: [12]  [20/84]  eta: 0:01:35  loss: 0.0504 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0504 (0.0513)  MSE: 0.0055 (0.0057)  PSNR: 22.1997 (22.2330)  lr: 0.000281  iter-time: 1.4603\n",
            "[07:38:44.665546] Epoch: [12]  [30/84]  eta: 0:01:20  loss: 0.0497 (0.0507)  SSIM: 0.0000 (0.0000)  MAE: 0.0497 (0.0507)  MSE: 0.0054 (0.0056)  PSNR: 22.2428 (22.2578)  lr: 0.000266  iter-time: 1.4629\n",
            "[07:38:59.300869] Epoch: [12]  [40/84]  eta: 0:01:05  loss: 0.0498 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0498 (0.0512)  MSE: 0.0054 (0.0058)  PSNR: 22.2966 (22.2302)  lr: 0.000250  iter-time: 1.4633\n",
            "[07:39:13.911057] Epoch: [12]  [50/84]  eta: 0:00:50  loss: 0.0531 (0.0516)  SSIM: 0.0000 (0.0000)  MAE: 0.0531 (0.0516)  MSE: 0.0062 (0.0058)  PSNR: 21.8787 (22.1583)  lr: 0.000235  iter-time: 1.4619\n",
            "[07:39:28.519615] Epoch: [12]  [60/84]  eta: 0:00:35  loss: 0.0524 (0.0517)  SSIM: 0.0000 (0.0000)  MAE: 0.0524 (0.0517)  MSE: 0.0059 (0.0059)  PSNR: 22.0179 (22.1626)  lr: 0.000220  iter-time: 1.4606\n",
            "[07:39:43.103601] Epoch: [12]  [70/84]  eta: 0:00:20  loss: 0.0501 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0501 (0.0515)  MSE: 0.0056 (0.0058)  PSNR: 22.2767 (22.1755)  lr: 0.000205  iter-time: 1.4594\n",
            "[07:39:57.670956] Epoch: [12]  [80/84]  eta: 0:00:05  loss: 0.0501 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0501 (0.0515)  MSE: 0.0056 (0.0058)  PSNR: 22.2767 (22.1956)  lr: 0.000191  iter-time: 1.4574\n",
            "[07:40:00.853086] Epoch: [12]  [83/84]  eta: 0:00:01  loss: 0.0504 (0.0516)  SSIM: 0.0000 (0.0000)  MAE: 0.0504 (0.0516)  MSE: 0.0057 (0.0059)  PSNR: 22.0296 (22.1687)  lr: 0.000187  iter-time: 1.3978\n",
            "[07:40:01.070502] Epoch: [12] Total time: 0:02:02 (1.4578 s / it)\n",
            "[07:40:01.072607] [Train] averaged stats: loss: 0.0504 (0.0516)  SSIM: 0.0000 (0.0000)  MAE: 0.0504 (0.0516)  MSE: 0.0057 (0.0059)  PSNR: 22.0296 (22.1687)  lr: 0.000187\n",
            "[07:40:01.999981] Epoch: [12]  [ 0/21]  eta: 0:00:19  loss: 0.0504 (0.0504)  SSIM: 0.0000 (0.0000)  MAE: 0.0504 (0.0504)  MSE: 0.0058 (0.0058)  PSNR: 22.3984 (22.3984)  iter-time: 0.9241\n",
            "[07:40:07.010625] Epoch: [12]  [10/21]  eta: 0:00:05  loss: 0.0509 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0509 (0.0514)  MSE: 0.0058 (0.0058)  PSNR: 22.1331 (22.1826)  iter-time: 0.5394\n",
            "[07:40:11.917843] Epoch: [12]  [20/21]  eta: 0:00:00  loss: 0.0511 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0515)  MSE: 0.0056 (0.0058)  PSNR: 22.1561 (22.1837)  iter-time: 0.4957\n",
            "[07:40:12.245600] Epoch: [12] Total time: 0:00:11 (0.5319 s / it)\n",
            "[07:40:12.245765] [Val] averaged stats: loss: 0.0511 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0515)  MSE: 0.0056 (0.0058)  PSNR: 22.1561 (22.1837)\n",
            "[07:40:12.251686] Val loss improved from 0.05176840030721256 to 0.05153455106275422, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:40:12.335447] [Val] best loss: 0.0515 best  SSIM: 0.0000 MAE: 0.0515 MSE: 0.0058 PSNR: 22.1837 \n",
            "[07:40:12.338469] [Time] 2.2m 31.6m/40.5m\n",
            "\n",
            "[07:40:12.338554] ~~~ Epoch 13/15 ~~~\n",
            "\n",
            "[07:40:14.264691] Epoch: [13]  [ 0/84]  eta: 0:02:41  loss: 0.0563 (0.0563)  SSIM: 0.0000 (0.0000)  MAE: 0.0563 (0.0563)  MSE: 0.0069 (0.0069)  PSNR: 21.3426 (21.3426)  lr: 0.000185  iter-time: 1.9238\n",
            "[07:40:28.843329] Epoch: [13]  [10/84]  eta: 0:01:51  loss: 0.0517 (0.0517)  SSIM: 0.0000 (0.0000)  MAE: 0.0517 (0.0517)  MSE: 0.0055 (0.0057)  PSNR: 22.2776 (22.1105)  lr: 0.000172  iter-time: 1.5001\n",
            "[07:40:43.415924] Epoch: [13]  [20/84]  eta: 0:01:34  loss: 0.0502 (0.0510)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0510)  MSE: 0.0055 (0.0057)  PSNR: 22.2254 (22.2602)  lr: 0.000159  iter-time: 1.4574\n",
            "[07:40:57.994552] Epoch: [13]  [30/84]  eta: 0:01:19  loss: 0.0492 (0.0504)  SSIM: 0.0000 (0.0000)  MAE: 0.0492 (0.0504)  MSE: 0.0054 (0.0056)  PSNR: 22.1448 (22.2709)  lr: 0.000146  iter-time: 1.4573\n",
            "[07:41:12.597701] Epoch: [13]  [40/84]  eta: 0:01:04  loss: 0.0497 (0.0509)  SSIM: 0.0000 (0.0000)  MAE: 0.0497 (0.0509)  MSE: 0.0054 (0.0057)  PSNR: 22.1448 (22.2332)  lr: 0.000133  iter-time: 1.4589\n",
            "[07:41:27.196694] Epoch: [13]  [50/84]  eta: 0:00:49  loss: 0.0530 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0530 (0.0513)  MSE: 0.0062 (0.0058)  PSNR: 22.0193 (22.1738)  lr: 0.000122  iter-time: 1.4600\n",
            "[07:41:41.848459] Epoch: [13]  [60/84]  eta: 0:00:35  loss: 0.0521 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0521 (0.0515)  MSE: 0.0059 (0.0058)  PSNR: 22.0737 (22.1503)  lr: 0.000110  iter-time: 1.4622\n",
            "[07:41:56.455927] Epoch: [13]  [70/84]  eta: 0:00:20  loss: 0.0501 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0501 (0.0513)  MSE: 0.0056 (0.0058)  PSNR: 22.1780 (22.1599)  lr: 0.000099  iter-time: 1.4626\n",
            "[07:42:11.075076] Epoch: [13]  [80/84]  eta: 0:00:05  loss: 0.0500 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0500 (0.0512)  MSE: 0.0056 (0.0058)  PSNR: 22.2351 (22.1840)  lr: 0.000089  iter-time: 1.4610\n",
            "[07:42:14.274280] Epoch: [13]  [83/84]  eta: 0:00:01  loss: 0.0502 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0514)  MSE: 0.0057 (0.0058)  PSNR: 22.1673 (22.1591)  lr: 0.000086  iter-time: 1.4015\n",
            "[07:42:14.617324] Epoch: [13] Total time: 0:02:02 (1.4557 s / it)\n",
            "[07:42:14.619120] [Train] averaged stats: loss: 0.0502 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0514)  MSE: 0.0057 (0.0058)  PSNR: 22.1673 (22.1591)  lr: 0.000086\n",
            "[07:42:15.587830] Epoch: [13]  [ 0/21]  eta: 0:00:20  loss: 0.0505 (0.0505)  SSIM: 0.0000 (0.0000)  MAE: 0.0505 (0.0505)  MSE: 0.0058 (0.0058)  PSNR: 22.3186 (22.3186)  iter-time: 0.9650\n",
            "[07:42:20.603147] Epoch: [13]  [10/21]  eta: 0:00:05  loss: 0.0508 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0508 (0.0513)  MSE: 0.0058 (0.0058)  PSNR: 22.1293 (22.1974)  iter-time: 0.5436\n",
            "[07:42:25.509934] Epoch: [13]  [20/21]  eta: 0:00:00  loss: 0.0511 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.1293 (22.1621)  iter-time: 0.4960\n",
            "[07:42:25.865737] Epoch: [13] Total time: 0:00:11 (0.5354 s / it)\n",
            "[07:42:25.865979] [Val] averaged stats: loss: 0.0511 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.1293 (22.1621)\n",
            "[07:42:25.866875] Val loss improved from 0.05153455106275422 to 0.05144472721786726, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:42:25.969319] [Val] best loss: 0.0514 best  SSIM: 0.0000 MAE: 0.0514 MSE: 0.0058 PSNR: 22.1621 \n",
            "[07:42:25.973819] [Time] 2.2m 33.8m/40.5m\n",
            "\n",
            "[07:42:25.974742] ~~~ Epoch 14/15 ~~~\n",
            "\n",
            "[07:42:28.300662] Epoch: [14]  [ 0/84]  eta: 0:03:15  loss: 0.0563 (0.0563)  SSIM: 0.0000 (0.0000)  MAE: 0.0563 (0.0563)  MSE: 0.0069 (0.0069)  PSNR: 21.4888 (21.4888)  lr: 0.000085  iter-time: 2.3223\n",
            "[07:42:42.890863] Epoch: [14]  [10/84]  eta: 0:01:53  loss: 0.0509 (0.0517)  SSIM: 0.0000 (0.0000)  MAE: 0.0509 (0.0517)  MSE: 0.0054 (0.0057)  PSNR: 22.1748 (22.0646)  lr: 0.000075  iter-time: 1.5372\n",
            "[07:42:57.491845] Epoch: [14]  [20/84]  eta: 0:01:36  loss: 0.0499 (0.0509)  SSIM: 0.0000 (0.0000)  MAE: 0.0499 (0.0509)  MSE: 0.0053 (0.0056)  PSNR: 22.1010 (22.1915)  lr: 0.000066  iter-time: 1.4593\n",
            "[07:43:12.084529] Epoch: [14]  [30/84]  eta: 0:01:20  loss: 0.0488 (0.0503)  SSIM: 0.0000 (0.0000)  MAE: 0.0488 (0.0503)  MSE: 0.0053 (0.0055)  PSNR: 22.3244 (22.2678)  lr: 0.000058  iter-time: 1.4595\n",
            "[07:43:26.669497] Epoch: [14]  [40/84]  eta: 0:01:05  loss: 0.0499 (0.0508)  SSIM: 0.0000 (0.0000)  MAE: 0.0499 (0.0508)  MSE: 0.0054 (0.0057)  PSNR: 22.3711 (22.2467)  lr: 0.000050  iter-time: 1.4587\n",
            "[07:43:41.272050] Epoch: [14]  [50/84]  eta: 0:00:50  loss: 0.0533 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0533 (0.0513)  MSE: 0.0062 (0.0057)  PSNR: 21.9842 (22.1872)  lr: 0.000042  iter-time: 1.4592\n",
            "[07:43:55.877925] Epoch: [14]  [60/84]  eta: 0:00:35  loss: 0.0519 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0519 (0.0514)  MSE: 0.0059 (0.0058)  PSNR: 22.0404 (22.1595)  lr: 0.000035  iter-time: 1.4602\n",
            "[07:44:10.514181] Epoch: [14]  [70/84]  eta: 0:00:20  loss: 0.0501 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0501 (0.0512)  MSE: 0.0054 (0.0057)  PSNR: 22.1010 (22.1496)  lr: 0.000029  iter-time: 1.4619\n",
            "[07:44:25.134288] Epoch: [14]  [80/84]  eta: 0:00:05  loss: 0.0498 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0498 (0.0512)  MSE: 0.0054 (0.0057)  PSNR: 22.1010 (22.1689)  lr: 0.000023  iter-time: 1.4627\n",
            "[07:44:28.331997] Epoch: [14]  [83/84]  eta: 0:00:01  loss: 0.0502 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 21.9939 (22.1442)  lr: 0.000022  iter-time: 1.4029\n",
            "[07:44:28.561601] Epoch: [14] Total time: 0:02:02 (1.4593 s / it)\n",
            "[07:44:28.563663] [Train] averaged stats: loss: 0.0502 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 21.9939 (22.1442)  lr: 0.000022\n",
            "[07:44:29.525448] Epoch: [14]  [ 0/21]  eta: 0:00:20  loss: 0.0505 (0.0505)  SSIM: 0.0000 (0.0000)  MAE: 0.0505 (0.0505)  MSE: 0.0058 (0.0058)  PSNR: 22.3913 (22.3913)  iter-time: 0.9583\n",
            "[07:44:34.589463] Epoch: [14]  [10/21]  eta: 0:00:06  loss: 0.0509 (0.0513)  SSIM: 0.0000 (0.0000)  MAE: 0.0509 (0.0513)  MSE: 0.0058 (0.0058)  PSNR: 22.1934 (22.2624)  iter-time: 0.5472\n",
            "[07:44:39.498924] Epoch: [14]  [20/21]  eta: 0:00:00  loss: 0.0511 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.2180 (22.2383)  iter-time: 0.4984\n",
            "[07:44:39.727266] Epoch: [14] Total time: 0:00:11 (0.5315 s / it)\n",
            "[07:44:39.727392] [Val] averaged stats: loss: 0.0511 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0511 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.2180 (22.2383)\n",
            "[07:44:39.731503] Val loss improved from 0.05144472721786726 to 0.051439215384778525, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:44:39.790885] [Val] best loss: 0.0514 best  SSIM: 0.0000 MAE: 0.0514 MSE: 0.0058 PSNR: 22.2383 \n",
            "[07:44:39.793659] [Time] 2.2m 36.0m/40.5m\n",
            "\n",
            "[07:44:39.793951] ~~~ Epoch 15/15 ~~~\n",
            "\n",
            "[07:44:41.894353] Epoch: [15]  [ 0/84]  eta: 0:02:56  loss: 0.0564 (0.0564)  SSIM: 0.0000 (0.0000)  MAE: 0.0564 (0.0564)  MSE: 0.0069 (0.0069)  PSNR: 21.4284 (21.4284)  lr: 0.000021  iter-time: 2.0979\n",
            "[07:44:56.488500] Epoch: [15]  [10/84]  eta: 0:01:52  loss: 0.0507 (0.0515)  SSIM: 0.0000 (0.0000)  MAE: 0.0507 (0.0515)  MSE: 0.0054 (0.0058)  PSNR: 22.2931 (22.2197)  lr: 0.000016  iter-time: 1.5172\n",
            "[07:45:11.074652] Epoch: [15]  [20/84]  eta: 0:01:35  loss: 0.0500 (0.0507)  SSIM: 0.0000 (0.0000)  MAE: 0.0500 (0.0507)  MSE: 0.0054 (0.0056)  PSNR: 22.2114 (22.2699)  lr: 0.000012  iter-time: 1.4588\n",
            "[07:45:25.637097] Epoch: [15]  [30/84]  eta: 0:01:19  loss: 0.0486 (0.0501)  SSIM: 0.0000 (0.0000)  MAE: 0.0486 (0.0501)  MSE: 0.0054 (0.0055)  PSNR: 22.2729 (22.3136)  lr: 0.000009  iter-time: 1.4572\n",
            "[07:45:40.200904] Epoch: [15]  [40/84]  eta: 0:01:04  loss: 0.0496 (0.0506)  SSIM: 0.0000 (0.0000)  MAE: 0.0496 (0.0506)  MSE: 0.0054 (0.0056)  PSNR: 22.2919 (22.2747)  lr: 0.000006  iter-time: 1.4560\n",
            "[07:45:54.776693] Epoch: [15]  [50/84]  eta: 0:00:49  loss: 0.0530 (0.0511)  SSIM: 0.0000 (0.0000)  MAE: 0.0530 (0.0511)  MSE: 0.0061 (0.0057)  PSNR: 22.0048 (22.2270)  lr: 0.000003  iter-time: 1.4568\n",
            "[07:46:09.348567] Epoch: [15]  [60/84]  eta: 0:00:35  loss: 0.0520 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0520 (0.0512)  MSE: 0.0059 (0.0058)  PSNR: 22.1536 (22.2158)  lr: 0.000002  iter-time: 1.4572\n",
            "[07:46:23.931098] Epoch: [15]  [70/84]  eta: 0:00:20  loss: 0.0499 (0.0510)  SSIM: 0.0000 (0.0000)  MAE: 0.0499 (0.0510)  MSE: 0.0054 (0.0057)  PSNR: 22.3202 (22.2223)  lr: 0.000000  iter-time: 1.4575\n",
            "[07:46:38.522119] Epoch: [15]  [80/84]  eta: 0:00:05  loss: 0.0497 (0.0510)  SSIM: 0.0000 (0.0000)  MAE: 0.0497 (0.0510)  MSE: 0.0055 (0.0057)  PSNR: 22.3472 (22.2309)  lr: 0.000000  iter-time: 1.4584\n",
            "[07:46:41.708189] Epoch: [15]  [83/84]  eta: 0:00:01  loss: 0.0502 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0512)  MSE: 0.0056 (0.0058)  PSNR: 22.0725 (22.2062)  lr: 0.000000  iter-time: 1.3994\n",
            "[07:46:42.064934] Epoch: [15] Total time: 0:02:02 (1.4556 s / it)\n",
            "[07:46:42.066371] [Train] averaged stats: loss: 0.0502 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0502 (0.0512)  MSE: 0.0056 (0.0058)  PSNR: 22.0725 (22.2062)  lr: 0.000000\n",
            "[07:46:42.996280] Epoch: [15]  [ 0/21]  eta: 0:00:19  loss: 0.0506 (0.0506)  SSIM: 0.0000 (0.0000)  MAE: 0.0506 (0.0506)  MSE: 0.0058 (0.0058)  PSNR: 22.4085 (22.4085)  iter-time: 0.9261\n",
            "[07:46:48.000445] Epoch: [15]  [10/21]  eta: 0:00:05  loss: 0.0508 (0.0512)  SSIM: 0.0000 (0.0000)  MAE: 0.0508 (0.0512)  MSE: 0.0058 (0.0057)  PSNR: 22.2094 (22.2675)  iter-time: 0.5389\n",
            "[07:46:52.890626] Epoch: [15]  [20/21]  eta: 0:00:00  loss: 0.0510 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.2094 (22.2343)  iter-time: 0.4946\n",
            "[07:46:53.244088] Epoch: [15] Total time: 0:00:11 (0.5321 s / it)\n",
            "[07:46:53.244215] [Val] averaged stats: loss: 0.0510 (0.0514)  SSIM: 0.0000 (0.0000)  MAE: 0.0510 (0.0514)  MSE: 0.0056 (0.0058)  PSNR: 22.2094 (22.2343)\n",
            "[07:46:53.245173] Val loss improved from 0.051439215384778525 to 0.05142003847729592, saving model to /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:46:53.331274] [Val] best loss: 0.0514 best  SSIM: 0.0000 MAE: 0.0514 MSE: 0.0058 PSNR: 22.2343 \n",
            "[07:46:53.334651] Creating training plots . . .\n",
            "[07:46:54.417698] [Time] 2.2m 38.3m/40.5m\n",
            "\n",
            "[07:46:54.417876] Training time: 0:38:16\n",
            "[07:46:54.417944] Train loss: 0.05119567714808952\n",
            "[07:46:54.417992] Train SSIM: 0.0\n",
            "[07:46:54.418038] Train MAE: 0.05119567626111564\n",
            "[07:46:54.418291] Train MSE: 0.005761542706750333\n",
            "[07:46:54.418345] Train PSNR: 22.206226008278982\n",
            "[07:46:54.423728] Validation loss: 0.05142003847729592\n",
            "[07:46:54.423796] Validation SSIM: 0.0\n",
            "[07:46:54.423837] Validation MAE: 0.05142003670334816\n",
            "[07:46:54.423872] Validation MSE: 0.00575344730168581\n",
            "[07:46:54.423906] Validation PSNR: 22.234262466430664\n",
            "[07:46:54.423942] Finished Training\n",
            "[07:46:55.493792] Releasing memory . . .\n",
            "[07:46:55.494148] ######################\n",
            "[07:46:55.495800] #   LOAD TEST DATA   #\n",
            "[07:46:55.495862] ######################\n",
            "[07:46:55.495928] 2) Loading test images . . .\n",
            "[07:46:55.496013] Loading data from /content/data/test/LR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00<00:00,  7.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:46:56.388411] Not all samples seem to have the same shape. Number of samples: 6\n",
            "[07:46:56.388581] *** First sample shape is (1, 6, 1023, 1023, 1)\n",
            "[07:46:56.388685] 3) Loading test masks . . .\n",
            "[07:46:56.388745] Loading data from /content/data/test/HR\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [00:00<00:00,  7.20it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:46:57.238482] Not all samples seem to have the same shape. Number of samples: 6\n",
            "[07:46:57.238591] *** First sample shape is (1, 6, 1023, 1023, 1)\n",
            "[07:46:57.240539] ############################\n",
            "[07:46:57.240614] #  PREPARE TEST GENERATOR  #\n",
            "[07:46:57.240673] ############################\n",
            "[07:46:57.296914] Loading checkpoint from file /content/output/my_3d_super_resolution/checkpoints/my_3d_super_resolution_1-checkpoint-best.pth\n",
            "[07:46:57.351084] Model weights loaded!\n",
            "[07:46:57.352354] ###############\n",
            "[07:46:57.352424] #  INFERENCE  #\n",
            "[07:46:57.352471] ###############\n",
            "[07:46:57.352505] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:46:57.405978] Processing image: np_27.tif\n",
            "[07:46:57.407084] ### 3D-OV-CROP ###\n",
            "[07:46:57.407159] Cropping (6, 1023, 1023, 1) images into (6, 128, 128, 1) with overlapping . . .\n",
            "[07:46:57.407200] Minimum overlap selected: (0, 0, 0)\n",
            "[07:46:57.407244] Padding: (2, 16, 16)\n",
            "[07:46:57.423990] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:46:57.424100] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:46:57.424146] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:46:57.521877] **** New data shape is: (363, 6, 128, 128, 1)\n",
            "[07:46:57.522964] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/super_resolution.py:317: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  4%|\u258d         | 1/23 [00:02<00:56,  2.55s/it]\u001b[A\n",
            "  9%|\u258a         | 2/23 [00:02<00:23,  1.12s/it]\u001b[A\n",
            " 13%|\u2588\u258e        | 3/23 [00:02<00:13,  1.51it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 4/23 [00:02<00:08,  2.23it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 5/23 [00:03<00:05,  3.03it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 6/23 [00:03<00:04,  3.86it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 7/23 [00:03<00:03,  4.68it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 8/23 [00:03<00:02,  5.43it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 9/23 [00:03<00:02,  5.91it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 10/23 [00:03<00:01,  6.53it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 11/23 [00:03<00:01,  7.00it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 12/23 [00:03<00:01,  7.37it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 13/23 [00:04<00:01,  7.66it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 14/23 [00:04<00:01,  7.86it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 15/23 [00:04<00:01,  7.84it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 16/23 [00:04<00:00,  7.93it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 17/23 [00:04<00:00,  8.03it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 18/23 [00:04<00:00,  8.14it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 19/23 [00:04<00:00,  8.17it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 20/23 [00:04<00:00,  8.23it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 21/23 [00:04<00:00,  8.26it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 22/23 [00:05<00:00,  8.30it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 23/23 [00:06<00:00,  1.99it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:04.069485] ### MERGE-3D-OV-CROP ###\n",
            "[07:47:04.069575] Merging (363, 6, 128, 128, 1) images into (6, 1023, 1023, 1) with overlapping . . .\n",
            "[07:47:04.069609] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:04.069643] Padding: (2, 16, 16)\n",
            "[07:47:04.076991] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:04.077060] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:04.077092] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:04.142727] **** New data shape is: (6, 1023, 1023, 1)\n",
            "[07:47:04.142880] ### END MERGE-3D-OV-CROP ###\n",
            "[07:47:04.150042] Saving (1, 6, 1023, 1023, 1) data as .tif in folder: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.59it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 1/6 [00:21<01:45, 21.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:18.529111] Processing image: np_28.tif\n",
            "[07:47:18.530461] ### 3D-OV-CROP ###\n",
            "[07:47:18.531231] Cropping (6, 1024, 1024, 1) images into (6, 128, 128, 1) with overlapping . . .\n",
            "[07:47:18.531897] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:18.532554] Padding: (2, 16, 16)\n",
            "[07:47:18.770917] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:18.773950] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:18.781242] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:19.110115] **** New data shape is: (363, 6, 128, 128, 1)\n",
            "[07:47:19.110273] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258d         | 1/23 [00:00<00:02,  8.74it/s]\u001b[A\n",
            "  9%|\u258a         | 2/23 [00:00<00:02,  8.17it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 3/23 [00:00<00:02,  8.16it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 4/23 [00:00<00:02,  7.95it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 5/23 [00:00<00:02,  7.38it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 6/23 [00:00<00:02,  7.28it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 7/23 [00:00<00:02,  6.80it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 8/23 [00:01<00:02,  6.73it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 9/23 [00:01<00:02,  6.98it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 10/23 [00:01<00:01,  7.25it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 11/23 [00:01<00:01,  7.45it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 12/23 [00:01<00:01,  7.47it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 13/23 [00:01<00:01,  7.41it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 14/23 [00:01<00:01,  7.16it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 15/23 [00:02<00:01,  6.95it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 16/23 [00:02<00:01,  6.56it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 17/23 [00:02<00:00,  7.02it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 18/23 [00:02<00:00,  7.23it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 19/23 [00:02<00:00,  7.42it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 20/23 [00:02<00:00,  7.69it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 21/23 [00:02<00:00,  7.85it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 22/23 [00:02<00:00,  7.92it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:22.236365] ### MERGE-3D-OV-CROP ###\n",
            "[07:47:22.236462] Merging (363, 6, 128, 128, 1) images into (6, 1024, 1024, 1) with overlapping . . .\n",
            "[07:47:22.236496] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:22.236527] Padding: (2, 16, 16)\n",
            "[07:47:22.241009] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:22.241746] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:22.242354] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:22.343236] **** New data shape is: (6, 1024, 1024, 1)\n",
            "[07:47:22.343369] ### END MERGE-3D-OV-CROP ###\n",
            "[07:47:22.351369] Saving (1, 6, 1024, 1024, 1) data as .tif in folder: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.12it/s]\u001b[A\n",
            " 33%|\u2588\u2588\u2588\u258e      | 2/6 [00:39<01:18, 19.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:36.990832] Processing image: np_29.tif\n",
            "[07:47:36.991012] ### 3D-OV-CROP ###\n",
            "[07:47:36.991064] Cropping (6, 1023, 1024, 1) images into (6, 128, 128, 1) with overlapping . . .\n",
            "[07:47:36.991110] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:36.991154] Padding: (2, 16, 16)\n",
            "[07:47:37.002567] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:37.002669] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:37.003877] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:37.091274] **** New data shape is: (363, 6, 128, 128, 1)\n",
            "[07:47:37.091409] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258d         | 1/23 [00:00<00:02,  9.11it/s]\u001b[A\n",
            "  9%|\u258a         | 2/23 [00:00<00:02,  8.58it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 3/23 [00:00<00:02,  8.39it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 4/23 [00:00<00:02,  8.34it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 5/23 [00:00<00:02,  8.31it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 6/23 [00:00<00:02,  8.29it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 7/23 [00:00<00:01,  8.21it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 8/23 [00:00<00:01,  7.95it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 9/23 [00:01<00:01,  8.06it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 10/23 [00:01<00:01,  8.11it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 11/23 [00:01<00:01,  8.13it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 12/23 [00:01<00:01,  8.19it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 13/23 [00:01<00:01,  8.23it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 14/23 [00:01<00:01,  8.25it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 15/23 [00:01<00:00,  8.20it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 16/23 [00:01<00:00,  8.18it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 17/23 [00:02<00:00,  8.24it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 18/23 [00:02<00:00,  8.24it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 19/23 [00:02<00:00,  8.27it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 20/23 [00:02<00:00,  8.29it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 21/23 [00:02<00:00,  8.28it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 22/23 [00:02<00:00,  8.24it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:39.897076] ### MERGE-3D-OV-CROP ###\n",
            "[07:47:39.897166] Merging (363, 6, 128, 128, 1) images into (6, 1023, 1024, 1) with overlapping . . .\n",
            "[07:47:39.897200] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:39.897231] Padding: (2, 16, 16)\n",
            "[07:47:39.905758] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:39.905871] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:39.905917] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:39.939933] **** New data shape is: (6, 1023, 1024, 1)\n",
            "[07:47:39.940050] ### END MERGE-3D-OV-CROP ###\n",
            "[07:47:39.947547] Saving (1, 6, 1023, 1024, 1) data as .tif in folder: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.70it/s]\u001b[A\n",
            " 50%|\u2588\u2588\u2588\u2588\u2588     | 3/6 [00:56<00:55, 18.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:54.241863] Processing image: np_30.tif\n",
            "[07:47:54.242025] ### 3D-OV-CROP ###\n",
            "[07:47:54.243604] Cropping (6, 1023, 1021, 1) images into (6, 128, 128, 1) with overlapping . . .\n",
            "[07:47:54.243671] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:54.244675] Padding: (2, 16, 16)\n",
            "[07:47:54.254485] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:54.254571] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:54.255630] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:54.349027] **** New data shape is: (363, 6, 128, 128, 1)\n",
            "[07:47:54.349167] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258d         | 1/23 [00:00<00:02,  9.15it/s]\u001b[A\n",
            "  9%|\u258a         | 2/23 [00:00<00:02,  8.56it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 3/23 [00:00<00:02,  8.39it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 4/23 [00:00<00:02,  8.37it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 5/23 [00:00<00:02,  8.30it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 6/23 [00:00<00:02,  8.30it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 7/23 [00:00<00:01,  8.27it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 8/23 [00:00<00:01,  8.13it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 9/23 [00:01<00:01,  8.19it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 10/23 [00:01<00:01,  8.22it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 11/23 [00:01<00:01,  8.21it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 12/23 [00:01<00:01,  8.22it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 13/23 [00:01<00:01,  8.29it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 14/23 [00:01<00:01,  8.30it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 15/23 [00:01<00:00,  8.24it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 16/23 [00:01<00:00,  8.19it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 17/23 [00:02<00:00,  8.22it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 18/23 [00:02<00:00,  8.18it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 19/23 [00:02<00:00,  8.25it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 20/23 [00:02<00:00,  8.26it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 21/23 [00:02<00:00,  8.29it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 22/23 [00:02<00:00,  8.28it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:47:57.147261] ### MERGE-3D-OV-CROP ###\n",
            "[07:47:57.147341] Merging (363, 6, 128, 128, 1) images into (6, 1023, 1021, 1) with overlapping . . .\n",
            "[07:47:57.147371] Minimum overlap selected: (0, 0, 0)\n",
            "[07:47:57.147408] Padding: (2, 16, 16)\n",
            "[07:47:57.155609] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:47:57.156726] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:47:57.157752] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:47:57.219713] **** New data shape is: (6, 1023, 1021, 1)\n",
            "[07:47:57.219851] ### END MERGE-3D-OV-CROP ###\n",
            "[07:47:57.226081] Saving (1, 6, 1023, 1021, 1) data as .tif in folder: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.59it/s]\u001b[A\n",
            " 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 4/6 [01:14<00:36, 18.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:48:11.491888] Processing image: np_31.tif\n",
            "[07:48:11.492040] ### 3D-OV-CROP ###\n",
            "[07:48:11.493485] Cropping (6, 1023, 1023, 1) images into (6, 128, 128, 1) with overlapping . . .\n",
            "[07:48:11.493543] Minimum overlap selected: (0, 0, 0)\n",
            "[07:48:11.495023] Padding: (2, 16, 16)\n",
            "[07:48:11.506479] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:48:11.506559] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:48:11.507722] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:48:11.617923] **** New data shape is: (363, 6, 128, 128, 1)\n",
            "[07:48:11.618090] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258d         | 1/23 [00:00<00:02,  8.45it/s]\u001b[A\n",
            "  9%|\u258a         | 2/23 [00:00<00:02,  8.31it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 3/23 [00:00<00:02,  8.15it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 4/23 [00:00<00:02,  8.16it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 5/23 [00:00<00:02,  8.15it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 6/23 [00:00<00:02,  8.13it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 7/23 [00:00<00:01,  8.03it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 8/23 [00:00<00:01,  7.94it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 9/23 [00:01<00:01,  7.92it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 10/23 [00:01<00:01,  7.90it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 11/23 [00:01<00:01,  7.96it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 12/23 [00:01<00:01,  7.96it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 13/23 [00:01<00:01,  7.95it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 14/23 [00:01<00:01,  8.00it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 15/23 [00:01<00:00,  8.06it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 16/23 [00:01<00:00,  8.07it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 17/23 [00:02<00:00,  8.06it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 18/23 [00:02<00:00,  8.06it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 19/23 [00:02<00:00,  7.99it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 20/23 [00:02<00:00,  8.04it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 21/23 [00:02<00:00,  8.09it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 22/23 [00:02<00:00,  8.12it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:48:14.503580] ### MERGE-3D-OV-CROP ###\n",
            "[07:48:14.503679] Merging (363, 6, 128, 128, 1) images into (6, 1023, 1023, 1) with overlapping . . .\n",
            "[07:48:14.505233] Minimum overlap selected: (0, 0, 0)\n",
            "[07:48:14.505313] Padding: (2, 16, 16)\n",
            "[07:48:14.512936] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:48:14.513837] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:48:14.514547] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:48:14.562928] **** New data shape is: (6, 1023, 1023, 1)\n",
            "[07:48:14.563072] ### END MERGE-3D-OV-CROP ###\n",
            "[07:48:14.571299] Saving (1, 6, 1023, 1023, 1) data as .tif in folder: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.35it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 5/6 [01:18<00:12, 12.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:48:15.584985] Processing image: np_33.tif\n",
            "[07:48:15.586013] ### 3D-OV-CROP ###\n",
            "[07:48:15.586072] Cropping (6, 1023, 1024, 1) images into (6, 128, 128, 1) with overlapping . . .\n",
            "[07:48:15.586115] Minimum overlap selected: (0, 0, 0)\n",
            "[07:48:15.586157] Padding: (2, 16, 16)\n",
            "[07:48:15.623565] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:48:15.623657] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:48:15.623705] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:48:15.743687] **** New data shape is: (363, 6, 128, 128, 1)\n",
            "[07:48:15.744479] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/23 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258d         | 1/23 [00:00<00:02,  9.19it/s]\u001b[A\n",
            "  9%|\u258a         | 2/23 [00:00<00:02,  8.50it/s]\u001b[A\n",
            " 13%|\u2588\u258e        | 3/23 [00:00<00:02,  8.44it/s]\u001b[A\n",
            " 17%|\u2588\u258b        | 4/23 [00:00<00:02,  8.32it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 5/23 [00:00<00:02,  8.32it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 6/23 [00:00<00:02,  8.33it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 7/23 [00:00<00:01,  8.36it/s]\u001b[A\n",
            " 35%|\u2588\u2588\u2588\u258d      | 8/23 [00:00<00:01,  8.17it/s]\u001b[A\n",
            " 39%|\u2588\u2588\u2588\u2589      | 9/23 [00:01<00:01,  8.22it/s]\u001b[A\n",
            " 43%|\u2588\u2588\u2588\u2588\u258e     | 10/23 [00:01<00:01,  8.27it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 11/23 [00:01<00:01,  8.30it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 12/23 [00:01<00:01,  8.35it/s]\u001b[A\n",
            " 57%|\u2588\u2588\u2588\u2588\u2588\u258b    | 13/23 [00:01<00:01,  8.40it/s]\u001b[A\n",
            " 61%|\u2588\u2588\u2588\u2588\u2588\u2588    | 14/23 [00:01<00:01,  8.36it/s]\u001b[A\n",
            " 65%|\u2588\u2588\u2588\u2588\u2588\u2588\u258c   | 15/23 [00:01<00:00,  8.30it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 16/23 [00:01<00:00,  8.22it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 17/23 [00:02<00:00,  8.26it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 18/23 [00:02<00:00,  8.30it/s]\u001b[A\n",
            " 83%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e | 19/23 [00:02<00:00,  8.28it/s]\u001b[A\n",
            " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 20/23 [00:02<00:00,  8.27it/s]\u001b[A\n",
            " 91%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 21/23 [00:02<00:00,  8.29it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 22/23 [00:02<00:00,  8.29it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:48:18.534502] ### MERGE-3D-OV-CROP ###\n",
            "[07:48:18.534596] Merging (363, 6, 128, 128, 1) images into (6, 1023, 1024, 1) with overlapping . . .\n",
            "[07:48:18.534852] Minimum overlap selected: (0, 0, 0)\n",
            "[07:48:18.534888] Padding: (2, 16, 16)\n",
            "[07:48:18.543856] Real overlapping (%): (0.0, 0.03125, 0.03125)\n",
            "[07:48:18.544490] Real overlapping (pixels): (0.0, 3.0, 3.0)\n",
            "[07:48:18.544551] (3, 11, 11) patches per (z,y,x) axis\n",
            "[07:48:18.639358] **** New data shape is: (6, 1023, 1024, 1)\n",
            "[07:48:18.639491] ### END MERGE-3D-OV-CROP ###\n",
            "[07:48:18.648784] Saving (1, 6, 1023, 1024, 1) data as .tif in folder: /content/output/my_3d_super_resolution/results/my_3d_super_resolution_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.50it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6/6 [01:22<00:00, 13.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[07:48:19.555627] Releasing memory . . .\n",
            "[07:48:19.556576] #############\n",
            "[07:48:19.556621] #  RESULTS  #\n",
            "[07:48:19.556650] #############\n",
            "[07:48:19.556697] Epoch number: 15\n",
            "[07:48:19.556732] Train time (s): 0:38:16\n",
            "[07:48:19.557125] Train loss: 0.05119567714808952\n",
            "[07:48:19.561641] Train SSIM: 0.0\n",
            "[07:48:19.562951] Train MAE: 0.05119567626111564\n",
            "[07:48:19.563753] Train MSE: 0.005761542706750333\n",
            "[07:48:19.563898] Train PSNR: 22.206226008278982\n",
            "[07:48:19.563944] Validation loss: 0.05142003847729592\n",
            "[07:48:19.563998] Validation SSIM: 0.0\n",
            "[07:48:19.564043] Validation MAE: 0.05142003670334816\n",
            "[07:48:19.564086] Validation MSE: 0.00575344730168581\n",
            "[07:48:19.564130] Validation PSNR: 22.234262466430664\n",
            "[07:48:19.564210] Test SSIM (merge patches): 0.0\n",
            "[07:48:19.564275] Test MAE (merge patches): 0.05346309207379818\n",
            "[07:48:19.564322] Test MSE (merge patches): 0.006147055032973488\n",
            "[07:48:19.564370] Test PSNR (merge patches): 22.156661987304688\n",
            "[07:48:19.571041]  \n",
            "[07:48:19.571132] FINISHED JOB my_3d_super_resolution_1 !!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play to train the model\n",
        "import os\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# remove template file it is exists\n",
        "template_file = '3d_super-resolution.yaml'\n",
        "if os.path.exists( template_file ):\n",
        "    os.remove( template_file )\n",
        "\n",
        "# Download template file\n",
        "!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/super-resolution/3d_super-resolution.yaml &> /dev/null\n",
        "\n",
        "# Check files before modifying the .yaml file\n",
        "if not os.path.exists(train_lr_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_lr_data_path)\n",
        "ids = sorted(next(os.walk(train_lr_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No files found in dir {}\".format(train_lr_data_path))\n",
        "else:\n",
        "    from skimage.io import imread\n",
        "    img_dtype = imread(os.path.join(train_lr_data_path, ids[0])).dtype\n",
        "\n",
        "if not os.path.exists(train_hr_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_hr_data_path)\n",
        "ids = sorted(next(os.walk(train_hr_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No files found in dir {}\".format(train_hr_data_path))\n",
        "\n",
        "if not os.path.exists(test_lr_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_lr_data_path)\n",
        "ids = sorted(next(os.walk(test_lr_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No files found in dir {}\".format(test_lr_data_path))\n",
        "\n",
        "if test_ground_truth:\n",
        "    if not os.path.exists(test_hr_data_path):\n",
        "        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_hr_data_path)\n",
        "    ids = sorted(next(os.walk(test_hr_data_path))[2])\n",
        "    if len(ids) == 0:\n",
        "        raise ValueError(\"No files found in dir {}\".format(test_hr_data_path))\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( template_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_lr_data_path\n",
        "biapy_config['DATA']['TRAIN']['GT_PATH'] = train_hr_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_lr_data_path\n",
        "biapy_config['DATA']['TEST']['GT_PATH'] = test_hr_data_path\n",
        "\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size_z)+', '+str(patch_size_xy)+', '+ str(patch_size_xy)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding_xy = patch_size_xy // 8\n",
        "if padding_xy < 1:\n",
        "    padding_xy = 2\n",
        "padding_z = patch_size_z // 8\n",
        "if padding_z < 1:\n",
        "    padding_z = 2\n",
        "\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding_z)+', '+ str(padding_xy)+', '+ str(padding_xy)+')'\n",
        "\n",
        "# Change normalization to 'custom' if dtype is uint16\n",
        "if img_dtype == np.uint16:\n",
        "    biapy_config['DATA']['NORMALIZATION'] = {}\n",
        "    biapy_config['DATA']['NORMALIZATION']['TYPE'] = 'custom'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# change source to build model - biapy, torchvision or bmz\n",
        "if changed_source:\n",
        "    if source.value == \"BiaPy\":\n",
        "        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "    elif source.value == 'BioImage Model Zoo':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n",
        "        biapy_config['MODEL']['BMZ'] = {}\n",
        "        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_ID'] = str(bmz.value).strip()\n",
        "else:\n",
        "    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "\n",
        "\n",
        "# Transcribe model architecture\n",
        "architecture = 'unet'\n",
        "if model_architecture == \"Residual U-Net\":\n",
        "    architecture = 'resunet'\n",
        "elif model_architecture == \"Attention U-Net\":\n",
        "    architecture = 'attention_unet'\n",
        "elif model_architecture == \"MultiResUNet\":\n",
        "    architecture = 'multiresunet'\n",
        "elif model_architecture == \"ResUNet++\":\n",
        "    architecture = 'resunet++'\n",
        "elif model_architecture == \"SEUNet\":\n",
        "    architecture = 'seunet'\n",
        "else: # U-NeXt V1\n",
        "    architecture = 'unext_v1'\n",
        "    biapy_config['MODEL']['CONVNEXT_LAYERS'] = \"[1, 1, 1, 1]\"\n",
        "    biapy_config['MODEL']['CONVNEXT_STEM_K_SIZE'] = 1\n",
        "\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "biapy_config['MODEL']['UNET_SR_UPSAMPLE_POSITION'] = \"post\"\n",
        "biapy_config['MODEL']['FEATURE_MAPS'] = [32, 64, 128]\n",
        "\n",
        "\n",
        "# Data augmentation\n",
        "if aggressive_data_augmentation == True:\n",
        "    biapy_config['AUGMENTOR']['DROPOUT'] = True\n",
        "    biapy_config['AUGMENTOR']['GRIDMASK'] = True\n",
        "    biapy_config['AUGMENTOR']['CUTOUT'] = True\n",
        "\n",
        "if anisotropic_data == True:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [1 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "else:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [2 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "\n",
        "# learning rate scheduler\n",
        "if learning_rate_scheduler == 'One cycle':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'onecycle'\n",
        "elif learning_rate_scheduler == 'Warm-up cosine decay':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'warmupcosine'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.0\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['WARMUP_COSINE_DECAY_EPOCHS'] = 0\n",
        "elif learning_rate_scheduler == 'Reduce on plateau':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'reduceonplateau'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_FACTOR'] = 0.5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_PATIENCE'] = 5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.00001\n",
        "\n",
        "# update scale factors\n",
        "biapy_config['PROBLEM']['SUPER_RESOLUTION']['UPSCALING'] = '('+str(scale_factor_Z)+','+str(scale_factor_XY)+','+str(scale_factor_XY)+')'\n",
        "\n",
        "# update test parameters\n",
        "biapy_config['TEST']['AUGMENTATION'] = test_time_augmentation\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "biapy_config['TEST']['ENABLE'] = True\n",
        "\n",
        "# model weights\n",
        "if checkpoint_path != '':\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    #biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")\n",
        "\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02a7ThqOkCPX"
      },
      "source": [
        "## **Inspection of the Loss Function and the peak signal-to-noise ratio (PSNR)**\n",
        "---\n",
        "\n",
        "Before proceeding with interpretations, it's pivotal to gauge the training evolution by juxtaposing the training loss against the validation loss. The validation loss casts light on the model's efficacy over a reserved subset of data unseen during training. A deeper understanding can be garnered from [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n",
        "\n",
        "- **Training Loss**: This captures the discrepancy between the model's predictions and the actual ground-truth after each epoch.\n",
        "\n",
        "- **Validation Loss**: This signifies the error between the model's estimates on validation images and their actual counterparts.\n",
        "\n",
        "As training unfurls, these metrics are expected to wane, eventually plateauing at an optimal, minimal value. Contrasting the trajectories of these losses can yield vital information about the model's adaptability.\n",
        "\n",
        "- **Decreasing Training and Validation Losses**: This trend is indicative of potential model improvements with further training. Elevating the `number_of_epochs` is advised in such scenarios. Notably, even if the loss curves seem to stabilize towards the tail end, it might be a mere visual effect due to y-axis scaling. The model is considered convergent once the curves genuinely flatten, marking the end of required training.\n",
        "\n",
        "- **Divergent Losses**: An upward tick in validation loss while training loss gravitates towards zero hints at overfitting. It suggests that the model is intricately memorizing training patterns at the cost of broader applicability. A more substantial training dataset can alleviate this.\n",
        "\n",
        "\n",
        "The **peak signal-to-noise ratio (PSNR)**, offers a means to evaluate the quality of the prediction against the ground truth. The higher value the better image you are creating.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "x_0GHi4Mgze6",
        "outputId": "046c5839-b378-4729-d094-39f2fc60bd27"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play the cell to show a plot of training error vs. epoch number and IoU vs epoch number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n",
        "\n",
        "psnr = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_PSNR.png' )\n",
        "\n",
        "fig = plt.figure( figsize = (20,10))\n",
        "ax1 = plt.subplot( 1, 2, 1 )\n",
        "_ = plt.imshow( loss_plot )\n",
        "_ = plt.axis('off')\n",
        "ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n",
        "\n",
        "ax2 = plt.subplot( 1, 2, 2 )\n",
        "_ = plt.imshow( psnr )\n",
        "_ = plt.axis('off')\n",
        "_= ax2.set_title( 'PSNR vs epoch number', fontdict = {'fontsize':22})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtjMST8lCqCr"
      },
      "source": [
        "## **Visualize super-resolution results (from the test set)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m13DvHP3KEw7",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a35f23f400994c15bd8ec4f7d52d65a7",
            "496ff0a3cd8d4092a131466e5284c089",
            "be39a4dd17db46349941bbd90ae0451f",
            "990ee4fe987946f1be11cc09d2a3f007",
            "c41be399aae042c182b0c998e6000ed7",
            "3013ee207ab64d4abd1f606692a85f60",
            "66f26de2b35a4668bfc9cea29d90e6dc",
            "c719b92881524ba4a7be68c5269b9418",
            "524c59fa863541909586e7daaaf23723",
            "be92aed9e03549beb9a3264940b329f5",
            "9caaf68973d64408a25c938e3d0f0461",
            "7cbb475820d844dc81162da588f52437",
            "9b1095d8fa264a62a2b4874d89f5ff79",
            "5c8479624d67402b9ef8160d1612d340",
            "714675cac0314568bbce0a205b122f18",
            "4c138a30ca294c66b5388fce9376611e",
            "f24b249d71184466a4464738dcb14fe0",
            "7398e7df573d4c3c90bf4ccda77aa91e",
            "a86b430ae3b24091a253d5f39db15b8c",
            "b1bbcb0d4147466f96509e8e16703cbd",
            "90a8c5b8818d400c9b3a594c31f88639"
          ]
        },
        "outputId": "925926c2-a6ce-4e2d-d788-649fae5b0e74"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=1, description='z', max=6, min=1), Output()), _dom_classes=('widget-inte\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a35f23f400994c15bd8ec4f7d52d65a7"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=1, description='z', max=6, min=1), Output()), _dom_classes=('widget-inte\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7cbb475820d844dc81162da588f52437"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=1, description='z', max=6, min=1), Output()), _dom_classes=('widget-inte\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a86b430ae3b24091a253d5f39db15b8c"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "sr_results = os.path.join(final_results, \"per_image\")\n",
        "\n",
        "#@markdown ### Play to visualize some results from the test set\n",
        "\n",
        "#@markdown The current model will be applied to some test images and results will be shown as browsable 2D stacks displaying:\n",
        "#@markdown 1. The LR **Source image**.\n",
        "#@markdown 2. The HR model **Prediction**.\n",
        "#@markdown 3. Its corresponding HR **Ground Truth** image.\n",
        "\n",
        "#@markdown Use the z-scroll to navigate between slices.\n",
        "\n",
        "# @markdown **Note**: it might take a few seconds to refresh the images.\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "md(\"After this last step, the resulting images should be placed in {}\".format(final_results))\n",
        "# Show a few examples to check that they have been stored correctly\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from numpy.random import randint, seed\n",
        "from matplotlib import pyplot as plt\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "ids_pred = sorted(next(os.walk(sr_results))[2])\n",
        "ids_input = sorted(next(os.walk(test_lr_data_path))[2])\n",
        "ids_gt = sorted(next(os.walk(test_hr_data_path))[2])\n",
        "\n",
        "samples_to_show = min(len(ids_input), 3)\n",
        "chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n",
        "seed(1)\n",
        "\n",
        "test_samples = []\n",
        "test_sample_preds = []\n",
        "test_sample_gts = []\n",
        "\n",
        "for i in range(len(chosen_images)):\n",
        "    aux = imread(os.path.join(test_lr_data_path, ids_input[chosen_images[i]]))\n",
        "    test_samples.append(aux)\n",
        "    #print(os.path.join(test_lr_data_path, ids_input[chosen_images[i]]))\n",
        "    aux = imread(os.path.join(sr_results, ids_pred[chosen_images[i]]))\n",
        "    test_sample_preds.append(aux)\n",
        "\n",
        "    aux = imread(os.path.join(test_hr_data_path, ids_gt[chosen_images[i]]))\n",
        "    test_sample_gts.append(aux)\n",
        "\n",
        "# function to show results in 3D within a widget\n",
        "def scroll_in_z(z):\n",
        "\n",
        "    plt.figure(figsize=(25,10))\n",
        "    # Source\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.axis('off')\n",
        "\n",
        "    if len( test_source[z-1].shape ) == 4: # RGB\n",
        "        plt.imshow( test_source[z-1] )\n",
        "    else:\n",
        "        plt.imshow(test_source[z-1], cmap='magma',vmin=np.percentile(test_source[z-1],0.1),vmax=np.percentile(test_source[z-1],99.9))\n",
        "    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.axis('off')\n",
        "    if len( test_prediction[z-1].shape ) == 4: # RGB\n",
        "        plt.imshow( test_prediction[z-1] )\n",
        "    else:\n",
        "        plt.imshow(test_prediction[z-1], cmap='magma',vmin=np.percentile(test_prediction[z-1],0.1),vmax=np.percentile(test_prediction[z-1],99.9))\n",
        "    plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # GT\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.axis('off')\n",
        "    if len( test_gt[z-1].shape ) == 4: # RGB\n",
        "        plt.imshow( test_gt[z-1] )\n",
        "    else:\n",
        "        plt.imshow(test_gt[z-1], cmap='magma',vmin=np.percentile(test_gt[z-1],0.1),vmax=np.percentile(test_gt[z-1],99.9))\n",
        "    plt.title('Ground Truth (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "for j in range(samples_to_show):\n",
        "    test_source = test_samples[j]\n",
        "    test_prediction = test_sample_preds[j]\n",
        "    test_gt = test_sample_gts[j]\n",
        "\n",
        "    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_source.shape[0], step=1, value=0));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1_CDlDdG0Oa"
      },
      "source": [
        "## **Download train model (weights and configuration file)**\n",
        "___\n",
        "If you want to **reuse the train model in the future**, you can download both the model weights and its configuration file (.YAML) by running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "YKBh1De3G_95",
        "outputId": "66d7e55a-84ad-4f6e-950d-6cf0975ca968"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4f15f24e-2d98-4bf2-a395-a72fd21f2996\", \"my_3d_super_resolution_1-checkpoint-best.pth\", 18374491)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "#@markdown ###Play to download the model weights\n",
        "\n",
        "checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n",
        "\n",
        "weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n",
        "\n",
        "files.download( os.path.join( checkpoints_path, weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "459fC7wIHCES",
        "outputId": "4184f01e-affd-425a-fbf0-38187882c919"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41a9f5a7-0d4c-4e9d-89c5-4865af4a8279\", \"my_3d_super_resolution.yaml\", 875)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download the model configuration file (.YAML)\n",
        "\n",
        "config_path = os.path.join(output_path, job_name, 'config_files')\n",
        "\n",
        "files.download( os.path.join( config_path, yaml_file))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB7XFDLjsVZa"
      },
      "source": [
        "## **Export your model to BioImage Model Zoo format**\n",
        "___\n",
        "If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWHr_sQK_-qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##Construct model's metadata to export it to the BioImage Model Zoo format. Choose just one option:\n",
        "\n",
        "#@markdown **Option 1: Reuse previous BioImage Model Zoo model configuration**\n",
        "\n",
        "#@markdown With this option, if you were using a model from BioImage Model Zoo you can select this option to reuse its configuration instead of provide all fields manually. If that's not the case and you try to use this option an error will be thrown.\n",
        "reuse_previous_BMZ_model_config = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Option 2: Manual export fields**\n",
        "\n",
        "#@markdown With this option you need to introduce manually the metadata of the model.\n",
        "\n",
        "# ------------- User input ------------\n",
        "# information about the model\n",
        "trained_model_name    = \"\" #@param {type:\"string\"}\n",
        "trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n",
        "trained_model_authors_github_user =  \"[First Author Github User, Second Author Github User, Third Author Github User]\" #@param {type:\"string\"}\n",
        "trained_model_description = \"\" #@param {type:\"string\"}\n",
        "trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n",
        "trained_model_references = [\"Ronneberger et al. arXiv in 2015\", \"Franco-Barranco, Daniel, et al. ISBI in 2023\"] #@param {type:\"string\"}\n",
        "trained_model_references_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n",
        "trained_model_tags = \"[\\\"tag-1\\\", \\\"tag-2\\\"]\" #@param {type:\"string\"}\n",
        "trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KH8UuC_CgpH2"
      },
      "outputs": [],
      "source": [
        "# @markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "bmz_results = os.path.join(final_results, \"bmz_model\")\n",
        "\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "\n",
        "    # create the author spec input\n",
        "    auth_names = trained_model_authors[1:-1].split(\",\")\n",
        "    auth_githubusers = trained_model_authors_github_user[1:-1].split(\",\")\n",
        "    assert len(auth_names) == len(auth_githubusers)\n",
        "    authors = [{\"name\": auth_name, \"github_user\": auth_guser} for auth_name, auth_guser in zip(auth_names, auth_githubusers)]\n",
        "\n",
        "    # create the citation input spec\n",
        "    assert len(trained_model_references_DOI) == len(trained_model_references)\n",
        "    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_references_DOI)]\n",
        "\n",
        "    tags = [t for t in trained_model_tags.split(\",\")]\n",
        "\n",
        "    with open(trained_model_documentation, \"w\") as f:\n",
        "        f.write(\"### **Description**\\n\")\n",
        "        f.write(f\"{trained_model_description}\\n\\n\")\n",
        "        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n",
        "\n",
        "    bmz_cfg = {}\n",
        "    # Description of the model\n",
        "    bmz_cfg['description'] = trained_model_description\n",
        "    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Daniel\", \"github_user\": \"danifranco\"}]\n",
        "    bmz_cfg['authors'] = authors\n",
        "    # License of the model. E.g. \"CC-BY-4.0\"\n",
        "    bmz_cfg['license'] = trained_model_license\n",
        "    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n",
        "    bmz_cfg['tags'] = tags\n",
        "    # Tags to make models more findable on the website, e.g. tags=[\"electron-microscopy\", \"mitochondria\"]\n",
        "    bmz_cfg['cite'] = citations\n",
        "    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n",
        "    bmz_cfg['doc'] = trained_model_documentation\n",
        "    # Name of the model\n",
        "    bmz_cfg[\"model_name\"] = trained_model_name\n",
        "    biapy.export_model_to_bmz(bmz_results, bmz_cfg)\n",
        "else:\n",
        "    try:\n",
        "        biapy.export_model_to_bmz(bmz_results, reuse_original_bmz_config=True)\n",
        "    except:\n",
        "        print(\"Seems that the was a problem reusing BMZ model specs. Please uncheck 'reuse_previous_BMZ_model_config' and do it manually\")\n",
        "\n",
        "download = True\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "    bmz_zip_path = f\"/{bmz_results}/{trained_model_name}.zip\"\n",
        "else:\n",
        "    ids = sorted(next(os.walk(bmz_results))[2])\n",
        "    ids = [x for x in ids if x.endswith(\".zip\")]\n",
        "    if len(ids) > 1:\n",
        "        print(f\"There are more than one ZIP files in {bmz_results} folder. Please check which one you want you want to download and do it manually.\")\n",
        "        download = False\n",
        "    elif len(ids) == 0:\n",
        "        print(f\"BMZ zip file could not be found.\")\n",
        "        download = False\n",
        "    else: # only one zip\n",
        "        ids = ids[0]\n",
        "    bmz_zip_path = f\"/{bmz_results}/{ids}\"\n",
        "\n",
        "if download and os.path.exists(bmz_zip_path):\n",
        "    files.download(bmz_zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How to use the trained model with new data**\n",
        "___\n",
        "To directly infer new data to the trained model, you can use [this notebook](https://github.com/BiaPyX/BiaPy/blob/master/notebooks/BiaPy_Inference.ipynb). It will be necessary to upload the downloaded YAML configuration file and model weights to that notebook."
      ],
      "metadata": {
        "id": "PFVjWbF8GZ2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjSgLwe0x-P0"
      },
      "source": [
        "## **Acknowledgments**\n",
        "___\n",
        "We extend our gratitude to the [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki) for their invaluable inspiration. Notably, we have adopted some of their descriptions concerning metrics and parameters.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}