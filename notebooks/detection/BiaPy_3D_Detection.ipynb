{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAryclxsQJ5"
      },
      "source": [
        "# **3D Object Detection pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook, we demonstrate the use of the [BiaPy](https://biapyx.github.io/) pipeline for **3D object detection** of microscopy data.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://raw.githubusercontent.com/BiaPyX/BiaPy-doc/master/source/img/detection_image_input.png' width='300px'/>\n",
        "<img src='https://github.com/BiaPyX/BiaPy-doc/blob/master/source/img/detection_csv_input.svg?raw=true' width='300px'/>\n",
        "<figcaption><b>Figure 1</b>: Example of a 3D object detection problem. From left to right: 3D brainbow image and its corresponding CSV file with the coordinates of the center of each cell. </figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Without any coding, we'll guide you step-by-step through the process to:\n",
        "1. **Upload a set of training and test images** along with their corresponding instance label images.\n",
        "2. **Train a Deep Neural Network (DNN)** model using the training set.\n",
        "3. **Apply the model** to the test images.\n",
        "4. **Download the segmentation results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired by the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus), [Lenka Backov\u00e1](mailto:lenka.backova@ehu.eus), [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org) and [Ane Paniagua](mailto:anepaniagua@gmail.com). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5ClE_HHQaE"
      },
      "source": [
        "## **Expected Inputs and Outputs**\n",
        "___\n",
        "\n",
        "### **Inputs**\n",
        "\n",
        "This notebook requires the following five input folders:\n",
        "\n",
        "- **Training Raw Images**: Consisting of the unprocessed 3D images intended for training.\n",
        "- **Training CSV Files**: Providing the coordinates for the center of each cell for model training. The number and size of these files should align with the training raw images.\n",
        "- **Test Raw Images**: Houses the 3D images on which the model will be tested.\n",
        "- **Test CSV Files**: Contains the coordinates of the centers of the cells for testing. Ensure that their number and sizes correspond to the test raw images.\n",
        "- **Output Folder**: A designated directory where segmentation results will be saved.\n",
        "\n",
        "### **Outputs**\n",
        "\n",
        "On successful execution, an output folder will emerge, containing a **CSV file** and a **TIFF image** for every test image. The CSV files list the coordinates of each cell's center, while the result images depict these central points as deduced by our pipeline.\n",
        "\n",
        "<font color='red'><b>Note:</b></font> For testing purposes, you can utilize the **example datasets provided under 'Manage File(s) Source > Option 3'**.\n",
        "\n",
        "**Data structure**\n",
        "\n",
        "To ensure the proper operation of the library the data directory tree should be something like this:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "\u251c\u2500\u2500 train\n",
        "\u2502   \u251c\u2500\u2500 raw\n",
        "\u2502   \u2502   \u251c\u2500\u2500 training-0001.tif\n",
        "\u2502   \u2502   \u251c\u2500\u2500 training-0002.tif\n",
        "\u2502   \u2502   \u251c\u2500\u2500 . . .\n",
        "\u2502   \u2502   \u2514\u2500\u2500 training-9999.tif\n",
        "\u2502   \u2514\u2500\u2500 label\n",
        "\u2502       \u251c\u2500\u2500 training_groundtruth-0001.csv\n",
        "\u2502       \u251c\u2500\u2500 training_groundtruth-0002.csv\n",
        "\u2502       \u251c\u2500\u2500 . . .\n",
        "\u2502       \u2514\u2500\u2500 training_groundtruth-9999.csv\n",
        "\u2514\u2500\u2500 test\n",
        "    \u251c\u2500\u2500 raw\n",
        "    \u2502   \u251c\u2500\u2500 testing-0001.tif\n",
        "    \u2502   \u251c\u2500\u2500 testing-0002.tif\n",
        "    \u2502   \u251c\u2500\u2500 . . .\n",
        "    \u2502   \u2514\u2500\u2500 testing-9999.tif\n",
        "    \u2514\u2500\u2500 label\n",
        "        \u251c\u2500\u2500 testing_groundtruth-0001.csv\n",
        "        \u251c\u2500\u2500 testing_groundtruth-0002.csv\n",
        "        \u251c\u2500\u2500 . . .\n",
        "        \u2514\u2500\u2500 testing_groundtruth-9999.csv\n",
        "```\n",
        "\n",
        "**\u26a0\ufe0f Warning:** Ensure that images and their corresponding CSV files are sorted in the same way. A common approach is to fill with zeros the image number added to the filenames (as in the example).\n",
        "\n",
        "**Input Format Support**\n",
        "\n",
        "This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.npy` (every extension for 3D images supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGSj0DrpUJoY"
      },
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bj_sbDFTiZ7"
      },
      "source": [
        "## **Check for GPU Access**\n",
        "---\n",
        "\n",
        "By default, the session is configured to use Python 3 with GPU acceleration. However, it's a good practice to double-check these settings:\n",
        "\n",
        "1. Navigate to **Runtime** in the top menu and select **Change the Runtime type**.\n",
        "2. Ensure the following settings:\n",
        "   - **Runtime type:** Python 3 (This program is written in the Python 3 programming language.)\n",
        "   - **Accelerator:** GPU (Graphics Processing Unit)\n",
        "\n",
        "This will ensure that you're using Python 3 and taking advantage of GPU acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLYsqrDALpVN"
      },
      "source": [
        "## **Install BiaPy**\n",
        "---\n",
        "This might take some minutes depending on the current installed libraries in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p33UIUUWLm3V",
        "outputId": "876ed77a-9c15-4605-cfaf-5e0ca1f33983",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biapy==3.6.1\n",
            "  Downloading biapy-3.6.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (1.6.1)\n",
            "Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (3.0.4)\n",
            "Collecting yacs>=0.1.8 (from biapy==3.6.1)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (0.25.2)\n",
            "Collecting edt>=2.3.2 (from biapy==3.6.1)\n",
            "  Downloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy>2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (2.0.2)\n",
            "Collecting fill-voids>=2.0.6 (from biapy==3.6.1)\n",
            "  Downloading fill_voids-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.76 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (2.2.2)\n",
            "Collecting torchinfo>=1.8.0 (from biapy==3.6.1)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.6.2.2 (from biapy==3.6.1)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: h5py>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (3.14.0)\n",
            "Collecting zarr<3.0,>=2.16.1 (from biapy==3.6.1)\n",
            "  Downloading zarr-2.18.7-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting bioimageio.core==0.8.0 (from biapy==3.6.1)\n",
            "  Downloading bioimageio_core-0.8.0-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting imagecodecs>=2024.1.1 (from biapy==3.6.1)\n",
            "  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pooch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.6.1) (1.8.2)\n",
            "Collecting diplib>=3.5.1 (from biapy==3.6.1)\n",
            "  Downloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting xarray==2025.1.* (from biapy==3.6.1)\n",
            "  Downloading xarray-2025.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting bioimageio.spec==0.5.4.1 (from bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading bioimageio.spec-0.5.4.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: imageio>=2.10 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.1) (2.37.0)\n",
            "Collecting loguru (from bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic-settings<3,>=2.5 (from bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pydantic<3,>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.1) (2.11.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.1) (2.32.3)\n",
            "Collecting ruyaml (from bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading ruyaml-0.91.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.8.0->biapy==3.6.1) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray==2025.1.*->biapy==3.6.1) (24.2)\n",
            "Requirement already satisfied: annotated-types<1,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (0.7.0)\n",
            "Collecting email-validator (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (3.8.2)\n",
            "Collecting pydantic<3,>=2.7.0 (from bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (2.9.0.post0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (13.9.4)\n",
            "Requirement already satisfied: tifffile>=2020.7.4 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (2025.6.11)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (3.23.0)\n",
            "Collecting fastremap (from fill-voids>=2.0.6->biapy==3.6.1)\n",
            "  Downloading fastremap-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.1) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.1) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.1) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.1) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.6.1) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.6.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.6.1) (2025.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.8.1->biapy==3.6.1) (4.3.8)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.6.1) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.6.1) (3.5)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.6.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.6.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.6.1) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.6.1) (5.29.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8->biapy==3.6.1) (6.0.2)\n",
            "Collecting asciitree (from zarr<3.0,>=2.16.1->biapy==3.6.1)\n",
            "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fasteners (from zarr<3.0,>=2.16.1->biapy==3.6.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0 (from zarr<3.0,>=2.16.1->biapy==3.6.1)\n",
            "  Downloading numcodecs-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting deprecated (from numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0->zarr<3.0,>=2.16.1->biapy==3.6.1)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<3,>=2.7.0->bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3,>=2.5->bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3,>=2.5->bioimageio.core==0.8.0->biapy==3.6.1) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.8.0->biapy==3.6.1) (2025.7.9)\n",
            "Requirement already satisfied: distro>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.8.0->biapy==3.6.1) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=39.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.8.0->biapy==3.6.1) (75.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,<0.16,>=0.10.0->zarr<3.0,>=2.16.1->biapy==3.6.1) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bioimageio.spec==0.5.4.1->bioimageio.core==0.8.0->biapy==3.6.1) (0.1.2)\n",
            "Downloading biapy-3.6.1-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.6/434.6 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio_core-0.8.0-py3-none-any.whl (174 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m174.7/174.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xarray-2025.1.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.spec-0.5.4.1-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m210.3/210.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading zarr-2.18.7-py3-none-any.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m211.3/211.3 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numcodecs-0.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading fastremap-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.3 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruyaml-0.91.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: asciitree\n",
            "  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5031 sha256=8bc99dacac6e16f723c9d35e37c543ee4dca9238839f16d12db63ffa8df639f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/c1/da/23077eb3b87d24d6f3852ed1ed1a1ac2d3c885ad6ebd2b4a07\n",
            "Successfully built asciitree\n",
            "Installing collected packages: asciitree, yacs, torchinfo, tensorboardX, ruyaml, python-dotenv, pydantic-core, loguru, imagecodecs, fastremap, fasteners, edt, dnspython, diplib, deprecated, pydantic, numcodecs, fill-voids, email-validator, zarr, xarray, pydantic-settings, bioimageio.spec, bioimageio.core, biapy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: xarray\n",
            "    Found existing installation: xarray 2025.3.1\n",
            "    Uninstalling xarray-2025.3.1:\n",
            "      Successfully uninstalled xarray-2025.3.1\n",
            "Successfully installed asciitree-0.3.3 biapy-3.6.1 bioimageio.core-0.8.0 bioimageio.spec-0.5.4.1 deprecated-1.2.18 diplib-3.5.2 dnspython-2.7.0 edt-3.0.0 email-validator-2.2.0 fasteners-0.19 fastremap-1.17.1 fill-voids-2.1.0 imagecodecs-2025.3.30 loguru-0.7.3 numcodecs-0.15.1 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.10.1 python-dotenv-1.1.1 ruyaml-0.91.0 tensorboardX-2.6.4 torchinfo-1.8.0 xarray-2025.1.2 yacs-0.1.8 zarr-2.18.7\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
            "Collecting timm==1.0.14\n",
            "  Downloading timm-1.0.14-py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting torchmetrics==1.4.* (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (2.4.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (0.19.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (0.33.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm==1.0.14) (0.5.3)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (24.2)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (1.15.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (11.8.86)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm==1.0.14) (3.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (11.2.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.14) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm==1.0.14) (1.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm==1.0.14) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm==1.0.14) (2025.7.9)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->timm==1.0.14) (1.3.0)\n",
            "Downloading timm-1.0.14-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-msssim, torch-fidelity, timm\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.17\n",
            "    Uninstalling timm-1.0.17:\n",
            "      Successfully uninstalled timm-1.0.17\n",
            "Successfully installed lightning-utilities-0.14.3 pytorch-msssim-1.0.0 timm-1.0.14 torch-fidelity-0.3.0 torchmetrics-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "# Install latest release of BiaPy\n",
        "!pip install biapy==3.6.1\n",
        "\n",
        "# Then install Pytorch + CUDA 11.8\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Finally install some packages that rely on the Pytorch installation\n",
        "!pip install timm==1.0.14 pytorch-msssim torchmetrics[image]==1.4.*\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "from biapy import BiaPy\n",
        "\n",
        "changed_source = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZmI9c09OhSo"
      },
      "source": [
        "## **Manage File(s) Source**\n",
        "---\n",
        "\n",
        "The input folder can be provided using three different options:\n",
        "1. **Direct Upload**: Directly upload the desired folder.\n",
        "2. **Google Drive**: Use a folder stored in your Google Drive.\n",
        "3. **Sample Data**: Use a sample dataset provided by us.\n",
        "\n",
        "The steps you'll need to follow vary depending on your chosen option. These steps are detailed in the subsequent sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPksHcHLO0SU"
      },
      "source": [
        "### **Option 1: Upload Local Files to the Notebook**\n",
        "---\n",
        "You will be prompted to upload your files to Colab and they will be stored under `/content/input/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xGS5LCaHPWR8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train raw images)\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/raw\n",
        "%cd /content/input/train/raw\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qyvRptgjXMMN"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload csv files (instance coordinates)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train/label\n",
        "%cd /content/input/train/label\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PafWC0U3XYjd"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (test raw images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test/raw\n",
        "%cd /content/input/test/raw\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Tl1qtfeJXYp1"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload csv files (instance coordinates)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test/label\n",
        "%cd /content/input/test/label\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXGd55gUYjK"
      },
      "source": [
        "### **Option 2: Mount Your Google Drive**\n",
        "---\n",
        "\n",
        "If you wish to use this notebook with data from your Google Drive, you'll first need to mount the drive to this notebook.\n",
        "\n",
        "Execute the cell below to initiate the Google Drive mounting process. A link will be displayed click on it. In the new browser window that opens, choose your drive and click 'Allow'. Copy the code that appears, return to this notebook, paste the code into the cell, and press 'Enter'. This action grants Colab access to your Google Drive data.\n",
        "\n",
        "After this process, you can access your data via the **Files** tab, located on the top left of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h-yXrZLdUk3Z"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL.\n",
        "\n",
        "#@markdown * Sign in your Google Account.\n",
        "\n",
        "#@markdown * Copy the authorization code.\n",
        "\n",
        "#@markdown * Enter the authorization code.\n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9FcxFB3H7az"
      },
      "source": [
        "### **Option 3: Download an Example Dataset**\n",
        "---\n",
        "Don't have data readily available but still want to test the notebook? No problem! Simply execute the following cell to download a sample dataset.\n",
        "\n",
        "Specifically, we'll use the  [NucMM-Z](https://arxiv.org/abs/2107.05840) which is publicly available online. While this dataset is tailored for instance segmentation, we'll generate a CSV file detailing the center of each instance, making it compatible with our workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD3aoo-ZUtW4",
        "outputId": "da1c28d3-6b1e-4be7-8baf-9e3cbcfd2e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "!pip install gdown==5.1.0 --quiet\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "gdown.download(\"https://drive.google.com/uc?id=19P4AcvBPJXeW7QRj92Jh1keunGa5fi8d\", \"NucMM-Z_training.zip\", quiet=True)\n",
        "!unzip -q NucMM-Z_training.zip\n",
        "!rm NucMM-Z_training.zip\n",
        "\n",
        "print( 'Dataset downloaded and unzipped under /content/data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEv7FBXFQvjv"
      },
      "source": [
        "## **Paths for Input Images and Output Files**\n",
        "___\n",
        "\n",
        "Depending on the option you chose for managing file sources, you'll set your paths differently:\n",
        "\n",
        "- **Option 1 (Upload from Local Machine)**:\n",
        "  - Set `train_data_path` to `/content/input/train/raw`\n",
        "  - Set `train_csv_path` to `/content/input/train/label`\n",
        "  - Set `test_data_path` to `/content/input/test/raw`\n",
        "  - Set `test_csv_path` to `/content/input/test/label`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "- **Option 2 (Use Google Drive Data)**:\n",
        "  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n",
        "  \n",
        "- **Option 3 (Use Our Sample Data)**:\n",
        "  - Set `train_data_path` to `/content/data/train/raw`\n",
        "  - Set `train_csv_path` to `/content/data/train/label`\n",
        "  - Set `test_data_path` to `/content/data/test/raw`\n",
        "  - Set `test_csv_path` to `/content/data/test/label`\n",
        "  - Set `output_path` to `/content/out`\n",
        "\n",
        "  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n",
        "\n",
        "**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vl4e0UIGYZcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3324b376-e806-4983-9b84-c709b784bbb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training raw images: 27\n",
            "Number of training CSV files: 27\n",
            "Number of test raw images: 27\n",
            "Number of test CSV files: 27\n"
          ]
        }
      ],
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train/raw' #@param {type:\"string\"}\n",
        "#@markdown #####Path to train CSV files\n",
        "train_csv_path = '/content/data/train/label' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test images\n",
        "test_data_path = '/content/data/test/raw' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test CSV files\n",
        "test_csv_path = '/content/data/test/label' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def count_image_files(directory):\n",
        "    if not directory or not os.path.exists(directory):\n",
        "        return 0\n",
        "    file_extensions = {'.csv', '.jpg', '.jpeg', '.png', '.tif', '.npy', '.tiff', '.h5', '.hd5', '.zarr'}\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in file_extensions:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "num_train_images = count_image_files(train_data_path)\n",
        "num_train_labels = count_image_files(train_csv_path)\n",
        "\n",
        "num_test_images = count_image_files(test_data_path)\n",
        "num_test_labels = count_image_files(test_csv_path)\n",
        "\n",
        "print(f\"Number of training raw images: {num_train_images}\")\n",
        "print(f\"Number of training CSV files: {num_train_labels}\")\n",
        "print(f\"Number of test raw images: {num_test_images}\")\n",
        "if test_csv_path != \"\":\n",
        "    print(f\"Number of test CSV files: {num_test_labels}\")\n",
        "\n",
        "if num_train_images != num_train_labels:\n",
        "    print(\"Error: The number of training raw images does not match the number of training CSV files.\")\n",
        "if test_csv_path != \"\" and num_test_images != num_test_labels:\n",
        "    print(\"Error: The number of test raw images does not match the number of test CSV files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "9l_FeRXLh4rD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## Play to visualize some data samples\n",
        "# @markdown Select the *Set* (training or test) to visualize samples from, and use the *Image index* and *Z value* scrolls to navigate among volumes and slices.\n",
        "# @markdown Detection points will be displayed as red Xs on top of the input image.\n",
        "\n",
        "# @markdown **Note**: it might take a few seconds to refresh the images.\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from skimage.io import imread\n",
        "import os\n",
        "from ipywidgets import interact, IntSlider, Layout, Dropdown, VBox, Output\n",
        "\n",
        "# Initialize global attributes\n",
        "instance_id = 0\n",
        "\n",
        "input_path = train_data_path\n",
        "ids_input = sorted(next(os.walk(input_path))[2])\n",
        "input_img = imread(os.path.join(input_path, ids_input[0]))\n",
        "\n",
        "gt_path = train_csv_path\n",
        "ids_gt = sorted(next(os.walk(gt_path))[2])\n",
        "gt_csv = pd.read_csv(os.path.join(gt_path, ids_gt[0]))\n",
        "\n",
        "\n",
        "# Initialize widgets\n",
        "\n",
        "# Dropdown widget to choose training or test set\n",
        "dropdown = Dropdown(\n",
        "    options=['training-set', 'test-set'],\n",
        "    value='training-set',\n",
        "    description='Set:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Slider widget to choose instance\n",
        "slider= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(ids_input),\n",
        "    step=1,\n",
        "    description='Image index:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "slider.style.description_width = 'initial'\n",
        "slider.style.handle_color='blue'\n",
        "\n",
        "# Slider widget to choose Z value\n",
        "sliderZ= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(input_img),\n",
        "    step=1,\n",
        "    description='Z value:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "sliderZ.style.description_width = 'initial'\n",
        "sliderZ.style.handle_color='blue'\n",
        "\n",
        "# Initialize Output instance to handle code output cell\n",
        "output = Output()\n",
        "\n",
        "# Function to update paths (input_path, gt_path) and image IDs (ids_input, ids_gt) depending on dropdown\n",
        "def update_paths(change):\n",
        "    global input_path, gt_path\n",
        "    global ids_input, ids_gt\n",
        "    global test_detection_masks, train_detection_masks\n",
        "\n",
        "    # Update image IDs based on the new paths\n",
        "    ids_input = sorted(next(os.walk(input_path))[2])\n",
        "\n",
        "    if change.new == 'test-set':\n",
        "        input_path = test_data_path\n",
        "        gt_path = test_csv_path\n",
        "    else:\n",
        "        input_path = train_data_path\n",
        "        gt_path = train_csv_path\n",
        "\n",
        "    ids_input = sorted(next(os.walk(input_path))[2])\n",
        "    try:\n",
        "        ids_gt = sorted(next(os.walk(gt_path))[2])\n",
        "    except StopIteration:\n",
        "        ids_gt = []\n",
        "\n",
        "    # Reset instance slider value to 1 when dropdown changes\n",
        "    slider.value = 1\n",
        "    slider.max = len(ids_input)\n",
        "    update_id({'new': 1})\n",
        "\n",
        "# Function to update image and label set (input_img, gt_csv) depending on instance slider value\n",
        "def update_id(change):\n",
        "    index = change['new']\n",
        "\n",
        "    global instance_id\n",
        "    instance_id = index-1\n",
        "\n",
        "    global input_path, ids_input, input_img\n",
        "\n",
        "    input_img = imread(os.path.join(input_path, ids_input[instance_id]))\n",
        "\n",
        "    global gt_path, ids_gt, gt_csv\n",
        "\n",
        "    if ids_gt != []: # If StopIteration exception was not thrown\n",
        "        gt_csv = pd.read_csv(os.path.join(gt_path, ids_gt[instance_id]))\n",
        "    else:\n",
        "        gt_csv = None\n",
        "\n",
        "    sliderZ.value = 1\n",
        "    sliderZ.max = len(input_img)\n",
        "    display_images({'new': 1})\n",
        "\n",
        "# Function to display images depending on sliderZ value\n",
        "def display_images(change):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "\n",
        "        index = change['new'] # New Z value\n",
        "\n",
        "        global input_img, gt_csv, instance_id\n",
        "\n",
        "        # # Print paths to ensure the images displayed are correct\n",
        "        # global input_path, ids_input, gt_path, ids_input, instance_id\n",
        "        # print(os.path.join(input_path, ids_input[instance_id]))\n",
        "        # print(os.path.join(gt_path, ids_gt[instance_id]))\n",
        "\n",
        "        # Display images\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        axs[0].imshow(input_img[index-1], cmap='gray')\n",
        "        axs[0].set_title(f\"Input image: {instance_id+1}, z: {index}\")\n",
        "\n",
        "        if gt_csv is not None: # If StopIteration exception was not thrown\n",
        "            df = gt_csv[gt_csv['axis-0'] == index-1]\n",
        "            y = df['axis-1']\n",
        "            x = df['axis-2']\n",
        "\n",
        "            axs[1].imshow(np.squeeze(input_img[index-1]), cmap= 'gray')\n",
        "            axs[1].scatter(x, y, color = 'red', marker= \"x\", s=200)\n",
        "            axs[1].set_title(\"Label\")\n",
        "        else:\n",
        "            print(\"No labels for this set.\")\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create an VBox to hold the dropdown and slider\n",
        "controls = VBox([dropdown, slider, sliderZ])\n",
        "display(controls, output)\n",
        "\n",
        "# Link widgets to functions\n",
        "dropdown.observe(update_paths, names='value')\n",
        "slider.observe(update_id, names='value')\n",
        "sliderZ.observe(display_images, names='value')\n",
        "\n",
        "# Initial display\n",
        "display_images({'new': slider.value})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593,
          "referenced_widgets": [
            "274dd0f917774d07aa1cb06a4b44a01d",
            "bd605191cf534467abacb16771264268",
            "e90332eed8df4c139184c431d41ff54e",
            "687a73964c644923b34e6b7e6ec315b8",
            "2ccb3eeaebd9488da052f5da9367e29c",
            "887f7e03306f4973aef85273b7fa124d",
            "85d79babe2054e00982d104360c392f3",
            "1501a93e0a214914ad1f28018af638ef",
            "d87201a8867d4764a46da5784a315a19",
            "e2873c14b9014e96a1207ca6933aedba",
            "f83e43e06b944ea4a5cf14a6a98cbaa9",
            "11b5eb27ba3643a9a9487045e1a146b7",
            "bffee5cb98d8464fb90e592458a88251"
          ]
        },
        "cellView": "form",
        "id": "y_veJYRNpcZB",
        "outputId": "cad9eb15-a57a-4cc8-e474-fc71f8b9b05e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Dropdown(description='Set:', options=('training-set', 'test-set'), value='training-set'), IntSl\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "274dd0f917774d07aa1cb06a4b44a01d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11b5eb27ba3643a9a9487045e1a146b7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZwoZC20rK42"
      },
      "source": [
        "## **Configure and Train the DNN Model**\n",
        "---\n",
        "\n",
        "Within this workflow, [BiaPy](https://biapyx.github.io/) aims to localize objects in the input image by pinpointing individual central points at their center of mass, as described by [Zhou et. al](https://arxiv.org/abs/1904.07850). To achieve this, we generate a mask utilizing the points listed in the CSV to train the network. The **central_point_dilation** variable determines the size of these central points. In case of 3D images, only in the middle slice of the object is considered to be the central point.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "daGtIo-V_Ydt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "b4f0f43a-a40a-471f-e2ea-ad5d5cb638e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ###OPTIONAL: Check BioImage Model Zoo (BMZ) models compatible with BiaPy\n",
        "# @markdown Use this option to generate a full list of the available BiaPy-compatible models in the BMZ.\n",
        "\n",
        "# @markdown **Important:** To select one of the listed models (if any), you will have to run the next cell and select \"BioImage Model Zoo\" as the source of the model. Then, paste the corresponding model's nickname into the created field.\n",
        "# @markdown <div><img src=\"https://bioimage.io/static/img/bioimage-io-logo.svg\" width=\"600\"/></div>\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pooch\n",
        "import yaml\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "from biapy.models import check_bmz_model_compatibility\n",
        "from packaging.version import Version\n",
        "from typing import Optional, Dict, Tuple, List, Literal\n",
        "\n",
        "# Change pooch verbosity\n",
        "logger = pooch.get_logger()\n",
        "logger.setLevel(\"WARNING\")\n",
        "\n",
        "# Extracted from BiaPy-GUI.\n",
        "# Adapted from BiaPy commit: e5d3bc13fe343160cede4684bdb90bcdf098e4a7 (3.6.1)\n",
        "def check_model_restrictions(\n",
        "    model_rdf,\n",
        "    workflow_specs,\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks model restrictions to be applied into the current configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_rdf : dict\n",
        "        BMZ model RDF that contains all the information of the model.\n",
        "\n",
        "    workflow_specs : dict\n",
        "        Specifications of the workflow. If not provided all possible models will be considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    option_list: dict\n",
        "        Variables and values to change in current configuration. These changes\n",
        "        are imposed by the selected model.\n",
        "    \"\"\"\n",
        "    specific_workflow = workflow_specs[\"workflow_type\"]\n",
        "\n",
        "    # Version of the model\n",
        "    model_version = Version(model_rdf[\"format_version\"])\n",
        "    opts = {}\n",
        "\n",
        "    # 1) Change PATCH_SIZE with the one stored in the model description. This differs from the code of BiaPy where\n",
        "    # get_test_inputs() is simply used as there a ModelDescr is build out of the RDF. Here we try to do it manually\n",
        "    # to avoid fetching files using the network as it may be slow.\n",
        "    input_image_shape = []\n",
        "    if \"shape\" in model_rdf[\"inputs\"][0]:\n",
        "        input_image_shape = model_rdf[\"inputs\"][0][\"shape\"]\n",
        "        # \"CebraNET Cellular Membranes in Volume SEM\" ('format_version': '0.4.10')\n",
        "        #   have: {'min': [1, 1, 64, 64, 64], 'step': [0, 0, 16, 16, 16]}\n",
        "        if isinstance(input_image_shape, dict) and \"min\" in input_image_shape:\n",
        "            input_image_shape = input_image_shape[\"min\"]\n",
        "    else:\n",
        "        # Check axes and dimension\n",
        "        input_image_shape = []\n",
        "        for axis in model_rdf[\"inputs\"][0][\"axes\"]:\n",
        "            if 'type' in axis:\n",
        "                if axis['type'] == \"batch\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif axis['type'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif 'id' in axis and 'size' in axis:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "            elif 'id' in axis:\n",
        "                if axis['id'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                else:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "    if len(input_image_shape) == 0:\n",
        "        raise ValueError(\"Couldn't load input info from BMZ model's RDF: {}\".format(model_rdf[\"inputs\"][0]))\n",
        "    opts[\"DATA.PATCH_SIZE\"] = tuple(input_image_shape[2:]) + (input_image_shape[1],)\n",
        "\n",
        "    # Capture model kwargs\n",
        "    if \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]:\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"kwargs\"]\n",
        "    elif (\n",
        "        \"architecture\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]\n",
        "        and \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"]\n",
        "    ):\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"][\"kwargs\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Couldn't extract kwargs from model description.\")\n",
        "\n",
        "    # 2) Workflow specific restrictions\n",
        "    # Classes in semantic segmentation\n",
        "    if specific_workflow in [\"SEMANTIC_SEG\"]:\n",
        "        # Check number of classes\n",
        "        classes = -1\n",
        "        if \"n_classes\" in model_kwargs:  # BiaPy\n",
        "            classes = model_kwargs[\"n_classes\"]\n",
        "        elif \"out_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"out_channels\"]\n",
        "        elif \"output_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"output_channels\"]\n",
        "        elif \"classes\" in model_kwargs:\n",
        "            classes = model_kwargs[\"classes\"]\n",
        "        if isinstance(classes, list):\n",
        "            classes = classes[-1]\n",
        "\n",
        "        if not isinstance(classes, int):\n",
        "            raise ValueError(f\"Classes not extracted correctly. Obtained {classes}\")\n",
        "        if classes == -1:\n",
        "            print(model_kwargs)\n",
        "            raise ValueError(\"Classes not found for semantic segmentation dir.\")\n",
        "\n",
        "        opts[\"MODEL.N_CLASSES\"] = max(2, classes)\n",
        "    elif specific_workflow in [\"INSTANCE_SEG\"]:\n",
        "        # Assumed it's BC. This needs a more elaborated process. Still deciding this:\n",
        "        # https://github.com/bioimage-io/spec-bioimage-io/issues/621\n",
        "\n",
        "        # Defaults\n",
        "        channels = 2\n",
        "        channel_code = \"BC\"\n",
        "\n",
        "        if \"out_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"out_channels\"]\n",
        "        elif \"output_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"output_channels\"]\n",
        "\n",
        "        if isinstance(channels, list):\n",
        "            channels = channels[-1]\n",
        "        if channels == 1:\n",
        "            channel_code = \"C\"\n",
        "        elif channels == 2:\n",
        "            channel_code = \"BC\"\n",
        "        elif channels == 3:\n",
        "            channel_code = \"BCM\"\n",
        "        elif channels == 8:\n",
        "            channel_code = \"A\"\n",
        "\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\"] = channel_code\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNEL_WEIGHTS\"] = [\n",
        "            1,\n",
        "        ] * channels\n",
        "        if channel_code in  [\"A\", \"BC\"]:\n",
        "            opts[\"LOSS.CLASS_REBALANCE\"] = True\n",
        "\n",
        "    if \"preprocessing\" not in model_rdf[\"inputs\"][0]:\n",
        "        return opts\n",
        "\n",
        "    preproc_info = model_rdf[\"inputs\"][0][\"preprocessing\"]\n",
        "    if len(preproc_info) == 0:\n",
        "        return opts\n",
        "    preproc_info = preproc_info[0]\n",
        "\n",
        "    # 3) Change preprocessing to the one stablished by BMZ by translate BMZ keywords into BiaPy's\n",
        "    # 'zero_mean_unit_variance' and 'fixed_zero_mean_unit_variance' norms of BMZ can be translated to our 'custom' norm\n",
        "    # providing mean and std\n",
        "    key_to_find = \"id\" if model_version > Version(\"0.5.0\") else \"name\"\n",
        "    if key_to_find in preproc_info:\n",
        "        if preproc_info[key_to_find] in [\"fixed_zero_mean_unit_variance\", \"zero_mean_unit_variance\"]:\n",
        "            if (\n",
        "                \"kwargs\" in preproc_info\n",
        "                and \"mean\" in preproc_info[\"kwargs\"]\n",
        "            ):\n",
        "                mean = preproc_info[\"kwargs\"][\"mean\"]\n",
        "                std = preproc_info[\"kwargs\"][\"std\"]\n",
        "            elif \"mean\" in preproc_info:\n",
        "                mean = preproc_info[\"mean\"]\n",
        "                std = preproc_info[\"std\"]\n",
        "            else:\n",
        "                mean, std = -1., -1.\n",
        "\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"custom\"\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_MEAN\"] = mean\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_STD\"] = std\n",
        "\n",
        "        # 'scale_linear' norm of BMZ is close to our 'div' norm (TODO: we need to control the \"gain\" arg)\n",
        "        elif preproc_info[key_to_find] == \"scale_linear\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"div\"\n",
        "\n",
        "        # 'scale_range' norm of BMZ is as our PERC_CLIP + 'scale_range' norm\n",
        "        elif preproc_info[key_to_find] == \"scale_range\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"scale_range\"\n",
        "            if (\n",
        "                float(preproc_info[\"kwargs\"][\"min_percentile\"]) != 0\n",
        "                or float(preproc_info[\"kwargs\"][\"max_percentile\"]) != 100\n",
        "            ):\n",
        "                opts[\"DATA.NORMALIZATION.PERC_CLIP\"] = True\n",
        "                opts[\"DATA.NORMALIZATION.PERC_LOWER\"] = float(preproc_info[\"kwargs\"][\"min_percentile\"])\n",
        "                opts[\"DATA.NORMALIZATION.PERC_UPPER\"] = float(preproc_info[\"kwargs\"][\"max_percentile\"])\n",
        "\n",
        "    return opts\n",
        "\n",
        "# Check the models that BiaPy can consume\n",
        "COLLECTION_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/collection.json\"\n",
        "collection_path = Path(pooch.retrieve(COLLECTION_URL, known_hash=None))\n",
        "with collection_path.open() as f:\n",
        "    collection = json.load(f)\n",
        "\n",
        "model_urls = [entry[\"rdf_source\"] for entry in collection[\"collection\"] if entry[\"type\"] == \"model\"]\n",
        "\n",
        "model_rdfs = []\n",
        "for mu in model_urls:\n",
        "    with open(Path(pooch.retrieve(mu, known_hash=None)), 'rt', encoding='utf8') as stream:\n",
        "        try:\n",
        "            model_rdfs.append(yaml.safe_load(stream))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "\n",
        "# Check axes, preprocessing functions used and postprocessing.\n",
        "pytorch_models = []\n",
        "imposed_vars = []\n",
        "\n",
        "workflow_specs = {\n",
        "    \"workflow_type\": \"DETECTION\",\n",
        "    \"ndim\": \"3D\",\n",
        "    \"nclasses\": \"all\",\n",
        "}\n",
        "for model_rdf in model_rdfs:\n",
        "    try:\n",
        "        (\n",
        "            preproc_info,\n",
        "            error,\n",
        "            error_message\n",
        "        ) = check_bmz_model_compatibility(model_rdf, workflow_specs=workflow_specs)\n",
        "    except:\n",
        "        error = True\n",
        "\n",
        "    if not error:\n",
        "        model_imposed_vars = check_model_restrictions(model_rdf, workflow_specs=workflow_specs)\n",
        "        imposed_vars.append(model_imposed_vars)\n",
        "        pytorch_models.append(model_rdf)\n",
        "\n",
        "# Print the possible models\n",
        "html = \"<table style='width:100%''>\"\n",
        "c = 0\n",
        "for i, model in enumerate(pytorch_models):\n",
        "\n",
        "    if 'nickname' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['nickname']\n",
        "        nickname_icon = model['config']['bioimageio']['nickname_icon']\n",
        "    elif 'id' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['id']\n",
        "        nickname_icon = model['config']['bioimageio']['id_emoji']\n",
        "    else:\n",
        "        doi = \"/\".join(model['id'].split(\"/\")[:2])\n",
        "        nickname = doi\n",
        "        nickname_icon = doi\n",
        "    cover_url = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/\"+nickname+\"/\"+str(model[\"version\"])+\"/files/\"+model['covers'][0]\n",
        "    restrictions = \"\"\n",
        "    for key, val in imposed_vars[i].items():\n",
        "        if key == 'MODEL.N_CLASSES':\n",
        "            restrictions += \"<p>number_of_classes: {}</p>\".format(val)\n",
        "        elif key == \"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\":\n",
        "            problem_channels = 'Binary mask + Contours'\n",
        "            if val == \"BC\":\n",
        "                problem_channels = \"Binary mask + Contours\"\n",
        "            elif val == 'BP':\n",
        "                problem_channels = \"Binary mask + Central points\"\n",
        "            elif val == 'BD':\n",
        "                problem_channels = \"Binary mask + Distance map\"\n",
        "            elif val == 'BCM':\n",
        "                problem_channels = \"Binary mask + Contours + Foreground mask\"\n",
        "            elif val == 'BCD':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map\"\n",
        "            elif val == 'BCDv2':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map with background\"\n",
        "            elif val == 'Dv2':\n",
        "                problem_channels = \"Distance map with background\"\n",
        "            restrictions += \"<p>problem_representation: {}</p>\".format(problem_channels)\n",
        "    if c == 0:\n",
        "        html += \"<tr>\"\n",
        "    html += \"<td style='width:33%'>\"\n",
        "    html += \"<p style='color:#2196f3'>%s</p><p>Nickname: %s (%s)</p>%s<img src='%s' height='200'></td>\"%(\n",
        "        model['name'],\n",
        "        nickname,\n",
        "        nickname_icon,\n",
        "        restrictions,\n",
        "        cover_url,\n",
        "    )\n",
        "    c +=1\n",
        "    if c == 3:\n",
        "        html += \"</tr>\"\n",
        "        c=0\n",
        "html += \"</table>\"\n",
        "if len( pytorch_models ) == 0:\n",
        "    display(HTML('<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>'))\n",
        "else:\n",
        "    display(HTML('<h1>List of models that can be used in BiaPy:</h1><br>'))\n",
        "    display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "uBZagA5Iqxoc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "72001304761447d3a652b41fc4559891",
            "07ecd1c549504bb3afdf7fe55f24b0bd",
            "f1b8a0c438424c04851329c207467da7"
          ]
        },
        "outputId": "77927ae2-2ce2-44a7-bbdb-8df9808acbc1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='Source:', options=('BiaPy', 'BioImage Model Zoo'), tooltips=('Models created during\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72001304761447d3a652b41fc4559891"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ###Play to select the source to build the model (BiaPy or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown **BiaPy**: to use the models implemented in BiaPy.\n",
        "\n",
        "#@markdown **Bioimage Model Zoo (BMZ)**: to use models from the [BMZ repository](https://bioimage.io/#/). You can run the above cell to generate an updated list of the models that can be used with BiaPy. Copy the nickname from the model and paste it below.\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "\n",
        "changed_source = True\n",
        "exists_bmz = False\n",
        "# create widgets\n",
        "source = widgets.ToggleButtons(\n",
        "    options=['BiaPy', 'BioImage Model Zoo'],\n",
        "    description='Source:',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltips=['Models created during this workflow', 'BioImage Model Zoo model'],\n",
        "#     icons=['check'] * 3\n",
        ")\n",
        "\n",
        "bmz = widgets.Text(\n",
        "    # value='10.5281/zenodo.5764892',\n",
        "    placeholder='Nickname of BMZ model',\n",
        "    description='ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# display the first widget\n",
        "display(source)\n",
        "\n",
        "# intialize the output - second widget\n",
        "out = Output()\n",
        "\n",
        "def changed(change):\n",
        "    '''\n",
        "    Monitor change in the first widget\n",
        "    '''\n",
        "    global out\n",
        "    global exists_bmz\n",
        "    if source.value == 'BiaPy':\n",
        "        bmz.layout.display = 'none'\n",
        "        out.clear_output() #clear output\n",
        "        out = Output() # redefine output\n",
        "    else:\n",
        "        bmz.layout.display = 'none'\n",
        "        bmz.layout.display = 'flex'\n",
        "        if not exists_bmz:\n",
        "          out.append_display_data(bmz)\n",
        "          display(out)\n",
        "        exists_bmz = True\n",
        "\n",
        "# monitor the source widget for changes\n",
        "source.observe(changed, 'value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gNxwa6KaWYn"
      },
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Data management**\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "* **`test_ground_truth`:** Select to use test data ground truth to measure the performance of the model's result. If selected, **test_data_gt_path** variable path set above will be used. **Default value: True**\n",
        "\n",
        "#### **Basic training parameters**\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 1**\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. **Default value: 150**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 20**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: U-Net, Residual U-Net, Attention U-Net (see [Franco-Barranco et al., 2021](https://link.springer.com/article/10.1007/s12021-021-09556-1)), SEUNet, MultiResUNet, ResUNet++, UNETR-Mini, UNETR-Small, UNETR-Base and U-NeXt V1. **Default value: Residual U-Net**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 8**\n",
        "\n",
        "* **`patch_size_xy`:** Input the XY size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 64**\n",
        "\n",
        "* **`patch_size_z`:** Input the Z size of the patches use to train your model (length in pixels in Z). The value should be smaller or equal to the dimensions of the image. **Default value: 64**\n",
        "\n",
        "* **`anisotropic_data`:** Select if your image data is anisotropic (lower resolution in Z with respect to XY). The model downsampling step size will be set accordingly. **Default value: False**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization. **Default value: ADAMW**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.0001**\n",
        "\n",
        "* **`learning_rate_scheduler`:** Select to adjust the learning rate between epochs. Options: \"None\", \"Reduce on plateau\", \"One cycle\", \"Warm-up cosine decay\". **Default value: arm-up cosine decay**\n",
        "\n",
        "* **`test_time_augmentation`:** Select to apply augmentation (flips and rotations) at test time. It usually provides more robust results but uses more time to produce each result. **Default value: False**\n",
        "\n",
        "* **`min_value_to_be_peak`:** Minimun probability value to consider a point as a peak. The lowest this value is, the more points will be detected. This value needs to between 0 and 1. **Default value: 0.2**\n",
        "\n",
        "* **`resolution_xy`:** Data resolution in physical units for y and x axis. **Default value: 0.51**\n",
        "\n",
        "* **`resolution_z`:** Data resolution in physical units for z axis. **Default value: 0.48**\n",
        "\n",
        "#### **Advanced Parameters of Detection - experienced users only**\n",
        "\n",
        "* **`central_point_dilation`:** Size of the disk that will be used to dilate the central point created from the CSV file to train the network. Set it to 0 to not dilate and only create a 3x3 square. Normally it is set to 3 but here we set it to 0 because the nuclei of this dataset are very small. **Default value: 0**\n",
        "\n",
        "* **`tolerance`:** Maximum distance of a predicted point from a ground truth point to be considered as a true positive. **Default value: 3**\n",
        "\n",
        "* **`remove_close_points`:** Merge close detections into single ones. **Default value: True**\n",
        "\n",
        "* **`remove_close_points_radius`:** Distance between two detections to be considered the same (if `remove_close_points` is set to True). **Default value: 3**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLdMygZVT5aH",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_3d_detection\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Data management:\n",
        "test_ground_truth = True #@param {type:\"boolean\"}\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "input_channels = 1 #@param {type:\"number\"}\n",
        "number_of_epochs =  150#@param {type:\"number\"}\n",
        "patience =  20#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "\n",
        "model_architecture = \"Residual U-Net\" #@param [\"U-Net\", \"Residual U-Net\", \"Attention U-Net\", 'MultiResUNet', 'ResUNet++', 'SEUNet', \"UNETR-Mini\",\"UNETR-Small\", \"UNETR-Base\", \"U-NeXt V1\"]\n",
        "\n",
        "batch_size =  8#@param {type:\"number\"}\n",
        "patch_size_xy = 64 #@param {type:\"number\"}\n",
        "patch_size_z = 64 #@param {type:\"number\"}\n",
        "resolution_xy = 0.51 #@param {type:\"number\"}\n",
        "resolution_z = 0.48 #@param {type:\"number\"}\n",
        "\n",
        "anisotropic_data = False #@param {type:\"boolean\"}\n",
        "\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n",
        "initial_learning_rate = 0.001 #@param {type:\"number\"}\n",
        "learning_rate_scheduler = \"Warm-up cosine decay\" #@param [\"None\", \"Reduce on plateau\",\"One cycle\", \"Warm-up cosine decay\"]\n",
        "\n",
        "test_time_augmentation = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Advanced Parameters of Detection:\n",
        "central_point_dilation = 0 #@param {type:\"number\"}\n",
        "min_value_to_be_peak = 0.2 #@param {type:\"number\"}\n",
        "tolerance = 3 #@param {type:\"number\"}\n",
        "remove_close_points = True #@param {type:\"boolean\"}\n",
        "remove_close_points_radius= 3 #@param {type:\"number\"}\n",
        "\n",
        "checkpoint_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iZ_TuIVZXGGM"
      },
      "outputs": [],
      "source": [
        "#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n",
        "#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n",
        "\n",
        "#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n",
        "from google.colab import files\n",
        "\n",
        "#s.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "checkpoint_path = '/content/' + list(uploaded.keys())[0]\n",
        "\n",
        "# open previously configured file, if exists\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# edit previous configuration file if it exists to load the checkpoint model\n",
        "if os.path.exists( yaml_file ):\n",
        "    import yaml\n",
        "    with open( yaml_file, 'r') as stream:\n",
        "        try:\n",
        "            biapy_config = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "    # save file\n",
        "    with open( yaml_file, 'w') as outfile:\n",
        "        yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Pre-trained model loaded and ready to re-train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8kLFc8_ajHD"
      },
      "source": [
        "### **Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CZKK9EoVmH-Y",
        "outputId": "a352c7fa-c964-4f0a-ecd2-15e231be6fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration finished.\n",
            "Date: 2024-09-04 06:16:48\n",
            "Arguments: Namespace(config='/content/my_3d_detection.yaml', result_dir='/content/output', name='my_3d_detection', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "Job: my_3d_detection_1\n",
            "Python       : 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "PyTorch:  2.4.0+cu121\n",
            "Not using distributed mode\n",
            "[06:16:48.452194] Configuration details:\n",
            "[06:16:48.452911] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: False\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: True\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    APPLICATION_MODE: image\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    PERC_CLIP: False\n",
            "    PERC_LOWER: -1.0\n",
            "    PERC_UPPER: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (64, 64, 64, 1)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/test/x/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/test/y_detection_masks\n",
            "    GT_PATH: /content/data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/test/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/test/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: True\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (8, 8, 8)\n",
            "    PATH: /content/data/test/x\n",
            "    RESOLUTION: (0.48, 0.51, 0.51)\n",
            "    SSL_SOURCE_DIR: /content/data/test/x_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/train/y_detection_masks\n",
            "    GT_PATH: /content/data/train/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: 3.814697265625e-06\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: /content/data/train/x\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    DIST_EVAL: True\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_3d_detection/train_logs\n",
            "  LOG_FILE_PREFIX: my_3d_detection_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: True\n",
            "  TYPE: CE\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: ELU\n",
            "  ARCHITECTURE: resunet\n",
            "  BMZ:\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [18, 36, 48, 64]\n",
            "  ISOTROPY: [True, True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: False\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 2\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: pre\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [2, 2, 2]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_3d_detection/results/my_3d_detection_1/charts\n",
            "  CHECKPOINT: /content/output/my_3d_detection/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_3d_detection/results/my_3d_detection_1/aug\n",
            "  GEN_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_mask_check\n",
            "  LWR_X_FILE: /content/output/my_3d_detection/checkpoints/lower_bound_X_perc.npy\n",
            "  LWR_Y_FILE: /content/output/my_3d_detection/checkpoints/lower_bound_Y_perc.npy\n",
            "  MAE_OUT_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/MAE_checks\n",
            "  MEAN_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_3d_detection/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_3d_detection/results/my_3d_detection_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/instance_associations\n",
            "    PATH: /content/output/my_3d_detection/results/my_3d_detection_1\n",
            "    PER_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: /content/data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/train_BC_instance_channels\n",
            "  UPR_X_FILE: /content/output/my_3d_detection/checkpoints/upper_bound_X_perc.npy\n",
            "  UPR_Y_FILE: /content/output/my_3d_detection/checkpoints/upper_bound_Y_perc.npy\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [0, 0, 0]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 3D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1, 1)\n",
            "  TYPE: DETECTION\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: 5\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    FORMAT: H5\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TOLERANCE: [3]\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['iou']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGN: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: True\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [3]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: True\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 8\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 150\n",
            "  LR: 0.001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: 0.0\n",
            "    NAME: warmupcosine\n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: 0\n",
            "  METRICS: ['iou']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 20\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[06:16:49.765279] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[06:16:49.765412] Initializing Detection_Workflow\n",
            "[06:16:49.765466] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[06:16:50.018315] ############################\n",
            "[06:16:50.018457] #  PREPARE DETECTION DATA  #\n",
            "[06:16:50.020039] ############################\n",
            "[06:16:50.021269] You select to create detection masks from given .csv files but no file is detected in /content/data/test/y_detection_masks. So let's prepare the data. Notice that, if you do not modify 'DATA.TEST.DETECTION_MASK_DIR' path, this process will be done just once!\n",
            "[06:16:50.022267] Creating test detection masks . . .\n",
            "[06:16:50.023130] Attempting to create mask from CSV file: /content/data/test/y/mask_000.csv\n",
            "[06:16:50.024003] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.024084] Its respective image seems to be: /content/data/test/x/vol_000.tif\n",
            "[06:16:50.033110] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.045039] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.066282] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.078500] Attempting to create mask from CSV file: /content/data/test/y/mask_001.csv\n",
            "[06:16:50.078580] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.078621] Its respective image seems to be: /content/data/test/x/vol_001.tif\n",
            "[06:16:50.088367] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.120328] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.142229] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.152353] Attempting to create mask from CSV file: /content/data/test/y/mask_002.csv\n",
            "[06:16:50.152432] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.152473] Its respective image seems to be: /content/data/test/x/vol_002.tif\n",
            "[06:16:50.161162] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.167792] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.192906] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.204872] Attempting to create mask from CSV file: /content/data/test/y/mask_003.csv\n",
            "[06:16:50.204982] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.205032] Its respective image seems to be: /content/data/test/x/vol_003.tif\n",
            "[06:16:50.213578] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.238599] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.258072] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.270789] Attempting to create mask from CSV file: /content/data/test/y/mask_004.csv\n",
            "[06:16:50.270867] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.270908] Its respective image seems to be: /content/data/test/x/vol_004.tif\n",
            "[06:16:50.286359] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.301728] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.322005] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.332920] Attempting to create mask from CSV file: /content/data/test/y/mask_005.csv\n",
            "[06:16:50.333020] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.333064] Its respective image seems to be: /content/data/test/x/vol_005.tif\n",
            "[06:16:50.344704] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.356523] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.380001] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.397460] Attempting to create mask from CSV file: /content/data/test/y/mask_006.csv\n",
            "[06:16:50.398602] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.398657] Its respective image seems to be: /content/data/test/x/vol_006.tif\n",
            "[06:16:50.411068] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.423911] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.442280] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.453424] Attempting to create mask from CSV file: /content/data/test/y/mask_007.csv\n",
            "[06:16:50.453511] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.453568] Its respective image seems to be: /content/data/test/x/vol_007.tif\n",
            "[06:16:50.464140] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.478917] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.502169] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.513140] Attempting to create mask from CSV file: /content/data/test/y/mask_008.csv\n",
            "[06:16:50.513226] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.513273] Its respective image seems to be: /content/data/test/x/vol_008.tif\n",
            "[06:16:50.524157] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.550800] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.573441] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.591129] Attempting to create mask from CSV file: /content/data/test/y/mask_009.csv\n",
            "[06:16:50.594003] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.594804] Its respective image seems to be: /content/data/test/x/vol_009.tif\n",
            "[06:16:50.605576] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.636318] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.657053] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.673136] Attempting to create mask from CSV file: /content/data/test/y/mask_010.csv\n",
            "[06:16:50.674455] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.674535] Its respective image seems to be: /content/data/test/x/vol_010.tif\n",
            "[06:16:50.686142] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.722303] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.749282] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.764158] Attempting to create mask from CSV file: /content/data/test/y/mask_011.csv\n",
            "[06:16:50.764229] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.764263] Its respective image seems to be: /content/data/test/x/vol_011.tif\n",
            "[06:16:50.771236] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.812799] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.832483] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.847250] Attempting to create mask from CSV file: /content/data/test/y/mask_012.csv\n",
            "[06:16:50.847322] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.847370] Its respective image seems to be: /content/data/test/x/vol_012.tif\n",
            "[06:16:50.859005] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.903166] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.935952] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:50.959902] Attempting to create mask from CSV file: /content/data/test/y/mask_013.csv\n",
            "[06:16:50.963066] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:50.963132] Its respective image seems to be: /content/data/test/x/vol_013.tif\n",
            "[06:16:50.974969] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.014031] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.041892] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.063814] Attempting to create mask from CSV file: /content/data/test/y/mask_014.csv\n",
            "[06:16:51.063889] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.063948] Its respective image seems to be: /content/data/test/x/vol_014.tif\n",
            "[06:16:51.076662] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.092083] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.114410] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.130902] Attempting to create mask from CSV file: /content/data/test/y/mask_015.csv\n",
            "[06:16:51.132253] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.132618] Its respective image seems to be: /content/data/test/x/vol_015.tif\n",
            "[06:16:51.145629] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.168660] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.194166] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.211702] Attempting to create mask from CSV file: /content/data/test/y/mask_016.csv\n",
            "[06:16:51.211776] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.211813] Its respective image seems to be: /content/data/test/x/vol_016.tif\n",
            "[06:16:51.225382] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.259839] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.286466] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.303092] Attempting to create mask from CSV file: /content/data/test/y/mask_017.csv\n",
            "[06:16:51.304323] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.304637] Its respective image seems to be: /content/data/test/x/vol_017.tif\n",
            "[06:16:51.317666] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.354219] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.383879] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.406026] Attempting to create mask from CSV file: /content/data/test/y/mask_018.csv\n",
            "[06:16:51.410037] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.410118] Its respective image seems to be: /content/data/test/x/vol_018.tif\n",
            "[06:16:51.427596] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.470770] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.499605] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.521497] Attempting to create mask from CSV file: /content/data/test/y/mask_019.csv\n",
            "[06:16:51.524436] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.524480] Its respective image seems to be: /content/data/test/x/vol_019.tif\n",
            "[06:16:51.537964] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.578371] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.610613] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.632494] Attempting to create mask from CSV file: /content/data/test/y/mask_020.csv\n",
            "[06:16:51.633518] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.633568] Its respective image seems to be: /content/data/test/x/vol_020.tif\n",
            "[06:16:51.646421] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.687401] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.716401] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.737636] Attempting to create mask from CSV file: /content/data/test/y/mask_021.csv\n",
            "[06:16:51.739615] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.740165] Its respective image seems to be: /content/data/test/x/vol_021.tif\n",
            "[06:16:51.753803] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.770768] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.798803] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.819069] Attempting to create mask from CSV file: /content/data/test/y/mask_022.csv\n",
            "[06:16:51.821163] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.821231] Its respective image seems to be: /content/data/test/x/vol_022.tif\n",
            "[06:16:51.841415] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.883877] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.915688] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.938702] Attempting to create mask from CSV file: /content/data/test/y/mask_023.csv\n",
            "[06:16:51.938787] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:51.938830] Its respective image seems to be: /content/data/test/x/vol_023.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.953519] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:51.979292] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.006328] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.026154] Attempting to create mask from CSV file: /content/data/test/y/mask_024.csv\n",
            "[06:16:52.027116] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:52.027168] Its respective image seems to be: /content/data/test/x/vol_024.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.046446] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.069223] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.101912] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.123055] Attempting to create mask from CSV file: /content/data/test/y/mask_025.csv\n",
            "[06:16:52.124547] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:52.125093] Its respective image seems to be: /content/data/test/x/vol_025.tif\n",
            "[06:16:52.138914] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.185408] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.216999] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                     "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.240836] Attempting to create mask from CSV file: /content/data/test/y/mask_026.csv\n",
            "[06:16:52.242887] WARNING: The image seems to have different name than its CSV file. Using the CSV file that's in the same spot (within the CSV files list) where the image is in its own list of images. Check if it is correct!\n",
            "[06:16:52.243207] Its respective image seems to be: /content/data/test/x/vol_026.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.264564] Creating all points . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.280967] Check points created to see if some of them are very close that create a large label\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.313697] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.334150] DATA.TRAIN.GT_PATH changed from /content/data/train/y to /content/data/train/y_detection_masks\n",
            "[06:16:52.334814] DATA.TEST.GT_PATH changed from /content/data/test/y to /content/data/test/y_detection_masks\n",
            "[06:16:52.335480] ##########################\n",
            "[06:16:52.335536] #   LOAD TRAINING DATA   #\n",
            "[06:16:52.335568] ##########################\n",
            "[06:16:52.335690] ### LOAD ###\n",
            "[06:16:52.335723] 0) Loading train images . . .\n",
            "[06:16:52.335757] Loading data from /content/data/train/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:00<00:00, 490.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.419337] *** Loaded data shape is (27, 64, 64, 64, 1)\n",
            "[06:16:52.420971] 1) Loading train GT . . .\n",
            "[06:16:52.421019] Loading data from /content/data/train/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:00<00:00, 97.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.711996] *** Loaded data shape is (27, 64, 64, 64, 1)\n",
            "[06:16:52.713207] Data that do not have 3.814697265625e-06% of foreground is discarded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:52.943915] 0 samples discarded!\n",
            "[06:16:52.946048] *** Remaining data shape is (27, 64, 64, 64, 1)\n",
            "[06:16:52.946882] Creating validation data\n",
            "[06:16:52.959433] Not all samples seem to have the same shape. Number of samples: 24\n",
            "[06:16:52.959547] *** Loaded train data shape is: (24, 64, 64, 64, 1)\n",
            "[06:16:52.959913] *** Loaded train GT shape is: (24, 64, 64, 64, 1)\n",
            "[06:16:52.960007] *** Loaded validation data shape is: (3, 64, 64, 64, 1)\n",
            "[06:16:52.960043] *** Loaded validation GT shape is: (3, 64, 64, 64, 1)\n",
            "[06:16:52.960076] ### END LOAD ###\n",
            "[06:16:52.960154] ###############\n",
            "[06:16:52.960188] # Build model #\n",
            "[06:16:52.960219] ###############\n",
            "[06:16:55.331138] ##############################\n",
            "[06:16:55.332378] #  PREPARE TRAIN GENERATORS  #\n",
            "[06:16:55.333089] ##############################\n",
            "[06:16:55.334163] Initializing train data generator . . .\n",
            "[06:16:55.338541] Checking which channel of the mask needs normalization . . .\n",
            "[06:16:55.358784] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('uint8'), 'div': 1}\n",
            "[06:16:55.359637] Normalization config used for Y: as_mask\n",
            "[06:16:55.361690] Initializing val data generator . . .\n",
            "[06:16:55.363369] Checking which channel of the mask needs normalization . . .\n",
            "[06:16:55.368462] Normalization config used for X: {'type': 'div', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('uint8'), 'div': 1}\n",
            "[06:16:55.369430] Normalization config used for Y: as_mask\n",
            "[06:16:55.370523] Creating generator samples . . .\n",
            "[06:16:55.371562] 0) Creating samples of data augmentation . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 64) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
            "  ia.warn(\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|\u2588         | 1/10 [00:00<00:01,  6.26it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 2/10 [00:00<00:01,  6.32it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 3/10 [00:00<00:01,  6.12it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:00,  6.23it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 50%|\u2588\u2588\u2588\u2588\u2588     | 5/10 [00:00<00:00,  5.29it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:01<00:00,  5.07it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 7/10 [00:01<00:00,  4.93it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:01<00:00,  4.86it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 90%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 | 9/10 [00:01<00:00,  4.91it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:01<00:00,  5.36it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:290: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:16:57.249868] Number of workers: 5\n",
            "[06:16:57.249988] Accumulate grad iterations: 1\n",
            "[06:16:57.250021] Effective batch size: 8\n",
            "[06:16:57.250071] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x78393fde29e0>\n",
            "[06:16:57.256432] #######################\n",
            "[06:16:57.256495] # Prepare logging tool #\n",
            "[06:16:57.256524] #######################\n",
            "[06:16:57.262216] AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0\n",
            "    maximize: False\n",
            "    weight_decay: 0.02\n",
            ")\n",
            "[06:16:57.262502] #####################\n",
            "[06:16:57.262538] #  TRAIN THE MODEL  #\n",
            "[06:16:57.262567] #####################\n",
            "[06:16:57.262600] Start training in epoch 1 - Total: 150\n",
            "[06:16:57.262646] ~~~ Epoch 1/150 ~~~\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:58: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:18.191714] Epoch: [1]  [0/3]  eta: 0:07:02  loss: 0.9945 (0.9945)  IoU: 0.0171 (0.0171)  lr: 0.001000  iter-time: 140.9130\n",
            "[06:19:19.893389] Epoch: [1]  [2/3]  eta: 0:00:47  loss: 0.8692 (0.8033)  IoU: 0.0221 (0.0284)  lr: 0.001000  iter-time: 47.5375\n",
            "[06:19:19.980020] Epoch: [1] Total time: 0:02:22 (47.5720 s / it)\n",
            "[06:19:19.980204] [Train] averaged stats: loss: 0.8692 (0.8033)  IoU: 0.0221 (0.0284)  lr: 0.001000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:19:34.170731] Epoch: [1]  [0/1]  eta: 0:00:14  loss: 0.6354 (0.6354)  IoU: 0.0110 (0.0110)  iter-time: 14.1854\n",
            "[06:19:34.274266] Epoch: [1] Total time: 0:00:14 (14.2894 s / it)\n",
            "[06:19:34.274389] [Val] averaged stats: loss: 0.6354 (0.6354)  IoU: 0.0110 (0.0110)\n",
            "[06:19:34.279286] Val loss improved from inf to 0.635416567325592, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:19:34.323714] [Val] best loss: 0.6354 best  IoU: 0.0110 \n",
            "[06:19:34.325775] [Time] 2.6m 2.6m/6.6h\n",
            "\n",
            "[06:19:34.325853] ~~~ Epoch 2/150 ~~~\n",
            "\n",
            "[06:19:35.416985] Epoch: [2]  [0/3]  eta: 0:00:03  loss: 0.4312 (0.4312)  IoU: 0.0527 (0.0527)  lr: 0.001000  iter-time: 1.0876\n",
            "[06:19:37.096895] Epoch: [2]  [2/3]  eta: 0:00:00  loss: 0.5107 (0.4857)  IoU: 0.0752 (0.0769)  lr: 0.001000  iter-time: 0.9214\n",
            "[06:19:37.181728] Epoch: [2] Total time: 0:00:02 (0.9513 s / it)\n",
            "[06:19:37.182747] [Train] averaged stats: loss: 0.5107 (0.4857)  IoU: 0.0752 (0.0769)  lr: 0.001000\n",
            "[06:19:37.425064] Epoch: [2]  [0/1]  eta: 0:00:00  loss: 0.4000 (0.4000)  IoU: 0.0326 (0.0326)  iter-time: 0.2392\n",
            "[06:19:37.503427] Epoch: [2] Total time: 0:00:00 (0.3180 s / it)\n",
            "[06:19:37.504259] [Val] averaged stats: loss: 0.4000 (0.4000)  IoU: 0.0326 (0.0326)\n",
            "[06:19:37.506400] Val loss improved from 0.635416567325592 to 0.39995020627975464, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:19:37.550267] [Val] best loss: 0.4000 best  IoU: 0.0326 \n",
            "[06:19:37.552632] [Time] 3.2s 2.7m/10.7m\n",
            "\n",
            "[06:19:37.553435] ~~~ Epoch 3/150 ~~~\n",
            "\n",
            "[06:19:38.649706] Epoch: [3]  [0/3]  eta: 0:00:03  loss: 0.3180 (0.3180)  IoU: 0.0793 (0.0793)  lr: 0.001000  iter-time: 1.0938\n",
            "[06:19:40.334370] Epoch: [3]  [2/3]  eta: 0:00:00  loss: 0.3527 (0.4082)  IoU: 0.0793 (0.0851)  lr: 0.000999  iter-time: 0.9255\n",
            "[06:19:40.462289] Epoch: [3] Total time: 0:00:02 (0.9693 s / it)\n",
            "[06:19:40.463336] [Train] averaged stats: loss: 0.3527 (0.4082)  IoU: 0.0793 (0.0851)  lr: 0.000999\n",
            "[06:19:40.796849] Epoch: [3]  [0/1]  eta: 0:00:00  loss: 0.1937 (0.1937)  IoU: 0.0014 (0.0014)  iter-time: 0.3313\n",
            "[06:19:40.951198] Epoch: [3] Total time: 0:00:00 (0.4862 s / it)\n",
            "[06:19:40.951321] [Val] averaged stats: loss: 0.1937 (0.1937)  IoU: 0.0014 (0.0014)\n",
            "[06:19:40.951924] Val loss improved from 0.39995020627975464 to 0.19367150962352753, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:19:41.027781] [Val] best loss: 0.1937 best  IoU: 0.0014 \n",
            "[06:19:41.031737] [Time] 3.5s 2.7m/11.3m\n",
            "\n",
            "[06:19:41.032365] ~~~ Epoch 4/150 ~~~\n",
            "\n",
            "[06:19:42.216971] Epoch: [4]  [0/3]  eta: 0:00:03  loss: 0.2844 (0.2844)  IoU: 0.1150 (0.1150)  lr: 0.000999  iter-time: 1.1810\n",
            "[06:19:43.894888] Epoch: [4]  [2/3]  eta: 0:00:00  loss: 0.3318 (0.3986)  IoU: 0.1181 (0.1196)  lr: 0.000999  iter-time: 0.9519\n",
            "[06:19:44.031564] Epoch: [4] Total time: 0:00:02 (0.9991 s / it)\n",
            "[06:19:44.032727] [Train] averaged stats: loss: 0.3318 (0.3986)  IoU: 0.1181 (0.1196)  lr: 0.000999\n",
            "[06:19:44.364192] Epoch: [4]  [0/1]  eta: 0:00:00  loss: 0.1642 (0.1642)  IoU: 0.0000 (0.0000)  iter-time: 0.3280\n",
            "[06:19:44.458728] Epoch: [4] Total time: 0:00:00 (0.4230 s / it)\n",
            "[06:19:44.459622] [Val] averaged stats: loss: 0.1642 (0.1642)  IoU: 0.0000 (0.0000)\n",
            "[06:19:44.461492] Val loss improved from 0.19367150962352753 to 0.16420143842697144, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:19:44.508293] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "[06:19:44.510691] [Time] 3.5s 2.8m/11.3m\n",
            "\n",
            "[06:19:44.511497] ~~~ Epoch 5/150 ~~~\n",
            "\n",
            "[06:19:45.588981] Epoch: [5]  [0/3]  eta: 0:00:03  loss: 0.2943 (0.2943)  IoU: 0.0838 (0.0838)  lr: 0.000998  iter-time: 1.0745\n",
            "[06:19:47.255719] Epoch: [5]  [2/3]  eta: 0:00:00  loss: 0.3328 (0.3558)  IoU: 0.0998 (0.0975)  lr: 0.000998  iter-time: 0.9133\n",
            "[06:19:47.342226] Epoch: [5] Total time: 0:00:02 (0.9431 s / it)\n",
            "[06:19:47.343354] [Train] averaged stats: loss: 0.3328 (0.3558)  IoU: 0.0998 (0.0975)  lr: 0.000998\n",
            "[06:19:47.588307] Epoch: [5]  [0/1]  eta: 0:00:00  loss: 0.1796 (0.1796)  IoU: 0.0000 (0.0000)  iter-time: 0.2419\n",
            "[06:19:47.673367] Epoch: [5] Total time: 0:00:00 (0.3275 s / it)\n",
            "[06:19:47.674316] [Val] averaged stats: loss: 0.1796 (0.1796)  IoU: 0.0000 (0.0000)\n",
            "[06:19:47.676242] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "[06:19:47.678372] Creating training plots . . .\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[06:19:48.071764] [Time] 3.6s 2.8m/11.5m\n",
            "\n",
            "[06:19:48.071831] ~~~ Epoch 6/150 ~~~\n",
            "\n",
            "[06:19:49.130486] Epoch: [6]  [0/3]  eta: 0:00:03  loss: 0.2677 (0.2677)  IoU: 0.1039 (0.1039)  lr: 0.000997  iter-time: 1.0560\n",
            "[06:19:50.797138] Epoch: [6]  [2/3]  eta: 0:00:00  loss: 0.3203 (0.3278)  IoU: 0.1161 (0.1200)  lr: 0.000996  iter-time: 0.9070\n",
            "[06:19:50.877497] Epoch: [6] Total time: 0:00:02 (0.9348 s / it)\n",
            "[06:19:50.878690] [Train] averaged stats: loss: 0.3203 (0.3278)  IoU: 0.1161 (0.1200)  lr: 0.000996\n",
            "[06:19:51.120883] Epoch: [6]  [0/1]  eta: 0:00:00  loss: 0.2629 (0.2629)  IoU: 0.0000 (0.0000)  iter-time: 0.2391\n",
            "[06:19:51.204019] Epoch: [6] Total time: 0:00:00 (0.3229 s / it)\n",
            "[06:19:51.204148] [Val] averaged stats: loss: 0.2629 (0.2629)  IoU: 0.0000 (0.0000)\n",
            "[06:19:51.206665] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[06:19:51.209005] [Time] 3.1s 2.9m/10.5m\n",
            "\n",
            "[06:19:51.209062] ~~~ Epoch 7/150 ~~~\n",
            "\n",
            "[06:19:52.289761] Epoch: [7]  [0/3]  eta: 0:00:03  loss: 0.2465 (0.2465)  IoU: 0.1057 (0.1057)  lr: 0.000996  iter-time: 1.0783\n",
            "[06:19:53.970255] Epoch: [7]  [2/3]  eta: 0:00:00  loss: 0.2955 (0.3075)  IoU: 0.1067 (0.1149)  lr: 0.000995  iter-time: 0.9191\n",
            "[06:19:54.050364] Epoch: [7] Total time: 0:00:02 (0.9468 s / it)\n",
            "[06:19:54.051518] [Train] averaged stats: loss: 0.2955 (0.3075)  IoU: 0.1067 (0.1149)  lr: 0.000995\n",
            "[06:19:54.290228] Epoch: [7]  [0/1]  eta: 0:00:00  loss: 0.2681 (0.2681)  IoU: 0.0000 (0.0000)  iter-time: 0.2355\n",
            "[06:19:54.412377] Epoch: [7] Total time: 0:00:00 (0.3581 s / it)\n",
            "[06:19:54.412518] [Val] averaged stats: loss: 0.2681 (0.2681)  IoU: 0.0000 (0.0000)\n",
            "[06:19:54.413181] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[06:19:54.415413] [Time] 3.2s 3.0m/10.6m\n",
            "\n",
            "[06:19:54.415462] ~~~ Epoch 8/150 ~~~\n",
            "\n",
            "[06:19:55.661256] Epoch: [8]  [0/3]  eta: 0:00:03  loss: 0.2329 (0.2329)  IoU: 0.1196 (0.1196)  lr: 0.000995  iter-time: 1.2415\n",
            "[06:19:57.336789] Epoch: [8]  [2/3]  eta: 0:00:00  loss: 0.2803 (0.3013)  IoU: 0.1407 (0.1456)  lr: 0.000994  iter-time: 0.9703\n",
            "[06:19:57.471813] Epoch: [8] Total time: 0:00:03 (1.0184 s / it)\n",
            "[06:19:57.472024] [Train] averaged stats: loss: 0.2803 (0.3013)  IoU: 0.1407 (0.1456)  lr: 0.000994\n",
            "[06:19:57.795399] Epoch: [8]  [0/1]  eta: 0:00:00  loss: 0.3150 (0.3150)  IoU: 0.0000 (0.0000)  iter-time: 0.3209\n",
            "[06:19:57.920428] Epoch: [8] Total time: 0:00:00 (0.4468 s / it)\n",
            "[06:19:57.921160] [Val] averaged stats: loss: 0.3150 (0.3150)  IoU: 0.0000 (0.0000)\n",
            "[06:19:57.923486] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[06:19:57.925715] [Time] 3.5s 3.0m/11.4m\n",
            "\n",
            "[06:19:57.925760] ~~~ Epoch 9/150 ~~~\n",
            "\n",
            "[06:19:58.987452] Epoch: [9]  [0/3]  eta: 0:00:03  loss: 0.2330 (0.2330)  IoU: 0.1114 (0.1114)  lr: 0.000993  iter-time: 1.0590\n",
            "[06:20:00.670687] Epoch: [9]  [2/3]  eta: 0:00:00  loss: 0.2725 (0.2858)  IoU: 0.1360 (0.1288)  lr: 0.000992  iter-time: 0.9135\n",
            "[06:20:00.766974] Epoch: [9] Total time: 0:00:02 (0.9467 s / it)\n",
            "[06:20:00.768091] [Train] averaged stats: loss: 0.2725 (0.2858)  IoU: 0.1360 (0.1288)  lr: 0.000992\n",
            "[06:20:01.015814] Epoch: [9]  [0/1]  eta: 0:00:00  loss: 0.2820 (0.2820)  IoU: 0.0000 (0.0000)  iter-time: 0.2445\n",
            "[06:20:01.093861] Epoch: [9] Total time: 0:00:00 (0.3231 s / it)\n",
            "[06:20:01.094013] [Val] averaged stats: loss: 0.2820 (0.2820)  IoU: 0.0000 (0.0000)\n",
            "[06:20:01.096461] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[06:20:01.098747] [Time] 3.2s 3.1m/10.6m\n",
            "\n",
            "[06:20:01.098807] ~~~ Epoch 10/150 ~~~\n",
            "\n",
            "[06:20:02.159594] Epoch: [10]  [0/3]  eta: 0:00:03  loss: 0.2174 (0.2174)  IoU: 0.1404 (0.1404)  lr: 0.000991  iter-time: 1.0582\n",
            "[06:20:03.847537] Epoch: [10]  [2/3]  eta: 0:00:00  loss: 0.2654 (0.2746)  IoU: 0.1520 (0.1542)  lr: 0.000990  iter-time: 0.9149\n",
            "[06:20:03.929457] Epoch: [10] Total time: 0:00:02 (0.9432 s / it)\n",
            "[06:20:03.930553] [Train] averaged stats: loss: 0.2654 (0.2746)  IoU: 0.1520 (0.1542)  lr: 0.000990\n",
            "[06:20:04.179355] Epoch: [10]  [0/1]  eta: 0:00:00  loss: 0.2903 (0.2903)  IoU: 0.0000 (0.0000)  iter-time: 0.2458\n",
            "[06:20:04.266796] Epoch: [10] Total time: 0:00:00 (0.3337 s / it)\n",
            "[06:20:04.267792] [Val] averaged stats: loss: 0.2903 (0.2903)  IoU: 0.0000 (0.0000)\n",
            "[06:20:04.269148] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "[06:20:04.271523] Creating training plots . . .\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[06:20:04.586815] [Time] 3.5s 3.1m/11.3m\n",
            "\n",
            "[06:20:04.588345] ~~~ Epoch 11/150 ~~~\n",
            "\n",
            "[06:20:05.698888] Epoch: [11]  [0/3]  eta: 0:00:03  loss: 0.2097 (0.2097)  IoU: 0.1359 (0.1359)  lr: 0.000989  iter-time: 1.1078\n",
            "[06:20:07.402185] Epoch: [11]  [2/3]  eta: 0:00:00  loss: 0.2534 (0.2637)  IoU: 0.1386 (0.1429)  lr: 0.000988  iter-time: 0.9366\n",
            "[06:20:07.484197] Epoch: [11] Total time: 0:00:02 (0.9649 s / it)\n",
            "[06:20:07.485205] [Train] averaged stats: loss: 0.2534 (0.2637)  IoU: 0.1386 (0.1429)  lr: 0.000988\n",
            "[06:20:07.724246] Epoch: [11]  [0/1]  eta: 0:00:00  loss: 0.2674 (0.2674)  IoU: 0.0000 (0.0000)  iter-time: 0.2360\n",
            "[06:20:07.803243] Epoch: [11] Total time: 0:00:00 (0.3155 s / it)\n",
            "[06:20:07.803377] [Val] averaged stats: loss: 0.2674 (0.2674)  IoU: 0.0000 (0.0000)\n",
            "[06:20:07.805805] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[06:20:07.808110] [Time] 3.2s 3.2m/10.7m\n",
            "\n",
            "[06:20:07.808172] ~~~ Epoch 12/150 ~~~\n",
            "\n",
            "[06:20:09.026529] Epoch: [12]  [0/3]  eta: 0:00:03  loss: 0.1992 (0.1992)  IoU: 0.1496 (0.1496)  lr: 0.000987  iter-time: 1.2159\n",
            "[06:20:10.741745] Epoch: [12]  [2/3]  eta: 0:00:00  loss: 0.2439 (0.2565)  IoU: 0.1673 (0.1709)  lr: 0.000985  iter-time: 0.9760\n",
            "[06:20:10.881831] Epoch: [12] Total time: 0:00:03 (1.0242 s / it)\n",
            "[06:20:10.882105] [Train] averaged stats: loss: 0.2439 (0.2565)  IoU: 0.1673 (0.1709)  lr: 0.000985\n",
            "[06:20:11.189358] Epoch: [12]  [0/1]  eta: 0:00:00  loss: 0.2379 (0.2379)  IoU: 0.0000 (0.0000)  iter-time: 0.3049\n",
            "[06:20:11.324857] Epoch: [12] Total time: 0:00:00 (0.4411 s / it)\n",
            "[06:20:11.325982] [Val] averaged stats: loss: 0.2379 (0.2379)  IoU: 0.0000 (0.0000)\n",
            "[06:20:11.327774] [Val] best loss: 0.1642 best  IoU: 0.0000 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[06:20:11.329922] [Time] 3.5s 3.2m/11.4m\n",
            "\n",
            "[06:20:11.330006] ~~~ Epoch 13/150 ~~~\n",
            "\n",
            "[06:20:12.437394] Epoch: [13]  [0/3]  eta: 0:00:03  loss: 0.1964 (0.1964)  IoU: 0.1387 (0.1387)  lr: 0.000984  iter-time: 1.1034\n",
            "[06:20:14.156222] Epoch: [13]  [2/3]  eta: 0:00:00  loss: 0.2357 (0.2464)  IoU: 0.1623 (0.1562)  lr: 0.000983  iter-time: 0.9403\n",
            "[06:20:14.241973] Epoch: [13] Total time: 0:00:02 (0.9698 s / it)\n",
            "[06:20:14.242966] [Train] averaged stats: loss: 0.2357 (0.2464)  IoU: 0.1623 (0.1562)  lr: 0.000983\n",
            "[06:20:14.497417] Epoch: [13]  [0/1]  eta: 0:00:00  loss: 0.1582 (0.1582)  IoU: 0.0120 (0.0120)  iter-time: 0.2511\n",
            "[06:20:14.580697] Epoch: [13] Total time: 0:00:00 (0.3351 s / it)\n",
            "[06:20:14.580853] [Val] averaged stats: loss: 0.1582 (0.1582)  IoU: 0.0120 (0.0120)\n",
            "[06:20:14.583347] Val loss improved from 0.16420143842697144 to 0.15824824571609497, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:14.630791] [Val] best loss: 0.1582 best  IoU: 0.0120 \n",
            "[06:20:14.631786] [Time] 3.3s 3.3m/10.9m\n",
            "\n",
            "[06:20:14.631874] ~~~ Epoch 14/150 ~~~\n",
            "\n",
            "[06:20:15.742969] Epoch: [14]  [0/3]  eta: 0:00:03  loss: 0.1858 (0.1858)  IoU: 0.1706 (0.1706)  lr: 0.000982  iter-time: 1.1085\n",
            "[06:20:17.469549] Epoch: [14]  [2/3]  eta: 0:00:00  loss: 0.2283 (0.2377)  IoU: 0.1740 (0.1831)  lr: 0.000980  iter-time: 0.9447\n",
            "[06:20:17.563730] Epoch: [14] Total time: 0:00:02 (0.9769 s / it)\n",
            "[06:20:17.564731] [Train] averaged stats: loss: 0.2283 (0.2377)  IoU: 0.1740 (0.1831)  lr: 0.000980\n",
            "[06:20:17.811971] Epoch: [14]  [0/1]  eta: 0:00:00  loss: 0.1402 (0.1402)  IoU: 0.0438 (0.0438)  iter-time: 0.2441\n",
            "[06:20:17.895580] Epoch: [14] Total time: 0:00:00 (0.3282 s / it)\n",
            "[06:20:17.895705] [Val] averaged stats: loss: 0.1402 (0.1402)  IoU: 0.0438 (0.0438)\n",
            "[06:20:17.898290] Val loss improved from 0.15824824571609497 to 0.140171080827713, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:17.943358] [Val] best loss: 0.1402 best  IoU: 0.0438 \n",
            "[06:20:17.944622] [Time] 3.3s 3.3m/10.9m\n",
            "\n",
            "[06:20:17.944698] ~~~ Epoch 15/150 ~~~\n",
            "\n",
            "[06:20:19.070750] Epoch: [15]  [0/3]  eta: 0:00:03  loss: 0.1825 (0.1825)  IoU: 0.1559 (0.1559)  lr: 0.000979  iter-time: 1.1236\n",
            "[06:20:20.795762] Epoch: [15]  [2/3]  eta: 0:00:00  loss: 0.2208 (0.2297)  IoU: 0.1785 (0.1736)  lr: 0.000977  iter-time: 0.9486\n",
            "[06:20:20.878422] Epoch: [15] Total time: 0:00:02 (0.9776 s / it)\n",
            "[06:20:20.879399] [Train] averaged stats: loss: 0.2208 (0.2297)  IoU: 0.1785 (0.1736)  lr: 0.000977\n",
            "[06:20:21.121840] Epoch: [15]  [0/1]  eta: 0:00:00  loss: 0.1272 (0.1272)  IoU: 0.0755 (0.0755)  iter-time: 0.2395\n",
            "[06:20:21.203200] Epoch: [15] Total time: 0:00:00 (0.3214 s / it)\n",
            "[06:20:21.203433] [Val] averaged stats: loss: 0.1272 (0.1272)  IoU: 0.0755 (0.0755)\n",
            "[06:20:21.203890] Val loss improved from 0.140171080827713 to 0.12717655301094055, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:21.251568] [Val] best loss: 0.1272 best  IoU: 0.0755 \n",
            "[06:20:21.253984] Creating training plots . . .\n",
            "[06:20:22.118792] [Time] 4.2s 3.4m/12.9m\n",
            "\n",
            "[06:20:22.120143] ~~~ Epoch 16/150 ~~~\n",
            "\n",
            "[06:20:23.427153] Epoch: [16]  [0/3]  eta: 0:00:03  loss: 0.1747 (0.1747)  IoU: 0.1795 (0.1795)  lr: 0.000976  iter-time: 1.3036\n",
            "[06:20:25.150251] Epoch: [16]  [2/3]  eta: 0:00:01  loss: 0.2165 (0.2238)  IoU: 0.1795 (0.1850)  lr: 0.000973  iter-time: 1.0080\n",
            "[06:20:25.295332] Epoch: [16] Total time: 0:00:03 (1.0577 s / it)\n",
            "[06:20:25.296486] [Train] averaged stats: loss: 0.2165 (0.2238)  IoU: 0.1795 (0.1850)  lr: 0.000973\n",
            "[06:20:25.625061] Epoch: [16]  [0/1]  eta: 0:00:00  loss: 0.1043 (0.1043)  IoU: 0.1537 (0.1537)  iter-time: 0.3250\n",
            "[06:20:25.711062] Epoch: [16] Total time: 0:00:00 (0.4115 s / it)\n",
            "[06:20:25.711191] [Val] averaged stats: loss: 0.1043 (0.1043)  IoU: 0.1537 (0.1537)\n",
            "[06:20:25.713652] Val loss improved from 0.12717655301094055 to 0.10432696342468262, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:25.758567] [Val] best loss: 0.1043 best  IoU: 0.1537 \n",
            "[06:20:25.761044] [Time] 3.6s 3.5m/11.7m\n",
            "\n",
            "[06:20:25.761759] ~~~ Epoch 17/150 ~~~\n",
            "\n",
            "[06:20:26.884455] Epoch: [17]  [0/3]  eta: 0:00:03  loss: 0.1723 (0.1723)  IoU: 0.1632 (0.1632)  lr: 0.000972  iter-time: 1.1198\n",
            "[06:20:28.589584] Epoch: [17]  [2/3]  eta: 0:00:00  loss: 0.2142 (0.2190)  IoU: 0.2030 (0.1904)  lr: 0.000970  iter-time: 0.9405\n",
            "[06:20:28.671986] Epoch: [17] Total time: 0:00:02 (0.9696 s / it)\n",
            "[06:20:28.673313] [Train] averaged stats: loss: 0.2142 (0.2190)  IoU: 0.2030 (0.1904)  lr: 0.000970\n",
            "[06:20:28.912365] Epoch: [17]  [0/1]  eta: 0:00:00  loss: 0.0749 (0.0749)  IoU: 0.1938 (0.1938)  iter-time: 0.2362\n",
            "[06:20:29.013206] Epoch: [17] Total time: 0:00:00 (0.3376 s / it)\n",
            "[06:20:29.013332] [Val] averaged stats: loss: 0.0749 (0.0749)  IoU: 0.1938 (0.1938)\n",
            "[06:20:29.015867] Val loss improved from 0.10432696342468262 to 0.07492710649967194, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:29.060147] [Val] best loss: 0.0749 best  IoU: 0.1938 \n",
            "[06:20:29.062665] [Time] 3.3s 3.5m/10.9m\n",
            "\n",
            "[06:20:29.063489] ~~~ Epoch 18/150 ~~~\n",
            "\n",
            "[06:20:30.183013] Epoch: [18]  [0/3]  eta: 0:00:03  loss: 0.1656 (0.1656)  IoU: 0.1883 (0.1883)  lr: 0.000969  iter-time: 1.1172\n",
            "[06:20:31.897539] Epoch: [18]  [2/3]  eta: 0:00:00  loss: 0.2053 (0.2115)  IoU: 0.1883 (0.1887)  lr: 0.000966  iter-time: 0.9427\n",
            "[06:20:31.979579] Epoch: [18] Total time: 0:00:02 (0.9717 s / it)\n",
            "[06:20:31.980640] [Train] averaged stats: loss: 0.2053 (0.2115)  IoU: 0.1883 (0.1887)  lr: 0.000966\n",
            "[06:20:32.241497] Epoch: [18]  [0/1]  eta: 0:00:00  loss: 0.0702 (0.0702)  IoU: 0.1998 (0.1998)  iter-time: 0.2578\n",
            "[06:20:32.326305] Epoch: [18] Total time: 0:00:00 (0.3432 s / it)\n",
            "[06:20:32.326413] [Val] averaged stats: loss: 0.0702 (0.0702)  IoU: 0.1998 (0.1998)\n",
            "[06:20:32.326907] Val loss improved from 0.07492710649967194 to 0.07023672759532928, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:32.370649] [Val] best loss: 0.0702 best  IoU: 0.1998 \n",
            "[06:20:32.371809] [Time] 3.3s 3.6m/10.9m\n",
            "\n",
            "[06:20:32.371907] ~~~ Epoch 19/150 ~~~\n",
            "\n",
            "[06:20:33.487782] Epoch: [19]  [0/3]  eta: 0:00:03  loss: 0.1591 (0.1591)  IoU: 0.1923 (0.1923)  lr: 0.000965  iter-time: 1.1130\n",
            "[06:20:35.190589] Epoch: [19]  [2/3]  eta: 0:00:00  loss: 0.2000 (0.2077)  IoU: 0.1923 (0.2038)  lr: 0.000962  iter-time: 0.9381\n",
            "[06:20:35.273607] Epoch: [19] Total time: 0:00:02 (0.9668 s / it)\n",
            "[06:20:35.273789] [Train] averaged stats: loss: 0.2000 (0.2077)  IoU: 0.1923 (0.2038)  lr: 0.000962\n",
            "[06:20:35.516181] Epoch: [19]  [0/1]  eta: 0:00:00  loss: 0.0635 (0.0635)  IoU: 0.1849 (0.1849)  iter-time: 0.2401\n",
            "[06:20:35.616186] Epoch: [19] Total time: 0:00:00 (0.3406 s / it)\n",
            "[06:20:35.616305] [Val] averaged stats: loss: 0.0635 (0.0635)  IoU: 0.1849 (0.1849)\n",
            "[06:20:35.616895] Val loss improved from 0.07023672759532928 to 0.06352968513965607, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:35.689796] [Val] best loss: 0.0635 best  IoU: 0.1849 \n",
            "[06:20:35.692782] [Time] 3.3s 3.6m/10.9m\n",
            "\n",
            "[06:20:35.693700] ~~~ Epoch 20/150 ~~~\n",
            "\n",
            "[06:20:36.985744] Epoch: [20]  [0/3]  eta: 0:00:03  loss: 0.1624 (0.1624)  IoU: 0.1662 (0.1662)  lr: 0.000961  iter-time: 1.2885\n",
            "[06:20:38.686305] Epoch: [20]  [2/3]  eta: 0:00:00  loss: 0.2024 (0.2045)  IoU: 0.2059 (0.2005)  lr: 0.000958  iter-time: 0.9959\n",
            "[06:20:38.827178] Epoch: [20] Total time: 0:00:03 (1.0438 s / it)\n",
            "[06:20:38.828388] [Train] averaged stats: loss: 0.2024 (0.2045)  IoU: 0.2059 (0.2005)  lr: 0.000958\n",
            "[06:20:39.167440] Epoch: [20]  [0/1]  eta: 0:00:00  loss: 0.0601 (0.0601)  IoU: 0.1786 (0.1786)  iter-time: 0.3348\n",
            "[06:20:39.257359] Epoch: [20] Total time: 0:00:00 (0.4252 s / it)\n",
            "[06:20:39.258394] [Val] averaged stats: loss: 0.0601 (0.0601)  IoU: 0.1786 (0.1786)\n",
            "[06:20:39.260361] Val loss improved from 0.06352968513965607 to 0.060076773166656494, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:39.303771] [Val] best loss: 0.0601 best  IoU: 0.1786 \n",
            "[06:20:39.306160] Creating training plots . . .\n",
            "[06:20:39.655578] [Time] 4.0s 3.7m/12.4m\n",
            "\n",
            "[06:20:39.655714] ~~~ Epoch 21/150 ~~~\n",
            "\n",
            "[06:20:40.746289] Epoch: [21]  [0/3]  eta: 0:00:03  loss: 0.1542 (0.1542)  IoU: 0.2122 (0.2122)  lr: 0.000957  iter-time: 1.0853\n",
            "[06:20:42.444772] Epoch: [21]  [2/3]  eta: 0:00:00  loss: 0.1952 (0.1985)  IoU: 0.2073 (0.2001)  lr: 0.000954  iter-time: 0.9275\n",
            "[06:20:42.538005] Epoch: [21] Total time: 0:00:02 (0.9595 s / it)\n",
            "[06:20:42.539232] [Train] averaged stats: loss: 0.1952 (0.1985)  IoU: 0.2073 (0.2001)  lr: 0.000954\n",
            "[06:20:42.787428] Epoch: [21]  [0/1]  eta: 0:00:00  loss: 0.0595 (0.0595)  IoU: 0.1786 (0.1786)  iter-time: 0.2452\n",
            "[06:20:42.870112] Epoch: [21] Total time: 0:00:00 (0.3283 s / it)\n",
            "[06:20:42.870233] [Val] averaged stats: loss: 0.0595 (0.0595)  IoU: 0.1786 (0.1786)\n",
            "[06:20:42.872294] Val loss improved from 0.060076773166656494 to 0.059467725455760956, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:42.918279] [Val] best loss: 0.0595 best  IoU: 0.1786 \n",
            "[06:20:42.920753] [Time] 3.3s 3.8m/10.8m\n",
            "\n",
            "[06:20:42.920831] ~~~ Epoch 22/150 ~~~\n",
            "\n",
            "[06:20:44.021909] Epoch: [22]  [0/3]  eta: 0:00:03  loss: 0.1515 (0.1515)  IoU: 0.2048 (0.2048)  lr: 0.000952  iter-time: 1.0984\n",
            "[06:20:45.722645] Epoch: [22]  [2/3]  eta: 0:00:00  loss: 0.1891 (0.1963)  IoU: 0.2048 (0.2176)  lr: 0.000949  iter-time: 0.9326\n",
            "[06:20:45.805574] Epoch: [22] Total time: 0:00:02 (0.9613 s / it)\n",
            "[06:20:45.806799] [Train] averaged stats: loss: 0.1891 (0.1963)  IoU: 0.2048 (0.2176)  lr: 0.000949\n",
            "[06:20:46.045733] Epoch: [22]  [0/1]  eta: 0:00:00  loss: 0.0566 (0.0566)  IoU: 0.1613 (0.1613)  iter-time: 0.2358\n",
            "[06:20:46.130106] Epoch: [22] Total time: 0:00:00 (0.3207 s / it)\n",
            "[06:20:46.130380] [Val] averaged stats: loss: 0.0566 (0.0566)  IoU: 0.1613 (0.1613)\n",
            "[06:20:46.133042] Val loss improved from 0.059467725455760956 to 0.056618522852659225, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:46.178640] [Val] best loss: 0.0566 best  IoU: 0.1613 \n",
            "[06:20:46.180484] [Time] 3.3s 3.8m/10.8m\n",
            "\n",
            "[06:20:46.183084] ~~~ Epoch 23/150 ~~~\n",
            "\n",
            "[06:20:47.297302] Epoch: [23]  [0/3]  eta: 0:00:03  loss: 0.1494 (0.1494)  IoU: 0.1805 (0.1805)  lr: 0.000948  iter-time: 1.1115\n",
            "[06:20:48.999185] Epoch: [23]  [2/3]  eta: 0:00:00  loss: 0.1875 (0.1906)  IoU: 0.2189 (0.2094)  lr: 0.000945  iter-time: 0.9373\n",
            "[06:20:49.083559] Epoch: [23] Total time: 0:00:02 (0.9664 s / it)\n",
            "[06:20:49.084572] [Train] averaged stats: loss: 0.1875 (0.1906)  IoU: 0.2189 (0.2094)  lr: 0.000945\n",
            "[06:20:49.391431] Epoch: [23]  [0/1]  eta: 0:00:00  loss: 0.0566 (0.0566)  IoU: 0.1701 (0.1701)  iter-time: 0.3031\n",
            "[06:20:49.527881] Epoch: [23] Total time: 0:00:00 (0.4401 s / it)\n",
            "[06:20:49.528074] [Val] averaged stats: loss: 0.0566 (0.0566)  IoU: 0.1701 (0.1701)\n",
            "[06:20:49.530247] Val loss improved from 0.056618522852659225 to 0.056595973670482635, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:49.606047] [Val] best loss: 0.0566 best  IoU: 0.1701 \n",
            "[06:20:49.610534] [Time] 3.4s 3.9m/11.2m\n",
            "\n",
            "[06:20:49.611449] ~~~ Epoch 24/150 ~~~\n",
            "\n",
            "[06:20:50.902233] Epoch: [24]  [0/3]  eta: 0:00:03  loss: 0.1419 (0.1419)  IoU: 0.2226 (0.2226)  lr: 0.000943  iter-time: 1.2875\n",
            "[06:20:52.602057] Epoch: [24]  [2/3]  eta: 0:00:00  loss: 0.1783 (0.1832)  IoU: 0.2226 (0.2192)  lr: 0.000940  iter-time: 0.9947\n",
            "[06:20:52.767366] Epoch: [24] Total time: 0:00:03 (1.0514 s / it)\n",
            "[06:20:52.767551] [Train] averaged stats: loss: 0.1783 (0.1832)  IoU: 0.2226 (0.2192)  lr: 0.000940\n",
            "[06:20:53.209208] Epoch: [24]  [0/1]  eta: 0:00:00  loss: 0.0559 (0.0559)  IoU: 0.1614 (0.1614)  iter-time: 0.4391\n",
            "[06:20:53.364366] Epoch: [24] Total time: 0:00:00 (0.5951 s / it)\n",
            "[06:20:53.364486] [Val] averaged stats: loss: 0.0559 (0.0559)  IoU: 0.1614 (0.1614)\n",
            "[06:20:53.366694] Val loss improved from 0.056595973670482635 to 0.05588574334979057, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:53.472529] [Val] best loss: 0.0559 best  IoU: 0.1614 \n",
            "[06:20:53.476853] [Time] 3.9s 3.9m/12.1m\n",
            "\n",
            "[06:20:53.477817] ~~~ Epoch 25/150 ~~~\n",
            "\n",
            "[06:20:54.744323] Epoch: [25]  [0/3]  eta: 0:00:03  loss: 0.1400 (0.1400)  IoU: 0.2104 (0.2104)  lr: 0.000938  iter-time: 1.2630\n",
            "[06:20:56.439443] Epoch: [25]  [2/3]  eta: 0:00:00  loss: 0.1753 (0.1824)  IoU: 0.2189 (0.2248)  lr: 0.000935  iter-time: 0.9850\n",
            "[06:20:56.593840] Epoch: [25] Total time: 0:00:03 (1.0380 s / it)\n",
            "[06:20:56.594123] [Train] averaged stats: loss: 0.1753 (0.1824)  IoU: 0.2189 (0.2248)  lr: 0.000935\n",
            "[06:20:56.920523] Epoch: [25]  [0/1]  eta: 0:00:00  loss: 0.0552 (0.0552)  IoU: 0.1553 (0.1553)  iter-time: 0.3214\n",
            "[06:20:57.005750] Epoch: [25] Total time: 0:00:00 (0.4071 s / it)\n",
            "[06:20:57.006716] [Val] averaged stats: loss: 0.0552 (0.0552)  IoU: 0.1553 (0.1553)\n",
            "[06:20:57.009165] Val loss improved from 0.05588574334979057 to 0.05516257882118225, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:20:57.059854] [Val] best loss: 0.0552 best  IoU: 0.1553 \n",
            "[06:20:57.062164] Creating training plots . . .\n",
            "[06:20:57.383304] [Time] 3.9s 4.0m/12.2m\n",
            "\n",
            "[06:20:57.383438] ~~~ Epoch 26/150 ~~~\n",
            "\n",
            "[06:20:58.500611] Epoch: [26]  [0/3]  eta: 0:00:03  loss: 0.1362 (0.1362)  IoU: 0.2062 (0.2062)  lr: 0.000933  iter-time: 1.1130\n",
            "[06:21:00.187903] Epoch: [26]  [2/3]  eta: 0:00:00  loss: 0.1725 (0.1770)  IoU: 0.2248 (0.2225)  lr: 0.000929  iter-time: 0.9330\n",
            "[06:21:00.276787] Epoch: [26] Total time: 0:00:02 (0.9636 s / it)\n",
            "[06:21:00.276999] [Train] averaged stats: loss: 0.1725 (0.1770)  IoU: 0.2248 (0.2225)  lr: 0.000929\n",
            "[06:21:00.531960] Epoch: [26]  [0/1]  eta: 0:00:00  loss: 0.0542 (0.0542)  IoU: 0.1644 (0.1644)  iter-time: 0.2522\n",
            "[06:21:00.614922] Epoch: [26] Total time: 0:00:00 (0.3362 s / it)\n",
            "[06:21:00.615084] [Val] averaged stats: loss: 0.0542 (0.0542)  IoU: 0.1644 (0.1644)\n",
            "[06:21:00.617488] Val loss improved from 0.05516257882118225 to 0.05416044592857361, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:21:00.667485] [Val] best loss: 0.0542 best  IoU: 0.1644 \n",
            "[06:21:00.669883] [Time] 3.3s 4.1m/10.9m\n",
            "\n",
            "[06:21:00.669994] ~~~ Epoch 27/150 ~~~\n",
            "\n",
            "[06:21:01.737658] Epoch: [27]  [0/3]  eta: 0:00:03  loss: 0.1328 (0.1328)  IoU: 0.2309 (0.2309)  lr: 0.000928  iter-time: 1.0653\n",
            "[06:21:03.423165] Epoch: [27]  [2/3]  eta: 0:00:00  loss: 0.1681 (0.1730)  IoU: 0.2309 (0.2324)  lr: 0.000924  iter-time: 0.9165\n",
            "[06:21:03.508211] Epoch: [27] Total time: 0:00:02 (0.9458 s / it)\n",
            "[06:21:03.509227] [Train] averaged stats: loss: 0.1681 (0.1730)  IoU: 0.2309 (0.2324)  lr: 0.000924\n",
            "[06:21:03.793282] Epoch: [27]  [0/1]  eta: 0:00:00  loss: 0.0530 (0.0530)  IoU: 0.1661 (0.1661)  iter-time: 0.2808\n",
            "[06:21:03.919164] Epoch: [27] Total time: 0:00:00 (0.4074 s / it)\n",
            "[06:21:03.919318] [Val] averaged stats: loss: 0.0530 (0.0530)  IoU: 0.1661 (0.1661)\n",
            "[06:21:03.921432] Val loss improved from 0.05416044592857361 to 0.052974216639995575, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:21:03.988124] [Val] best loss: 0.0530 best  IoU: 0.1661 \n",
            "[06:21:03.990631] [Time] 3.3s 4.1m/11.0m\n",
            "\n",
            "[06:21:03.990717] ~~~ Epoch 28/150 ~~~\n",
            "\n",
            "[06:21:05.236180] Epoch: [28]  [0/3]  eta: 0:00:03  loss: 0.1298 (0.1298)  IoU: 0.2212 (0.2212)  lr: 0.000922  iter-time: 1.2425\n",
            "[06:21:06.923975] Epoch: [28]  [2/3]  eta: 0:00:00  loss: 0.1653 (0.1710)  IoU: 0.2321 (0.2331)  lr: 0.000918  iter-time: 0.9757\n",
            "[06:21:07.064475] Epoch: [28] Total time: 0:00:03 (1.0242 s / it)\n",
            "[06:21:07.064675] [Train] averaged stats: loss: 0.1653 (0.1710)  IoU: 0.2321 (0.2331)  lr: 0.000918\n",
            "[06:21:07.395013] Epoch: [28]  [0/1]  eta: 0:00:00  loss: 0.0529 (0.0529)  IoU: 0.1656 (0.1656)  iter-time: 0.3280\n",
            "[06:21:07.483078] Epoch: [28] Total time: 0:00:00 (0.4166 s / it)\n",
            "[06:21:07.483210] [Val] averaged stats: loss: 0.0529 (0.0529)  IoU: 0.1656 (0.1656)\n",
            "[06:21:07.485833] Val loss improved from 0.052974216639995575 to 0.05294425040483475, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:21:07.529876] [Val] best loss: 0.0529 best  IoU: 0.1656 \n",
            "[06:21:07.532326] [Time] 3.5s 4.2m/11.4m\n",
            "\n",
            "[06:21:07.532412] ~~~ Epoch 29/150 ~~~\n",
            "\n",
            "[06:21:08.653638] Epoch: [29]  [0/3]  eta: 0:00:03  loss: 0.1286 (0.1286)  IoU: 0.2237 (0.2237)  lr: 0.000916  iter-time: 1.1177\n",
            "[06:21:10.353251] Epoch: [29]  [2/3]  eta: 0:00:00  loss: 0.1627 (0.1670)  IoU: 0.2380 (0.2363)  lr: 0.000913  iter-time: 0.9386\n",
            "[06:21:10.441588] Epoch: [29] Total time: 0:00:02 (0.9694 s / it)\n",
            "[06:21:10.442630] [Train] averaged stats: loss: 0.1627 (0.1670)  IoU: 0.2380 (0.2363)  lr: 0.000913\n",
            "[06:21:10.689874] Epoch: [29]  [0/1]  eta: 0:00:00  loss: 0.0524 (0.0524)  IoU: 0.1689 (0.1689)  iter-time: 0.2441\n",
            "[06:21:10.775228] Epoch: [29] Total time: 0:00:00 (0.3301 s / it)\n",
            "[06:21:10.776079] [Val] averaged stats: loss: 0.0524 (0.0524)  IoU: 0.1689 (0.1689)\n",
            "[06:21:10.778007] Val loss improved from 0.05294425040483475 to 0.0523991696536541, saving model to /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:21:10.822108] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "[06:21:10.824401] [Time] 3.3s 4.2m/10.9m\n",
            "\n",
            "[06:21:10.824481] ~~~ Epoch 30/150 ~~~\n",
            "\n",
            "[06:21:11.946474] Epoch: [30]  [0/3]  eta: 0:00:03  loss: 0.1253 (0.1253)  IoU: 0.2351 (0.2351)  lr: 0.000911  iter-time: 1.1183\n",
            "[06:21:13.650127] Epoch: [30]  [2/3]  eta: 0:00:00  loss: 0.1645 (0.1687)  IoU: 0.2351 (0.2347)  lr: 0.000907  iter-time: 0.9401\n",
            "[06:21:13.734622] Epoch: [30] Total time: 0:00:02 (0.9693 s / it)\n",
            "[06:21:13.735669] [Train] averaged stats: loss: 0.1645 (0.1687)  IoU: 0.2351 (0.2347)  lr: 0.000907\n",
            "[06:21:13.989669] Epoch: [30]  [0/1]  eta: 0:00:00  loss: 0.0537 (0.0537)  IoU: 0.1749 (0.1749)  iter-time: 0.2510\n",
            "[06:21:14.073725] Epoch: [30] Total time: 0:00:00 (0.3355 s / it)\n",
            "[06:21:14.073847] [Val] averaged stats: loss: 0.0537 (0.0537)  IoU: 0.1749 (0.1749)\n",
            "[06:21:14.074496] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "[06:21:14.079058] Creating training plots . . .\n",
            "EarlyStopping counter: 1 out of 20\n",
            "[06:21:14.395016] [Time] 3.6s 4.3m/11.5m\n",
            "\n",
            "[06:21:14.395108] ~~~ Epoch 31/150 ~~~\n",
            "\n",
            "[06:21:15.512883] Epoch: [31]  [0/3]  eta: 0:00:03  loss: 0.1292 (0.1292)  IoU: 0.2237 (0.2237)  lr: 0.000905  iter-time: 1.1150\n",
            "[06:21:17.218746] Epoch: [31]  [2/3]  eta: 0:00:00  loss: 0.1960 (0.1762)  IoU: 0.2408 (0.2398)  lr: 0.000900  iter-time: 0.9398\n",
            "[06:21:17.299767] Epoch: [31] Total time: 0:00:02 (0.9678 s / it)\n",
            "[06:21:17.300789] [Train] averaged stats: loss: 0.1960 (0.1762)  IoU: 0.2408 (0.2398)  lr: 0.000900\n",
            "[06:21:17.600959] Epoch: [31]  [0/1]  eta: 0:00:00  loss: 0.0580 (0.0580)  IoU: 0.1496 (0.1496)  iter-time: 0.2971\n",
            "[06:21:17.723031] Epoch: [31] Total time: 0:00:00 (0.4198 s / it)\n",
            "[06:21:17.723155] [Val] averaged stats: loss: 0.0580 (0.0580)  IoU: 0.1496 (0.1496)\n",
            "[06:21:17.723694] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[06:21:17.725406] [Time] 3.3s 4.3m/11.0m\n",
            "\n",
            "[06:21:17.725453] ~~~ Epoch 32/150 ~~~\n",
            "\n",
            "[06:21:18.994880] Epoch: [32]  [0/3]  eta: 0:00:03  loss: 0.1353 (0.1353)  IoU: 0.2096 (0.2096)  lr: 0.000898  iter-time: 1.2620\n",
            "[06:21:20.690778] Epoch: [32]  [2/3]  eta: 0:00:00  loss: 0.1754 (0.1975)  IoU: 0.1918 (0.1963)  lr: 0.000894  iter-time: 0.9848\n",
            "[06:21:20.829092] Epoch: [32] Total time: 0:00:03 (1.0326 s / it)\n",
            "[06:21:20.831645] [Train] averaged stats: loss: 0.1754 (0.1975)  IoU: 0.1918 (0.1963)  lr: 0.000894\n",
            "[06:21:21.157140] Epoch: [32]  [0/1]  eta: 0:00:00  loss: 0.0614 (0.0614)  IoU: 0.1552 (0.1552)  iter-time: 0.3220\n",
            "[06:21:21.242724] Epoch: [32] Total time: 0:00:00 (0.4081 s / it)\n",
            "[06:21:21.242847] [Val] averaged stats: loss: 0.0614 (0.0614)  IoU: 0.1552 (0.1552)\n",
            "[06:21:21.245327] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[06:21:21.247632] [Time] 3.5s 4.4m/11.4m\n",
            "\n",
            "[06:21:21.247687] ~~~ Epoch 33/150 ~~~\n",
            "\n",
            "[06:21:22.359553] Epoch: [33]  [0/3]  eta: 0:00:03  loss: 0.1662 (0.1662)  IoU: 0.2300 (0.2300)  lr: 0.000892  iter-time: 1.1080\n",
            "[06:21:24.065289] Epoch: [33]  [2/3]  eta: 0:00:00  loss: 0.1703 (0.1913)  IoU: 0.2384 (0.2383)  lr: 0.000887  iter-time: 0.9374\n",
            "[06:21:24.162902] Epoch: [33] Total time: 0:00:02 (0.9709 s / it)\n",
            "[06:21:24.164016] [Train] averaged stats: loss: 0.1703 (0.1913)  IoU: 0.2384 (0.2383)  lr: 0.000887\n",
            "[06:21:24.410649] Epoch: [33]  [0/1]  eta: 0:00:00  loss: 0.0705 (0.0705)  IoU: 0.1513 (0.1513)  iter-time: 0.2436\n",
            "[06:21:24.494559] Epoch: [33] Total time: 0:00:00 (0.3280 s / it)\n",
            "[06:21:24.494665] [Val] averaged stats: loss: 0.0705 (0.0705)  IoU: 0.1513 (0.1513)\n",
            "[06:21:24.497045] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[06:21:24.499282] [Time] 3.3s 4.5m/10.8m\n",
            "\n",
            "[06:21:24.499335] ~~~ Epoch 34/150 ~~~\n",
            "\n",
            "[06:21:25.577529] Epoch: [34]  [0/3]  eta: 0:00:03  loss: 0.1543 (0.1543)  IoU: 0.1856 (0.1856)  lr: 0.000885  iter-time: 1.0756\n",
            "[06:21:27.281224] Epoch: [34]  [2/3]  eta: 0:00:00  loss: 0.1749 (0.1886)  IoU: 0.2013 (0.2111)  lr: 0.000881  iter-time: 0.9259\n",
            "[06:21:27.363773] Epoch: [34] Total time: 0:00:02 (0.9545 s / it)\n",
            "[06:21:27.365169] [Train] averaged stats: loss: 0.1749 (0.1886)  IoU: 0.2013 (0.2111)  lr: 0.000881\n",
            "[06:21:27.624907] Epoch: [34]  [0/1]  eta: 0:00:00  loss: 0.0554 (0.0554)  IoU: 0.2124 (0.2124)  iter-time: 0.2567\n",
            "[06:21:27.710966] Epoch: [34] Total time: 0:00:00 (0.3432 s / it)\n",
            "[06:21:27.711099] [Val] averaged stats: loss: 0.0554 (0.0554)  IoU: 0.2124 (0.2124)\n",
            "[06:21:27.713620] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[06:21:27.715761] [Time] 3.2s 4.5m/10.8m\n",
            "\n",
            "[06:21:27.716744] ~~~ Epoch 35/150 ~~~\n",
            "\n",
            "[06:21:28.833881] Epoch: [35]  [0/3]  eta: 0:00:03  loss: 0.1301 (0.1301)  IoU: 0.2544 (0.2544)  lr: 0.000878  iter-time: 1.1147\n",
            "[06:21:30.535965] Epoch: [35]  [2/3]  eta: 0:00:00  loss: 0.1659 (0.1770)  IoU: 0.2544 (0.2476)  lr: 0.000874  iter-time: 0.9384\n",
            "[06:21:30.619539] Epoch: [35] Total time: 0:00:02 (0.9673 s / it)\n",
            "[06:21:30.620604] [Train] averaged stats: loss: 0.1659 (0.1770)  IoU: 0.2544 (0.2476)  lr: 0.000874\n",
            "[06:21:30.873695] Epoch: [35]  [0/1]  eta: 0:00:00  loss: 0.0550 (0.0550)  IoU: 0.1696 (0.1696)  iter-time: 0.2499\n",
            "[06:21:30.957379] Epoch: [35] Total time: 0:00:00 (0.3341 s / it)\n",
            "[06:21:30.958379] [Val] averaged stats: loss: 0.0550 (0.0550)  IoU: 0.1696 (0.1696)\n",
            "[06:21:30.960164] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "[06:21:30.962299] Creating training plots . . .\n",
            "EarlyStopping counter: 6 out of 20\n",
            "[06:21:31.394263] [Time] 3.7s 4.6m/11.7m\n",
            "\n",
            "[06:21:31.394338] ~~~ Epoch 36/150 ~~~\n",
            "\n",
            "[06:21:32.616323] Epoch: [36]  [0/3]  eta: 0:00:03  loss: 0.1341 (0.1341)  IoU: 0.1928 (0.1928)  lr: 0.000872  iter-time: 1.2142\n",
            "[06:21:34.320870] Epoch: [36]  [2/3]  eta: 0:00:00  loss: 0.1659 (0.1704)  IoU: 0.2394 (0.2302)  lr: 0.000867  iter-time: 0.9724\n",
            "[06:21:34.473056] Epoch: [36] Total time: 0:00:03 (1.0242 s / it)\n",
            "[06:21:34.473724] [Train] averaged stats: loss: 0.1659 (0.1704)  IoU: 0.2394 (0.2302)  lr: 0.000867\n",
            "[06:21:34.808372] Epoch: [36]  [0/1]  eta: 0:00:00  loss: 0.0547 (0.0547)  IoU: 0.1834 (0.1834)  iter-time: 0.3280\n",
            "[06:21:34.896994] Epoch: [36] Total time: 0:00:00 (0.4171 s / it)\n",
            "[06:21:34.897814] [Val] averaged stats: loss: 0.0547 (0.0547)  IoU: 0.1834 (0.1834)\n",
            "[06:21:34.899682] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[06:21:34.901864] [Time] 3.5s 4.6m/11.3m\n",
            "\n",
            "[06:21:34.902783] ~~~ Epoch 37/150 ~~~\n",
            "\n",
            "[06:21:35.966181] Epoch: [37]  [0/3]  eta: 0:00:03  loss: 0.1231 (0.1231)  IoU: 0.2345 (0.2345)  lr: 0.000864  iter-time: 1.0604\n",
            "[06:21:37.668194] Epoch: [37]  [2/3]  eta: 0:00:00  loss: 0.1552 (0.1604)  IoU: 0.2367 (0.2363)  lr: 0.000860  iter-time: 0.9204\n",
            "[06:21:37.749474] Epoch: [37] Total time: 0:00:02 (0.9484 s / it)\n",
            "[06:21:37.750623] [Train] averaged stats: loss: 0.1552 (0.1604)  IoU: 0.2367 (0.2363)  lr: 0.000860\n",
            "[06:21:37.996499] Epoch: [37]  [0/1]  eta: 0:00:00  loss: 0.0556 (0.0556)  IoU: 0.1804 (0.1804)  iter-time: 0.2428\n",
            "[06:21:38.079739] Epoch: [37] Total time: 0:00:00 (0.3266 s / it)\n",
            "[06:21:38.079870] [Val] averaged stats: loss: 0.0556 (0.0556)  IoU: 0.1804 (0.1804)\n",
            "[06:21:38.082411] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[06:21:38.084619] [Time] 3.2s 4.7m/10.7m\n",
            "\n",
            "[06:21:38.084672] ~~~ Epoch 38/150 ~~~\n",
            "\n",
            "[06:21:39.201427] Epoch: [38]  [0/3]  eta: 0:00:03  loss: 0.1199 (0.1199)  IoU: 0.2561 (0.2561)  lr: 0.000857  iter-time: 1.1142\n",
            "[06:21:40.906119] Epoch: [38]  [2/3]  eta: 0:00:00  loss: 0.1496 (0.1556)  IoU: 0.2561 (0.2635)  lr: 0.000852  iter-time: 0.9387\n",
            "[06:21:40.987214] Epoch: [38] Total time: 0:00:02 (0.9672 s / it)\n",
            "[06:21:40.988194] [Train] averaged stats: loss: 0.1496 (0.1556)  IoU: 0.2561 (0.2635)  lr: 0.000852\n",
            "[06:21:41.235571] Epoch: [38]  [0/1]  eta: 0:00:00  loss: 0.0565 (0.0565)  IoU: 0.1552 (0.1552)  iter-time: 0.2444\n",
            "[06:21:41.321290] Epoch: [38] Total time: 0:00:00 (0.3307 s / it)\n",
            "[06:21:41.322144] [Val] averaged stats: loss: 0.0565 (0.0565)  IoU: 0.1552 (0.1552)\n",
            "[06:21:41.324133] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[06:21:41.326384] [Time] 3.2s 4.7m/10.8m\n",
            "\n",
            "[06:21:41.327347] ~~~ Epoch 39/150 ~~~\n",
            "\n",
            "[06:21:42.439136] Epoch: [39]  [0/3]  eta: 0:00:03  loss: 0.1185 (0.1185)  IoU: 0.2275 (0.2275)  lr: 0.000850  iter-time: 1.1091\n",
            "[06:21:44.143700] Epoch: [39]  [2/3]  eta: 0:00:00  loss: 0.1453 (0.1521)  IoU: 0.2524 (0.2466)  lr: 0.000845  iter-time: 0.9374\n",
            "[06:21:44.234537] Epoch: [39] Total time: 0:00:02 (0.9687 s / it)\n",
            "[06:21:44.235609] [Train] averaged stats: loss: 0.1453 (0.1521)  IoU: 0.2524 (0.2466)  lr: 0.000845\n",
            "[06:21:44.491137] Epoch: [39]  [0/1]  eta: 0:00:00  loss: 0.0549 (0.0549)  IoU: 0.1819 (0.1819)  iter-time: 0.2524\n",
            "[06:21:44.576872] Epoch: [39] Total time: 0:00:00 (0.3386 s / it)\n",
            "[06:21:44.577031] [Val] averaged stats: loss: 0.0549 (0.0549)  IoU: 0.1819 (0.1819)\n",
            "[06:21:44.579489] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[06:21:44.582217] [Time] 3.3s 4.8m/10.9m\n",
            "\n",
            "[06:21:44.582615] ~~~ Epoch 40/150 ~~~\n",
            "\n",
            "[06:21:45.758955] Epoch: [40]  [0/3]  eta: 0:00:03  loss: 0.1135 (0.1135)  IoU: 0.2637 (0.2637)  lr: 0.000842  iter-time: 1.1739\n",
            "[06:21:47.458974] Epoch: [40]  [2/3]  eta: 0:00:00  loss: 0.1365 (0.1451)  IoU: 0.2651 (0.2721)  lr: 0.000837  iter-time: 0.9569\n",
            "[06:21:47.595500] Epoch: [40] Total time: 0:00:03 (1.0040 s / it)\n",
            "[06:21:47.595698] [Train] averaged stats: loss: 0.1365 (0.1451)  IoU: 0.2651 (0.2721)  lr: 0.000837\n",
            "[06:21:47.934278] Epoch: [40]  [0/1]  eta: 0:00:00  loss: 0.0559 (0.0559)  IoU: 0.1681 (0.1681)  iter-time: 0.3361\n",
            "[06:21:48.032406] Epoch: [40] Total time: 0:00:00 (0.4350 s / it)\n",
            "[06:21:48.032534] [Val] averaged stats: loss: 0.0559 (0.0559)  IoU: 0.1681 (0.1681)\n",
            "[06:21:48.035025] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "[06:21:48.037083] Creating training plots . . .\n",
            "EarlyStopping counter: 11 out of 20\n",
            "[06:21:48.366769] [Time] 3.8s 4.9m/11.9m\n",
            "\n",
            "[06:21:48.366833] ~~~ Epoch 41/150 ~~~\n",
            "\n",
            "[06:21:49.435834] Epoch: [41]  [0/3]  eta: 0:00:03  loss: 0.1106 (0.1106)  IoU: 0.2428 (0.2428)  lr: 0.000835  iter-time: 1.0651\n",
            "[06:21:51.139686] Epoch: [41]  [2/3]  eta: 0:00:00  loss: 0.1354 (0.1414)  IoU: 0.2668 (0.2646)  lr: 0.000829  iter-time: 0.9225\n",
            "[06:21:51.221849] Epoch: [41] Total time: 0:00:02 (0.9509 s / it)\n",
            "[06:21:51.222849] [Train] averaged stats: loss: 0.1354 (0.1414)  IoU: 0.2668 (0.2646)  lr: 0.000829\n",
            "[06:21:51.475835] Epoch: [41]  [0/1]  eta: 0:00:00  loss: 0.0538 (0.0538)  IoU: 0.1857 (0.1857)  iter-time: 0.2500\n",
            "[06:21:51.561205] Epoch: [41] Total time: 0:00:00 (0.3358 s / it)\n",
            "[06:21:51.562066] [Val] averaged stats: loss: 0.0538 (0.0538)  IoU: 0.1857 (0.1857)\n",
            "[06:21:51.564036] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 12 out of 20\n",
            "[06:21:51.566252] [Time] 3.2s 4.9m/10.8m\n",
            "\n",
            "[06:21:51.566306] ~~~ Epoch 42/150 ~~~\n",
            "\n",
            "[06:21:52.674485] Epoch: [42]  [0/3]  eta: 0:00:03  loss: 0.1082 (0.1082)  IoU: 0.2785 (0.2785)  lr: 0.000827  iter-time: 1.1059\n",
            "[06:21:54.368289] Epoch: [42]  [2/3]  eta: 0:00:00  loss: 0.1264 (0.1358)  IoU: 0.2785 (0.2783)  lr: 0.000821  iter-time: 0.9322\n",
            "[06:21:54.458031] Epoch: [42] Total time: 0:00:02 (0.9636 s / it)\n",
            "[06:21:54.459102] [Train] averaged stats: loss: 0.1264 (0.1358)  IoU: 0.2785 (0.2783)  lr: 0.000821\n",
            "[06:21:54.715016] Epoch: [42]  [0/1]  eta: 0:00:00  loss: 0.0531 (0.0531)  IoU: 0.1766 (0.1766)  iter-time: 0.2529\n",
            "[06:21:54.803032] Epoch: [42] Total time: 0:00:00 (0.3414 s / it)\n",
            "[06:21:54.803371] [Val] averaged stats: loss: 0.0531 (0.0531)  IoU: 0.1766 (0.1766)\n",
            "[06:21:54.805779] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 13 out of 20\n",
            "[06:21:54.807969] [Time] 3.2s 5.0m/10.8m\n",
            "\n",
            "[06:21:54.808948] ~~~ Epoch 43/150 ~~~\n",
            "\n",
            "[06:21:55.901406] Epoch: [43]  [0/3]  eta: 0:00:03  loss: 0.1059 (0.1059)  IoU: 0.2538 (0.2538)  lr: 0.000819  iter-time: 1.0901\n",
            "[06:21:57.595143] Epoch: [43]  [2/3]  eta: 0:00:00  loss: 0.1221 (0.1316)  IoU: 0.3000 (0.2847)  lr: 0.000813  iter-time: 0.9275\n",
            "[06:21:57.683459] Epoch: [43] Total time: 0:00:02 (0.9579 s / it)\n",
            "[06:21:57.684565] [Train] averaged stats: loss: 0.1221 (0.1316)  IoU: 0.3000 (0.2847)  lr: 0.000813\n",
            "[06:21:57.930465] Epoch: [43]  [0/1]  eta: 0:00:00  loss: 0.0534 (0.0534)  IoU: 0.1818 (0.1818)  iter-time: 0.2428\n",
            "[06:21:58.043857] Epoch: [43] Total time: 0:00:00 (0.3567 s / it)\n",
            "[06:21:58.044561] [Val] averaged stats: loss: 0.0534 (0.0534)  IoU: 0.1818 (0.1818)\n",
            "[06:21:58.047789] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 14 out of 20\n",
            "[06:21:58.050288] [Time] 3.2s 5.0m/10.8m\n",
            "\n",
            "[06:21:58.050360] ~~~ Epoch 44/150 ~~~\n",
            "\n",
            "[06:21:59.338456] Epoch: [44]  [0/3]  eta: 0:00:03  loss: 0.1000 (0.1000)  IoU: 0.2807 (0.2807)  lr: 0.000811  iter-time: 1.2813\n",
            "[06:22:01.035658] Epoch: [44]  [2/3]  eta: 0:00:00  loss: 0.1214 (0.1278)  IoU: 0.2874 (0.2864)  lr: 0.000805  iter-time: 0.9915\n",
            "[06:22:01.193868] Epoch: [44] Total time: 0:00:03 (1.0468 s / it)\n",
            "[06:22:01.194963] [Train] averaged stats: loss: 0.1214 (0.1278)  IoU: 0.2874 (0.2864)  lr: 0.000805\n",
            "[06:22:01.550652] Epoch: [44]  [0/1]  eta: 0:00:00  loss: 0.0529 (0.0529)  IoU: 0.1880 (0.1880)  iter-time: 0.3533\n",
            "[06:22:01.672208] Epoch: [44] Total time: 0:00:00 (0.4755 s / it)\n",
            "[06:22:01.673071] [Val] averaged stats: loss: 0.0529 (0.0529)  IoU: 0.1880 (0.1880)\n",
            "[06:22:01.674917] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 15 out of 20\n",
            "[06:22:01.677061] [Time] 3.6s 5.1m/11.5m\n",
            "\n",
            "[06:22:01.677122] ~~~ Epoch 45/150 ~~~\n",
            "\n",
            "[06:22:02.774217] Epoch: [45]  [0/3]  eta: 0:00:03  loss: 0.0931 (0.0931)  IoU: 0.2992 (0.2992)  lr: 0.000802  iter-time: 1.0947\n",
            "[06:22:04.470574] Epoch: [45]  [2/3]  eta: 0:00:00  loss: 0.1027 (0.1167)  IoU: 0.3133 (0.3118)  lr: 0.000797  iter-time: 0.9298\n",
            "[06:22:04.564891] Epoch: [45] Total time: 0:00:02 (0.9623 s / it)\n",
            "[06:22:04.565990] [Train] averaged stats: loss: 0.1027 (0.1167)  IoU: 0.3133 (0.3118)  lr: 0.000797\n",
            "[06:22:04.824352] Epoch: [45]  [0/1]  eta: 0:00:00  loss: 0.0535 (0.0535)  IoU: 0.1903 (0.1903)  iter-time: 0.2553\n",
            "[06:22:04.908625] Epoch: [45] Total time: 0:00:00 (0.3401 s / it)\n",
            "[06:22:04.909641] [Val] averaged stats: loss: 0.0535 (0.0535)  IoU: 0.1903 (0.1903)\n",
            "[06:22:04.911531] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "[06:22:04.913702] Creating training plots . . .\n",
            "EarlyStopping counter: 16 out of 20\n",
            "[06:22:05.226824] [Time] 3.5s 5.1m/11.4m\n",
            "\n",
            "[06:22:05.226887] ~~~ Epoch 46/150 ~~~\n",
            "\n",
            "[06:22:06.333788] Epoch: [46]  [0/3]  eta: 0:00:03  loss: 0.0905 (0.0905)  IoU: 0.2976 (0.2976)  lr: 0.000794  iter-time: 1.1041\n",
            "[06:22:08.017453] Epoch: [46]  [2/3]  eta: 0:00:00  loss: 0.1053 (0.1137)  IoU: 0.3207 (0.3177)  lr: 0.000788  iter-time: 0.9288\n",
            "[06:22:08.099340] Epoch: [46] Total time: 0:00:02 (0.9571 s / it)\n",
            "[06:22:08.100347] [Train] averaged stats: loss: 0.1053 (0.1137)  IoU: 0.3207 (0.3177)  lr: 0.000788\n",
            "[06:22:08.349128] Epoch: [46]  [0/1]  eta: 0:00:00  loss: 0.0559 (0.0559)  IoU: 0.1952 (0.1952)  iter-time: 0.2459\n",
            "[06:22:08.432064] Epoch: [46] Total time: 0:00:00 (0.3293 s / it)\n",
            "[06:22:08.433048] [Val] averaged stats: loss: 0.0559 (0.0559)  IoU: 0.1952 (0.1952)\n",
            "[06:22:08.434766] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 17 out of 20\n",
            "[06:22:08.437160] [Time] 3.2s 5.2m/10.8m\n",
            "\n",
            "[06:22:08.437224] ~~~ Epoch 47/150 ~~~\n",
            "\n",
            "[06:22:09.569472] Epoch: [47]  [0/3]  eta: 0:00:03  loss: 0.0837 (0.0837)  IoU: 0.3152 (0.3152)  lr: 0.000785  iter-time: 1.1282\n",
            "[06:22:11.268268] Epoch: [47]  [2/3]  eta: 0:00:00  loss: 0.1038 (0.1075)  IoU: 0.3292 (0.3250)  lr: 0.000780  iter-time: 0.9419\n",
            "[06:22:11.353862] Epoch: [47] Total time: 0:00:02 (0.9714 s / it)\n",
            "[06:22:11.354955] [Train] averaged stats: loss: 0.1038 (0.1075)  IoU: 0.3292 (0.3250)  lr: 0.000780\n",
            "[06:22:11.608798] Epoch: [47]  [0/1]  eta: 0:00:00  loss: 0.0556 (0.0556)  IoU: 0.1964 (0.1964)  iter-time: 0.2508\n",
            "[06:22:11.732869] Epoch: [47] Total time: 0:00:00 (0.3755 s / it)\n",
            "[06:22:11.733035] [Val] averaged stats: loss: 0.0556 (0.0556)  IoU: 0.1964 (0.1964)\n",
            "[06:22:11.733647] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 18 out of 20\n",
            "[06:22:11.738736] [Time] 3.3s 5.2m/11.0m\n",
            "\n",
            "[06:22:11.739147] ~~~ Epoch 48/150 ~~~\n",
            "\n",
            "[06:22:13.001733] Epoch: [48]  [0/3]  eta: 0:00:03  loss: 0.0786 (0.0786)  IoU: 0.3236 (0.3236)  lr: 0.000777  iter-time: 1.2580\n",
            "[06:22:14.704200] Epoch: [48]  [2/3]  eta: 0:00:00  loss: 0.0879 (0.0975)  IoU: 0.3576 (0.3471)  lr: 0.000771  iter-time: 0.9857\n",
            "[06:22:14.839243] Epoch: [48] Total time: 0:00:03 (1.0324 s / it)\n",
            "[06:22:14.839439] [Train] averaged stats: loss: 0.0879 (0.0975)  IoU: 0.3576 (0.3471)  lr: 0.000771\n",
            "[06:22:15.199790] Epoch: [48]  [0/1]  eta: 0:00:00  loss: 0.0561 (0.0561)  IoU: 0.2003 (0.2003)  iter-time: 0.3556\n",
            "[06:22:15.287278] Epoch: [48] Total time: 0:00:00 (0.4435 s / it)\n",
            "[06:22:15.288284] [Val] averaged stats: loss: 0.0561 (0.0561)  IoU: 0.2003 (0.2003)\n",
            "[06:22:15.289002] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 19 out of 20\n",
            "[06:22:15.292974] [Time] 3.6s 5.3m/11.4m\n",
            "\n",
            "[06:22:15.293047] ~~~ Epoch 49/150 ~~~\n",
            "\n",
            "[06:22:16.400976] Epoch: [49]  [0/3]  eta: 0:00:03  loss: 0.0790 (0.0790)  IoU: 0.3451 (0.3451)  lr: 0.000768  iter-time: 1.1054\n",
            "[06:22:18.102873] Epoch: [49]  [2/3]  eta: 0:00:00  loss: 0.0948 (0.0982)  IoU: 0.3479 (0.3516)  lr: 0.000762  iter-time: 0.9348\n",
            "[06:22:18.186739] Epoch: [49] Total time: 0:00:02 (0.9642 s / it)\n",
            "[06:22:18.187821] [Train] averaged stats: loss: 0.0948 (0.0982)  IoU: 0.3479 (0.3516)  lr: 0.000762\n",
            "[06:22:18.454024] Epoch: [49]  [0/1]  eta: 0:00:00  loss: 0.0572 (0.0572)  IoU: 0.2020 (0.2020)  iter-time: 0.2633\n",
            "[06:22:18.535295] Epoch: [49] Total time: 0:00:00 (0.3451 s / it)\n",
            "[06:22:18.535719] [Val] averaged stats: loss: 0.0572 (0.0572)  IoU: 0.2020 (0.2020)\n",
            "[06:22:18.538402] [Val] best loss: 0.0524 best  IoU: 0.1689 \n",
            "EarlyStopping counter: 20 out of 20\n",
            "[06:22:18.540610] Early stopping\n",
            "[06:22:18.540681] Training time: 0:05:21\n",
            "[06:22:18.540724] Train loss: 0.09817488739887874\n",
            "[06:22:18.540773] Train IoU: 0.3515549798806508\n",
            "[06:22:18.540821] Validation loss: 0.0523991696536541\n",
            "[06:22:18.540887] Validation IoU: 0.16887322068214417\n",
            "[06:22:18.540949] Finished Training\n",
            "[06:22:18.911057] Releasing memory . . .\n",
            "[06:22:18.911381] ######################\n",
            "[06:22:18.913276] #   LOAD TEST DATA   #\n",
            "[06:22:18.913342] ######################\n",
            "[06:22:18.913402] 2) Loading test images . . .\n",
            "[06:22:18.913492] Loading data from /content/data/test/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:00<00:00, 898.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:18.960568] *** Loaded data shape is (27, 64, 64, 64, 1)\n",
            "[06:22:18.960695] 3) Loading test masks . . .\n",
            "[06:22:18.963237] Loading data from /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:00<00:00, 198.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:19.111754] *** Loaded data shape is (27, 64, 64, 64, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:19.114072] ############################\n",
            "[06:22:19.114156] #  PREPARE TEST GENERATOR  #\n",
            "[06:22:19.114197] ############################\n",
            "[06:22:19.122574] Loading checkpoint from file /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:22:19.202468] Model weights loaded!\n",
            "[06:22:19.204206] ###############\n",
            "[06:22:19.204286] #  INFERENCE  #\n",
            "[06:22:19.204331] ###############\n",
            "[06:22:19.204380] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/27 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:19.217219] Processing image: vol_000.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  1.12it/s]\u001b[A\n",
            "                                             \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.131314] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.187474] Capturing the local maxima \n",
            "[06:22:20.188987] Class 1\n",
            "[06:22:20.206087] Removing close points . . .\n",
            "[06:22:20.206162] Initial number of points: 100\n",
            "[06:22:20.208866] Final number of points: 62\n",
            "[06:22:20.209618] Creating the images with detected points . . .\n",
            "[06:22:20.235731] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.291337] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.321332] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:20.322444] Its respective CSV file seems to be: /content/data/test/y/mask_000.csv\n",
            "[06:22:20.322970] Reading GT data from: /content/data/test/y/mask_000.csv\n",
            "[06:22:20.326387] Detection (class 1)\n",
            "[06:22:20.329634] Points in ground truth: 61, Points in prediction: 62\n",
            "[06:22:20.330509] True positives: 54, False positives: 8, False negatives: 7\n",
            "[06:22:20.331219] Detection metrics: {'Precision': 0.8709677419354839, 'Recall': 0.8852459016393442, 'F1': 0.8780487804878049, 'TP': 54, 'FP': 8, 'FN': 7}\n",
            "[06:22:20.336030] All classes 1\n",
            "[06:22:20.336123] Detection metrics: ['Precision', 0.8709677419354839, 'Recall', 0.8852459016393442, 'F1', 0.8780487804878049]\n",
            "[06:22:20.336178] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:20.403543] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.503265] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258e         | 1/27 [00:01<00:34,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.539013] Processing image: vol_001.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.570218] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.633554] Capturing the local maxima \n",
            "[06:22:20.633686] Class 1\n",
            "[06:22:20.667849] Removing close points . . .\n",
            "[06:22:20.667956] Initial number of points: 826\n",
            "[06:22:20.677777] Final number of points: 539\n",
            "[06:22:20.678062] Creating the images with detected points . . .\n",
            "[06:22:20.706110] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.764016] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:20.796897] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:20.798280] Its respective CSV file seems to be: /content/data/test/y/mask_001.csv\n",
            "[06:22:20.799209] Reading GT data from: /content/data/test/y/mask_001.csv\n",
            "[06:22:20.802722] Detection (class 1)\n",
            "[06:22:20.837874] Points in ground truth: 649, Points in prediction: 539\n",
            "[06:22:20.839362] True positives: 531, False positives: 8, False negatives: 118\n",
            "[06:22:20.840219] Detection metrics: {'Precision': 0.9851576994434137, 'Recall': 0.8181818181818182, 'F1': 0.893939393939394, 'TP': 531, 'FP': 8, 'FN': 118}\n",
            "[06:22:20.846157] All classes 1\n",
            "[06:22:20.846246] Detection metrics: ['Precision', 0.9851576994434137, 'Recall', 0.8181818181818182, 'F1', 0.893939393939394]\n",
            "[06:22:20.847460] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:21.259830] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.367275] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|\u258b         | 2/27 [00:02<00:26,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.400488] Processing image: vol_002.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.431265] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.486355] Capturing the local maxima \n",
            "[06:22:21.487579] Class 1\n",
            "[06:22:21.503309] Removing close points . . .\n",
            "[06:22:21.503387] Initial number of points: 102\n",
            "[06:22:21.506109] Final number of points: 47\n",
            "[06:22:21.506242] Creating the images with detected points . . .\n",
            "[06:22:21.532173] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.587339] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.610631] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:21.611611] Its respective CSV file seems to be: /content/data/test/y/mask_002.csv\n",
            "[06:22:21.611663] Reading GT data from: /content/data/test/y/mask_002.csv\n",
            "[06:22:21.613827] Detection (class 1)\n",
            "[06:22:21.615797] Points in ground truth: 19, Points in prediction: 47\n",
            "[06:22:21.615886] True positives: 19, False positives: 28, False negatives: 0\n",
            "[06:22:21.615994] Detection metrics: {'Precision': 0.40425531914893614, 'Recall': 1.0, 'F1': 0.5757575757575757, 'TP': 19, 'FP': 28, 'FN': 0}\n",
            "[06:22:21.622355] All classes 1\n",
            "[06:22:21.622457] Detection metrics: ['Precision', 0.40425531914893614, 'Recall', 1.0, 'F1', 0.5757575757575757]\n",
            "[06:22:21.622517] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:21.665385] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.764057] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|\u2588         | 3/27 [00:02<00:18,  1.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.803427] Processing image: vol_003.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.835368] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:21.891235] Capturing the local maxima \n",
            "[06:22:21.892526] Class 1\n",
            "[06:22:21.923770] Removing close points . . .\n",
            "[06:22:21.923870] Initial number of points: 885\n",
            "[06:22:21.933587] Final number of points: 503\n",
            "[06:22:21.933906] Creating the images with detected points . . .\n",
            "[06:22:21.974244] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.046902] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.085118] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:22.086858] Its respective CSV file seems to be: /content/data/test/y/mask_003.csv\n",
            "[06:22:22.087949] Reading GT data from: /content/data/test/y/mask_003.csv\n",
            "[06:22:22.091498] Detection (class 1)\n",
            "[06:22:22.134550] Points in ground truth: 501, Points in prediction: 503\n",
            "[06:22:22.135480] True positives: 430, False positives: 73, False negatives: 71\n",
            "[06:22:22.135603] Detection metrics: {'Precision': 0.8548707753479126, 'Recall': 0.8582834331337326, 'F1': 0.8565737051792829, 'TP': 430, 'FP': 73, 'FN': 71}\n",
            "[06:22:22.143014] All classes 1\n",
            "[06:22:22.143110] Detection metrics: ['Precision', 0.8548707753479126, 'Recall', 0.8582834331337326, 'F1', 0.8565737051792829]\n",
            "[06:22:22.144297] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:22.449333] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.546850] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 15%|\u2588\u258d        | 4/27 [00:03<00:17,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.592040] Processing image: vol_004.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.629274] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.687504] Capturing the local maxima \n",
            "[06:22:22.688731] Class 1\n",
            "[06:22:22.710181] Removing close points . . .\n",
            "[06:22:22.710260] Initial number of points: 450\n",
            "[06:22:22.716185] Final number of points: 264\n",
            "[06:22:22.716444] Creating the images with detected points . . .\n",
            "[06:22:22.743396] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.801427] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:22.831409] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:22.832603] Its respective CSV file seems to be: /content/data/test/y/mask_004.csv\n",
            "[06:22:22.833374] Reading GT data from: /content/data/test/y/mask_004.csv\n",
            "[06:22:22.836746] Detection (class 1)\n",
            "[06:22:22.846876] Points in ground truth: 259, Points in prediction: 264\n",
            "[06:22:22.846972] True positives: 225, False positives: 39, False negatives: 34\n",
            "[06:22:22.847065] Detection metrics: {'Precision': 0.8522727272727273, 'Recall': 0.8687258687258688, 'F1': 0.8604206500956023, 'TP': 225, 'FP': 39, 'FN': 34}\n",
            "[06:22:22.851896] All classes 1\n",
            "[06:22:22.852027] Detection metrics: ['Precision', 0.8522727272727273, 'Recall', 0.8687258687258688, 'F1', 0.8604206500956023]\n",
            "[06:22:22.853396] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:23.033295] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.162815] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 19%|\u2588\u258a        | 5/27 [00:03<00:15,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.208117] Processing image: vol_005.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.248500] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.305617] Capturing the local maxima \n",
            "[06:22:23.306821] Class 1\n",
            "[06:22:23.326026] Removing close points . . .\n",
            "[06:22:23.326104] Initial number of points: 267\n",
            "[06:22:23.330070] Final number of points: 179\n",
            "[06:22:23.330225] Creating the images with detected points . . .\n",
            "[06:22:23.356521] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.416983] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.449511] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:23.450951] Its respective CSV file seems to be: /content/data/test/y/mask_005.csv\n",
            "[06:22:23.452336] Reading GT data from: /content/data/test/y/mask_005.csv\n",
            "[06:22:23.455998] Detection (class 1)\n",
            "[06:22:23.462749] Points in ground truth: 174, Points in prediction: 179\n",
            "[06:22:23.462825] True positives: 161, False positives: 18, False negatives: 13\n",
            "[06:22:23.462905] Detection metrics: {'Precision': 0.8994413407821229, 'Recall': 0.9252873563218391, 'F1': 0.9121813031161473, 'TP': 161, 'FP': 18, 'FN': 13}\n",
            "[06:22:23.467801] All classes 1\n",
            "[06:22:23.467893] Detection metrics: ['Precision', 0.8994413407821229, 'Recall', 0.9252873563218391, 'F1', 0.9121813031161473]\n",
            "[06:22:23.469150] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:23.568119] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.674031] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 6/27 [00:04<00:13,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.714165] Processing image: vol_006.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.751733] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.806648] Capturing the local maxima \n",
            "[06:22:23.807861] Class 1\n",
            "[06:22:23.826112] Removing close points . . .\n",
            "[06:22:23.826953] Initial number of points: 51\n",
            "[06:22:23.828451] Final number of points: 36\n",
            "[06:22:23.829332] Creating the images with detected points . . .\n",
            "[06:22:23.855706] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.911627] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:23.935378] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:23.935462] Its respective CSV file seems to be: /content/data/test/y/mask_006.csv\n",
            "[06:22:23.935499] Reading GT data from: /content/data/test/y/mask_006.csv\n",
            "[06:22:23.942295] Detection (class 1)\n",
            "[06:22:23.947503] Points in ground truth: 22, Points in prediction: 36\n",
            "[06:22:23.947600] True positives: 22, False positives: 14, False negatives: 0\n",
            "[06:22:23.947682] Detection metrics: {'Precision': 0.6111111111111112, 'Recall': 1.0, 'F1': 0.7586206896551725, 'TP': 22, 'FP': 14, 'FN': 0}\n",
            "[06:22:23.953261] All classes 1\n",
            "[06:22:23.953364] Detection metrics: ['Precision', 0.6111111111111112, 'Recall', 1.0, 'F1', 0.7586206896551725]\n",
            "[06:22:23.954404] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:24.005424] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.142123] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 7/27 [00:04<00:11,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.180986] Processing image: vol_007.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.226028] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.309958] Capturing the local maxima \n",
            "[06:22:24.311270] Class 1\n",
            "[06:22:24.341140] Removing close points . . .\n",
            "[06:22:24.341229] Initial number of points: 183\n",
            "[06:22:24.346669] Final number of points: 122\n",
            "[06:22:24.348175] Creating the images with detected points . . .\n",
            "[06:22:24.391705] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.464803] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.494556] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:24.495373] Its respective CSV file seems to be: /content/data/test/y/mask_007.csv\n",
            "[06:22:24.495422] Reading GT data from: /content/data/test/y/mask_007.csv\n",
            "[06:22:24.500100] Detection (class 1)\n",
            "[06:22:24.507647] Points in ground truth: 121, Points in prediction: 122\n",
            "[06:22:24.509083] True positives: 111, False positives: 11, False negatives: 10\n",
            "[06:22:24.509909] Detection metrics: {'Precision': 0.9098360655737705, 'Recall': 0.9173553719008265, 'F1': 0.9135802469135802, 'TP': 111, 'FP': 11, 'FN': 10}\n",
            "[06:22:24.516644] All classes 1\n",
            "[06:22:24.517590] Detection metrics: ['Precision', 0.9098360655737705, 'Recall', 0.9173553719008265, 'F1', 0.9135802469135802]\n",
            "[06:22:24.518524] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:24.614637] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.719212] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2589       | 8/27 [00:05<00:11,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.756576] Processing image: vol_008.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.797485] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.862943] Capturing the local maxima \n",
            "[06:22:24.864318] Class 1\n",
            "[06:22:24.891405] Removing close points . . .\n",
            "[06:22:24.891490] Initial number of points: 657\n",
            "[06:22:24.899566] Final number of points: 377\n",
            "[06:22:24.899811] Creating the images with detected points . . .\n",
            "[06:22:24.931272] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:24.997970] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.037092] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:25.039266] Its respective CSV file seems to be: /content/data/test/y/mask_008.csv\n",
            "[06:22:25.040101] Reading GT data from: /content/data/test/y/mask_008.csv\n",
            "[06:22:25.045621] Detection (class 1)\n",
            "[06:22:25.079410] Points in ground truth: 369, Points in prediction: 377\n",
            "[06:22:25.080407] True positives: 325, False positives: 52, False negatives: 44\n",
            "[06:22:25.080525] Detection metrics: {'Precision': 0.8620689655172413, 'Recall': 0.8807588075880759, 'F1': 0.871313672922252, 'TP': 325, 'FP': 52, 'FN': 44}\n",
            "[06:22:25.087058] All classes 1\n",
            "[06:22:25.087857] Detection metrics: ['Precision', 0.8620689655172413, 'Recall', 0.8807588075880759, 'F1', 0.871313672922252]\n",
            "[06:22:25.087952] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:25.379499] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.528144] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|\u2588\u2588\u2588\u258e      | 9/27 [00:06<00:11,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.564377] Processing image: vol_009.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.600903] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.665774] Capturing the local maxima \n",
            "[06:22:25.666819] Class 1\n",
            "[06:22:25.707550] Removing close points . . .\n",
            "[06:22:25.708729] Initial number of points: 812\n",
            "[06:22:25.725310] Final number of points: 429\n",
            "[06:22:25.726452] Creating the images with detected points . . .\n",
            "[06:22:25.778395] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.847113] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:25.889099] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:25.890446] Its respective CSV file seems to be: /content/data/test/y/mask_009.csv\n",
            "[06:22:25.891204] Reading GT data from: /content/data/test/y/mask_009.csv\n",
            "[06:22:25.894759] Detection (class 1)\n",
            "[06:22:25.920158] Points in ground truth: 372, Points in prediction: 429\n",
            "[06:22:25.921078] True positives: 325, False positives: 104, False negatives: 47\n",
            "[06:22:25.921786] Detection metrics: {'Precision': 0.7575757575757576, 'Recall': 0.8736559139784946, 'F1': 0.8114856429463171, 'TP': 325, 'FP': 104, 'FN': 47}\n",
            "[06:22:25.928694] All classes 1\n",
            "[06:22:25.929739] Detection metrics: ['Precision', 0.7575757575757576, 'Recall', 0.8736559139784946, 'F1', 0.8114856429463171]\n",
            "[06:22:25.930679] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:26.214135] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:26.374269] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 37%|\u2588\u2588\u2588\u258b      | 10/27 [00:07<00:12,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:26.418068] Processing image: vol_010.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:26.456093] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:26.529971] Capturing the local maxima \n",
            "[06:22:26.531238] Class 1\n",
            "[06:22:26.586522] Removing close points . . .\n",
            "[06:22:26.587642] Initial number of points: 949\n",
            "[06:22:26.606463] Final number of points: 485\n",
            "[06:22:26.607746] Creating the images with detected points . . .\n",
            "[06:22:26.671578] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:26.735615] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:26.771542] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:26.772770] Its respective CSV file seems to be: /content/data/test/y/mask_010.csv\n",
            "[06:22:26.773583] Reading GT data from: /content/data/test/y/mask_010.csv\n",
            "[06:22:26.776706] Detection (class 1)\n",
            "[06:22:26.816743] Points in ground truth: 502, Points in prediction: 485\n",
            "[06:22:26.817798] True positives: 419, False positives: 66, False negatives: 83\n",
            "[06:22:26.818562] Detection metrics: {'Precision': 0.8639175257731959, 'Recall': 0.8346613545816733, 'F1': 0.8490374873353597, 'TP': 419, 'FP': 66, 'FN': 83}\n",
            "[06:22:26.826866] All classes 1\n",
            "[06:22:26.827646] Detection metrics: ['Precision', 0.8639175257731959, 'Recall', 0.8346613545816733, 'F1', 0.8490374873353597]\n",
            "[06:22:26.828315] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:27.205577] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:27.370822] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 41%|\u2588\u2588\u2588\u2588      | 11/27 [00:08<00:12,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:27.419531] Processing image: vol_011.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:27.468236] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:27.555285] Capturing the local maxima \n",
            "[06:22:27.556511] Class 1\n",
            "[06:22:27.598962] Removing close points . . .\n",
            "[06:22:27.600110] Initial number of points: 759\n",
            "[06:22:27.616616] Final number of points: 431\n",
            "[06:22:27.617794] Creating the images with detected points . . .\n",
            "[06:22:27.675629] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:27.743588] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:27.785130] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:27.786450] Its respective CSV file seems to be: /content/data/test/y/mask_011.csv\n",
            "[06:22:27.787196] Reading GT data from: /content/data/test/y/mask_011.csv\n",
            "[06:22:27.790788] Detection (class 1)\n",
            "[06:22:27.836644] Points in ground truth: 421, Points in prediction: 431\n",
            "[06:22:27.837857] True positives: 370, False positives: 61, False negatives: 51\n",
            "[06:22:27.838698] Detection metrics: {'Precision': 0.8584686774941995, 'Recall': 0.8788598574821853, 'F1': 0.8685446009389672, 'TP': 370, 'FP': 61, 'FN': 51}\n",
            "[06:22:27.850267] All classes 1\n",
            "[06:22:27.851190] Detection metrics: ['Precision', 0.8584686774941995, 'Recall', 0.8788598574821853, 'F1', 0.8685446009389672]\n",
            "[06:22:27.852159] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:28.206405] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:28.354016] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 44%|\u2588\u2588\u2588\u2588\u258d     | 12/27 [00:09<00:12,  1.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:28.408449] Processing image: vol_012.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:28.446934] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:28.512788] Capturing the local maxima \n",
            "[06:22:28.514169] Class 1\n",
            "[06:22:28.571332] Removing close points . . .\n",
            "[06:22:28.572627] Initial number of points: 870\n",
            "[06:22:28.597522] Final number of points: 506\n",
            "[06:22:28.601661] Creating the images with detected points . . .\n",
            "[06:22:28.658450] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:28.729922] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:28.768067] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:28.769326] Its respective CSV file seems to be: /content/data/test/y/mask_012.csv\n",
            "[06:22:28.770176] Reading GT data from: /content/data/test/y/mask_012.csv\n",
            "[06:22:28.774441] Detection (class 1)\n",
            "[06:22:28.820221] Points in ground truth: 565, Points in prediction: 506\n",
            "[06:22:28.821209] True positives: 475, False positives: 31, False negatives: 90\n",
            "[06:22:28.822018] Detection metrics: {'Precision': 0.9387351778656127, 'Recall': 0.8407079646017699, 'F1': 0.8870214752567693, 'TP': 475, 'FP': 31, 'FN': 90}\n",
            "[06:22:28.830527] All classes 1\n",
            "[06:22:28.831416] Detection metrics: ['Precision', 0.9387351778656127, 'Recall', 0.8407079646017699, 'F1', 0.8870214752567693]\n",
            "[06:22:28.832191] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:29.303332] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:29.467527] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 13/27 [00:10<00:13,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:29.505332] Processing image: vol_013.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:29.544605] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:29.620493] Capturing the local maxima \n",
            "[06:22:29.621823] Class 1\n",
            "[06:22:29.677289] Removing close points . . .\n",
            "[06:22:29.678694] Initial number of points: 562\n",
            "[06:22:29.692193] Final number of points: 372\n",
            "[06:22:29.693462] Creating the images with detected points . . .\n",
            "[06:22:29.742877] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:29.815184] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:29.855601] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:29.855735] Its respective CSV file seems to be: /content/data/test/y/mask_013.csv\n",
            "[06:22:29.855796] Reading GT data from: /content/data/test/y/mask_013.csv\n",
            "[06:22:29.861270] Detection (class 1)\n",
            "[06:22:29.892244] Points in ground truth: 388, Points in prediction: 372\n",
            "[06:22:29.893840] True positives: 338, False positives: 34, False negatives: 50\n",
            "[06:22:29.893970] Detection metrics: {'Precision': 0.9086021505376344, 'Recall': 0.8711340206185567, 'F1': 0.8894736842105262, 'TP': 338, 'FP': 34, 'FN': 50}\n",
            "[06:22:29.901606] All classes 1\n",
            "[06:22:29.901717] Detection metrics: ['Precision', 0.9086021505376344, 'Recall', 0.8711340206185567, 'F1', 0.8894736842105262]\n",
            "[06:22:29.901784] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:30.316182] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.446098] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 14/27 [00:11<00:12,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.483037] Processing image: vol_014.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.520633] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.580390] Capturing the local maxima \n",
            "[06:22:30.580496] Class 1\n",
            "[06:22:30.599340] Removing close points . . .\n",
            "[06:22:30.599418] Initial number of points: 128\n",
            "[06:22:30.602294] Final number of points: 81\n",
            "[06:22:30.602430] Creating the images with detected points . . .\n",
            "[06:22:30.629705] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.699723] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.728050] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:30.728151] Its respective CSV file seems to be: /content/data/test/y/mask_014.csv\n",
            "[06:22:30.728196] Reading GT data from: /content/data/test/y/mask_014.csv\n",
            "[06:22:30.733828] Detection (class 1)\n",
            "[06:22:30.738534] Points in ground truth: 71, Points in prediction: 81\n",
            "[06:22:30.739532] True positives: 63, False positives: 18, False negatives: 8\n",
            "[06:22:30.740428] Detection metrics: {'Precision': 0.7777777777777778, 'Recall': 0.8873239436619719, 'F1': 0.8289473684210527, 'TP': 63, 'FP': 18, 'FN': 8}\n",
            "[06:22:30.744830] All classes 1\n",
            "[06:22:30.745874] Detection metrics: ['Precision', 0.7777777777777778, 'Recall', 0.8873239436619719, 'F1', 0.8289473684210527]\n",
            "[06:22:30.746856] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:30.821038] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.924157] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 15/27 [00:11<00:09,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:30.963115] Processing image: vol_015.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.007758] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.077460] Capturing the local maxima \n",
            "[06:22:31.079561] Class 1\n",
            "[06:22:31.106341] Removing close points . . .\n",
            "[06:22:31.107915] Initial number of points: 311\n",
            "[06:22:31.114540] Final number of points: 176\n",
            "[06:22:31.116758] Creating the images with detected points . . .\n",
            "[06:22:31.163019] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.240445] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.275688] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:31.276738] Its respective CSV file seems to be: /content/data/test/y/mask_015.csv\n",
            "[06:22:31.276808] Reading GT data from: /content/data/test/y/mask_015.csv\n",
            "[06:22:31.282576] Detection (class 1)\n",
            "[06:22:31.293413] Points in ground truth: 163, Points in prediction: 176\n",
            "[06:22:31.293510] True positives: 147, False positives: 29, False negatives: 16\n",
            "[06:22:31.293599] Detection metrics: {'Precision': 0.8352272727272727, 'Recall': 0.901840490797546, 'F1': 0.8672566371681416, 'TP': 147, 'FP': 29, 'FN': 16}\n",
            "[06:22:31.301656] All classes 1\n",
            "[06:22:31.301770] Detection metrics: ['Precision', 0.8352272727272727, 'Recall', 0.901840490797546, 'F1', 0.8672566371681416]\n",
            "[06:22:31.301840] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:31.407776] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.511409] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 16/27 [00:12<00:08,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.547873] Processing image: vol_016.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.587865] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.649565] Capturing the local maxima \n",
            "[06:22:31.650813] Class 1\n",
            "[06:22:31.686136] Removing close points . . .\n",
            "[06:22:31.686247] Initial number of points: 688\n",
            "[06:22:31.694758] Final number of points: 377\n",
            "[06:22:31.695089] Creating the images with detected points . . .\n",
            "[06:22:31.739182] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.799873] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:31.830607] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:31.831957] Its respective CSV file seems to be: /content/data/test/y/mask_016.csv\n",
            "[06:22:31.832918] Reading GT data from: /content/data/test/y/mask_016.csv\n",
            "[06:22:31.836147] Detection (class 1)\n",
            "[06:22:31.857039] Points in ground truth: 337, Points in prediction: 377\n",
            "[06:22:31.858267] True positives: 285, False positives: 92, False negatives: 52\n",
            "[06:22:31.859068] Detection metrics: {'Precision': 0.7559681697612732, 'Recall': 0.8456973293768546, 'F1': 0.7983193277310925, 'TP': 285, 'FP': 92, 'FN': 52}\n",
            "[06:22:31.864501] All classes 1\n",
            "[06:22:31.864595] Detection metrics: ['Precision', 0.7559681697612732, 'Recall', 0.8456973293768546, 'F1', 0.7983193277310925]\n",
            "[06:22:31.864658] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:32.074095] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.209894] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 17/27 [00:13<00:07,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.247251] Processing image: vol_017.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.284996] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.345039] Capturing the local maxima \n",
            "[06:22:32.346393] Class 1\n",
            "[06:22:32.385211] Removing close points . . .\n",
            "[06:22:32.385320] Initial number of points: 885\n",
            "[06:22:32.395957] Final number of points: 408\n",
            "[06:22:32.396337] Creating the images with detected points . . .\n",
            "[06:22:32.430056] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.493768] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.525062] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:32.526111] Its respective CSV file seems to be: /content/data/test/y/mask_017.csv\n",
            "[06:22:32.526748] Reading GT data from: /content/data/test/y/mask_017.csv\n",
            "[06:22:32.529432] Detection (class 1)\n",
            "[06:22:32.551887] Points in ground truth: 286, Points in prediction: 408\n",
            "[06:22:32.553033] True positives: 250, False positives: 158, False negatives: 36\n",
            "[06:22:32.553905] Detection metrics: {'Precision': 0.6127450980392157, 'Recall': 0.8741258741258742, 'F1': 0.7204610951008646, 'TP': 250, 'FP': 158, 'FN': 36}\n",
            "[06:22:32.558734] All classes 1\n",
            "[06:22:32.558822] Detection metrics: ['Precision', 0.6127450980392157, 'Recall', 0.8741258741258742, 'F1', 0.7204610951008646]\n",
            "[06:22:32.558884] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:32.735980] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.852862] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 18/27 [00:13<00:06,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.887546] Processing image: vol_018.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.924023] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:32.996244] Capturing the local maxima \n",
            "[06:22:32.997782] Class 1\n",
            "[06:22:33.037098] Removing close points . . .\n",
            "[06:22:33.038336] Initial number of points: 519\n",
            "[06:22:33.050876] Final number of points: 302\n",
            "[06:22:33.052338] Creating the images with detected points . . .\n",
            "[06:22:33.103983] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.176847] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.218851] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:33.219006] Its respective CSV file seems to be: /content/data/test/y/mask_018.csv\n",
            "[06:22:33.219068] Reading GT data from: /content/data/test/y/mask_018.csv\n",
            "[06:22:33.225092] Detection (class 1)\n",
            "[06:22:33.244823] Points in ground truth: 307, Points in prediction: 302\n",
            "[06:22:33.246009] True positives: 268, False positives: 34, False negatives: 39\n",
            "[06:22:33.246106] Detection metrics: {'Precision': 0.8874172185430463, 'Recall': 0.8729641693811075, 'F1': 0.8801313628899836, 'TP': 268, 'FP': 34, 'FN': 39}\n",
            "[06:22:33.252609] All classes 1\n",
            "[06:22:33.252721] Detection metrics: ['Precision', 0.8874172185430463, 'Recall', 0.8729641693811075, 'F1', 0.8801313628899836]\n",
            "[06:22:33.252783] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:33.462236] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.567980] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 19/27 [00:14<00:05,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.602548] Processing image: vol_019.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.641550] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.709691] Capturing the local maxima \n",
            "[06:22:33.710942] Class 1\n",
            "[06:22:33.736451] Removing close points . . .\n",
            "[06:22:33.736534] Initial number of points: 467\n",
            "[06:22:33.742537] Final number of points: 303\n",
            "[06:22:33.742755] Creating the images with detected points . . .\n",
            "[06:22:33.770057] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.841139] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:33.873355] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:33.874500] Its respective CSV file seems to be: /content/data/test/y/mask_019.csv\n",
            "[06:22:33.875370] Reading GT data from: /content/data/test/y/mask_019.csv\n",
            "[06:22:33.878719] Detection (class 1)\n",
            "[06:22:33.893665] Points in ground truth: 326, Points in prediction: 303\n",
            "[06:22:33.894459] True positives: 283, False positives: 20, False negatives: 43\n",
            "[06:22:33.895250] Detection metrics: {'Precision': 0.933993399339934, 'Recall': 0.8680981595092024, 'F1': 0.8998410174880763, 'TP': 283, 'FP': 20, 'FN': 43}\n",
            "[06:22:33.901523] All classes 1\n",
            "[06:22:33.902394] Detection metrics: ['Precision', 0.933993399339934, 'Recall', 0.8680981595092024, 'F1', 0.8998410174880763]\n",
            "[06:22:33.903105] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:34.129868] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.240893] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 20/27 [00:15<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.278967] Processing image: vol_020.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.313542] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.377996] Capturing the local maxima \n",
            "[06:22:34.379149] Class 1\n",
            "[06:22:34.409841] Removing close points . . .\n",
            "[06:22:34.409937] Initial number of points: 599\n",
            "[06:22:34.417136] Final number of points: 321\n",
            "[06:22:34.417393] Creating the images with detected points . . .\n",
            "[06:22:34.448472] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.508652] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.545069] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:34.546375] Its respective CSV file seems to be: /content/data/test/y/mask_020.csv\n",
            "[06:22:34.547717] Reading GT data from: /content/data/test/y/mask_020.csv\n",
            "[06:22:34.550947] Detection (class 1)\n",
            "[06:22:34.565362] Points in ground truth: 315, Points in prediction: 321\n",
            "[06:22:34.565453] True positives: 276, False positives: 45, False negatives: 39\n",
            "[06:22:34.565541] Detection metrics: {'Precision': 0.8598130841121495, 'Recall': 0.8761904761904762, 'F1': 0.8679245283018867, 'TP': 276, 'FP': 45, 'FN': 39}\n",
            "[06:22:34.571331] All classes 1\n",
            "[06:22:34.571426] Detection metrics: ['Precision', 0.8598130841121495, 'Recall', 0.8761904761904762, 'F1', 0.8679245283018867]\n",
            "[06:22:34.571486] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:34.776208] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.895395] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 21/27 [00:15<00:04,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.936543] Processing image: vol_021.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:34.985007] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.058103] Capturing the local maxima \n",
            "[06:22:35.059372] Class 1\n",
            "[06:22:35.089731] Removing close points . . .\n",
            "[06:22:35.092951] Initial number of points: 95\n",
            "[06:22:35.095603] Final number of points: 48\n",
            "[06:22:35.099002] Creating the images with detected points . . .\n",
            "[06:22:35.157449] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.230625] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.267347] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:35.267439] Its respective CSV file seems to be: /content/data/test/y/mask_021.csv\n",
            "[06:22:35.268104] Reading GT data from: /content/data/test/y/mask_021.csv\n",
            "[06:22:35.271281] Detection (class 1)\n",
            "[06:22:35.281148] Points in ground truth: 36, Points in prediction: 48\n",
            "[06:22:35.281235] True positives: 34, False positives: 14, False negatives: 2\n",
            "[06:22:35.281324] Detection metrics: {'Precision': 0.7083333333333334, 'Recall': 0.9444444444444444, 'F1': 0.8095238095238096, 'TP': 34, 'FP': 14, 'FN': 2}\n",
            "[06:22:35.287230] All classes 1\n",
            "[06:22:35.287848] Detection metrics: ['Precision', 0.7083333333333334, 'Recall', 0.9444444444444444, 'F1', 0.8095238095238096]\n",
            "[06:22:35.287917] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:35.355299] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.469251] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 22/27 [00:16<00:03,  1.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.506552] Processing image: vol_022.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.544192] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.608511] Capturing the local maxima \n",
            "[06:22:35.609614] Class 1\n",
            "[06:22:35.645413] Removing close points . . .\n",
            "[06:22:35.645509] Initial number of points: 715\n",
            "[06:22:35.653541] Final number of points: 398\n",
            "[06:22:35.654848] Creating the images with detected points . . .\n",
            "[06:22:35.695144] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.757281] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:35.789159] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:35.790031] Its respective CSV file seems to be: /content/data/test/y/mask_022.csv\n",
            "[06:22:35.790755] Reading GT data from: /content/data/test/y/mask_022.csv\n",
            "[06:22:35.793203] Detection (class 1)\n",
            "[06:22:35.816736] Points in ground truth: 374, Points in prediction: 398\n",
            "[06:22:35.818250] True positives: 310, False positives: 88, False negatives: 64\n",
            "[06:22:35.818985] Detection metrics: {'Precision': 0.7788944723618091, 'Recall': 0.8288770053475936, 'F1': 0.8031088082901553, 'TP': 310, 'FP': 88, 'FN': 64}\n",
            "[06:22:35.824655] All classes 1\n",
            "[06:22:35.825505] Detection metrics: ['Precision', 0.7788944723618091, 'Recall', 0.8288770053475936, 'F1', 0.8031088082901553]\n",
            "[06:22:35.826260] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:36.072089] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.206146] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 23/27 [00:17<00:02,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.244893] Processing image: vol_023.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.288317] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.348921] Capturing the local maxima \n",
            "[06:22:36.350195] Class 1\n",
            "[06:22:36.376900] Removing close points . . .\n",
            "[06:22:36.377013] Initial number of points: 292\n",
            "[06:22:36.382986] Final number of points: 158\n",
            "[06:22:36.384077] Creating the images with detected points . . .\n",
            "[06:22:36.416371] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.480194] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.512557] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:36.515264] Its respective CSV file seems to be: /content/data/test/y/mask_023.csv\n",
            "[06:22:36.516199] Reading GT data from: /content/data/test/y/mask_023.csv\n",
            "[06:22:36.520679] Detection (class 1)\n",
            "[06:22:36.526751] Points in ground truth: 112, Points in prediction: 158\n",
            "[06:22:36.527675] True positives: 110, False positives: 48, False negatives: 2\n",
            "[06:22:36.528638] Detection metrics: {'Precision': 0.6962025316455697, 'Recall': 0.9821428571428571, 'F1': 0.8148148148148149, 'TP': 110, 'FP': 48, 'FN': 2}\n",
            "[06:22:36.533170] All classes 1\n",
            "[06:22:36.534249] Detection metrics: ['Precision', 0.6962025316455697, 'Recall', 0.9821428571428571, 'F1', 0.8148148148148149]\n",
            "[06:22:36.534347] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:36.617111] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.733712] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 24/27 [00:17<00:01,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.768862] Processing image: vol_024.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.810098] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:36.873432] Capturing the local maxima \n",
            "[06:22:36.875693] Class 1\n",
            "[06:22:36.906334] Removing close points . . .\n",
            "[06:22:36.907432] Initial number of points: 313\n",
            "[06:22:36.914646] Final number of points: 143\n",
            "[06:22:36.915064] Creating the images with detected points . . .\n",
            "[06:22:36.951958] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.025784] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.057983] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:37.059366] Its respective CSV file seems to be: /content/data/test/y/mask_024.csv\n",
            "[06:22:37.060955] Reading GT data from: /content/data/test/y/mask_024.csv\n",
            "[06:22:37.064591] Detection (class 1)\n",
            "[06:22:37.070507] Points in ground truth: 82, Points in prediction: 143\n",
            "[06:22:37.071644] True positives: 74, False positives: 69, False negatives: 8\n",
            "[06:22:37.072685] Detection metrics: {'Precision': 0.5174825174825175, 'Recall': 0.9024390243902439, 'F1': 0.6577777777777779, 'TP': 74, 'FP': 69, 'FN': 8}\n",
            "[06:22:37.078610] All classes 1\n",
            "[06:22:37.080214] Detection metrics: ['Precision', 0.5174825174825175, 'Recall', 0.9024390243902439, 'F1', 0.6577777777777779]\n",
            "[06:22:37.081174] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:37.173361] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.319791] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 25/27 [00:18<00:01,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.361511] Processing image: vol_025.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.408336] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.485946] Capturing the local maxima \n",
            "[06:22:37.487174] Class 1\n",
            "[06:22:37.525443] Removing close points . . .\n",
            "[06:22:37.526742] Initial number of points: 651\n",
            "[06:22:37.542245] Final number of points: 372\n",
            "[06:22:37.542719] Creating the images with detected points . . .\n",
            "[06:22:37.575823] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.642686] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:37.676265] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:37.676347] Its respective CSV file seems to be: /content/data/test/y/mask_025.csv\n",
            "[06:22:37.676382] Reading GT data from: /content/data/test/y/mask_025.csv\n",
            "[06:22:37.682329] Detection (class 1)\n",
            "[06:22:37.703066] Points in ground truth: 330, Points in prediction: 372\n",
            "[06:22:37.704135] True positives: 295, False positives: 77, False negatives: 35\n",
            "[06:22:37.704889] Detection metrics: {'Precision': 0.793010752688172, 'Recall': 0.8939393939393939, 'F1': 0.8404558404558404, 'TP': 295, 'FP': 77, 'FN': 35}\n",
            "[06:22:37.711291] All classes 1\n",
            "[06:22:37.712124] Detection metrics: ['Precision', 0.793010752688172, 'Recall', 0.8939393939393939, 'F1', 0.8404558404558404]\n",
            "[06:22:37.712819] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:37.910756] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.064668] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 26/27 [00:18<00:00,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.100532] Processing image: vol_026.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.137322] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.197243] Capturing the local maxima \n",
            "[06:22:38.198452] Class 1\n",
            "[06:22:38.218285] Removing close points . . .\n",
            "[06:22:38.218894] Initial number of points: 120\n",
            "[06:22:38.221169] Final number of points: 60\n",
            "[06:22:38.221318] Creating the images with detected points . . .\n",
            "[06:22:38.271667] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.334768] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.358715] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:22:38.359916] Its respective CSV file seems to be: /content/data/test/y/mask_026.csv\n",
            "[06:22:38.360755] Reading GT data from: /content/data/test/y/mask_026.csv\n",
            "[06:22:38.363656] Detection (class 1)\n",
            "[06:22:38.365896] Points in ground truth: 30, Points in prediction: 60\n",
            "[06:22:38.367587] True positives: 29, False positives: 31, False negatives: 1\n",
            "[06:22:38.368453] Detection metrics: {'Precision': 0.48333333333333334, 'Recall': 0.9666666666666667, 'F1': 0.6444444444444445, 'TP': 29, 'FP': 31, 'FN': 1}\n",
            "[06:22:38.372185] All classes 1\n",
            "[06:22:38.373152] Detection metrics: ['Precision', 0.48333333333333334, 'Recall', 0.9666666666666667, 'F1', 0.6444444444444445]\n",
            "[06:22:38.374023] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:22:38.427395] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.541002] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:19<00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:22:38.572660] Releasing memory . . .\n",
            "[06:22:38.572737] #############\n",
            "[06:22:38.572773] #  RESULTS  #\n",
            "[06:22:38.572806] #############\n",
            "[06:22:38.572851] Epoch number: 49\n",
            "[06:22:38.572884] Train time (s): 0:05:21\n",
            "[06:22:38.573018] Train loss: 0.0975427155693372\n",
            "[06:22:38.573123] Train Foreground IoU: 0.3515549798806508\n",
            "[06:22:38.573162] Validation loss: 0.0523991696536541\n",
            "[06:22:38.573199] Validation Foreground IoU: 0.16887322068214417\n",
            "[06:22:38.573272] Test Foreground IoU (per patch): 0.14807002825869453\n",
            "[06:22:38.573311] Test Foreground IoU (merge patches): 0.14807002825869453\n",
            "[06:22:38.573345] Test Precision (merge patches): 0.7858325924638713\n",
            "[06:22:38.573378] Test Recall (merge patches): 0.8925039816195708\n",
            "[06:22:38.573411] Test F1 (merge patches): 0.8244076200430628\n",
            "[06:22:38.573449] Test TP (merge patches): 230.7037037037037\n",
            "[06:22:38.573481] Test FP (merge patches): 47.03703703703704\n",
            "[06:22:38.573513] Test FN (merge patches): 35.666666666666664\n",
            "[06:22:38.573542]  \n",
            "[06:22:38.573604] FINISHED JOB my_3d_detection_1 !!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play to train the model\n",
        "import os\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# remove template file it is exists\n",
        "template_file = '3d_detection.yaml'\n",
        "if os.path.exists( template_file ):\n",
        "    os.remove( template_file )\n",
        "\n",
        "# Download template file\n",
        "!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/detection/3d_detection.yaml &> /dev/null\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No csv files in dir {}\".format(train_data_path))\n",
        "if not os.path.exists(train_csv_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_csv_path)\n",
        "ids = sorted(next(os.walk(train_csv_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No images found in dir {}\".format(train_csv_path))\n",
        "\n",
        "# Check folders before modifying the .yaml file\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No images found in dir {}\".format(test_data_path))\n",
        "if test_ground_truth:\n",
        "    if not os.path.exists(test_csv_path):\n",
        "        raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_csv_path)\n",
        "    ids = sorted(next(os.walk(test_csv_path))[2])\n",
        "    if len(ids) == 0:\n",
        "        raise ValueError(\"No csv files in dir {}\".format(test_csv_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( template_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "biapy_config['SYSTEM']['NUM_CPUS'] = -1\n",
        "biapy_config['PROBLEM']['DETECTION'] = {}\n",
        "biapy_config['PROBLEM']['DETECTION']['CENTRAL_POINT_DILATION'] = [central_point_dilation]\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['TRAIN']['GT_PATH'] = train_csv_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "biapy_config['DATA']['TEST']['GT_PATH'] = test_csv_path\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size_z)+', '+ str(patch_size_xy)+', '+ str(patch_size_xy)+ ', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding_xy = patch_size_xy // 8\n",
        "padding_z = patch_size_z // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding_z)+', '+ str(padding_xy)+', '+ str(padding_xy)+')'\n",
        "biapy_config['DATA']['TEST']['RESOLUTION'] = '('+str(resolution_z)+', '+ str(resolution_xy)+', ' + str(resolution_xy)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# change source to build model - biapy, torchvision or bmz\n",
        "if changed_source:\n",
        "    if source.value == \"BiaPy\":\n",
        "        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "    elif source.value == 'Torchvision':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"torchvision\"\n",
        "        biapy_config['MODEL']['TORCHVISION_MODEL_NAME'] = t_vision.value\n",
        "    elif source.value == 'BioImage Model Zoo':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n",
        "        biapy_config['MODEL']['BMZ'] = {}\n",
        "        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_ID'] = str(bmz.value).strip()\n",
        "else:\n",
        "    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "\n",
        "\n",
        "# Transcribe model architecture\n",
        "# Available models: \"U-Net\", \"Residual U-Net\", \"Attention U-Net\",\n",
        "# 'MultiResUNet', 'SEUNet', 'ResUNet++', \"UNETR-Mini\",\"UNETR-Small\"\n",
        "# \"UNETR-Base\"architecture = 'unet'\n",
        "if model_architecture == \"U-Net\":\n",
        "    architecture = 'unet'\n",
        "elif model_architecture == \"Residual U-Net\":\n",
        "    architecture = 'resunet'\n",
        "elif model_architecture == \"Attention U-Net\":\n",
        "    architecture = 'attention_unet'\n",
        "elif model_architecture == \"MultiResUNet\":\n",
        "    architecture = 'multiresunet'\n",
        "elif model_architecture == \"SEUNet\":\n",
        "    architecture = 'seunet'\n",
        "elif model_architecture == \"ResUNet++\":\n",
        "    architecture = 'resunet++'\n",
        "elif model_architecture == \"UNETR-Mini\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 64\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 4\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4. # to get 256\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 4\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 1\n",
        "elif model_architecture == \"UNETR-Small\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 128\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 8\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4. # to get 512\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 8\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 2\n",
        "elif model_architecture == \"UNETR-Base\":\n",
        "    architecture = 'unetr'\n",
        "    biapy_config['MODEL']['VIT_TOKEN_SIZE'] = 16\n",
        "    biapy_config['MODEL']['VIT_EMBED_DIM'] = 384\n",
        "    biapy_config['MODEL']['VIT_NUM_LAYERS'] = 12\n",
        "    biapy_config['MODEL']['VIT_MLP_RATIO'] = 4.\n",
        "    biapy_config['MODEL']['VIT_NUM_HEADS'] = 12\n",
        "    biapy_config['MODEL']['UNETR_VIT_HIDD_MULT'] = 3\n",
        "    biapy_config['MODEL']['UNETR_VIT_NUM_FILTERS'] = 32\n",
        "    biapy_config['TEST']['FULL_IMG'] = False\n",
        "else: # U-NeXt V1\n",
        "    architecture = 'unext_v1'\n",
        "    biapy_config['MODEL']['FEATURE_MAPS'] = \"[16, 32, 64, 128]\"\n",
        "    biapy_config['MODEL']['CONVNEXT_LAYERS'] = \"[1, 1, 1, 1]\"\n",
        "    biapy_config['MODEL']['CONVNEXT_STEM_K_SIZE'] = 1\n",
        "\n",
        "\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "if anisotropic_data == True:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [1 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "else:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [2 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "\n",
        "\n",
        "# Class rebalance\n",
        "biapy_config['LOSS'] = {}\n",
        "biapy_config['LOSS']['CLASS_REBALANCE'] = True\n",
        "\n",
        "# learning rate scheduler\n",
        "if learning_rate_scheduler == 'One cycle':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'onecycle'\n",
        "elif learning_rate_scheduler == 'Warm-up cosine decay':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'warmupcosine'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.0\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['WARMUP_COSINE_DECAY_EPOCHS'] = 0\n",
        "elif learning_rate_scheduler == 'Reduce on plateau':\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER'] = {}\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['NAME'] = 'reduceonplateau'\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_FACTOR'] = 0.5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['REDUCEONPLATEAU_PATIENCE'] = 5\n",
        "    biapy_config['TRAIN']['LR_SCHEDULER']['MIN_LR'] = 0.00001\n",
        "\n",
        "# update test parameters\n",
        "biapy_config['TEST']['FULL_IMG']=False\n",
        "biapy_config['TEST']['AUGMENTATION'] = test_time_augmentation\n",
        "biapy_config['DATA']['TEST']['LOAD_GT'] = test_ground_truth\n",
        "biapy_config['TEST']['ENABLE'] = True\n",
        "biapy_config['TEST']['REDUCE_MEMORY'] = True\n",
        "\n",
        "# Detection parameters\n",
        "biapy_config['TEST']['DET_MIN_TH_TO_BE_PEAK'] = min_value_to_be_peak\n",
        "biapy_config['TEST']['DET_TOLERANCE'] = tolerance\n",
        "biapy_config['TEST']['DET_EXCLUDE_BORDER'] = False\n",
        "biapy_config['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS'] = remove_close_points\n",
        "biapy_config['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS_RADIUS'] = remove_close_points_radius\n",
        "\n",
        "# model weights\n",
        "if checkpoint_path != '':\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4i0N2vOWUes"
      },
      "source": [
        "## **Inspection of the Loss Function and the Intersection over Union (IoU)**\n",
        "---\n",
        "\n",
        "Before proceeding with interpretations, it's pivotal to gauge the training evolution by juxtaposing the training loss against the validation loss. The validation loss casts light on the model's efficacy over a reserved subset of data unseen during training. A deeper understanding can be garnered from [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n",
        "\n",
        "- **Training Loss**: This captures the discrepancy between the model's predictions and the actual ground-truth after each epoch.\n",
        "\n",
        "- **Validation Loss**: This signifies the error between the model's estimates on validation images and their actual counterparts.\n",
        "\n",
        "As training unfurls, these metrics are expected to wane, eventually plateauing at an optimal, minimal value. Contrasting the trajectories of these losses can yield vital information about the model's adaptability.\n",
        "\n",
        "- **Decreasing Training and Validation Losses**: This trend is indicative of potential model improvements with further training. Elevating the `number_of_epochs` is advised in such scenarios. Notably, even if the loss curves seem to stabilize towards the tail end, it might be a mere visual effect due to y-axis scaling. The model is considered convergent once the curves genuinely flatten, marking the end of required training.\n",
        "\n",
        "- **Divergent Losses**: An upward tick in validation loss while training loss gravitates towards zero hints at overfitting. It suggests that the model is intricately memorizing training patterns at the cost of broader applicability. A more substantial training dataset can alleviate this.\n",
        "\n",
        "The **Jaccard Index, also known as the Intersection over Union (IoU)**, offers a means to evaluate the overlap between the target mask and prediction. **A score inching towards 1 denotes optimal performance.** It's a handy metric to gauge the precision of your model in predicting cellular structures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "ur21krhZVwX2",
        "outputId": "9285dce0-50e7-4029-e615-949e8a38cefe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play the cell to show a plot of training error vs. epoch number and IoU vs epoch number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n",
        "\n",
        "iou_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_IoU.png' )\n",
        "\n",
        "fig = plt.figure( figsize = (20,10))\n",
        "ax1 = plt.subplot( 1, 2, 1 )\n",
        "_ = plt.imshow( loss_plot )\n",
        "_ = plt.axis('off')\n",
        "ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n",
        "\n",
        "ax2 = plt.subplot( 1, 2, 2 )\n",
        "_ = plt.imshow( iou_plot )\n",
        "_ = plt.axis('off')\n",
        "_= ax2.set_title( 'Intersection over Union (IoU) vs epoch number', fontdict = {'fontsize':22})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30kYCWjYI9W1"
      },
      "source": [
        "## **Visualize detection results (from the test set)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3a77163cf9c44e02ba7985ebe4b67da5",
            "9d2874c84f194e819725916dc97bb798",
            "037c5f9ca0184fb3847e322a90ba375b",
            "bfd726fb095346d098d443851b92c538",
            "32a1f4a163ce4fb7ab0c1e846c60d8dd",
            "b1538e0c004848eea86147c40b5929d9",
            "bccd8ed23f164ac09534c37142717ee7",
            "abf3fc981ddd48bcb80fbb6742cca65f",
            "0be9bc22de2e4c52a481232f5ce10e0f",
            "c3e3f89aaf9c4fc59fa5b6a391c17626",
            "a9e0523eb34241a0848b733e0bd33fa3",
            "07c913ddc9a643ef95c373e60ccb0ce9",
            "79162c3b78b344618c9faa7b50a4535d",
            "62020c5372224506963a9d2fba545349",
            "5f773d90cfac4e55af5eae59f45ec903",
            "76c57cb3014e47d898c93f1a21ed265f",
            "87f1f50790e64ba0b4d56ef92941d4ad",
            "7242ab6a7f5b41c1bacf39d1978fce2a",
            "21dbf73b088c4dce92f182b0574dd3a5",
            "3422d6fec5f64cbda3196cda951d4d48",
            "cc2d1e42c9f6453489a67d5f5c4c9cc5"
          ]
        },
        "id": "cEIcTV3Tj6OJ",
        "outputId": "addd9d77-7b6e-4306-c9ef-631d123ed3cf",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a77163cf9c44e02ba7985ebe4b67da5"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abf3fc981ddd48bcb80fbb6742cca65f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21dbf73b088c4dce92f182b0574dd3a5"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "#@markdown ###Play to visualize some results from the test set\n",
        "#@markdown The current model will be applied to some test images and results will be shown as browsable 2D stacks displaying:\n",
        "#@markdown 1. The original **Source** (input) image.\n",
        "#@markdown 2. Its corresponding **Ground truth** labels (if `test_ground_truth` was checked).\n",
        "#@markdown 3. The model **Prediction** detections image.\n",
        "#@markdown 4. The **Associations** between predicted and ground truth detections (if `test_ground_truth` was checked).\n",
        "\n",
        "#@markdown Associations between predictions and ground truth are illustrated as follows:\n",
        "#@markdown - **Green**: True positives.\n",
        "#@markdown - **Red**: False negatives.\n",
        "#@markdown - **Blue**: False positives.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from numpy.random import randint, seed\n",
        "from matplotlib import pyplot as plt\n",
        "from ipywidgets import interact, fixed\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "detection_results = os.path.join(final_results, \"per_image_local_max_check\")\n",
        "assoc_results = os.path.join(final_results, \"point_associations\")\n",
        "if test_ground_truth:\n",
        "    test_data_gt_path = \"/content/data/test/y_detection_masks\"\n",
        "\n",
        "# Show a few examples to check that they have been stored correctly\n",
        "ids_pred = sorted(next(os.walk(detection_results))[2])\n",
        "ids_pred = [x for x in ids_pred if not x.endswith('.csv') ]\n",
        "ids_assoc = sorted(next(os.walk(assoc_results))[2])\n",
        "ids_assoc = [x for x in ids_assoc if not x.endswith('.csv') ]\n",
        "ids_assoc = [x for x in ids_assoc if \"_gt_ids\" not in x ]\n",
        "ids_assoc = [x for x in ids_assoc if \"_pred_ids\" not in x ]\n",
        "ids_input = sorted(next(os.walk(test_data_path))[2])\n",
        "if test_ground_truth:\n",
        "    ids_gt = sorted(next(os.walk(test_data_gt_path))[2])\n",
        "\n",
        "samples_to_show = min(len(ids_input), 3)\n",
        "chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n",
        "seed(1)\n",
        "\n",
        "test_samples = []\n",
        "test_sample_preds = []\n",
        "if test_ground_truth:\n",
        "    test_sample_gt = []\n",
        "    test_sample_assoc = []\n",
        "\n",
        "# read 3D images again\n",
        "for i in range(len(chosen_images)):\n",
        "    aux = imread(os.path.join(test_data_path, ids_input[chosen_images[i]]))\n",
        "    test_samples.append(np.squeeze(aux))\n",
        "\n",
        "    aux = imread(os.path.join(detection_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n",
        "    test_sample_preds.append(np.squeeze(aux))\n",
        "\n",
        "    if test_ground_truth:\n",
        "        aux = imread(os.path.join(test_data_gt_path, ids_gt[chosen_images[i]])).astype(np.uint16)\n",
        "        test_sample_gt.append(np.squeeze(aux))\n",
        "\n",
        "        aux = imread(os.path.join(assoc_results, ids_assoc[chosen_images[i]]))\n",
        "        test_sample_assoc.append(np.squeeze(aux))\n",
        "\n",
        "# function to show results in 3D within a widget\n",
        "def scroll_in_z(z, j):\n",
        "    plt.figure(figsize=(18,4))\n",
        "    # Source\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_samples[j][z-1], cmap='gray')\n",
        "    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_sample_preds[j][z-1], interpolation='nearest')\n",
        "    plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    if test_ground_truth:\n",
        "        # Target (Ground-truth)\n",
        "        plt.subplot(1,4,2)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_gt[j][z-1], interpolation='nearest')\n",
        "        plt.title('Ground truth (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "        # Overlay\n",
        "        plt.subplot(1,4,4)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(test_sample_assoc[j][z-1], interpolation='nearest')\n",
        "        plt.title('Associations (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "for j in range(samples_to_show):\n",
        "    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_samples[j].shape[0], step=1, value=test_samples[j].shape[0]//2), j=fixed(j));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mlQnAH6uAawl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0977e401-23f4-4773-9238-560ef71e9c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:30:37.660266] Output paths:\n",
            "[06:30:37.662520]     Detection files are in /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        }
      ],
      "source": [
        "#@markdown ###Play to display the path to the output files (one 3D TIFF label image for each input image).\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "detection_results = os.path.join(final_results, \"per_image_local_max_check\")\n",
        "\n",
        "print(\"Output paths:\")\n",
        "print(\"    Detection files are in {}\".format(detection_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "VwabL1znb1h7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f3838a-32e0-4cb9-f071-c6b79477be5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:30:38.667145] Output paths:\n",
            "[06:30:38.667672]     Detection files are in /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        }
      ],
      "source": [
        "#@markdown ###Play to display the path to the association files (one 3D TIFF label image for each input image).\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "detection_assoc_results = os.path.join(final_results, \"point_associations\")\n",
        "\n",
        "print(\"Output paths:\")\n",
        "print(\"    Detection files are in {}\".format(detection_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdCIYo4ohcAw"
      },
      "source": [
        "## **Download detection results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gnRa9DOUP0FM",
        "outputId": "e3a120af-1594-4e53-bb31-e6295a109094"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_9972b2b8-0cd4-4077-a54b-6a5e68907fea\", \"detection.zip\", 175589)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download a zip file with all detection results in test.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "!zip -q -j /content/detection.zip $detection_results/*.tif\n",
        "\n",
        "files.download(\"/content/detection.zip\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cOkH_YgqX0l2",
        "outputId": "0bac80c9-4426-4092-937d-10ea253f774d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_a15ab68c-c8f5-4acc-8e1a-2a512912ddbf\", \"detection_associations.zip\", 791332)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ### Click to Download a ZIP File with All Detection Association Results from Testing\n",
        "#@markdown For each test sample, several files are expected:\n",
        "#@markdown - '*_fn.csv': Contains the false positives (FPs)\n",
        "#@markdown - '*_gt_assoc.csv': Houses the associations between ground truth (GT) and prediction, encompassing both true positives (TP) and false negatives (FN)\n",
        "#@markdown - '*_gt_ids.tif': Represents labels for ground truth points\n",
        "#@markdown - '*_pred_ids.tif': Contains labels for predicted points\n",
        "#@markdown - '*.tif': Showcases associations between GT and predictions with colored indicators:\n",
        "#@markdown   - **Green**: True positives (TP)\n",
        "#@markdown   - **Red**: False negatives (FN)\n",
        "#@markdown   - **Blue**: False positives (FP)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "!zip -q -j /content/detection_associations.zip $detection_assoc_results/*.tif\n",
        "\n",
        "files.download(\"/content/detection_associations.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwt72WYddVgl"
      },
      "source": [
        "## **Download train model (weights and configuration file)**\n",
        "---\n",
        "If you want to **reuse the train model in the future**, you can download both the model weights and its configuration file (.YAML) by running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XoFclBfEduZC",
        "outputId": "6886ef7c-453d-4f0e-bfa2-e0deb21663ef"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_087df531-2b63-4abb-a826-4d6d702616bb\", \"model_weights_my_3d_instance_segmentation_1.h5\", 8366600)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "#@markdown ###Play to download the model weights\n",
        "\n",
        "checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n",
        "\n",
        "weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n",
        "\n",
        "files.download( os.path.join( checkpoints_path, weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "raDdSsz1dujE",
        "outputId": "deac9145-d0f1-4426-ddad-13f34126f4f0"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_32a5000b-a7f2-4315-9748-8d2c8ae8fb41\", \"my_3d_instance_segmentation.yaml\", 1049)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download the model configuration file (.YAML)\n",
        "\n",
        "config_path = os.path.join(output_path, job_name, 'config_files')\n",
        "\n",
        "files.download( os.path.join( config_path, yaml_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aruFYtbIqxoi"
      },
      "source": [
        "## **Export your model to BioImage Model Zoo format**\n",
        "---\n",
        "If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWHr_sQK_-qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##Construct model's metadata to export it to the BioImage Model Zoo format. Choose just one option:\n",
        "\n",
        "#@markdown **Option 1: Reuse previous BioImage Model Zoo model configuration**\n",
        "\n",
        "#@markdown With this option, if you were using a model from BioImage Model Zoo you can select this option to reuse its configuration instead of provide all fields manually. If that's not the case and you try to use this option an error will be thrown.\n",
        "reuse_previous_BMZ_model_config = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Option 2: Manual export fields**\n",
        "\n",
        "#@markdown With this option you need to introduce manually the metadata of the model.\n",
        "\n",
        "# ------------- User input ------------\n",
        "# information about the model\n",
        "trained_model_name    = \"\" #@param {type:\"string\"}\n",
        "trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n",
        "trained_model_authors_github_user =  \"[First Author Github User, Second Author Github User, Third Author Github User]\" #@param {type:\"string\"}\n",
        "trained_model_description = \"\" #@param {type:\"string\"}\n",
        "trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n",
        "trained_model_references = [\"Ronneberger et al. arXiv in 2015\", \"Franco-Barranco, Daniel, et al. ISBI in 2023\"] #@param {type:\"string\"}\n",
        "trained_model_references_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n",
        "trained_model_tags = \"[\\\"tag-1\\\", \\\"tag-2\\\"]\" #@param {type:\"string\"}\n",
        "trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KH8UuC_CgpH2"
      },
      "outputs": [],
      "source": [
        "# @markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "bmz_results = os.path.join(final_results, \"bmz_model\")\n",
        "\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "\n",
        "    # create the author spec input\n",
        "    auth_names = trained_model_authors[1:-1].split(\",\")\n",
        "    auth_githubusers = trained_model_authors_github_user[1:-1].split(\",\")\n",
        "    assert len(auth_names) == len(auth_githubusers)\n",
        "    authors = [{\"name\": auth_name, \"github_user\": auth_guser} for auth_name, auth_guser in zip(auth_names, auth_githubusers)]\n",
        "\n",
        "    # create the citation input spec\n",
        "    assert len(trained_model_references_DOI) == len(trained_model_references)\n",
        "    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_references_DOI)]\n",
        "\n",
        "    tags = [t for t in trained_model_tags.split(\",\")]\n",
        "\n",
        "    with open(trained_model_documentation, \"w\") as f:\n",
        "        f.write(\"### **Description**\\n\")\n",
        "        f.write(f\"{trained_model_description}\\n\\n\")\n",
        "        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n",
        "\n",
        "    bmz_cfg = {}\n",
        "    # Description of the model\n",
        "    bmz_cfg['description'] = trained_model_description\n",
        "    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Daniel\", \"github_user\": \"danifranco\"}]\n",
        "    bmz_cfg['authors'] = authors\n",
        "    # License of the model. E.g. \"CC-BY-4.0\"\n",
        "    bmz_cfg['license'] = trained_model_license\n",
        "    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n",
        "    bmz_cfg['tags'] = tags\n",
        "    # Tags to make models more findable on the website, e.g. tags=[\"electron-microscopy\", \"mitochondria\"]\n",
        "    bmz_cfg['cite'] = citations\n",
        "    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n",
        "    bmz_cfg['doc'] = trained_model_documentation\n",
        "    # Name of the model\n",
        "    bmz_cfg[\"model_name\"] = trained_model_name\n",
        "    biapy.export_model_to_bmz(bmz_results, bmz_cfg)\n",
        "else:\n",
        "    try:\n",
        "        biapy.export_model_to_bmz(bmz_results, reuse_original_bmz_config=True)\n",
        "    except:\n",
        "        print(\"Seems that the was a problem reusing BMZ model specs. Please uncheck 'reuse_previous_BMZ_model_config' and do it manually\")\n",
        "\n",
        "download = True\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "    bmz_zip_path = f\"/{bmz_results}/{trained_model_name}.zip\"\n",
        "else:\n",
        "    ids = sorted(next(os.walk(bmz_results))[2])\n",
        "    ids = [x for x in ids if x.endswith(\".zip\")]\n",
        "    if len(ids) > 1:\n",
        "        print(f\"There are more than one ZIP files in {bmz_results} folder. Please check which one you want you want to download and do it manually.\")\n",
        "        download = False\n",
        "    elif len(ids) == 0:\n",
        "        print(f\"BMZ zip file could not be found.\")\n",
        "        download = False\n",
        "    else: # only one zip\n",
        "        ids = ids[0]\n",
        "    bmz_zip_path = f\"/{bmz_results}/{ids}\"\n",
        "\n",
        "if download and os.path.exists(bmz_zip_path):\n",
        "    files.download(bmz_zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObM24OqXIIEL"
      },
      "source": [
        "## **Advanced options**\n",
        "---\n",
        "Here you will be able to modify some parameters of the post-processing step to improve your detection results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYWec6IqNzIH"
      },
      "source": [
        "### **Adjust detection threshold values**\n",
        "---\n",
        "* **`min_value_to_be_peak`:** Minimun probability value to consider a point as a peak. The lowest this value is, the more points will be detected. Decrease it if you get to few detections, and increase it if you get too many false positives. **Default: 0.3.**\n",
        "\n",
        "* **`tolerance`:** Maximum distance of a predicted point from a ground truth point to be considered as a true positive. **Default value: 10**\n",
        "\n",
        "* **`remove_close_points`:** Merge close detections into single ones. **Default value: True**\n",
        "\n",
        "* **`remove_close_points_radius`:** Distance between two detections to be considered the same (if `remove_close_points` is set to True). **Default value: 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OyTutXhTIwTO"
      },
      "outputs": [],
      "source": [
        "#@markdown ### Detection parameters:\n",
        "min_value_to_be_peak = 0.3 #@param {type:\"number\"}\n",
        "tolerance = 10 #@param {type:\"number\"}\n",
        "remove_close_points = True #@param {type:\"boolean\"}\n",
        "remove_close_points_radius= 3 #@param {type:\"number\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4msBG9zOE64"
      },
      "source": [
        "### **Run inference**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCUY_JxANO9_",
        "outputId": "940cda98-bfda-42ce-8a6f-81c81f4bb160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:51.866660] Inference configuration finished.\n",
            "[06:36:51.879535] Date: 2024-09-04 06:36:51\n",
            "[06:36:51.879642] Arguments: Namespace(config='/content/my_3d_detection_inference.yaml', result_dir='/content/output', name='my_3d_detection', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "[06:36:51.879709] Job: my_3d_detection_1\n",
            "[06:36:51.879757] Python       : 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "[06:36:51.879798] PyTorch:  2.4.0+cu121\n",
            "[06:36:51.881021] Not using distributed mode\n",
            "[06:36:51.887625] Configuration details:\n",
            "[06:36:51.887688] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: True\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: False\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: True\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    APPLICATION_MODE: image\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    PERC_CLIP: False\n",
            "    PERC_LOWER: -1.0\n",
            "    PERC_UPPER: -1.0\n",
            "    TYPE: div\n",
            "  PATCH_SIZE: (64, 64, 64, 1)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/test/x/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/test/y_detection_masks\n",
            "    GT_PATH: /content/data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/test/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/test/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: True\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (8, 8, 8)\n",
            "    PATH: /content/data/test/x\n",
            "    RESOLUTION: (0.48, 0.51, 0.51)\n",
            "    SSL_SOURCE_DIR: /content/data/test/x_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: /content/data/train/y_detection_masks\n",
            "    GT_PATH: /content/data/train/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: /content/data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: 3.814697265625e-06\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: /content/data/train/x\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train/x_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    DIST_EVAL: True\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_3d_detection/train_logs\n",
            "  LOG_FILE_PREFIX: my_3d_detection_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: True\n",
            "  TYPE: CE\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: ELU\n",
            "  ARCHITECTURE: resunet\n",
            "  BMZ:\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0.0, 0.0, 0.0, 0.0]\n",
            "  FEATURE_MAPS: [18, 36, 48, 64]\n",
            "  ISOTROPY: [True, True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LAST_ACTIVATION: sigmoid\n",
            "  LOAD_CHECKPOINT: True\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 2\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: pre\n",
            "  UPSAMPLE_LAYER: convtranspose\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [2, 2, 2]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_3d_detection/results/my_3d_detection_1/charts\n",
            "  CHECKPOINT: /content/output/my_3d_detection/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_3d_detection/results/my_3d_detection_1/aug\n",
            "  GEN_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_3d_detection/results/my_3d_detection_1/gen_mask_check\n",
            "  LWR_X_FILE: /content/output/my_3d_detection/checkpoints/lower_bound_X_perc.npy\n",
            "  LWR_Y_FILE: /content/output/my_3d_detection/checkpoints/lower_bound_Y_perc.npy\n",
            "  MAE_OUT_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/MAE_checks\n",
            "  MEAN_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_3d_detection/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_3d_detection/results/my_3d_detection_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_3d_detection/results/my_3d_detection_1/instance_associations\n",
            "    PATH: /content/output/my_3d_detection/results/my_3d_detection_1\n",
            "    PER_IMAGE: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_3d_detection/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: /content/data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/train_BC_instance_channels\n",
            "  UPR_X_FILE: /content/output/my_3d_detection/checkpoints/upper_bound_X_perc.npy\n",
            "  UPR_Y_FILE: /content/output/my_3d_detection/checkpoints/upper_bound_Y_perc.npy\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_detection/results/my_3d_detection_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_3d_detection/results/my_3d_detection_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [0, 0, 0]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 3D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1, 1)\n",
            "  TYPE: DETECTION\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: 5\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    FORMAT: H5\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.3]\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['iou']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGN: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: True\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [3]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: True\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 8\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: False\n",
            "  EPOCHS: 150\n",
            "  LR: 0.001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: 0.0\n",
            "    NAME: warmupcosine\n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: 0\n",
            "  METRICS: ['iou']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 20\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[06:36:51.888619] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[06:36:51.888665] Initializing Detection_Workflow\n",
            "[06:36:51.888705] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[06:36:51.893357] ############################\n",
            "[06:36:51.893423] #  PREPARE DETECTION DATA  #\n",
            "[06:36:51.893466] ############################\n",
            "[06:36:51.895488] DATA.TEST.GT_PATH changed from /content/data/test/y to /content/data/test/y_detection_masks\n",
            "[06:36:51.896567] ######################\n",
            "[06:36:51.896641] #   LOAD TEST DATA   #\n",
            "[06:36:51.896686] ######################\n",
            "[06:36:51.896736] 2) Loading test images . . .\n",
            "[06:36:51.896800] Loading data from /content/data/test/x\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:00<00:00, 1280.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:51.931155] *** Loaded data shape is (27, 64, 64, 64, 1)\n",
            "[06:36:51.931269] 3) Loading test masks . . .\n",
            "[06:36:51.932867] Loading data from /content/data/test/y_detection_masks\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:00<00:00, 188.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.084809] *** Loaded data shape is (27, 64, 64, 64, 1)\n",
            "[06:36:52.085075] ###############\n",
            "[06:36:52.085124] # Build model #\n",
            "[06:36:52.085157] ###############\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.144789] Loading checkpoint from file /content/output/my_3d_detection/checkpoints/my_3d_detection_1-checkpoint-best.pth\n",
            "[06:36:52.238436] Model weights loaded!\n",
            "[06:36:52.239860] ############################\n",
            "[06:36:52.239947] #  PREPARE TEST GENERATOR  #\n",
            "[06:36:52.239988] ############################\n",
            "[06:36:52.246226] ###############\n",
            "[06:36:52.246308] #  INFERENCE  #\n",
            "[06:36:52.246364] ###############\n",
            "[06:36:52.246413] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/27 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.256712] Processing image: vol_000.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.295271] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.344401] Capturing the local maxima \n",
            "[06:36:52.346350] Class 1\n",
            "[06:36:52.362609] Removing close points . . .\n",
            "[06:36:52.362686] Initial number of points: 87\n",
            "[06:36:52.365148] Final number of points: 54\n",
            "[06:36:52.365284] Creating the images with detected points . . .\n",
            "[06:36:52.390799] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.436214] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.460460] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:52.461360] Its respective CSV file seems to be: /content/data/test/y/mask_000.csv\n",
            "[06:36:52.461430] Reading GT data from: /content/data/test/y/mask_000.csv\n",
            "[06:36:52.465007] Detection (class 1)\n",
            "[06:36:52.467797] Points in ground truth: 61, Points in prediction: 54\n",
            "[06:36:52.467876] True positives: 53, False positives: 1, False negatives: 8\n",
            "[06:36:52.467974] Detection metrics: {'Precision': 0.9814814814814815, 'Recall': 0.8688524590163934, 'F1': 0.9217391304347826, 'TP': 53, 'FP': 1, 'FN': 8}\n",
            "[06:36:52.472261] All classes 1\n",
            "[06:36:52.472386] Detection metrics: ['Precision', 0.9814814814814815, 'Recall', 0.8688524590163934, 'F1', 0.9217391304347826]\n",
            "[06:36:52.472450] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:52.529992] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.619150] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|\u258e         | 1/27 [00:00<00:10,  2.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.651067] Processing image: vol_001.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.689338] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.748444] Capturing the local maxima \n",
            "[06:36:52.749355] Class 1\n",
            "[06:36:52.783050] Removing close points . . .\n",
            "[06:36:52.783163] Initial number of points: 799\n",
            "[06:36:52.792402] Final number of points: 535\n",
            "[06:36:52.792713] Creating the images with detected points . . .\n",
            "[06:36:52.819059] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.869197] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:52.901372] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:52.901480] Its respective CSV file seems to be: /content/data/test/y/mask_001.csv\n",
            "[06:36:52.901533] Reading GT data from: /content/data/test/y/mask_001.csv\n",
            "[06:36:52.905700] Detection (class 1)\n",
            "[06:36:52.936358] Points in ground truth: 649, Points in prediction: 535\n",
            "[06:36:52.936779] True positives: 535, False positives: 0, False negatives: 114\n",
            "[06:36:52.936897] Detection metrics: {'Precision': 1.0, 'Recall': 0.8243451463790447, 'F1': 0.9037162162162162, 'TP': 535, 'FP': 0, 'FN': 114}\n",
            "[06:36:52.944569] All classes 1\n",
            "[06:36:52.944679] Detection metrics: ['Precision', 1.0, 'Recall', 0.8243451463790447, 'F1', 0.9037162162162162]\n",
            "[06:36:52.944733] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:53.355740] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.453403] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "  7%|\u258b         | 2/27 [00:01<00:16,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.488391] Processing image: vol_002.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.523579] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.570383] Capturing the local maxima \n",
            "[06:36:53.571241] Class 1\n",
            "[06:36:53.588369] Removing close points . . .\n",
            "[06:36:53.589032] Initial number of points: 78\n",
            "[06:36:53.590608] Final number of points: 37\n",
            "[06:36:53.590732] Creating the images with detected points . . .\n",
            "[06:36:53.616956] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.663877] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.688087] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:53.688186] Its respective CSV file seems to be: /content/data/test/y/mask_002.csv\n",
            "[06:36:53.688246] Reading GT data from: /content/data/test/y/mask_002.csv\n",
            "[06:36:53.691739] Detection (class 1)\n",
            "[06:36:53.695786] Points in ground truth: 19, Points in prediction: 37\n",
            "[06:36:53.695863] True positives: 19, False positives: 18, False negatives: 0\n",
            "[06:36:53.695957] Detection metrics: {'Precision': 0.5135135135135135, 'Recall': 1.0, 'F1': 0.6785714285714285, 'TP': 19, 'FP': 18, 'FN': 0}\n",
            "[06:36:53.700292] All classes 1\n",
            "[06:36:53.700408] Detection metrics: ['Precision', 0.5135135135135135, 'Recall', 1.0, 'F1', 0.6785714285714285]\n",
            "[06:36:53.700473] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:53.748754] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.841377] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 11%|\u2588         | 3/27 [00:01<00:12,  1.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.875437] Processing image: vol_003.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.915740] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:53.970787] Capturing the local maxima \n",
            "[06:36:53.972011] Class 1\n",
            "[06:36:54.016622] Removing close points . . .\n",
            "[06:36:54.017608] Initial number of points: 834\n",
            "[06:36:54.035671] Final number of points: 496\n",
            "[06:36:54.037328] Creating the images with detected points . . .\n",
            "[06:36:54.091085] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:54.158191] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:54.199520] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:54.200839] Its respective CSV file seems to be: /content/data/test/y/mask_003.csv\n",
            "[06:36:54.201826] Reading GT data from: /content/data/test/y/mask_003.csv\n",
            "[06:36:54.205603] Detection (class 1)\n",
            "[06:36:54.261601] Points in ground truth: 501, Points in prediction: 496\n",
            "[06:36:54.261744] True positives: 496, False positives: 0, False negatives: 5\n",
            "[06:36:54.262499] Detection metrics: {'Precision': 1.0, 'Recall': 0.9900199600798403, 'F1': 0.9949849548645937, 'TP': 496, 'FP': 0, 'FN': 5}\n",
            "[06:36:54.275768] All classes 1\n",
            "[06:36:54.278284] Detection metrics: ['Precision', 1.0, 'Recall', 0.9900199600798403, 'F1', 0.9949849548645937]\n",
            "[06:36:54.281395] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:54.627003] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:54.767133] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 15%|\u2588\u258d        | 4/27 [00:02<00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:54.807232] Processing image: vol_004.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:54.850406] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:54.935894] Capturing the local maxima \n",
            "[06:36:54.937060] Class 1\n",
            "[06:36:54.963359] Removing close points . . .\n",
            "[06:36:54.964519] Initial number of points: 403\n",
            "[06:36:54.977319] Final number of points: 244\n",
            "[06:36:54.980047] Creating the images with detected points . . .\n",
            "[06:36:55.035268] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.116108] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.157771] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:55.161273] Its respective CSV file seems to be: /content/data/test/y/mask_004.csv\n",
            "[06:36:55.162075] Reading GT data from: /content/data/test/y/mask_004.csv\n",
            "[06:36:55.164919] Detection (class 1)\n",
            "[06:36:55.177320] Points in ground truth: 259, Points in prediction: 244\n",
            "[06:36:55.181600] True positives: 244, False positives: 0, False negatives: 15\n",
            "[06:36:55.182465] Detection metrics: {'Precision': 1.0, 'Recall': 0.9420849420849421, 'F1': 0.970178926441352, 'TP': 244, 'FP': 0, 'FN': 15}\n",
            "[06:36:55.187986] All classes 1\n",
            "[06:36:55.188857] Detection metrics: ['Precision', 1.0, 'Recall', 0.9420849420849421, 'F1', 0.970178926441352]\n",
            "[06:36:55.189680] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:55.372986] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.527675] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 19%|\u2588\u258a        | 5/27 [00:03<00:15,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.573123] Processing image: vol_005.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.617540] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.682572] Capturing the local maxima \n",
            "[06:36:55.683497] Class 1\n",
            "[06:36:55.708056] Removing close points . . .\n",
            "[06:36:55.708917] Initial number of points: 250\n",
            "[06:36:55.713344] Final number of points: 170\n",
            "[06:36:55.714314] Creating the images with detected points . . .\n",
            "[06:36:55.757315] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.822600] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:55.857991] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:55.859067] Its respective CSV file seems to be: /content/data/test/y/mask_005.csv\n",
            "[06:36:55.859788] Reading GT data from: /content/data/test/y/mask_005.csv\n",
            "[06:36:55.865804] Detection (class 1)\n",
            "[06:36:55.876478] Points in ground truth: 174, Points in prediction: 170\n",
            "[06:36:55.877437] True positives: 170, False positives: 0, False negatives: 4\n",
            "[06:36:55.878263] Detection metrics: {'Precision': 1.0, 'Recall': 0.9770114942528736, 'F1': 0.9883720930232558, 'TP': 170, 'FP': 0, 'FN': 4}\n",
            "[06:36:55.883214] All classes 1\n",
            "[06:36:55.885372] Detection metrics: ['Precision', 1.0, 'Recall', 0.9770114942528736, 'F1', 0.9883720930232558]\n",
            "[06:36:55.886201] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:56.055492] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.236139] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 22%|\u2588\u2588\u258f       | 6/27 [00:04<00:15,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.286330] Processing image: vol_006.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.333903] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.408524] Capturing the local maxima \n",
            "[06:36:56.410441] Class 1\n",
            "[06:36:56.429619] Removing close points . . .\n",
            "[06:36:56.431332] Initial number of points: 39\n",
            "[06:36:56.434079] Final number of points: 27\n",
            "[06:36:56.434925] Creating the images with detected points . . .\n",
            "[06:36:56.496575] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.562979] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.586521] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:56.587747] Its respective CSV file seems to be: /content/data/test/y/mask_006.csv\n",
            "[06:36:56.588454] Reading GT data from: /content/data/test/y/mask_006.csv\n",
            "[06:36:56.590631] Detection (class 1)\n",
            "[06:36:56.594254] Points in ground truth: 22, Points in prediction: 27\n",
            "[06:36:56.595296] True positives: 21, False positives: 6, False negatives: 1\n",
            "[06:36:56.596288] Detection metrics: {'Precision': 0.7777777777777778, 'Recall': 0.9545454545454546, 'F1': 0.8571428571428572, 'TP': 21, 'FP': 6, 'FN': 1}\n",
            "[06:36:56.599746] All classes 1\n",
            "[06:36:56.600700] Detection metrics: ['Precision', 0.7777777777777778, 'Recall', 0.9545454545454546, 'F1', 0.8571428571428572]\n",
            "[06:36:56.601591] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:56.660763] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.812581] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 26%|\u2588\u2588\u258c       | 7/27 [00:04<00:13,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.852433] Processing image: vol_007.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.888577] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:56.968126] Capturing the local maxima \n",
            "[06:36:56.969972] Class 1\n",
            "[06:36:56.993620] Removing close points . . .\n",
            "[06:36:56.994698] Initial number of points: 166\n",
            "[06:36:56.999291] Final number of points: 115\n",
            "[06:36:57.001126] Creating the images with detected points . . .\n",
            "[06:36:57.063275] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.135738] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.164698] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:57.164827] Its respective CSV file seems to be: /content/data/test/y/mask_007.csv\n",
            "[06:36:57.166899] Reading GT data from: /content/data/test/y/mask_007.csv\n",
            "[06:36:57.171360] Detection (class 1)\n",
            "[06:36:57.178742] Points in ground truth: 121, Points in prediction: 115\n",
            "[06:36:57.178840] True positives: 115, False positives: 0, False negatives: 6\n",
            "[06:36:57.178936] Detection metrics: {'Precision': 1.0, 'Recall': 0.9504132231404959, 'F1': 0.9745762711864406, 'TP': 115, 'FP': 0, 'FN': 6}\n",
            "[06:36:57.186143] All classes 1\n",
            "[06:36:57.186259] Detection metrics: ['Precision', 1.0, 'Recall', 0.9504132231404959, 'F1', 0.9745762711864406]\n",
            "[06:36:57.186331] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:57.326628] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.487231] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2589       | 8/27 [00:05<00:12,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.529076] Processing image: vol_008.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.565724] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.637164] Capturing the local maxima \n",
            "[06:36:57.640337] Class 1\n",
            "[06:36:57.677192] Removing close points . . .\n",
            "[06:36:57.677884] Initial number of points: 602\n",
            "[06:36:57.692167] Final number of points: 356\n",
            "[06:36:57.693673] Creating the images with detected points . . .\n",
            "[06:36:57.744391] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.814772] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:57.849891] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:57.851072] Its respective CSV file seems to be: /content/data/test/y/mask_008.csv\n",
            "[06:36:57.851899] Reading GT data from: /content/data/test/y/mask_008.csv\n",
            "[06:36:57.855276] Detection (class 1)\n",
            "[06:36:57.876298] Points in ground truth: 369, Points in prediction: 356\n",
            "[06:36:57.877251] True positives: 356, False positives: 0, False negatives: 13\n",
            "[06:36:57.878091] Detection metrics: {'Precision': 1.0, 'Recall': 0.964769647696477, 'F1': 0.9820689655172414, 'TP': 356, 'FP': 0, 'FN': 13}\n",
            "[06:36:57.885009] All classes 1\n",
            "[06:36:57.885918] Detection metrics: ['Precision', 1.0, 'Recall', 0.964769647696477, 'F1', 0.9820689655172414]\n",
            "[06:36:57.886721] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:58.203517] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:58.379685] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 33%|\u2588\u2588\u2588\u258e      | 9/27 [00:06<00:13,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:58.423733] Processing image: vol_009.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:58.474913] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:58.560812] Capturing the local maxima \n",
            "[06:36:58.560951] Class 1\n",
            "[06:36:58.602647] Removing close points . . .\n",
            "[06:36:58.602743] Initial number of points: 738\n",
            "[06:36:58.611580] Final number of points: 409\n",
            "[06:36:58.612814] Creating the images with detected points . . .\n",
            "[06:36:58.644431] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:58.695712] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:58.726627] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:58.727522] Its respective CSV file seems to be: /content/data/test/y/mask_009.csv\n",
            "[06:36:58.728325] Reading GT data from: /content/data/test/y/mask_009.csv\n",
            "[06:36:58.731078] Detection (class 1)\n",
            "[06:36:58.747195] Points in ground truth: 372, Points in prediction: 409\n",
            "[06:36:58.747275] True positives: 372, False positives: 37, False negatives: 0\n",
            "[06:36:58.747376] Detection metrics: {'Precision': 0.9095354523227384, 'Recall': 1.0, 'F1': 0.9526248399487836, 'TP': 372, 'FP': 37, 'FN': 0}\n",
            "[06:36:58.753153] All classes 1\n",
            "[06:36:58.753951] Detection metrics: ['Precision', 0.9095354523227384, 'Recall', 1.0, 'F1', 0.9526248399487836]\n",
            "[06:36:58.754670] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:58.963656] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.104951] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 37%|\u2588\u2588\u2588\u258b      | 10/27 [00:06<00:12,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.148007] Processing image: vol_010.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.203138] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.265264] Capturing the local maxima \n",
            "[06:36:59.266134] Class 1\n",
            "[06:36:59.298826] Removing close points . . .\n",
            "[06:36:59.298910] Initial number of points: 878\n",
            "[06:36:59.311625] Final number of points: 465\n",
            "[06:36:59.311983] Creating the images with detected points . . .\n",
            "[06:36:59.351211] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.402086] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.435568] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:36:59.436621] Its respective CSV file seems to be: /content/data/test/y/mask_010.csv\n",
            "[06:36:59.437339] Reading GT data from: /content/data/test/y/mask_010.csv\n",
            "[06:36:59.440310] Detection (class 1)\n",
            "[06:36:59.465805] Points in ground truth: 502, Points in prediction: 465\n",
            "[06:36:59.465899] True positives: 465, False positives: 0, False negatives: 37\n",
            "[06:36:59.468944] Detection metrics: {'Precision': 1.0, 'Recall': 0.9262948207171314, 'F1': 0.9617373319544984, 'TP': 465, 'FP': 0, 'FN': 37}\n",
            "[06:36:59.474947] All classes 1\n",
            "[06:36:59.475544] Detection metrics: ['Precision', 1.0, 'Recall', 0.9262948207171314, 'F1', 0.9617373319544984]\n",
            "[06:36:59.476100] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:36:59.788146] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.930920] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 41%|\u2588\u2588\u2588\u2588      | 11/27 [00:07<00:12,  1.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:36:59.974102] Processing image: vol_011.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.053560] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.162453] Capturing the local maxima \n",
            "[06:37:00.163921] Class 1\n",
            "[06:37:00.216076] Removing close points . . .\n",
            "[06:37:00.217477] Initial number of points: 711\n",
            "[06:37:00.233652] Final number of points: 421\n",
            "[06:37:00.234954] Creating the images with detected points . . .\n",
            "[06:37:00.291754] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.352808] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.393102] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:00.394295] Its respective CSV file seems to be: /content/data/test/y/mask_011.csv\n",
            "[06:37:00.395051] Reading GT data from: /content/data/test/y/mask_011.csv\n",
            "[06:37:00.398403] Detection (class 1)\n",
            "[06:37:00.433146] Points in ground truth: 421, Points in prediction: 421\n",
            "[06:37:00.434388] True positives: 421, False positives: 0, False negatives: 0\n",
            "[06:37:00.435175] Detection metrics: {'Precision': 1.0, 'Recall': 1.0, 'F1': 1.0, 'TP': 421, 'FP': 0, 'FN': 0}\n",
            "[06:37:00.442029] All classes 1\n",
            "[06:37:00.442977] Detection metrics: ['Precision', 1.0, 'Recall', 1.0, 'F1', 1.0]\n",
            "[06:37:00.443721] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:00.697874] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.842576] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 44%|\u2588\u2588\u2588\u2588\u258d     | 12/27 [00:08<00:12,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.883148] Processing image: vol_012.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.919320] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:00.991348] Capturing the local maxima \n",
            "[06:37:00.992267] Class 1\n",
            "[06:37:01.038787] Removing close points . . .\n",
            "[06:37:01.039979] Initial number of points: 833\n",
            "[06:37:01.063601] Final number of points: 500\n",
            "[06:37:01.067714] Creating the images with detected points . . .\n",
            "[06:37:01.118994] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:01.191298] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:01.228212] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:01.229410] Its respective CSV file seems to be: /content/data/test/y/mask_012.csv\n",
            "[06:37:01.230374] Reading GT data from: /content/data/test/y/mask_012.csv\n",
            "[06:37:01.233912] Detection (class 1)\n",
            "[06:37:01.268833] Points in ground truth: 565, Points in prediction: 500\n",
            "[06:37:01.268949] True positives: 500, False positives: 0, False negatives: 65\n",
            "[06:37:01.269065] Detection metrics: {'Precision': 1.0, 'Recall': 0.8849557522123894, 'F1': 0.9389671361502347, 'TP': 500, 'FP': 0, 'FN': 65}\n",
            "[06:37:01.288580] All classes 1\n",
            "[06:37:01.288708] Detection metrics: ['Precision', 1.0, 'Recall', 0.8849557522123894, 'F1', 0.9389671361502347]\n",
            "[06:37:01.288772] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:01.687239] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:01.830917] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 13/27 [00:09<00:12,  1.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:01.871882] Processing image: vol_013.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:01.943878] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.051744] Capturing the local maxima \n",
            "[06:37:02.051860] Class 1\n",
            "[06:37:02.116752] Removing close points . . .\n",
            "[06:37:02.118283] Initial number of points: 528\n",
            "[06:37:02.129585] Final number of points: 361\n",
            "[06:37:02.130864] Creating the images with detected points . . .\n",
            "[06:37:02.191498] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.263913] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.297864] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:02.299224] Its respective CSV file seems to be: /content/data/test/y/mask_013.csv\n",
            "[06:37:02.300400] Reading GT data from: /content/data/test/y/mask_013.csv\n",
            "[06:37:02.303715] Detection (class 1)\n",
            "[06:37:02.328276] Points in ground truth: 388, Points in prediction: 361\n",
            "[06:37:02.329581] True positives: 361, False positives: 0, False negatives: 27\n",
            "[06:37:02.330465] Detection metrics: {'Precision': 1.0, 'Recall': 0.9304123711340206, 'F1': 0.9639519359145527, 'TP': 361, 'FP': 0, 'FN': 27}\n",
            "[06:37:02.338214] All classes 1\n",
            "[06:37:02.339540] Detection metrics: ['Precision', 1.0, 'Recall', 0.9304123711340206, 'F1', 0.9639519359145527]\n",
            "[06:37:02.340598] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:02.627145] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.806030] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 14/27 [00:10<00:11,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.849376] Processing image: vol_014.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.900736] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:02.988602] Capturing the local maxima \n",
            "[06:37:02.989781] Class 1\n",
            "[06:37:03.019263] Removing close points . . .\n",
            "[06:37:03.020541] Initial number of points: 102\n",
            "[06:37:03.024005] Final number of points: 66\n",
            "[06:37:03.025149] Creating the images with detected points . . .\n",
            "[06:37:03.078357] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.168683] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.200873] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:03.202083] Its respective CSV file seems to be: /content/data/test/y/mask_014.csv\n",
            "[06:37:03.202941] Reading GT data from: /content/data/test/y/mask_014.csv\n",
            "[06:37:03.206152] Detection (class 1)\n",
            "[06:37:03.209987] Points in ground truth: 71, Points in prediction: 66\n",
            "[06:37:03.210828] True positives: 65, False positives: 1, False negatives: 6\n",
            "[06:37:03.211698] Detection metrics: {'Precision': 0.9848484848484849, 'Recall': 0.9154929577464789, 'F1': 0.948905109489051, 'TP': 65, 'FP': 1, 'FN': 6}\n",
            "[06:37:03.215423] All classes 1\n",
            "[06:37:03.216247] Detection metrics: ['Precision', 0.9848484848484849, 'Recall', 0.9154929577464789, 'F1', 0.948905109489051]\n",
            "[06:37:03.217128] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:03.304832] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.469604] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 56%|\u2588\u2588\u2588\u2588\u2588\u258c    | 15/27 [00:11<00:09,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.512413] Processing image: vol_015.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.581346] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.656228] Capturing the local maxima \n",
            "[06:37:03.662507] Class 1\n",
            "[06:37:03.702012] Removing close points . . .\n",
            "[06:37:03.703485] Initial number of points: 261\n",
            "[06:37:03.709442] Final number of points: 159\n",
            "[06:37:03.709635] Creating the images with detected points . . .\n",
            "[06:37:03.763662] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.834721] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:03.865160] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:03.865284] Its respective CSV file seems to be: /content/data/test/y/mask_015.csv\n",
            "[06:37:03.865337] Reading GT data from: /content/data/test/y/mask_015.csv\n",
            "[06:37:03.870008] Detection (class 1)\n",
            "[06:37:03.878459] Points in ground truth: 163, Points in prediction: 159\n",
            "[06:37:03.878577] True positives: 159, False positives: 0, False negatives: 4\n",
            "[06:37:03.878676] Detection metrics: {'Precision': 1.0, 'Recall': 0.9754601226993865, 'F1': 0.9875776397515528, 'TP': 159, 'FP': 0, 'FN': 4}\n",
            "[06:37:03.885227] All classes 1\n",
            "[06:37:03.885350] Detection metrics: ['Precision', 1.0, 'Recall', 0.9754601226993865, 'F1', 0.9875776397515528]\n",
            "[06:37:03.885425] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:04.041644] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.168632] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 16/27 [00:11<00:08,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.207982] Processing image: vol_016.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.247550] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.334041] Capturing the local maxima \n",
            "[06:37:04.334138] Class 1\n",
            "[06:37:04.364331] Removing close points . . .\n",
            "[06:37:04.364415] Initial number of points: 627\n",
            "[06:37:04.373959] Final number of points: 357\n",
            "[06:37:04.374366] Creating the images with detected points . . .\n",
            "[06:37:04.403130] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.461499] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.499890] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:04.500019] Its respective CSV file seems to be: /content/data/test/y/mask_016.csv\n",
            "[06:37:04.500066] Reading GT data from: /content/data/test/y/mask_016.csv\n",
            "[06:37:04.504089] Detection (class 1)\n",
            "[06:37:04.517876] Points in ground truth: 337, Points in prediction: 357\n",
            "[06:37:04.518561] True positives: 337, False positives: 20, False negatives: 0\n",
            "[06:37:04.518661] Detection metrics: {'Precision': 0.9439775910364145, 'Recall': 1.0, 'F1': 0.9711815561959654, 'TP': 337, 'FP': 20, 'FN': 0}\n",
            "[06:37:04.523841] All classes 1\n",
            "[06:37:04.523953] Detection metrics: ['Precision', 0.9439775910364145, 'Recall', 1.0, 'F1', 0.9711815561959654]\n",
            "[06:37:04.524014] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:04.707605] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.804396] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 17/27 [00:12<00:07,  1.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.843101] Processing image: vol_017.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.879838] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:04.936694] Capturing the local maxima \n",
            "[06:37:04.937817] Class 1\n",
            "[06:37:04.972555] Removing close points . . .\n",
            "[06:37:04.972986] Initial number of points: 734\n",
            "[06:37:04.984589] Final number of points: 382\n",
            "[06:37:04.984968] Creating the images with detected points . . .\n",
            "[06:37:05.031603] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.098125] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.135317] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:05.141112] Its respective CSV file seems to be: /content/data/test/y/mask_017.csv\n",
            "[06:37:05.142276] Reading GT data from: /content/data/test/y/mask_017.csv\n",
            "[06:37:05.147377] Detection (class 1)\n",
            "[06:37:05.170088] Points in ground truth: 286, Points in prediction: 382\n",
            "[06:37:05.170196] True positives: 286, False positives: 96, False negatives: 0\n",
            "[06:37:05.170291] Detection metrics: {'Precision': 0.7486910994764397, 'Recall': 1.0, 'F1': 0.8562874251497006, 'TP': 286, 'FP': 96, 'FN': 0}\n",
            "[06:37:05.177852] All classes 1\n",
            "[06:37:05.177971] Detection metrics: ['Precision', 0.7486910994764397, 'Recall', 1.0, 'F1', 0.8562874251497006]\n",
            "[06:37:05.178034] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:05.347364] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.449149] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 67%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 18/27 [00:13<00:06,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.488889] Processing image: vol_018.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.534777] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.595873] Capturing the local maxima \n",
            "[06:37:05.597906] Class 1\n",
            "[06:37:05.626246] Removing close points . . .\n",
            "[06:37:05.626330] Initial number of points: 478\n",
            "[06:37:05.633352] Final number of points: 290\n",
            "[06:37:05.633575] Creating the images with detected points . . .\n",
            "[06:37:05.668737] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.719882] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:05.753557] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:05.754469] Its respective CSV file seems to be: /content/data/test/y/mask_018.csv\n",
            "[06:37:05.754535] Reading GT data from: /content/data/test/y/mask_018.csv\n",
            "[06:37:05.758109] Detection (class 1)\n",
            "[06:37:05.768895] Points in ground truth: 307, Points in prediction: 290\n",
            "[06:37:05.769529] True positives: 290, False positives: 0, False negatives: 17\n",
            "[06:37:05.769630] Detection metrics: {'Precision': 1.0, 'Recall': 0.9446254071661238, 'F1': 0.9715242881072027, 'TP': 290, 'FP': 0, 'FN': 17}\n",
            "[06:37:05.774271] All classes 1\n",
            "[06:37:05.774378] Detection metrics: ['Precision', 1.0, 'Recall', 0.9446254071661238, 'F1', 0.9715242881072027]\n",
            "[06:37:05.774442] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:05.956648] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.087646] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 19/27 [00:13<00:05,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.134364] Processing image: vol_019.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.183849] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.266064] Capturing the local maxima \n",
            "[06:37:06.266168] Class 1\n",
            "[06:37:06.301369] Removing close points . . .\n",
            "[06:37:06.301481] Initial number of points: 431\n",
            "[06:37:06.307637] Final number of points: 292\n",
            "[06:37:06.307842] Creating the images with detected points . . .\n",
            "[06:37:06.335397] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.390545] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.424624] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:06.424722] Its respective CSV file seems to be: /content/data/test/y/mask_019.csv\n",
            "[06:37:06.426411] Reading GT data from: /content/data/test/y/mask_019.csv\n",
            "[06:37:06.429233] Detection (class 1)\n",
            "[06:37:06.439384] Points in ground truth: 326, Points in prediction: 292\n",
            "[06:37:06.439461] True positives: 292, False positives: 0, False negatives: 34\n",
            "[06:37:06.439548] Detection metrics: {'Precision': 1.0, 'Recall': 0.8957055214723927, 'F1': 0.9449838187702265, 'TP': 292, 'FP': 0, 'FN': 34}\n",
            "[06:37:06.446707] All classes 1\n",
            "[06:37:06.447194] Detection metrics: ['Precision', 1.0, 'Recall', 0.8957055214723927, 'F1', 0.9449838187702265]\n",
            "[06:37:06.447267] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:06.694209] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.797244] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 74%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d  | 20/27 [00:14<00:04,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.831550] Processing image: vol_020.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.874466] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:06.934720] Capturing the local maxima \n",
            "[06:37:06.934820] Class 1\n",
            "[06:37:06.964843] Removing close points . . .\n",
            "[06:37:06.964958] Initial number of points: 549\n",
            "[06:37:06.974149] Final number of points: 303\n",
            "[06:37:06.975194] Creating the images with detected points . . .\n",
            "[06:37:07.014192] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.084860] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.128531] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:07.128646] Its respective CSV file seems to be: /content/data/test/y/mask_020.csv\n",
            "[06:37:07.128688] Reading GT data from: /content/data/test/y/mask_020.csv\n",
            "[06:37:07.133620] Detection (class 1)\n",
            "[06:37:07.153009] Points in ground truth: 315, Points in prediction: 303\n",
            "[06:37:07.153141] True positives: 303, False positives: 0, False negatives: 12\n",
            "[06:37:07.153250] Detection metrics: {'Precision': 1.0, 'Recall': 0.9619047619047619, 'F1': 0.9805825242718447, 'TP': 303, 'FP': 0, 'FN': 12}\n",
            "[06:37:07.159971] All classes 1\n",
            "[06:37:07.160996] Detection metrics: ['Precision', 1.0, 'Recall', 0.9619047619047619, 'F1', 0.9805825242718447]\n",
            "[06:37:07.161082] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:07.349607] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.451877] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 78%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a  | 21/27 [00:15<00:04,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.487473] Processing image: vol_021.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.524102] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.592436] Capturing the local maxima \n",
            "[06:37:07.593801] Class 1\n",
            "[06:37:07.624478] Removing close points . . .\n",
            "[06:37:07.625489] Initial number of points: 75\n",
            "[06:37:07.627616] Final number of points: 40\n",
            "[06:37:07.628441] Creating the images with detected points . . .\n",
            "[06:37:07.672976] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.725324] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.753492] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:07.754723] Its respective CSV file seems to be: /content/data/test/y/mask_021.csv\n",
            "[06:37:07.755582] Reading GT data from: /content/data/test/y/mask_021.csv\n",
            "[06:37:07.757917] Detection (class 1)\n",
            "[06:37:07.762266] Points in ground truth: 36, Points in prediction: 40\n",
            "[06:37:07.763271] True positives: 36, False positives: 4, False negatives: 0\n",
            "[06:37:07.764267] Detection metrics: {'Precision': 0.9, 'Recall': 1.0, 'F1': 0.9473684210526316, 'TP': 36, 'FP': 4, 'FN': 0}\n",
            "[06:37:07.767895] All classes 1\n",
            "[06:37:07.768020] Detection metrics: ['Precision', 0.9, 'Recall', 1.0, 'F1', 0.9473684210526316]\n",
            "[06:37:07.769392] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:07.811238] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.905466] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 22/27 [00:15<00:03,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.937313] Processing image: vol_022.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:07.972590] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.060432] Capturing the local maxima \n",
            "[06:37:08.060546] Class 1\n",
            "[06:37:08.097793] Removing close points . . .\n",
            "[06:37:08.097892] Initial number of points: 643\n",
            "[06:37:08.110581] Final number of points: 371\n",
            "[06:37:08.110985] Creating the images with detected points . . .\n",
            "[06:37:08.153632] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.222358] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.263731] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:08.265179] Its respective CSV file seems to be: /content/data/test/y/mask_022.csv\n",
            "[06:37:08.270423] Reading GT data from: /content/data/test/y/mask_022.csv\n",
            "[06:37:08.273665] Detection (class 1)\n",
            "[06:37:08.295426] Points in ground truth: 374, Points in prediction: 371\n",
            "[06:37:08.295508] True positives: 371, False positives: 0, False negatives: 3\n",
            "[06:37:08.297246] Detection metrics: {'Precision': 1.0, 'Recall': 0.9919786096256684, 'F1': 0.9959731543624161, 'TP': 371, 'FP': 0, 'FN': 3}\n",
            "[06:37:08.302795] All classes 1\n",
            "[06:37:08.302913] Detection metrics: ['Precision', 1.0, 'Recall', 0.9919786096256684, 'F1', 0.9959731543624161]\n",
            "[06:37:08.303006] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:08.506904] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.632317] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 85%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c | 23/27 [00:16<00:02,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.678438] Processing image: vol_023.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.743900] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:08.848807] Capturing the local maxima \n",
            "[06:37:08.849975] Class 1\n",
            "[06:37:08.878575] Removing close points . . .\n",
            "[06:37:08.879504] Initial number of points: 239\n",
            "[06:37:08.886465] Final number of points: 137\n",
            "[06:37:08.892274] Creating the images with detected points . . .\n",
            "[06:37:08.936471] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.022395] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.054084] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:09.054171] Its respective CSV file seems to be: /content/data/test/y/mask_023.csv\n",
            "[06:37:09.054207] Reading GT data from: /content/data/test/y/mask_023.csv\n",
            "[06:37:09.056271] Detection (class 1)\n",
            "[06:37:09.073657] Points in ground truth: 112, Points in prediction: 137\n",
            "[06:37:09.074642] True positives: 112, False positives: 25, False negatives: 0\n",
            "[06:37:09.075688] Detection metrics: {'Precision': 0.8175182481751825, 'Recall': 1.0, 'F1': 0.8995983935742973, 'TP': 112, 'FP': 25, 'FN': 0}\n",
            "[06:37:09.085716] All classes 1\n",
            "[06:37:09.087753] Detection metrics: ['Precision', 0.8175182481751825, 'Recall', 1.0, 'F1', 0.8995983935742973]\n",
            "[06:37:09.088741] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:09.212701] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.364614] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 89%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589 | 24/27 [00:17<00:02,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.401548] Processing image: vol_024.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.460607] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.558486] Capturing the local maxima \n",
            "[06:37:09.559638] Class 1\n",
            "[06:37:09.602833] Removing close points . . .\n",
            "[06:37:09.604092] Initial number of points: 266\n",
            "[06:37:09.610578] Final number of points: 130\n",
            "[06:37:09.611658] Creating the images with detected points . . .\n",
            "[06:37:09.659987] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.733525] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:09.762465] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:09.763684] Its respective CSV file seems to be: /content/data/test/y/mask_024.csv\n",
            "[06:37:09.764515] Reading GT data from: /content/data/test/y/mask_024.csv\n",
            "[06:37:09.767598] Detection (class 1)\n",
            "[06:37:09.772376] Points in ground truth: 82, Points in prediction: 130\n",
            "[06:37:09.774333] True positives: 82, False positives: 48, False negatives: 0\n",
            "[06:37:09.775107] Detection metrics: {'Precision': 0.6307692307692307, 'Recall': 1.0, 'F1': 0.7735849056603773, 'TP': 82, 'FP': 48, 'FN': 0}\n",
            "[06:37:09.779094] All classes 1\n",
            "[06:37:09.780127] Detection metrics: ['Precision', 0.6307692307692307, 'Recall', 1.0, 'F1', 0.7735849056603773]\n",
            "[06:37:09.781069] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:09.873859] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.016550] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 25/27 [00:17<00:01,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.055602] Processing image: vol_025.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.124438] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.246763] Capturing the local maxima \n",
            "[06:37:10.250672] Class 1\n",
            "[06:37:10.318607] Removing close points . . .\n",
            "[06:37:10.321016] Initial number of points: 590\n",
            "[06:37:10.338597] Final number of points: 353\n",
            "[06:37:10.339914] Creating the images with detected points . . .\n",
            "[06:37:10.400087] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.484971] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.526225] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:10.528035] Its respective CSV file seems to be: /content/data/test/y/mask_025.csv\n",
            "[06:37:10.529641] Reading GT data from: /content/data/test/y/mask_025.csv\n",
            "[06:37:10.534765] Detection (class 1)\n",
            "[06:37:10.570103] Points in ground truth: 330, Points in prediction: 353\n",
            "[06:37:10.571431] True positives: 330, False positives: 23, False negatives: 0\n",
            "[06:37:10.572252] Detection metrics: {'Precision': 0.9348441926345609, 'Recall': 1.0, 'F1': 0.9663250366032211, 'TP': 330, 'FP': 23, 'FN': 0}\n",
            "[06:37:10.579406] All classes 1\n",
            "[06:37:10.580332] Detection metrics: ['Precision', 0.9348441926345609, 'Recall', 1.0, 'F1', 0.9663250366032211]\n",
            "[06:37:10.581467] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:10.831517] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:10.986712] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 96%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b| 26/27 [00:18<00:00,  1.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.027449] Processing image: vol_026.tif\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/base_workflow.py:2038: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.066349] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.131968] Capturing the local maxima \n",
            "[06:37:11.132880] Class 1\n",
            "[06:37:11.163649] Removing close points . . .\n",
            "[06:37:11.164390] Initial number of points: 97\n",
            "[06:37:11.167072] Final number of points: 54\n",
            "[06:37:11.168031] Creating the images with detected points . . .\n",
            "[06:37:11.217452] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.299606] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/per_image_local_max_check\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.331679] WARNING: The CSV file seems to have different name than image. Using the CSV file with the same position as the CSV in the directory. Check if it is correct!\n",
            "[06:37:11.334262] Its respective CSV file seems to be: /content/data/test/y/mask_026.csv\n",
            "[06:37:11.334349] Reading GT data from: /content/data/test/y/mask_026.csv\n",
            "[06:37:11.336746] Detection (class 1)\n",
            "[06:37:11.342953] Points in ground truth: 30, Points in prediction: 54\n",
            "[06:37:11.344322] True positives: 30, False positives: 24, False negatives: 0\n",
            "[06:37:11.345321] Detection metrics: {'Precision': 0.5555555555555556, 'Recall': 1.0, 'F1': 0.7142857142857143, 'TP': 30, 'FP': 24, 'FN': 0}\n",
            "[06:37:11.349625] All classes 1\n",
            "[06:37:11.350866] Detection metrics: ['Precision', 0.5555555555555556, 'Recall', 1.0, 'F1', 0.7142857142857143]\n",
            "[06:37:11.351857] Creating the image with a summary of detected points and false positives with colors . . .\n",
            "[06:37:11.416458] Saving (1, 64, 64, 64, 1) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.566714] Saving (1, 64, 64, 64, 3) data as .tif in folder: /content/output/my_3d_detection/results/my_3d_detection_1/point_associations\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 27/27 [00:19<00:00,  1.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[06:37:11.604863] Releasing memory . . .\n",
            "[06:37:11.604978] #############\n",
            "[06:37:11.605018] #  RESULTS  #\n",
            "[06:37:11.605047] #############\n",
            "[06:37:11.605124] Test Foreground IoU (per patch): 0.14807002825869453\n",
            "[06:37:11.605162] Test Foreground IoU (merge patches): 0.14807002825869453\n",
            "[06:37:11.605194] Test Precision (merge patches): 0.9147597269478289\n",
            "[06:37:11.605226] Test Recall (merge patches): 0.9592175056249584\n",
            "[06:37:11.605257] Test F1 (merge patches): 0.9276596323940905\n",
            "[06:37:11.605290] Test TP (merge patches): 252.62962962962962\n",
            "[06:37:11.605321] Test FP (merge patches): 11.222222222222221\n",
            "[06:37:11.605354] Test FN (merge patches): 13.74074074074074\n",
            "[06:37:11.605386]  \n",
            "[06:37:11.605451] FINISHED JOB my_3d_detection_1 !!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### Play to run inference on test with the new parameters\n",
        "biapy_config_inference = biapy_config\n",
        "\n",
        "# set the training to false to peform inference\n",
        "biapy_config_inference['TRAIN']['ENABLE'] = False\n",
        "\n",
        "# Detection parameters\n",
        "biapy_config['PROBLEM']['DETECTION']['CENTRAL_POINT_DILATION'] = [central_point_dilation]\n",
        "biapy_config_inference['TEST']['DET_MIN_TH_TO_BE_PEAK'] = min_value_to_be_peak\n",
        "biapy_config_inference['TEST']['DET_TOLERANCE'] = [tolerance]\n",
        "biapy_config_inference['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS'] = remove_close_points\n",
        "biapy_config_inference['TEST']['POST_PROCESSING']['REMOVE_CLOSE_POINTS_RADIUS'] = remove_close_points_radius\n",
        "biapy_config_inference['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "# save file\n",
        "inference_file = \"/content/\"+str(job_name)+\"_inference.yaml\"\n",
        "\n",
        "with open( inference_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config_inference, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Inference configuration finished.\")\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(inference_file, result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "418a0bea13fb4c02ac97db47b1b75e8d",
            "f6fa69a7b4f345e6a60977d1d0c8e316",
            "e2962022f4ca4dc5a5f69e68cdc6a71e",
            "c27b8f12fe084913b2d8d509ac102004",
            "4bd259a1591845f587a13e1471b0016f",
            "0f0a6d2602c0485781acac71e2ffcfe5",
            "24b4b5c0045f4426acd89c0c534906c6",
            "cf485f92581748a39b1326e05ad8fbfa",
            "437d0202f2f74c44b89a929c9b121a05",
            "fa8500eb9f23446ca8eaa6d84f730096",
            "2507bb0fb04548d989aca760f855286a",
            "ff9e33cec0bb4b58bd374ece64749abd",
            "fc2529cbef134a459a9f2ea5e85324e2",
            "56b7b9901ed745b8aea00a868c061bef",
            "b2174deac0bf4867923a37a35a710734",
            "897b0acd5b3943cab6862fbab4b9d28e",
            "4001eb4169094c4e8e071e43dc086d7b",
            "7db46ed3bc264e3ebf12d588a8654713",
            "844916dde0864491997df0634403296f",
            "bbf7af8ef3eb4b47850d2145a42bec08",
            "17fef096201847f6b27aedd9c77e2e70"
          ]
        },
        "id": "pRJRFyLsNhB_",
        "outputId": "3da40ff3-537e-4ce8-c4f2-619ea1cb8a47"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "418a0bea13fb4c02ac97db47b1b75e8d"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff9e33cec0bb4b58bd374ece64749abd"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=32, description='z', max=64, min=1), Output()), _dom_classes=('widget-in\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "844916dde0864491997df0634403296f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "#@markdown ###Play to visualize some results from the test set\n",
        "#@markdown The current model will be applied to some test images and results will be shown displaying:\n",
        "#@markdown 1. The original **Test input image**.\n",
        "#@markdown 2. The model **Prediction** labels.\n",
        "#@markdown 3. Its corresponding **Ground truth** labels (if `test_ground_truth` was checked),\n",
        "#@markdown 4. The **Associations** between predicted and ground truth detections (if `test_ground_truth` was checked).\n",
        "\n",
        "#@markdown Associations between predictions and ground truth are illustrated as follows:\n",
        "#@markdown - **Green**: True positives.\n",
        "#@markdown - **Red**: False negatives.\n",
        "#@markdown - **Blue**: False positives.\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from numpy.random import randint, seed\n",
        "from matplotlib import pyplot as plt\n",
        "from ipywidgets import interact, fixed\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "detection_results = os.path.join(final_results, \"per_image_local_max_check\")\n",
        "assoc_results = os.path.join(final_results, \"point_associations\")\n",
        "test_data_gt_path = \"/content/data/train/y_detection_masks\"\n",
        "\n",
        "# Show a few examples to check that they have been stored correctly\n",
        "ids_pred = sorted(next(os.walk(detection_results))[2])\n",
        "ids_pred = [x for x in ids_pred if not x.endswith('.csv') ]\n",
        "ids_assoc = sorted(next(os.walk(assoc_results))[2])\n",
        "ids_assoc = [x for x in ids_assoc if not x.endswith('.csv') ]\n",
        "ids_assoc = [x for x in ids_assoc if \"_gt_ids\" not in x ]\n",
        "ids_assoc = [x for x in ids_assoc if \"_pred_ids\" not in x ]\n",
        "ids_input = sorted(next(os.walk(test_data_path))[2])\n",
        "ids_gt = sorted(next(os.walk(test_data_gt_path))[2])\n",
        "\n",
        "samples_to_show = min(len(ids_input), 3)\n",
        "chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n",
        "seed(1)\n",
        "\n",
        "test_samples = []\n",
        "test_sample_preds = []\n",
        "test_sample_gt = []\n",
        "test_sample_assoc = []\n",
        "\n",
        "# read 3D images again\n",
        "for i in range(len(chosen_images)):\n",
        "    aux = imread(os.path.join(test_data_path, ids_input[chosen_images[i]]))\n",
        "    test_samples.append(np.squeeze(aux))\n",
        "\n",
        "    aux = imread(os.path.join(detection_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n",
        "    test_sample_preds.append(np.squeeze(aux))\n",
        "\n",
        "    aux = imread(os.path.join(test_data_gt_path, ids_gt[chosen_images[i]])).astype(np.uint16)\n",
        "    test_sample_gt.append(np.squeeze(aux))\n",
        "\n",
        "    aux = imread(os.path.join(assoc_results, ids_assoc[chosen_images[i]]))\n",
        "    test_sample_assoc.append(np.squeeze(aux))\n",
        "\n",
        "# function to show results in 3D within a widget\n",
        "def scroll_in_z(z, j):\n",
        "\n",
        "    plt.figure(figsize=(18,4))\n",
        "    # Source\n",
        "    plt.subplot(1,4,1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_samples[j][z-1], cmap='gray')\n",
        "    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Target (Ground-truth)\n",
        "    plt.subplot(1,4,2)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_sample_gt[j][z-1], interpolation='nearest')\n",
        "    plt.title('Ground truth (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(1,4,3)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_sample_preds[j][z-1], interpolation='nearest')\n",
        "    plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Overlay\n",
        "    plt.subplot(1,4,4)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_sample_assoc[j][z-1], interpolation='nearest')\n",
        "    plt.title('Associations (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "for j in range(samples_to_show):\n",
        "    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_sample_gt[j].shape[0], step=1, value=test_sample_gt[j].shape[0]//2), j=fixed(j));"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How to use the trained model with new data**\n",
        "---\n",
        "To directly infer new data to the trained model, you can use [this notebook](https://github.com/BiaPyX/BiaPy/blob/master/notebooks/BiaPy_Inference.ipynb). It will be necessary to upload the downloaded YAML configuration file and model weights to that notebook."
      ],
      "metadata": {
        "id": "PFVjWbF8GZ2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAzTcs0wuR3d"
      },
      "source": [
        "## **Acknowledgments**\n",
        "---\n",
        "\n",
        "We extend our gratitude to the [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki) which have been a beacon of inspiration for our work. Specific elements, such as descriptions of metrics and parameters, as well as the 3D visualization widget code, have been incorporated from their [U-Net 3D notebook](https://colab.research.google.com/github/HenriquesLab/ZeroCostDL4Mic/blob/master/Colab_notebooks/U-Net_3D_ZeroCostDL4Mic.ipynb). Their contributions to the field have immensely enriched our endeavor.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}