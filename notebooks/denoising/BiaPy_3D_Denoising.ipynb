{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcAryclxsQJ5"
      },
      "source": [
        "# **3D Image Denoising pipeline**\n",
        "___  \n",
        "  \n",
        "In this notebook, we demonstrate the use of the [BiaPy](https://biapyx.github.io/) pipeline for  **3D image denoising** of microscopy data.\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://biapy.readthedocs.io/en/latest/_images/denosing_overview.svg' width='500px'/>\n",
        "<figcaption><b>Figure 1</b>: Example of a 3D image denoising problem.</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Without any coding, we'll guide you step-by-step through the process to:\n",
        "1. **Upload a set of training and test images** along with their corresponding instance label images.\n",
        "2. **Train a Deep Neural Network (DNN)** model using the training set.\n",
        "3. **Apply the model** to the test images.\n",
        "4. **Download the segmentation results** to your local machine.\n",
        "\n",
        "**Disclaimer:** The structure of the notebook is heavily inspired by the fantastic [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki).\n",
        "\n",
        "**Contact:** This notebook was created by [Ignacio Arganda-Carreras](mailto:ignacio.arganda@ehu.eus), [Lenka Backov\u00e1](mailto:lenka.backova@ehu.eus), [Daniel Franco-Barranco](mailto:daniel.franco@dipc.org) and [Ane Paniagua](mailto:anepaniagua@gmail.com). For suggestions, comments, or issues, please reach out to us via email or [create an issue in BiaPy's repository](https://github.com/BiaPyX/BiaPy/issues). Thank you!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hG5ClE_HHQaE"
      },
      "source": [
        "## **Expected Inputs and Outputs**\n",
        "___\n",
        "\n",
        "### **Inputs**\n",
        "\n",
        "This notebook expects the following folders as input:\n",
        "\n",
        "1. **Training Raw Images**: Contains the raw 3D images used for training the model.\n",
        "2. **Test Raw Images**: Houses the raw 3D images for testing the model.\n",
        "3. **Output Folder**: A designated path where the classification results will be saved.\n",
        "\n",
        "## **Outputs**\n",
        "\n",
        "Upon successful execution, a new folder will be generated, housing the denoising results. The resulting denoised files can be easily downloaded at the end of this notebook.\n",
        "\n",
        "<font color='red'><b>Note:</b></font> For testing purposes, you can utilize the **example datasets provided under 'Manage File(s) Source > Option 3'**.\n",
        "\n",
        "**Data structure**\n",
        "\n",
        "To ensure the proper operation of the library the data directory tree should be something like this:\n",
        "\n",
        "```\n",
        "dataset/\n",
        "\u251c\u2500\u2500 train   \n",
        "\u2502   \u251c\u2500\u2500 training-0001.tif\n",
        "\u2502   \u251c\u2500\u2500 training-0002.tif\n",
        "\u2502   \u251c\u2500\u2500 . . .\n",
        "\u2502   \u2514\u2500\u2500 training-9999.tif\n",
        "\u2514\u2500\u2500 test\n",
        "    \u251c\u2500\u2500 testing-0001.tif\n",
        "    \u251c\u2500\u2500 testing-0002.tif\n",
        "    \u251c\u2500\u2500 . . .\n",
        "    \u2514\u2500\u2500 testing-9999.tif\n",
        "```\n",
        "\n",
        "**Input Format Support**\n",
        "\n",
        "This notebook is compatible with a range of input formats. You can use the following file extensions: `.tif`, `.npy` (every extension for 3D images supported by [scikit-image](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread)).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGSj0DrpUJoY"
      },
      "source": [
        "## **Prepare the environment**\n",
        "___\n",
        "\n",
        "Establish connection with Google services. You **must be logged in to Google** to continue.\n",
        "Since this is not Google's own code, you will probably see a message warning you of the dangers of running unfamiliar code. This is completely normal.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bj_sbDFTiZ7"
      },
      "source": [
        "## **Check for GPU Access**\n",
        "---\n",
        "\n",
        "By default, the session is configured to use Python 3 with GPU acceleration. However, it's a good practice to double-check these settings:\n",
        "\n",
        "1. Navigate to **Runtime** in the top menu and select **Change the Runtime type**.\n",
        "2. Ensure the following settings:\n",
        "   - **Runtime type:** Python 3 (This program is written in the Python 3 programming language.)\n",
        "   - **Accelerator:** GPU (Graphics Processing Unit)\n",
        "\n",
        "This will ensure that you're using Python 3 and taking advantage of GPU acceleration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLYsqrDALpVN"
      },
      "source": [
        "## **Install BiaPy**\n",
        "---\n",
        "This might take some minutes depending on the current installed libraries in Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dab9c0f-6c01-4eed-ef98-547d2492a139",
        "cellView": "form",
        "id": "DBnE4c_xD88A"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biapy==3.5.12\n",
            "  Downloading biapy-3.5.12-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.6.1)\n",
            "Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.0.4)\n",
            "Collecting yacs>=0.1.8 (from biapy==3.5.12)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.67.1)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (0.25.2)\n",
            "Collecting edt>=2.3.2 (from biapy==3.5.12)\n",
            "  Downloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Collecting fill-voids>=2.0.6 (from biapy==3.5.12)\n",
            "  Downloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: opencv-python>=4.8.0.76 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (4.11.0.86)\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.2.2)\n",
            "Collecting torchinfo>=1.8.0 (from biapy==3.5.12)\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting tensorboardX>=2.6.2.2 (from biapy==3.5.12)\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: h5py>=3.9.0 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (3.13.0)\n",
            "Requirement already satisfied: zarr>=2.16.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2.18.4)\n",
            "Collecting bioimageio.core==0.7.0 (from biapy==3.5.12)\n",
            "  Downloading bioimageio.core-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting imagecodecs>=2024.1.1 (from biapy==3.5.12)\n",
            "  Downloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.26.4)\n",
            "Collecting imgaug>=0.4.0 (from biapy==3.5.12)\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pooch>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (1.8.2)\n",
            "Collecting diplib>=3.5.1 (from biapy==3.5.12)\n",
            "  Downloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting pydantic<2.10,>=2.7.0 (from biapy==3.5.12)\n",
            "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xarray==2025.1.* in /usr/local/lib/python3.11/dist-packages (from biapy==3.5.12) (2025.1.2)\n",
            "Collecting bioimageio.spec==0.5.3.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading bioimageio.spec-0.5.3.5-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: imageio>=2.10 in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.37.0)\n",
            "Collecting loguru (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting pydantic-settings>=2.5 (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (2.32.3)\n",
            "Collecting ruyaml (from bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading ruyaml-0.91.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from bioimageio.core==0.7.0->biapy==3.5.12) (4.12.2)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from xarray==2025.1.*->biapy==3.5.12) (24.2)\n",
            "Requirement already satisfied: annotated-types<1,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.7.0)\n",
            "Collecting email-validator (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.8.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (13.9.4)\n",
            "Requirement already satisfied: tifffile>=2020.7.4 in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2025.3.13)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.21.0)\n",
            "Collecting fastremap (from fill-voids>=2.0.6->biapy==3.5.12)\n",
            "  Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.17.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (11.1.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.11/dist-packages (from imgaug>=0.4.0->biapy==3.5.12) (2.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.1->biapy==3.5.12) (3.2.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.5.3->biapy==3.5.12) (2025.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.8.1->biapy==3.5.12) (4.3.7)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<2.10,>=2.7.0->biapy==3.5.12)\n",
            "  Downloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (3.4.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.21.0->biapy==3.5.12) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.0->biapy==3.5.12) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.6.2.2->biapy==3.5.12) (5.29.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs>=0.1.8->biapy==3.5.12) (6.0.2)\n",
            "Requirement already satisfied: asciitree in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.3.3)\n",
            "Requirement already satisfied: fasteners in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.19)\n",
            "Requirement already satisfied: numcodecs!=0.14.0,!=0.14.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from zarr>=2.16.1->biapy==3.5.12) (0.15.1)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.2.18)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings>=2.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bioimageio.core==0.7.0->biapy==3.5.12) (2025.1.31)\n",
            "Requirement already satisfied: distro>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (1.9.0)\n",
            "Requirement already satisfied: setuptools>=39.0 in /usr/local/lib/python3.11/dist-packages (from ruyaml->bioimageio.core==0.7.0->biapy==3.5.12) (75.1.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->numcodecs!=0.14.0,!=0.14.1,>=0.10.0->zarr>=2.16.1->biapy==3.5.12) (1.17.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->bioimageio.spec==0.5.3.5->bioimageio.core==0.7.0->biapy==3.5.12) (0.1.2)\n",
            "Downloading biapy-3.5.12-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m411.1/411.1 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.core-0.7.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bioimageio.spec-0.5.3.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diplib-3.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading edt-3.0.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fill_voids-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imagecodecs-2024.12.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.5 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m45.5/45.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m948.0/948.0 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading fastremap-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruyaml-0.91.0-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: yacs, torchinfo, tensorboardX, ruyaml, python-dotenv, pydantic-core, loguru, imagecodecs, fastremap, edt, dnspython, diplib, pydantic, fill-voids, email-validator, pydantic-settings, imgaug, bioimageio.spec, bioimageio.core, biapy\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "Successfully installed biapy-3.5.12 bioimageio.core-0.7.0 bioimageio.spec-0.5.3.5 diplib-3.5.2 dnspython-2.7.0 edt-3.0.0 email-validator-2.2.0 fastremap-1.15.1 fill-voids-2.0.8 imagecodecs-2024.12.30 imgaug-0.4.0 loguru-0.7.3 pydantic-2.9.2 pydantic-core-2.23.4 pydantic-settings-2.8.1 python-dotenv-1.1.0 ruyaml-0.91.0 tensorboardX-2.6.2.2 torchinfo-1.8.0 yacs-0.1.8\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m857.8/857.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.19.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.19.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.4.0\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m142.9/142.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.19.0) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.6.0+cu124\n",
            "    Uninstalling torchaudio-2.6.0+cu124:\n",
            "      Successfully uninstalled torchaudio-2.6.0+cu124\n",
            "Successfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 torch-2.4.0+cu118 torchaudio-2.4.0+cu118 torchvision-0.19.0+cu118 triton-3.0.0\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting torchmetrics==1.4.* (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torchmetrics-1.4.3-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (24.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.4.0+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics==1.4.*->torchmetrics[image]==1.4.*)\n",
            "  Downloading lightning_utilities-0.14.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting torch-fidelity<=0.4.0 (from torchmetrics[image]==1.4.*)\n",
            "  Downloading torch_fidelity-0.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: torchvision>=0.8 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (0.19.0+cu118)\n",
            "Requirement already satisfied: scipy>1.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.29.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.89)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.87)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.11.3.6)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (10.3.0.86)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.4.1.48)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.7.5.86)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (11.8.86)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (11.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-fidelity<=0.4.0->torchmetrics[image]==1.4.*) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.10.0->torchmetrics==1.4.*->torchmetrics[image]==1.4.*) (1.3.0)\n",
            "Downloading torchmetrics-1.4.3-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m869.5/869.5 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading lightning_utilities-0.14.2-py3-none-any.whl (28 kB)\n",
            "Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-msssim, torch-fidelity\n",
            "Successfully installed lightning-utilities-0.14.2 pytorch-msssim-1.0.0 torch-fidelity-0.3.0 torchmetrics-1.4.3\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to install BiaPy and its dependences\n",
        "# Install latest release of BiaPy\n",
        "!pip install biapy==3.6.1\n",
        "\n",
        "# Then install Pytorch + CUDA 11.8\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# Finally install some packages that rely on the Pytorch installation\n",
        "!pip install timm==1.0.14 pytorch-msssim torchmetrics[image]==1.4.*\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "from skimage.io import imread\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "from biapy import BiaPy\n",
        "\n",
        "changed_source = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZmI9c09OhSo"
      },
      "source": [
        "## **Manage File(s) Source**\n",
        "---\n",
        "\n",
        "The input folder can be provided using three different options:\n",
        "1. **Direct Upload**: Directly upload the desired folder.\n",
        "2. **Google Drive**: Use a folder stored in your Google Drive.\n",
        "3. **Sample Data**: Use a sample dataset provided by us.\n",
        "\n",
        "The steps you'll need to follow vary depending on your chosen option. These steps are detailed in the subsequent sections.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPksHcHLO0SU"
      },
      "source": [
        "### **Option 1: Upload Local Files to the Notebook**\n",
        "---\n",
        "\n",
        "You will be prompted to upload your files to Colab and they will be stored under `/content/input/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xGS5LCaHPWR8"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to upload local files (train raw images)\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/train\n",
        "%cd /content/input/train\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84HfvCrU0B3L"
      },
      "outputs": [],
      "source": [
        "# @title  { display-mode: \"form\" }\n",
        "#@markdown ##Play the cell to upload local files (test raw images)\n",
        "\n",
        "from google.colab import files\n",
        "!mkdir -p /content/input/test\n",
        "%cd /content/input/test\n",
        "uploaded = files.upload()\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLXGd55gUYjK"
      },
      "source": [
        "### **Option 2: Mount Your Google Drive**\n",
        "---\n",
        "\n",
        "If you wish to use this notebook with data from your Google Drive, you'll first need to mount the drive to this notebook.\n",
        "\n",
        "Execute the cell below to initiate the Google Drive mounting process. A link will be displayed click on it. In the new browser window that opens, choose your drive and click 'Allow'. Copy the code that appears, return to this notebook, paste the code into the cell, and press 'Enter'. This action grants Colab access to your Google Drive data.\n",
        "\n",
        "After this process, you can access your data via the **Files** tab, located on the top left of this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h-yXrZLdUk3Z"
      },
      "outputs": [],
      "source": [
        "#@markdown ##Play the cell to connect your Google Drive to Colab\n",
        "\n",
        "#@markdown * Click on the URL.\n",
        "\n",
        "#@markdown * Sign in your Google Account.\n",
        "\n",
        "#@markdown * Copy the authorization code.\n",
        "\n",
        "#@markdown * Enter the authorization code.\n",
        "\n",
        "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\".\n",
        "\n",
        "# mount user's Google Drive to Google Colab.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9FcxFB3H7az"
      },
      "source": [
        "### **Option 3: Download an Example Dataset**\n",
        "---\n",
        "Don't have data readily available but still want to test the notebook? No problem! Simply execute the following cell to download a sample dataset.\n",
        "\n",
        "Specifically, we'll use an image sourced from  [Noise2Void](https://github.com/juglab/n2v), graciously provided by Romina Piscitello of the Eaton Lab at MPI-CBG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD3aoo-ZUtW4",
        "outputId": "84b93da4-5fe7-4631-89ac-905a9f4200bd",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and unzipped under /content/data\n"
          ]
        }
      ],
      "source": [
        "#@markdown ##Play to download an example dataset\n",
        "!pip install gdown==5.1.0 --quiet\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "os.chdir('/content/')\n",
        "gdown.download(\"https://drive.google.com/uc?id=1OIjnUoJKdnbClBlpzk7V5R8wtoLont-r\", \"flywing3D.zip\", quiet=True)\n",
        "\n",
        "!unzip -q flywing3D.zip\n",
        "!rm flywing3D.zip\n",
        "\n",
        "print('Dataset downloaded and unzipped under /content/data')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEv7FBXFQvjv"
      },
      "source": [
        "## **Paths for Input Images and Output Files**\n",
        "___\n",
        "\n",
        "Depending on the option you chose for managing file sources, you'll set your paths differently:\n",
        "\n",
        "- **Option 1 (Upload from Local Machine)**:\n",
        "  - Set `train_data_path` to `/content/input/train`\n",
        "  - Set `test_data_path` to `/content/input/test`\n",
        "  - Set `output_path` to `/content/out`\n",
        "  \n",
        "- **Option 2 (Use Google Drive Data)**:\n",
        "  - Insert the paths to your input files and your desired output directory here, i.e., `/content/gdrive/MyDrive/...`.\n",
        "  \n",
        "- **Option 3 (Use Our Sample Data)**:\n",
        "  - Set `train_data_path` to `/content/data/train`\n",
        "  - Set `test_data_path` to `/content/data/test`\n",
        "  - Set `output_path` to `/content/out`\n",
        "\n",
        "  **Note**: Ensure you download your results from the `/content/out` directory after the process!\n",
        "\n",
        "**Helpful Tip**: If you're unsure about the paths to your folders, look at the top left of this notebook for a small folder icon. Navigate through the directories until you locate your desired folder. Right-click on it and select \"Copy Path\" to copy the folder's path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vl4e0UIGYZcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4ecf54e-7c3d-4e81-ee36-d736e609f284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images: 1\n",
            "Number of test images: 1\n"
          ]
        }
      ],
      "source": [
        "#@markdown #####Path to train images\n",
        "train_data_path = '/content/data/train' #@param {type:\"string\"}\n",
        "#@markdown #####Path to test images\n",
        "test_data_path = '/content/data/test' #@param {type:\"string\"}\n",
        "#@markdown #####Path to store the resulting images (it'll be created if not existing):\n",
        "output_path = '/content/output' #@param {type:\"string\"}\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def count_image_files(directory):\n",
        "    if not directory or not os.path.exists(directory):\n",
        "        return 0\n",
        "    image_extensions = {'.jpg', '.jpeg', '.png', '.tif', '.npy', '.tiff', '.h5', '.hd5', '.zarr'}\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if Path(file).suffix.lower() in image_extensions:\n",
        "                count += 1\n",
        "    return count\n",
        "\n",
        "num_train_images = count_image_files(train_data_path)\n",
        "num_test_images = count_image_files(test_data_path)\n",
        "\n",
        "\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of test images: {num_test_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Dataset Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "wv-ckuR_iYYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown ## Play to visualize some data samples\n",
        "# @markdown Select the set to show images from, the image index to navigate between samples, and the z value to move between slices.\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.io import imread\n",
        "import os\n",
        "from ipywidgets import interact, IntSlider, Layout, Dropdown, HBox, Output\n",
        "\n",
        "# Initialize global attributes\n",
        "instance_id = 0\n",
        "input_path = train_data_path\n",
        "ids_input = sorted(next(os.walk(input_path))[2])\n",
        "input_img = imread(os.path.join(input_path, ids_input[0]))\n",
        "\n",
        "# Initialize widgets\n",
        "\n",
        "# Dropdown widget to choose training or test set\n",
        "dropdown = Dropdown(\n",
        "    options=['training-set', 'test-set'],\n",
        "    value='training-set',\n",
        "    description='Set:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "# Slider widget to choose instance\n",
        "slider= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(ids_input),\n",
        "    step=1,\n",
        "    description='Image index:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "slider.style.description_width = 'initial'\n",
        "slider.style.handle_color='blue'\n",
        "\n",
        "# Slider widget to choose Z value\n",
        "sliderZ= IntSlider(\n",
        "    value=0,\n",
        "    min=1,\n",
        "    max=len(input_img),\n",
        "    step=1,\n",
        "    description='Z value:',\n",
        "    disabled=False,\n",
        "    continuous_update=False,\n",
        "    orientation='horizontal',\n",
        "    readout=True,\n",
        "    layout=Layout(width='500px', margin = '0 0 0 10px')\n",
        ")\n",
        "\n",
        "sliderZ.style.description_width = 'initial'\n",
        "sliderZ.style.handle_color='blue'\n",
        "\n",
        "# Initialize Output instance to handle code output cell\n",
        "output = Output()\n",
        "\n",
        "# Function to update path and image IDs (input_path, ids_input) depending on dropdown\n",
        "def update_paths(change):\n",
        "    global input_path, gt_path\n",
        "    if change.new == 'test-set':\n",
        "        input_path = test_data_path\n",
        "    else:\n",
        "        input_path = train_data_path\n",
        "\n",
        "    # Update image IDs based on the new paths\n",
        "    global ids_input\n",
        "    ids_input = sorted(next(os.walk(input_path))[2])\n",
        "\n",
        "    # Reset slider value to 1 when dropdown changes\n",
        "    slider.value = 1\n",
        "    slider.max = len(ids_input)\n",
        "    update_id({'new': 1})\n",
        "\n",
        "# Function to update image (input_img, instance_id) depending on slider value\n",
        "def update_id(change):\n",
        "    index = change['new']\n",
        "\n",
        "    global instance_id\n",
        "    instance_id = index - 1\n",
        "\n",
        "    global input_path, ids_input\n",
        "    input_img_path = os.path.join(input_path, ids_input[instance_id])\n",
        "\n",
        "    global input_img\n",
        "    input_img = imread(input_img_path)\n",
        "\n",
        "    sliderZ.value = 1\n",
        "    sliderZ.max = len(input_img)\n",
        "    display_images({'new': 1})\n",
        "\n",
        "# Function to display images depending on sliderZ value\n",
        "def display_images(change):\n",
        "    with output:\n",
        "        output.clear_output(wait=True)\n",
        "        index = change['new']\n",
        "\n",
        "        global input_img, instance_id\n",
        "\n",
        "        # # Print instance path to ensure the image displayed is correct\n",
        "        # global input_path, ids_input\n",
        "        # print(os.path.join(input_path, ids_input[instance_id]))\n",
        "\n",
        "        # Display images\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.title(f\"Input image: {instance_id+1}, Z: {index}\")\n",
        "        plt.imshow(input_img[index-1], cmap='magma',vmin=np.percentile(input_img[index-1],0.1),vmax=np.percentile(input_img[index-1],99.9))\n",
        "        # plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Create an HBox to hold the dropdown and slider\n",
        "controls = HBox([dropdown, slider, sliderZ])\n",
        "display(controls, output)\n",
        "\n",
        "# Link widgets to functions\n",
        "dropdown.observe(update_paths, names='value')\n",
        "slider.observe(update_id, names='value')\n",
        "sliderZ.observe(display_images, names='value')\n",
        "\n",
        "# Initial display\n",
        "display_images({'new': slider.value})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432,
          "referenced_widgets": [
            "329194bc03df4be08af77f214bd53223",
            "15765738191c414eb1ee981b3d8fd1ad",
            "c017a55ba59f43d79ecad5e9ead7e9eb",
            "609b38a3858f46c8b2b670d431e9cb25",
            "82ca48950f554ba59c7d232085b962c5",
            "aaab73f392524675bdc6df8d37146c00",
            "2c9068ec61f446f2b859b201c4b555ee",
            "067e86e00d2f40f4b78f25c6310ee6fd",
            "cbb6413192ba4a5c986225001f0d373f",
            "39647b123dd04fc9af0743e8baaf6668",
            "ed07fae3d17c490b82e93b7e378d2a76",
            "04d9bd55484d499ea72f1c166f822060",
            "f1ce95e7787d448799cbdb71d7a5b7c0"
          ]
        },
        "id": "inny5qEcC11j",
        "outputId": "4352fa6a-163d-4d8c-e61b-f5a342d10366",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Dropdown(description='Set:', options=('training-set', 'test-set'), value='training-set'), IntSl\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "329194bc03df4be08af77f214bd53223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04d9bd55484d499ea72f1c166f822060"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZwoZC20rK42"
      },
      "source": [
        "## **Configure and train the DNN model**\n",
        "[BiaPy](https://biapy.readthedocs.io/en/latest/) contains a few deep learning models to perform denoising with [Noise2Void](https://github.com/juglab/n2v) approach.\n",
        "\n",
        "The selection of the model and the pipeline hyperparameters can be configured by editing the YAML configuration file or (easier) by running the next cells.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "27054b22-f6fb-401b-c2bd-550d457a0ea9",
        "cellView": "form",
        "id": "daGtIo-V_Ydt"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown ###OPTIONAL: Check BioImage Model Zoo (BMZ) models compatible with BiaPy\n",
        "# @markdown Use this option to generate a full list of the available BiaPy-compatible models in the BMZ.\n",
        "\n",
        "# @markdown **Important:** To select one of the listed models (if any), you will have to run the next cell and select \"BioImage Model Zoo\" as the source of the model. Then, paste the corresponding model's nickname into the created field.\n",
        "# @markdown <div><img src=\"https://bioimage.io/static/img/bioimage-io-logo.svg\" width=\"600\"/></div>\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "import pooch\n",
        "import yaml\n",
        "from IPython.display import HTML, display\n",
        "import logging\n",
        "from biapy.models import check_bmz_model_compatibility\n",
        "from packaging.version import Version\n",
        "from typing import Optional, Dict, Tuple, List, Literal\n",
        "\n",
        "# Change pooch verbosity\n",
        "logger = pooch.get_logger()\n",
        "logger.setLevel(\"WARNING\")\n",
        "\n",
        "# Extracted from BiaPy-GUI.\n",
        "# Adapted from BiaPy commit: 284ec3838766392c9a333ac9d27b55816a267bb9 (3.5.2)\n",
        "def check_model_restrictions(\n",
        "    model_rdf,\n",
        "    workflow_specs,\n",
        "):\n",
        "    \"\"\"\n",
        "    Checks model restrictions to be applied into the current configuration.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model_rdf : dict\n",
        "        BMZ model RDF that contains all the information of the model.\n",
        "\n",
        "    workflow_specs : dict\n",
        "        Specifications of the workflow. If not provided all possible models will be considered.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    option_list: dict\n",
        "        Variables and values to change in current configuration. These changes\n",
        "        are imposed by the selected model.\n",
        "    \"\"\"\n",
        "    specific_workflow = workflow_specs[\"workflow_type\"]\n",
        "\n",
        "    # Version of the model\n",
        "    model_version = Version(model_rdf[\"format_version\"])\n",
        "    opts = {}\n",
        "\n",
        "    # 1) Change PATCH_SIZE with the one stored in the model description. This differs from the code of BiaPy where\n",
        "    # get_test_inputs() is simply used as there a ModelDescr is build out of the RDF. Here we try to do it manually\n",
        "    # to avoid fetching files using the network as it may be slow.\n",
        "    input_image_shape = []\n",
        "    if \"shape\" in model_rdf[\"inputs\"][0]:\n",
        "        input_image_shape = model_rdf[\"inputs\"][0][\"shape\"]\n",
        "        # \"CebraNET Cellular Membranes in Volume SEM\" ('format_version': '0.4.10')\n",
        "        #   have: {'min': [1, 1, 64, 64, 64], 'step': [0, 0, 16, 16, 16]}\n",
        "        if isinstance(input_image_shape, dict) and \"min\" in input_image_shape:\n",
        "            input_image_shape = input_image_shape[\"min\"]\n",
        "    else:\n",
        "        # Check axes and dimension\n",
        "        input_image_shape = []\n",
        "        for axis in model_rdf[\"inputs\"][0][\"axes\"]:\n",
        "            if 'type' in axis:\n",
        "                if axis['type'] == \"batch\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif axis['type'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                elif 'id' in axis and 'size' in axis:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "            elif 'id' in axis:\n",
        "                if axis['id'] == \"channel\":\n",
        "                    input_image_shape += [1,]\n",
        "                else:\n",
        "                    if isinstance(axis['size'], int):\n",
        "                        input_image_shape += [axis['size'],]\n",
        "                    elif 'min' in axis['size']:\n",
        "                        input_image_shape += [axis['size']['min'],]\n",
        "    if len(input_image_shape) == 0:\n",
        "        raise ValueError(\"Couldn't load input info from BMZ model's RDF: {}\".format(model_rdf[\"inputs\"][0]))\n",
        "    opts[\"DATA.PATCH_SIZE\"] = tuple(input_image_shape[2:]) + (input_image_shape[1],)\n",
        "\n",
        "    # Capture model kwargs\n",
        "    if \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]:\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"kwargs\"]\n",
        "    elif (\n",
        "        \"architecture\" in model_rdf[\"weights\"][\"pytorch_state_dict\"]\n",
        "        and \"kwargs\" in model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"]\n",
        "    ):\n",
        "        model_kwargs = model_rdf[\"weights\"][\"pytorch_state_dict\"][\"architecture\"][\"kwargs\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Couldn't extract kwargs from model description.\")\n",
        "\n",
        "    # 2) Workflow specific restrictions\n",
        "    # Classes in semantic segmentation\n",
        "    if specific_workflow in [\"SEMANTIC_SEG\"]:\n",
        "        # Check number of classes\n",
        "        classes = -1\n",
        "        if \"n_classes\" in model_kwargs: # BiaPy\n",
        "            classes = model_kwargs[\"n_classes\"]\n",
        "        elif \"out_channels\" in model_kwargs:\n",
        "            classes = model_kwargs[\"out_channels\"]\n",
        "        elif \"classes\" in model_kwargs:\n",
        "            classes = model_kwargs[\"classes\"]\n",
        "\n",
        "        if isinstance(classes, list):\n",
        "            classes = classes[0]\n",
        "        if not isinstance(classes, int):\n",
        "            raise ValueError(f\"Classes not extracted correctly. Obtained {classes}\")\n",
        "\n",
        "        if specific_workflow == \"SEMANTIC_SEG\" and classes == -1:\n",
        "            raise ValueError(\"Classes not found for semantic segmentation dir. \")\n",
        "        opts[\"MODEL.N_CLASSES\"] = max(2,classes)\n",
        "    elif specific_workflow in [\"INSTANCE_SEG\"]:\n",
        "        # Assumed it's BC. This needs a more elaborated process. Still deciding this:\n",
        "        # https://github.com/bioimage-io/spec-bioimage-io/issues/621\n",
        "        channels = 2\n",
        "        if \"out_channels\" in model_kwargs:\n",
        "            channels = model_kwargs[\"out_channels\"]\n",
        "        if channels == 1:\n",
        "            channel_code = \"C\"\n",
        "        elif channels == 2:\n",
        "            channel_code = \"BC\"\n",
        "        elif channels == 3:\n",
        "            channel_code = \"BCM\"\n",
        "        if channels > 3:\n",
        "            raise ValueError(f\"Not recognized number of channels for instance segmentation. Obtained {channels}\")\n",
        "\n",
        "        opts[\"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\"] = channel_code\n",
        "\n",
        "    if \"preprocessing\" not in model_rdf[\"inputs\"][0]:\n",
        "        return opts\n",
        "\n",
        "    preproc_info = model_rdf[\"inputs\"][0][\"preprocessing\"]\n",
        "    if len(preproc_info) == 0:\n",
        "        return opts\n",
        "    preproc_info = preproc_info[0]\n",
        "\n",
        "    # 3) Change preprocessing to the one stablished by BMZ by translate BMZ keywords into BiaPy's\n",
        "    # 'zero_mean_unit_variance' and 'fixed_zero_mean_unit_variance' norms of BMZ can be translated to our 'custom' norm\n",
        "    # providing mean and std\n",
        "    key_to_find = \"id\" if model_version > Version(\"0.5.0\") else \"name\"\n",
        "    if key_to_find in preproc_info:\n",
        "        if preproc_info[key_to_find] in [\"fixed_zero_mean_unit_variance\", \"zero_mean_unit_variance\"]:\n",
        "            if (\n",
        "                \"kwargs\" in preproc_info\n",
        "                and \"mean\" in preproc_info[\"kwargs\"]\n",
        "            ):\n",
        "                mean = preproc_info[\"kwargs\"][\"mean\"]\n",
        "                std = preproc_info[\"kwargs\"][\"std\"]\n",
        "            elif \"mean\" in preproc_info:\n",
        "                mean = preproc_info[\"mean\"]\n",
        "                std = preproc_info[\"std\"]\n",
        "            else:\n",
        "                mean, std = -1., -1.\n",
        "\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"custom\"\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_MEAN\"] = mean\n",
        "            opts[\"DATA.NORMALIZATION.CUSTOM_STD\"] = std\n",
        "\n",
        "        # 'scale_linear' norm of BMZ is close to our 'div' norm (TODO: we need to control the \"gain\" arg)\n",
        "        elif preproc_info[key_to_find] == \"scale_linear\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"div\"\n",
        "\n",
        "        # 'scale_range' norm of BMZ is as our PERC_CLIP + 'scale_range' norm\n",
        "        elif preproc_info[key_to_find] == \"scale_range\":\n",
        "            opts[\"DATA.NORMALIZATION.TYPE\"] = \"scale_range\"\n",
        "            if (\n",
        "                float(preproc_info[\"kwargs\"][\"min_percentile\"]) != 0\n",
        "                or float(preproc_info[\"kwargs\"][\"max_percentile\"]) != 100\n",
        "            ):\n",
        "                opts[\"DATA.NORMALIZATION.PERC_CLIP\"] = True\n",
        "                opts[\"DATA.NORMALIZATION.PERC_LOWER\"] = float(preproc_info[\"kwargs\"][\"min_percentile\"])\n",
        "                opts[\"DATA.NORMALIZATION.PERC_UPPER\"] = float(preproc_info[\"kwargs\"][\"max_percentile\"])\n",
        "\n",
        "    return opts\n",
        "\n",
        "# Check the models that BiaPy can consume\n",
        "COLLECTION_URL = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/collection.json\"\n",
        "collection_path = Path(pooch.retrieve(COLLECTION_URL, known_hash=None))\n",
        "with collection_path.open() as f:\n",
        "    collection = json.load(f)\n",
        "\n",
        "model_urls = [entry[\"rdf_source\"] for entry in collection[\"collection\"] if entry[\"type\"] == \"model\"]\n",
        "\n",
        "model_rdfs = []\n",
        "for mu in model_urls:\n",
        "    with open(Path(pooch.retrieve(mu, known_hash=None)), 'rt', encoding='utf8') as stream:\n",
        "        try:\n",
        "            model_rdfs.append(yaml.safe_load(stream))\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "\n",
        "# Check axes, preprocessing functions used and postprocessing.\n",
        "pytorch_models = []\n",
        "imposed_vars = []\n",
        "\n",
        "workflow_specs = {\n",
        "    \"workflow_type\": \"DENOISING\",\n",
        "    \"ndim\": \"3D\",\n",
        "    \"nclasses\": \"all\",\n",
        "}\n",
        "for model_rdf in model_rdfs:\n",
        "    try:\n",
        "        (\n",
        "            preproc_info,\n",
        "            error,\n",
        "            error_message\n",
        "        ) = check_bmz_model_compatibility(model_rdf, workflow_specs=workflow_specs)\n",
        "    except:\n",
        "        error = True\n",
        "\n",
        "    if not error:\n",
        "        model_imposed_vars = check_model_restrictions(model_rdf, workflow_specs=workflow_specs)\n",
        "        imposed_vars.append(model_imposed_vars)\n",
        "        pytorch_models.append(model_rdf)\n",
        "\n",
        "# Print the possible models\n",
        "html = \"<table style='width:100%''>\"\n",
        "c = 0\n",
        "for i, model in enumerate(pytorch_models):\n",
        "\n",
        "    if 'nickname' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['nickname']\n",
        "        nickname_icon = model['config']['bioimageio']['nickname_icon']\n",
        "    elif 'id' in model['config']['bioimageio']:\n",
        "        nickname = model['config']['bioimageio']['id']\n",
        "        nickname_icon = model['config']['bioimageio']['id_emoji']\n",
        "    else:\n",
        "        doi = \"/\".join(model['id'].split(\"/\")[:2])\n",
        "        nickname = doi\n",
        "        nickname_icon = doi\n",
        "    cover_url = \"https://uk1s3.embassy.ebi.ac.uk/public-datasets/bioimage.io/\"+nickname+\"/\"+str(model[\"version\"])+\"/files/\"+model['covers'][0]\n",
        "    restrictions = \"\"\n",
        "    for key, val in imposed_vars[i].items():\n",
        "        if key == 'MODEL.N_CLASSES':\n",
        "            restrictions += \"<p>number_of_classes: {}</p>\".format(val)\n",
        "        elif key == \"PROBLEM.INSTANCE_SEG.DATA_CHANNELS\":\n",
        "            problem_channels = 'Binary mask + Contours'\n",
        "            if val == \"BC\":\n",
        "                problem_channels = \"Binary mask + Contours\"\n",
        "            elif val == 'BP':\n",
        "                problem_channels = \"Binary mask + Central points\"\n",
        "            elif val == 'BD':\n",
        "                problem_channels = \"Binary mask + Distance map\"\n",
        "            elif val == 'BCM':\n",
        "                problem_channels = \"Binary mask + Contours + Foreground mask\"\n",
        "            elif val == 'BCD':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map\"\n",
        "            elif val == 'BCDv2':\n",
        "                problem_channels = \"Binary mask + Contours + Distance map with background\"\n",
        "            elif val == 'Dv2':\n",
        "                problem_channels = \"Distance map with background\"\n",
        "            restrictions += \"<p>problem_representation: {}</p>\".format(problem_channels)\n",
        "    if c == 0:\n",
        "        html += \"<tr>\"\n",
        "    html += \"<td style='width:33%'>\"\n",
        "    html += \"<p style='color:#2196f3'>%s</p><p>Nickname: %s (%s)</p>%s<img src='%s' height='200'></td>\"%(\n",
        "        model['name'],\n",
        "        nickname,\n",
        "        nickname_icon,\n",
        "        restrictions,\n",
        "        cover_url,\n",
        "    )\n",
        "    c +=1\n",
        "    if c == 3:\n",
        "        html += \"</tr>\"\n",
        "        c=0\n",
        "html += \"</table>\"\n",
        "if len( pytorch_models ) == 0:\n",
        "    display(HTML('<h1>No BMZ models compatible with BiaPy were found for this task.</h1><br>'))\n",
        "else:\n",
        "    display(HTML('<h1>List of models that can be used in BiaPy:</h1><br>'))\n",
        "    display(HTML(html))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "014b2b8d71b04e069d36a1c95e3c30b6",
            "0f57199d3d9143d5a47f2e8261108061",
            "1dea4b23064f4862909d8b6bd5412181"
          ]
        },
        "id": "Zn30l9mSoFNB",
        "outputId": "540775b6-f6a2-450d-c128-d65dbfe32724"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ToggleButtons(description='Source:', options=('BiaPy', 'BioImage Model Zoo'), tooltips=('Models created during\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "014b2b8d71b04e069d36a1c95e3c30b6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ###Play to select the source to build the model (BiaPy or BioImage Model Zoo) { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "\n",
        "#@markdown **BiaPy**: to use the models implemented in BiaPy.\n",
        "\n",
        "#@markdown **Bioimage Model Zoo (BMZ)**: to use models from the [BMZ repository](https://bioimage.io/#/). You can run the above cell to generate an updated list of the models that can be used with BiaPy. Copy the nickname from the model and paste it below.\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import Output\n",
        "\n",
        "changed_source = True\n",
        "exists_bmz = False\n",
        "# create widgets\n",
        "source = widgets.ToggleButtons(\n",
        "    options=['BiaPy', 'BioImage Model Zoo'],\n",
        "    description='Source:',\n",
        "    disabled=False,\n",
        "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltips=['Models created during this workflow', 'BioImage Model Zoo model'],\n",
        "#     icons=['check'] * 3\n",
        ")\n",
        "\n",
        "bmz = widgets.Text(\n",
        "    # value='10.5281/zenodo.5764892',\n",
        "    placeholder='Nickname of BMZ model',\n",
        "    description='ID:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# display the first widget\n",
        "display(source)\n",
        "\n",
        "# intialize the output - second widget\n",
        "out = Output()\n",
        "\n",
        "def changed(change):\n",
        "    '''\n",
        "    Monitor change in the first widget\n",
        "    '''\n",
        "    global out\n",
        "    global exists_bmz\n",
        "    if source.value == 'BiaPy':\n",
        "        bmz.layout.display = 'none'\n",
        "        out.clear_output() #clear output\n",
        "        out = Output() # redefine output\n",
        "    else:\n",
        "        bmz.layout.display = 'none'\n",
        "        bmz.layout.display = 'flex'\n",
        "        if not exists_bmz:\n",
        "          out.append_display_data(bmz)\n",
        "          display(out)\n",
        "        exists_bmz = True\n",
        "\n",
        "# monitor the source widget for changes\n",
        "source.observe(changed, 'value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfUyeHEP4vY3"
      },
      "source": [
        "### **Select your parameters**\n",
        "---\n",
        "#### **Name of the model**\n",
        "* **`model_name`:** Use only my_model -style, not my-model (Use \"_\" not \"-\"). Do not use spaces in the name. Avoid using the name of an existing model (saved in the same folder) as it will be overwritten.\n",
        "\n",
        "#### **Basic training parameters**\n",
        "\n",
        "* **`input_channels`:** Input the number of channels of your images (grayscale = 1, RGB = 3). **Default value: 1**\n",
        "\n",
        "* **`number_of_epochs`:** Input how many epochs (rounds) the network will be trained. For the example dataset, reasonable results can already be observed after 100 epochs. **Default value: 20**\n",
        "\n",
        "* **`percentage_validation`:**  Input the percentage of your training dataset you want to use to validate the network during the training. **Default value: 10**\n",
        "\n",
        "* **`patience`:**  Input how many epochs you want to wait without the model improving its results in the validation set to stop training. **Default value: 5**\n",
        "\n",
        "#### **Advanced Parameters - experienced users only**\n",
        "* **`model_architecture`:**  Select the architecture of the DNN used as backbone of the pipeline. Options: U-Net, Residual U-Net, Attention U-Net (see [Franco-Barranco et al., 2021](https://link.springer.com/article/10.1007/s12021-021-09556-1)), SEUNet, MultiResUNet, ResUNet++, UNETR-Mini, UNETR-Small and UNETR-Base. **Default value: U-Net**\n",
        "\n",
        "* **`batch_size:`** This parameter defines the number of patches seen in each training step. Reducing or increasing the **batch size** may slow or speed up your training, respectively, and can influence network performance. **Default value: 4**\n",
        "\n",
        "* **`patch_size_xy`:**Input the XY size of the patches use to train your model (length in pixels in X and Y). The value should be smaller or equal to the dimensions of the image. **Default value: 64**\n",
        "\n",
        "* **`patch_size_z`:** Input the Z size of the patches use to train your model (length in pixels in Z). The value should be smaller or equal to the dimensions of the image. **Default value: 32**\n",
        "\n",
        "* **`anisotropic_data`:** Select if your image data is anisotropic (lower resolution in Z with respect to XY). The model downsampling step size will be set accordingly.\n",
        "  **Default value: True**\n",
        "\n",
        "* **`optimizer`:** Select the optimizer used to train your model. Options: ADAM, ADAMW, Stochastic Gradient Descent (SGD). ADAM usually converges faster, while ADAMW provides a balance between fast convergence and better handling of weight decay regularization. SGD is known for better generalization. **Default value: ADAMW**\n",
        "\n",
        "* **`initial_learning_rate`:** Input the initial value to be used as learning rate. If you select ADAM as optimizer, this value should be around 10e-4. **Default value: 0.0001**\n",
        "\n",
        "* **`test_time_augmentation`:** Select to apply augmentation (flips and rotations) at test time. It usually provides more robust results but uses more time to produce each result. **Default value: False**\n",
        "\n",
        "#### **Noise2Void parameters**\n",
        "* **`n2v_perc_pix`:**  The fraction of pixels manipulated per each patch used for training. For instances, 0.198% of the input pixels per patch or a patch size of 64 by 64 pixels corresponds to about 8 pixels. **Default value: 0.198**\n",
        "\n",
        "* **`pixel_manipulator:`** Controls how the pixels are going to be manipulated to train the network. **Default value: uniform_withCP**\n",
        "\n",
        "* **`neighborhood_radius`:** Size of the neighborhood to compute the replacement. **Default value: 5**\n",
        "\n",
        "* **`apply_structmask`:** Wheter to apply a structured mask as is proposed in [Noise2Void](https://github.com/juglab/n2v) to alleviate the limitation of the method of not removing efectively the structured noise (section 4.4 of their paper). **Default value: False**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RLdMygZVT5aH"
      },
      "outputs": [],
      "source": [
        "#@markdown ###Name of the model:\n",
        "model_name = \"my_3d_denoising\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ### Basic training parameters:\n",
        "input_channels = 1 #@param {type:\"number\"}\n",
        "number_of_epochs =  100#@param {type:\"number\"}\n",
        "percentage_validation =  10 #@param {type:\"number\"}\n",
        "patience =  20#@param {type:\"number\"}\n",
        "\n",
        "#@markdown ### Advanced training parameters:\n",
        "model_architecture = \"U-Net\" #@param [\"U-Net\", \"Residual U-Net\", \"Attention U-Net\", 'MultiResUNet', 'ResUNet++', 'SEUNet', \"UNETR-Mini\",\"UNETR-Small\", \"UNETR-Base\"]\n",
        "batch_size =  4#@param {type:\"number\"}\n",
        "patch_size_xy = 64 #@param {type:\"number\"}\n",
        "patch_size_z = 32 #@param {type:\"number\"}\n",
        "anisotropic_data = True #@param {type:\"boolean\"}\n",
        "optimizer = \"ADAMW\" #@param [\"ADAM\", \"SGD\",\"ADAMW\"]\n",
        "initial_learning_rate = 0.0001 #@param {type:\"number\"}\n",
        "test_time_augmentation = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Noise2Void parameters:\n",
        "n2v_perc_pix = 0.198 #@param {type:\"number\"}\n",
        "pixel_manipulator =  'uniform_withCP' #@param ['uniform_withCP','normal_withoutCP', 'mean', 'median', 'uniform_withoutCP','normal_additive','normal_fitted','identity']\n",
        "neighborhood_radius = 5 #@param {type:\"number\"}\n",
        "apply_structmask = False #@param {type:\"boolean\"}\n",
        "\n",
        "checkpoint_path = ''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LwtK1Hp6XgYs"
      },
      "outputs": [],
      "source": [
        "#@markdown ##OPTIONAL: Play the cell to upload initial model weights\n",
        "#@markdown Use this option to start the training from a **pre-trained model** if you have one. Otherwise, skip this cell.\n",
        "\n",
        "#@markdown **Important**: remember the weights must correspond to the selected architecture, patch size and number of input channels. Otherwise, an error will be shown when training.\n",
        "from google.colab import files\n",
        "\n",
        "#s.chdir('/content/')\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "checkpoint_path = '/content/' + list(uploaded.keys())[0]\n",
        "\n",
        "# open previously configured file, if exists\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# edit previous configuration file if it exists to load the checkpoint model\n",
        "if os.path.exists( yaml_file ):\n",
        "    import yaml\n",
        "    with open( yaml_file, 'r') as stream:\n",
        "        try:\n",
        "            biapy_config = yaml.safe_load(stream)\n",
        "        except yaml.YAMLError as exc:\n",
        "            print(exc)\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "    # save file\n",
        "    with open( yaml_file, 'w') as outfile:\n",
        "        yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Pre-trained model loaded and ready to re-train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDNWZYlu4zSG"
      },
      "source": [
        "### **Train the model**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CZKK9EoVmH-Y",
        "outputId": "a30e669b-450c-4301-a6b0-2842bf9cfd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training configuration finished.\n",
            "Date: 2024-08-26 13:02:56\n",
            "Arguments: Namespace(config='/content/my_3d_denoising.yaml', result_dir='/content/output', name='my_3d_denoising', run_id=1, gpu=0, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', dist_backend='nccl')\n",
            "Job: my_3d_denoising_1\n",
            "Python       : 3.10.12 (main, Jul 29 2024, 16:56:48) [GCC 11.4.0]\n",
            "PyTorch:  2.4.0+cu118\n",
            "Not using distributed mode\n",
            "[13:02:56.363677] Configuration details:\n",
            "[13:02:56.363769] AUGMENTOR:\n",
            "  AFFINE_MODE: reflect\n",
            "  AUG_NUM_SAMPLES: 10\n",
            "  AUG_SAMPLES: True\n",
            "  BRIGHTNESS: False\n",
            "  BRIGHTNESS_FACTOR: (-0.1, 0.1)\n",
            "  BRIGHTNESS_MODE: 3D\n",
            "  CBLUR_DOWN_RANGE: (2, 8)\n",
            "  CBLUR_INSIDE: True\n",
            "  CBLUR_SIZE: (0.2, 0.4)\n",
            "  CHANNEL_SHUFFLE: False\n",
            "  CMIX_SIZE: (0.2, 0.4)\n",
            "  CNOISE_NB_ITERATIONS: (1, 3)\n",
            "  CNOISE_SCALE: (0.05, 0.1)\n",
            "  CNOISE_SIZE: (0.2, 0.4)\n",
            "  CONTRAST: False\n",
            "  CONTRAST_FACTOR: (-0.1, 0.1)\n",
            "  CONTRAST_MODE: 3D\n",
            "  COUT_APPLY_TO_MASK: False\n",
            "  COUT_CVAL: 0.0\n",
            "  COUT_NB_ITERATIONS: (1, 3)\n",
            "  COUT_SIZE: (0.05, 0.3)\n",
            "  CUTBLUR: False\n",
            "  CUTMIX: False\n",
            "  CUTNOISE: False\n",
            "  CUTOUT: False\n",
            "  DA_PROB: 0.5\n",
            "  DRAW_GRID: False\n",
            "  DROPOUT: False\n",
            "  DROP_RANGE: (0, 0.2)\n",
            "  ELASTIC: False\n",
            "  ENABLE: True\n",
            "  E_ALPHA: (12, 16)\n",
            "  E_MODE: constant\n",
            "  E_SIGMA: 4\n",
            "  GAMMA_CONTRAST: False\n",
            "  GAUSSIAN_NOISE: False\n",
            "  GAUSSIAN_NOISE_MEAN: 0.0\n",
            "  GAUSSIAN_NOISE_USE_INPUT_IMG_MEAN_AND_VAR: False\n",
            "  GAUSSIAN_NOISE_VAR: 0.05\n",
            "  GC_GAMMA: (1.25, 1.75)\n",
            "  GRAYSCALE: False\n",
            "  GRIDMASK: False\n",
            "  GRID_D_RANGE: (0.4, 1)\n",
            "  GRID_INVERT: False\n",
            "  GRID_RATIO: 0.6\n",
            "  GRID_ROTATE: 1.0\n",
            "  G_BLUR: False\n",
            "  G_SIGMA: (1.0, 2.0)\n",
            "  HFLIP: True\n",
            "  MB_KERNEL: (3, 7)\n",
            "  MEDIAN_BLUR: False\n",
            "  MISALIGNMENT: False\n",
            "  MISSING_SECTIONS: False\n",
            "  MISSP_ITERATIONS: (10, 30)\n",
            "  MOTB_K_RANGE: (8, 12)\n",
            "  MOTION_BLUR: False\n",
            "  MS_DISPLACEMENT: 16\n",
            "  MS_ROTATE_RATIO: 0.5\n",
            "  PEPPER: False\n",
            "  PEPPER_AMOUNT: 0.05\n",
            "  POISSON_NOISE: False\n",
            "  RANDOM_ROT: False\n",
            "  RANDOM_ROT_RANGE: (-180, 180)\n",
            "  ROT90: False\n",
            "  SALT: False\n",
            "  SALT_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER: False\n",
            "  SALT_AND_PEPPER_AMOUNT: 0.05\n",
            "  SALT_AND_PEPPER_PROP: 0.5\n",
            "  SHEAR: False\n",
            "  SHEAR_RANGE: (-20, 20)\n",
            "  SHIFT: False\n",
            "  SHIFT_RANGE: (0.1, 0.2)\n",
            "  SHUFFLE_TRAIN_DATA_EACH_EPOCH: True\n",
            "  SHUFFLE_VAL_DATA_EACH_EPOCH: False\n",
            "  VFLIP: True\n",
            "  ZFLIP: True\n",
            "  ZOOM: False\n",
            "  ZOOM_IN_Z: False\n",
            "  ZOOM_RANGE: (0.8, 1.2)\n",
            "DATA:\n",
            "  CHECK_GENERATORS: False\n",
            "  EXTRACT_RANDOM_PATCH: False\n",
            "  FORCE_RGB: False\n",
            "  NORMALIZATION:\n",
            "    APPLICATION_MODE: image\n",
            "    CUSTOM_MEAN: -1.0\n",
            "    CUSTOM_STD: -1.0\n",
            "    PERC_CLIP: False\n",
            "    PERC_LOWER: -1.0\n",
            "    PERC_UPPER: -1.0\n",
            "    TYPE: custom\n",
            "  PATCH_SIZE: (32, 64, 64, 1)\n",
            "  PREPROCESS:\n",
            "    CANNY:\n",
            "      ENABLE: False\n",
            "      HIGH_THRESHOLD: None\n",
            "      LOW_THRESHOLD: None\n",
            "    CLAHE:\n",
            "      CLIP_LIMIT: 0.01\n",
            "      ENABLE: False\n",
            "      KERNEL_SIZE: None\n",
            "    GAUSSIAN_BLUR:\n",
            "      CHANNEL_AXIS: None\n",
            "      ENABLE: False\n",
            "      MODE: nearest\n",
            "      SIGMA: 1\n",
            "    MATCH_HISTOGRAM:\n",
            "      ENABLE: False\n",
            "      REFERENCE_PATH: user_data/test/x\n",
            "    MEDIAN_BLUR:\n",
            "      ENABLE: False\n",
            "    RESIZE:\n",
            "      ANTI_ALIASING: False\n",
            "      CLIP: True\n",
            "      CVAL: 0.0\n",
            "      ENABLE: False\n",
            "      MODE: reflect\n",
            "      ORDER: 1\n",
            "      OUTPUT_SHAPE: (512, 512)\n",
            "      PRESERVE_RANGE: True\n",
            "    TEST: False\n",
            "    TRAIN: False\n",
            "    VAL: False\n",
            "    ZOOM:\n",
            "      ENABLE: False\n",
            "      ZOOM_FACTOR: [1, 1, 1, 1, 1]\n",
            "  PROBABILITY_MAP: False\n",
            "  REFLECT_TO_COMPLETE_SHAPE: False\n",
            "  TEST:\n",
            "    ARGMAX_TO_OUTPUT: True\n",
            "    BINARY_MASKS: /content/data/test/../bin_mask\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/test/y_detection_masks\n",
            "    GT_PATH: user_data/test/y\n",
            "    INSTANCE_CHANNELS_DIR: /content/data/test_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/test/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    LOAD_GT: False\n",
            "    MEDIAN_PADDING: False\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (4, 8, 8)\n",
            "    PATH: /content/data/test\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/test_ssl_source\n",
            "    USE_VAL_AS_TEST: False\n",
            "  TRAIN:\n",
            "    CHECK_DATA: True\n",
            "    DETECTION_MASK_DIR: user_data/train/y_detection_masks\n",
            "    GT_PATH: user_data/train/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: /content/data/train_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/train/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    MINIMUM_FOREGROUND_PER: -1.0\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: /content/data/train\n",
            "    REPLICATE: 0\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SSL_SOURCE_DIR: /content/data/train_ssl_source\n",
            "  VAL:\n",
            "    CROSS_VAL: False\n",
            "    CROSS_VAL_FOLD: 1\n",
            "    CROSS_VAL_NFOLD: 5\n",
            "    DETECTION_MASK_DIR: user_data/val/y_detection_masks\n",
            "    DIST_EVAL: True\n",
            "    FROM_TRAIN: True\n",
            "    GT_PATH: user_data/val/y\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    INSTANCE_CHANNELS_DIR: user_data/val/x_BC_thick\n",
            "    INSTANCE_CHANNELS_MASK_DIR: user_data/val/y_BC_thick\n",
            "    IN_MEMORY: True\n",
            "    OVERLAP: (0, 0, 0)\n",
            "    PADDING: (0, 0, 0)\n",
            "    PATH: user_data/val/x\n",
            "    RANDOM: True\n",
            "    RESOLUTION: (1, 1, 1)\n",
            "    SPLIT_TRAIN: 0.1\n",
            "    SSL_SOURCE_DIR: user_data/val/x_ssl_source\n",
            "  W_BACKGROUND: 0.06\n",
            "  W_FOREGROUND: 0.94\n",
            "LOG:\n",
            "  CHART_CREATION_FREQ: 5\n",
            "  LOG_DIR: /content/output/my_3d_denoising/train_logs\n",
            "  LOG_FILE_PREFIX: my_3d_denoising_1\n",
            "  TENSORBOARD_LOG_DIR: /content/output/my_3d_denoising/results/my_3d_denoising_1/tensorboard\n",
            "LOSS:\n",
            "  CLASS_REBALANCE: False\n",
            "  TYPE: MSE\n",
            "  WEIGHTS: [0.66, 0.34]\n",
            "MODEL:\n",
            "  ACTIVATION: relu\n",
            "  ARCHITECTURE: unet\n",
            "  BMZ:\n",
            "    SOURCE_MODEL_ID: \n",
            "  CONVNEXT_LAYERS: [2, 2, 2, 2, 2]\n",
            "  CONVNEXT_LAYER_SCALE: 1e-06\n",
            "  CONVNEXT_SD_PROB: 0.1\n",
            "  CONVNEXT_STEM_K_SIZE: 2\n",
            "  DROPOUT_VALUES: [0, 0, 0]\n",
            "  FEATURE_MAPS: [32, 64, 128]\n",
            "  ISOTROPY: [True, True, True]\n",
            "  KERNEL_SIZE: 3\n",
            "  LARGER_IO: False\n",
            "  LAST_ACTIVATION: linear\n",
            "  LOAD_CHECKPOINT: False\n",
            "  LOAD_CHECKPOINT_EPOCH: best_on_val\n",
            "  LOAD_CHECKPOINT_ONLY_WEIGHTS: True\n",
            "  MAE_DEC_HIDDEN_SIZE: 512\n",
            "  MAE_DEC_MLP_DIMS: 2048\n",
            "  MAE_DEC_NUM_HEADS: 16\n",
            "  MAE_DEC_NUM_LAYERS: 8\n",
            "  MAE_MASK_RATIO: 0.5\n",
            "  MAE_MASK_TYPE: grid\n",
            "  NORMALIZATION: bn\n",
            "  N_CLASSES: 2\n",
            "  SAVE_CKPT_FREQ: -1\n",
            "  SOURCE: biapy\n",
            "  TORCHVISION_MODEL_NAME: \n",
            "  UNETR_DEC_ACTIVATION: relu\n",
            "  UNETR_DEC_KERNEL_SIZE: 3\n",
            "  UNETR_VIT_HIDD_MULT: 3\n",
            "  UNETR_VIT_NUM_FILTERS: 16\n",
            "  UNET_SR_UPSAMPLE_POSITION: pre\n",
            "  UPSAMPLE_LAYER: upsampling\n",
            "  VIT_EMBED_DIM: 768\n",
            "  VIT_MLP_RATIO: 4.0\n",
            "  VIT_MODEL: custom\n",
            "  VIT_NORM_EPS: 1e-06\n",
            "  VIT_NUM_HEADS: 12\n",
            "  VIT_NUM_LAYERS: 12\n",
            "  VIT_TOKEN_SIZE: 16\n",
            "  Z_DOWN: [1, 1]\n",
            "PATHS:\n",
            "  CHARTS: /content/output/my_3d_denoising/results/my_3d_denoising_1/charts\n",
            "  CHECKPOINT: /content/output/my_3d_denoising/checkpoints\n",
            "  CHECKPOINT_FILE: \n",
            "  DA_SAMPLES: /content/output/my_3d_denoising/results/my_3d_denoising_1/aug\n",
            "  GEN_CHECKS: /content/output/my_3d_denoising/results/my_3d_denoising_1/gen_check\n",
            "  GEN_MASK_CHECKS: /content/output/my_3d_denoising/results/my_3d_denoising_1/gen_mask_check\n",
            "  LWR_X_FILE: /content/output/my_3d_denoising/checkpoints/lower_bound_X_perc.npy\n",
            "  LWR_Y_FILE: /content/output/my_3d_denoising/checkpoints/lower_bound_Y_perc.npy\n",
            "  MAE_OUT_DIR: /content/output/my_3d_denoising/results/my_3d_denoising_1/MAE_checks\n",
            "  MEAN_INFO_FILE: /content/output/my_3d_denoising/checkpoints/normalization_mean_value.npy\n",
            "  PROB_MAP_DIR: /content/output/my_3d_denoising/prob_map\n",
            "  PROB_MAP_FILENAME: prob_map.npy\n",
            "  PROFILER: /content/output/my_3d_denoising/results/my_3d_denoising_1/profiler\n",
            "  RESULT_DIR:\n",
            "    AS_3D_STACK: /content/output/my_3d_denoising/results/my_3d_denoising_1/as_3d_stack\n",
            "    AS_3D_STACK_BIN: /content/output/my_3d_denoising/results/my_3d_denoising_1/as_3d_stack_binarized\n",
            "    AS_3D_STACK_POST_PROCESSING: /content/output/my_3d_denoising/results/my_3d_denoising_1/as_3d_stack_post_processing\n",
            "    DET_ASSOC_POINTS: /content/output/my_3d_denoising/results/my_3d_denoising_1/point_associations\n",
            "    DET_LOCAL_MAX_COORDS_CHECK: /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image_local_max_check\n",
            "    FULL_IMAGE: /content/output/my_3d_denoising/results/my_3d_denoising_1/full_image\n",
            "    FULL_IMAGE_BIN: /content/output/my_3d_denoising/results/my_3d_denoising_1/full_image_binarized\n",
            "    FULL_IMAGE_INSTANCES: /content/output/my_3d_denoising/results/my_3d_denoising_1/full_image_instances\n",
            "    FULL_IMAGE_POST_PROCESSING: /content/output/my_3d_denoising/results/my_3d_denoising_1/full_image_post_processing\n",
            "    INST_ASSOC_POINTS: /content/output/my_3d_denoising/results/my_3d_denoising_1/instance_associations\n",
            "    PATH: /content/output/my_3d_denoising/results/my_3d_denoising_1\n",
            "    PER_IMAGE: /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image\n",
            "    PER_IMAGE_BIN: /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image_binarized\n",
            "    PER_IMAGE_INSTANCES: /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image_instances\n",
            "    PER_IMAGE_POST_PROCESSING: /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image_post_processing\n",
            "  STD_INFO_FILE: /content/output/my_3d_denoising/checkpoints/normalization_std_value.npy\n",
            "  TEST_FULL_GT_H5: user_data/test/y/h5\n",
            "  TEST_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_denoising/results/my_3d_denoising_1/test_BC_instance_channels\n",
            "  TRAIN_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_denoising/results/my_3d_denoising_1/train_BC_instance_channels\n",
            "  UPR_X_FILE: /content/output/my_3d_denoising/checkpoints/upper_bound_X_perc.npy\n",
            "  UPR_Y_FILE: /content/output/my_3d_denoising/checkpoints/upper_bound_Y_perc.npy\n",
            "  VAL_INSTANCE_CHANNELS_CHECK: /content/output/my_3d_denoising/results/my_3d_denoising_1/val_BC_instance_channels\n",
            "  WATERSHED_DIR: /content/output/my_3d_denoising/results/my_3d_denoising_1/watershed\n",
            "PROBLEM:\n",
            "  DENOISING:\n",
            "    N2V_MANIPULATOR: uniform_withCP\n",
            "    N2V_NEIGHBORHOOD_RADIUS: 5\n",
            "    N2V_PERC_PIX: 0.198\n",
            "    N2V_STRUCTMASK: False\n",
            "  DETECTION:\n",
            "    CENTRAL_POINT_DILATION: [2]\n",
            "    CHECK_POINTS_CREATED: True\n",
            "    DATA_CHECK_MW: False\n",
            "  IMAGE_TO_IMAGE:\n",
            "    MULTIPLE_RAW_ONE_TARGET_LOADER: False\n",
            "  INSTANCE_SEG:\n",
            "    DATA_CHANNELS: BC\n",
            "    DATA_CHANNEL_WEIGHTS: (1, 1)\n",
            "    DATA_CHECK_MW: False\n",
            "    DATA_CONTOUR_MODE: thick\n",
            "    DATA_MW_TH_BINARY_MASK: 0.5\n",
            "    DATA_MW_TH_CONTOUR: 0.1\n",
            "    DATA_MW_TH_DISTANCE: 1.0\n",
            "    DATA_MW_TH_FOREGROUND: 0.3\n",
            "    DATA_MW_TH_POINTS: 0.5\n",
            "    DATA_MW_TH_TYPE: auto\n",
            "    DATA_REMOVE_BEFORE_MW: False\n",
            "    DATA_REMOVE_SMALL_OBJ_BEFORE: 10\n",
            "    DISTANCE_CHANNEL_MASK: True\n",
            "    ERODE_AND_DILATE_FOREGROUND: False\n",
            "    FORE_DILATION_RADIUS: 5\n",
            "    FORE_EROSION_RADIUS: 5\n",
            "    SEED_MORPH_RADIUS: []\n",
            "    SEED_MORPH_SEQUENCE: []\n",
            "    WATERSHED_BY_2D_SLICES: False\n",
            "  NDIM: 3D\n",
            "  SELF_SUPERVISED:\n",
            "    NOISE: 0.2\n",
            "    PRETEXT_TASK: crappify\n",
            "    RESIZING_FACTOR: 4\n",
            "  SEMANTIC_SEG:\n",
            "    IGNORE_CLASS_ID: 0\n",
            "  SUPER_RESOLUTION:\n",
            "    UPSCALING: (1, 1, 1)\n",
            "  TYPE: DENOISING\n",
            "SYSTEM:\n",
            "  DEVICE: cpu\n",
            "  NUM_CPUS: 2\n",
            "  NUM_GPUS: 0\n",
            "  NUM_WORKERS: 5\n",
            "  PIN_MEM: True\n",
            "  SEED: 0\n",
            "TEST:\n",
            "  ANALIZE_2D_IMGS_AS_3D_STACK: False\n",
            "  AUGMENTATION: False\n",
            "  AUGMENTATION_MODE: mean\n",
            "  BY_CHUNKS:\n",
            "    ENABLE: False\n",
            "    FLUSH_EACH: 100\n",
            "    FORMAT: H5\n",
            "    INPUT_IMG_AXES_ORDER: TZCYX\n",
            "    INPUT_MASK_AXES_ORDER: TZCYX\n",
            "    INPUT_ZARR_MULTIPLE_DATA: False\n",
            "    INPUT_ZARR_MULTIPLE_DATA_GT_PATH: \n",
            "    INPUT_ZARR_MULTIPLE_DATA_RAW_PATH: \n",
            "    SAVE_OUT_TIF: False\n",
            "    WORKFLOW_PROCESS:\n",
            "      ENABLE: True\n",
            "      TYPE: chunk_by_chunk\n",
            "  DET_BLOB_LOG_MAX_SIGMA: 10\n",
            "  DET_BLOB_LOG_MIN_SIGMA: 5\n",
            "  DET_BLOB_LOG_NUM_SIGMA: 2\n",
            "  DET_EXCLUDE_BORDER: False\n",
            "  DET_IGNORE_POINTS_OUTSIDE_BOX: []\n",
            "  DET_MIN_TH_TO_BE_PEAK: [0.2]\n",
            "  DET_PEAK_LOCAL_MAX_MIN_DISTANCE: 1\n",
            "  DET_POINT_CREATION_FUNCTION: peak_local_max\n",
            "  DET_TOLERANCE: [10]\n",
            "  ENABLE: True\n",
            "  FULL_IMG: False\n",
            "  MATCHING_STATS: True\n",
            "  MATCHING_STATS_THS: [0.3, 0.5, 0.75]\n",
            "  MATCHING_STATS_THS_COLORED_IMG: [0.3]\n",
            "  METRICS: ['mae', 'mse']\n",
            "  POST_PROCESSING:\n",
            "    APPLY_MASK: False\n",
            "    CLEAR_BORDER: False\n",
            "    DET_WATERSHED: False\n",
            "    DET_WATERSHED_DONUTS_CLASSES: [-1]\n",
            "    DET_WATERSHED_DONUTS_NUCLEUS_DIAMETER: 30\n",
            "    DET_WATERSHED_DONUTS_PATCH: [13, 120, 120]\n",
            "    DET_WATERSHED_FIRST_DILATION: [[-1, -1]]\n",
            "    MEASURE_PROPERTIES:\n",
            "      ENABLE: False\n",
            "      REMOVE_BY_PROPERTIES:\n",
            "        ENABLE: False\n",
            "        PROPS: []\n",
            "        SIGN: []\n",
            "        VALUES: []\n",
            "    MEDIAN_FILTER: False\n",
            "    MEDIAN_FILTER_AXIS: []\n",
            "    MEDIAN_FILTER_SIZE: []\n",
            "    REMOVE_CLOSE_POINTS: False\n",
            "    REMOVE_CLOSE_POINTS_RADIUS: [-1.0]\n",
            "    REPARE_LARGE_BLOBS_SIZE: -1\n",
            "    VORONOI_ON_MASK: False\n",
            "    VORONOI_TH: 0.0\n",
            "  REDUCE_MEMORY: False\n",
            "  REUSE_PREDICTIONS: False\n",
            "  VERBOSE: True\n",
            "TRAIN:\n",
            "  ACCUM_ITER: 1\n",
            "  BATCH_SIZE: 4\n",
            "  CHECKPOINT_MONITOR: val_loss\n",
            "  ENABLE: True\n",
            "  EPOCHS: 100\n",
            "  LR: 0.0001\n",
            "  LR_SCHEDULER:\n",
            "    MIN_LR: -1.0\n",
            "    NAME: \n",
            "    REDUCEONPLATEAU_FACTOR: 0.5\n",
            "    REDUCEONPLATEAU_PATIENCE: -1\n",
            "    WARMUP_COSINE_DECAY_EPOCHS: -1\n",
            "  METRICS: ['mae', 'mse']\n",
            "  OPTIMIZER: ADAMW\n",
            "  OPT_BETAS: (0.9, 0.999)\n",
            "  PATIENCE: 20\n",
            "  VERBOSE: False\n",
            "  W_DECAY: 0.02\n",
            "[13:02:58.205014] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "[13:02:58.205181] Initializing Denoising_Workflow\n",
            "[13:02:58.206773] *~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~*\n",
            "\n",
            "[13:02:58.468575] ##########################\n",
            "[13:02:58.468688] #   LOAD TRAINING DATA   #\n",
            "[13:02:58.468729] ##########################\n",
            "[13:02:58.470710] ### LOAD ###\n",
            "[13:02:58.470759] 0) Loading train images . . .\n",
            "[13:02:58.472070] Loading data from /content/data/train\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:02:58.929662] *** Loaded data shape is (198, 32, 64, 64, 1)\n",
            "[13:02:58.936627] Creating validation data\n",
            "[13:02:58.972919] Not all samples seem to have the same shape. Number of samples: 178\n",
            "[13:02:58.973763] *** Loaded train data shape is: (178, 32, 64, 64, 1)\n",
            "[13:02:58.973824] *** Loaded validation data shape is: (20, 32, 64, 64, 1)\n",
            "[13:02:58.973869] ### END LOAD ###\n",
            "[13:02:58.973947] ###############\n",
            "[13:02:58.976341] # Build model #\n",
            "[13:02:58.976400] ###############\n",
            "[13:03:01.318187] ##############################\n",
            "[13:03:01.319215] #  PREPARE TRAIN GENERATORS  #\n",
            "[13:03:01.319941] ##############################\n",
            "[13:03:01.320259] Initializing train data generator . . .\n",
            "[13:03:01.322010] Normalization config used for X: {'type': 'custom', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('float32')}\n",
            "[13:03:01.326860] Initializing val data generator . . .\n",
            "[13:03:01.328433] Normalization config used for X: {'type': 'custom', 'mask_norm': 'as_mask', 'application_mode': 'image', 'enable': True, 'orig_dtype': dtype('float32')}\n",
            "[13:03:01.329357] Creating generator samples . . .\n",
            "[13:03:01.329439] 0) Creating samples of data augmentation . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/imgaug/augmenters/base.py:49: SuspiciousSingleImageShapeWarning: You provided a numpy array of shape (64, 64, 32) as a single-image augmentation input, which was interpreted as (H, W, C). The last dimension however has a size of >=32, which indicates that you provided a multi-image array with shape (N, H, W) instead. If that is the case, you should use e.g. augmenter(imageS=<your input>) or augment_imageS(<your input>). Otherwise your multi-image input will be interpreted as a single image during augmentation.\n",
            "  ia.warn(\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 20%|\u2588\u2588        | 2/10 [00:00<00:00, 11.91it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 40%|\u2588\u2588\u2588\u2588      | 4/10 [00:00<00:00, 12.23it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 60%|\u2588\u2588\u2588\u2588\u2588\u2588    | 6/10 [00:00<00:00, 11.63it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            " 80%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 8/10 [00:00<00:00, 11.37it/s]\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "                                     \u001b[A\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 10/10 [00:00<00:00, 11.50it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:290: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self._scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:03:02.203755] Number of workers: 5\n",
            "[13:03:02.203818] Accumulate grad iterations: 1\n",
            "[13:03:02.203851] Effective batch size: 4\n",
            "[13:03:02.203901] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f8e96e07970>\n",
            "[13:03:02.207002] #######################\n",
            "[13:03:02.207086] # Prepare logging tool #\n",
            "[13:03:02.207126] #######################\n",
            "[13:03:02.216258] AdamW (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            "\n",
            "Parameter Group 1\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0001\n",
            "    maximize: False\n",
            "    weight_decay: 0.02\n",
            ")\n",
            "[13:03:02.216559] #####################\n",
            "[13:03:02.216617] #  TRAIN THE MODEL  #\n",
            "[13:03:02.216660] #####################\n",
            "[13:03:02.216709] Start training in epoch 1 - Total: 100\n",
            "[13:03:02.216768] ~~~ Epoch 1/100 ~~~\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:58: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:03:58.008005] Epoch: [1]  [ 0/45]  eta: 0:41:50  loss: 1.4902 (1.4902)  MAE: 0.6247 (0.6247)  MSE: 0.7018 (0.7018)  lr: 0.000100  iter-time: 55.7854\n",
            "[13:04:01.876783] Epoch: [1]  [10/45]  eta: 0:03:09  loss: 1.4902 (1.7974)  MAE: 0.6328 (0.6279)  MSE: 0.6972 (0.6807)  lr: 0.000100  iter-time: 5.4230\n",
            "[13:04:05.748008] Epoch: [1]  [20/45]  eta: 0:01:15  loss: 1.4685 (1.6420)  MAE: 0.6020 (0.6111)  MSE: 0.6740 (0.6787)  lr: 0.000100  iter-time: 0.3868\n",
            "[13:04:09.602264] Epoch: [1]  [30/45]  eta: 0:00:32  loss: 1.3271 (1.5421)  MAE: 0.5756 (0.5915)  MSE: 0.6497 (0.6536)  lr: 0.000100  iter-time: 0.3860\n",
            "[13:04:13.510290] Epoch: [1]  [40/45]  eta: 0:00:08  loss: 1.2051 (1.4749)  MAE: 0.5333 (0.5756)  MSE: 0.5632 (0.6234)  lr: 0.000100  iter-time: 0.3879\n",
            "[13:04:46.272683] Epoch: [1]  [44/45]  eta: 0:00:02  loss: 1.2051 (1.4527)  MAE: 0.5167 (0.5686)  MSE: 0.5463 (0.6092)  lr: 0.000100  iter-time: 1.9489\n",
            "[13:04:46.353926] Epoch: [1] Total time: 0:01:44 (2.3140 s / it)\n",
            "[13:04:46.354128] [Train] averaged stats: loss: 1.2051 (1.4527)  MAE: 0.5167 (0.5686)  MSE: 0.5463 (0.6092)  lr: 0.000100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/biapy/engine/train_engine.py:134: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:04:46.716783] Epoch: [1]  [0/5]  eta: 0:00:01  loss: 1.5929 (1.5929)  MAE: 0.4508 (0.4508)  MSE: 0.3484 (0.3484)  iter-time: 0.3581\n",
            "[13:04:47.226911] Epoch: [1]  [4/5]  eta: 0:00:00  loss: 1.5929 (1.5726)  MAE: 0.4613 (0.4594)  MSE: 0.3827 (0.3757)  iter-time: 0.1735\n",
            "[13:04:47.301756] Epoch: [1] Total time: 0:00:00 (0.1887 s / it)\n",
            "[13:04:47.301883] [Val] averaged stats: loss: 1.5929 (1.5726)  MAE: 0.4613 (0.4594)  MSE: 0.3827 (0.3757)\n",
            "[13:04:47.304467] Val loss improved from inf to 1.572579264640808, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:04:47.343099] [Val] best loss: 1.5726 best  MAE: 0.4594 MSE: 0.3757 \n",
            "[13:04:47.345347] [Time] 1.8m 1.8m/2.9h\n",
            "\n",
            "[13:04:47.345424] ~~~ Epoch 2/100 ~~~\n",
            "\n",
            "[13:04:47.969844] Epoch: [2]  [ 0/45]  eta: 0:00:27  loss: 1.1027 (1.1027)  MAE: 0.4454 (0.4454)  MSE: 0.4544 (0.4544)  lr: 0.000100  iter-time: 0.6211\n",
            "[13:04:52.088345] Epoch: [2]  [10/45]  eta: 0:00:15  loss: 1.1344 (1.1997)  MAE: 0.4749 (0.4722)  MSE: 0.4544 (0.4623)  lr: 0.000100  iter-time: 0.4305\n",
            "[13:04:56.185346] Epoch: [2]  [20/45]  eta: 0:00:10  loss: 1.0837 (1.1517)  MAE: 0.4518 (0.4566)  MSE: 0.4457 (0.4521)  lr: 0.000100  iter-time: 0.4103\n",
            "[13:05:00.229701] Epoch: [2]  [30/45]  eta: 0:00:06  loss: 1.1860 (1.1877)  MAE: 0.4280 (0.4445)  MSE: 0.3725 (0.4201)  lr: 0.000100  iter-time: 0.4067\n",
            "[13:05:04.271461] Epoch: [2]  [40/45]  eta: 0:00:02  loss: 1.2402 (1.2125)  MAE: 0.4135 (0.4361)  MSE: 0.3368 (0.3976)  lr: 0.000100  iter-time: 0.4041\n",
            "[13:05:05.700503] Epoch: [2]  [44/45]  eta: 0:00:00  loss: 1.1802 (1.2087)  MAE: 0.4110 (0.4333)  MSE: 0.3334 (0.3913)  lr: 0.000100  iter-time: 0.3946\n",
            "[13:05:05.802083] Epoch: [2] Total time: 0:00:18 (0.4101 s / it)\n",
            "[13:05:05.804355] [Train] averaged stats: loss: 1.1802 (1.2087)  MAE: 0.4110 (0.4333)  MSE: 0.3334 (0.3913)  lr: 0.000100\n",
            "[13:05:06.264894] Epoch: [2]  [0/5]  eta: 0:00:02  loss: 1.3557 (1.3557)  MAE: 0.3871 (0.3871)  MSE: 0.2740 (0.2740)  iter-time: 0.4571\n",
            "[13:05:06.762658] Epoch: [2]  [4/5]  eta: 0:00:00  loss: 1.3557 (1.3439)  MAE: 0.4005 (0.4014)  MSE: 0.3188 (0.3152)  iter-time: 0.1905\n",
            "[13:05:06.904143] Epoch: [2] Total time: 0:00:01 (0.2194 s / it)\n",
            "[13:05:06.904279] [Val] averaged stats: loss: 1.3557 (1.3439)  MAE: 0.4005 (0.4014)  MSE: 0.3188 (0.3152)\n",
            "[13:05:06.904875] Val loss improved from 1.572579264640808 to 1.3439124345779419, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:05:06.984258] [Val] best loss: 1.3439 best  MAE: 0.4014 MSE: 0.3152 \n",
            "[13:05:06.986743] [Time] 19.6s 2.1m/34.5m\n",
            "\n",
            "[13:05:06.986819] ~~~ Epoch 3/100 ~~~\n",
            "\n",
            "[13:05:07.836775] Epoch: [3]  [ 0/45]  eta: 0:00:38  loss: 1.3987 (1.3987)  MAE: 0.3533 (0.3533)  MSE: 0.3190 (0.3190)  lr: 0.000100  iter-time: 0.8473\n",
            "[13:05:11.870631] Epoch: [3]  [10/45]  eta: 0:00:15  loss: 1.2631 (1.2156)  MAE: 0.3908 (0.3820)  MSE: 0.3033 (0.2957)  lr: 0.000100  iter-time: 0.4434\n",
            "[13:05:15.850359] Epoch: [3]  [20/45]  eta: 0:00:10  loss: 0.9578 (1.0667)  MAE: 0.3631 (0.3667)  MSE: 0.2613 (0.2706)  lr: 0.000100  iter-time: 0.4004\n",
            "[13:05:19.810685] Epoch: [3]  [30/45]  eta: 0:00:06  loss: 0.9727 (1.0578)  MAE: 0.3485 (0.3631)  MSE: 0.2503 (0.2713)  lr: 0.000100  iter-time: 0.3968\n",
            "[13:05:23.774077] Epoch: [3]  [40/45]  eta: 0:00:02  loss: 1.0192 (1.0557)  MAE: 0.3571 (0.3609)  MSE: 0.2709 (0.2760)  lr: 0.000100  iter-time: 0.3960\n",
            "[13:05:25.171434] Epoch: [3]  [44/45]  eta: 0:00:00  loss: 1.0067 (1.0621)  MAE: 0.3538 (0.3591)  MSE: 0.2710 (0.2739)  lr: 0.000100  iter-time: 0.3865\n",
            "[13:05:25.333938] Epoch: [3] Total time: 0:00:18 (0.4077 s / it)\n",
            "[13:05:25.334993] [Train] averaged stats: loss: 1.0067 (1.0621)  MAE: 0.3538 (0.3591)  MSE: 0.2710 (0.2739)  lr: 0.000100\n",
            "[13:05:25.775346] Epoch: [3]  [0/5]  eta: 0:00:02  loss: 1.3015 (1.3015)  MAE: 0.3237 (0.3237)  MSE: 0.1926 (0.1926)  iter-time: 0.4360\n",
            "[13:05:26.261192] Epoch: [3]  [4/5]  eta: 0:00:00  loss: 1.2894 (1.2599)  MAE: 0.3416 (0.3411)  MSE: 0.2367 (0.2336)  iter-time: 0.1838\n",
            "[13:05:26.345484] Epoch: [3] Total time: 0:00:01 (0.2014 s / it)\n",
            "[13:05:26.345619] [Val] averaged stats: loss: 1.2894 (1.2599)  MAE: 0.3416 (0.3411)  MSE: 0.2367 (0.2336)\n",
            "[13:05:26.348136] Val loss improved from 1.3439124345779419 to 1.2599470615386963, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:05:26.397223] [Val] best loss: 1.2599 best  MAE: 0.3411 MSE: 0.2336 \n",
            "[13:05:26.399821] [Time] 19.4s 2.4m/34.1m\n",
            "\n",
            "[13:05:26.399898] ~~~ Epoch 4/100 ~~~\n",
            "\n",
            "[13:05:27.086829] Epoch: [4]  [ 0/45]  eta: 0:00:30  loss: 0.6356 (0.6356)  MAE: 0.2886 (0.2886)  MSE: 0.2378 (0.2378)  lr: 0.000100  iter-time: 0.6848\n",
            "[13:05:31.041284] Epoch: [4]  [10/45]  eta: 0:00:14  loss: 1.0875 (1.0239)  MAE: 0.3248 (0.3233)  MSE: 0.2327 (0.2297)  lr: 0.000100  iter-time: 0.4216\n",
            "[13:05:34.990531] Epoch: [4]  [20/45]  eta: 0:00:10  loss: 0.9237 (0.9678)  MAE: 0.3071 (0.3126)  MSE: 0.2025 (0.2112)  lr: 0.000100  iter-time: 0.3950\n",
            "[13:05:38.989456] Epoch: [4]  [30/45]  eta: 0:00:06  loss: 0.8785 (0.9677)  MAE: 0.2988 (0.3060)  MSE: 0.1770 (0.1973)  lr: 0.000100  iter-time: 0.3972\n",
            "[13:05:42.976245] Epoch: [4]  [40/45]  eta: 0:00:02  loss: 1.1202 (1.0182)  MAE: 0.2883 (0.3014)  MSE: 0.1579 (0.1874)  lr: 0.000100  iter-time: 0.3991\n",
            "[13:05:44.376531] Epoch: [4]  [44/45]  eta: 0:00:00  loss: 1.0998 (1.0041)  MAE: 0.2870 (0.3000)  MSE: 0.1564 (0.1847)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:05:44.470491] Epoch: [4] Total time: 0:00:18 (0.4016 s / it)\n",
            "[13:05:44.472020] [Train] averaged stats: loss: 1.0998 (1.0041)  MAE: 0.2870 (0.3000)  MSE: 0.1564 (0.1847)  lr: 0.000100\n",
            "[13:05:44.843131] Epoch: [4]  [0/5]  eta: 0:00:01  loss: 1.1800 (1.1800)  MAE: 0.2670 (0.2670)  MSE: 0.1247 (0.1247)  iter-time: 0.3681\n",
            "[13:05:45.334093] Epoch: [4]  [4/5]  eta: 0:00:00  loss: 1.2083 (1.2175)  MAE: 0.2799 (0.2795)  MSE: 0.1460 (0.1445)  iter-time: 0.1717\n",
            "[13:05:45.411531] Epoch: [4] Total time: 0:00:00 (0.1874 s / it)\n",
            "[13:05:45.411661] [Val] averaged stats: loss: 1.2083 (1.2175)  MAE: 0.2799 (0.2795)  MSE: 0.1460 (0.1445)\n",
            "[13:05:45.414176] Val loss improved from 1.2599470615386963 to 1.217516040802002, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:05:45.463510] [Val] best loss: 1.2175 best  MAE: 0.2795 MSE: 0.1445 \n",
            "[13:05:45.466374] [Time] 19.1s 2.7m/33.5m\n",
            "\n",
            "[13:05:45.466456] ~~~ Epoch 5/100 ~~~\n",
            "\n",
            "[13:05:46.210718] Epoch: [5]  [ 0/45]  eta: 0:00:33  loss: 0.7724 (0.7724)  MAE: 0.2489 (0.2489)  MSE: 0.1482 (0.1482)  lr: 0.000100  iter-time: 0.7420\n",
            "[13:05:50.195335] Epoch: [5]  [10/45]  eta: 0:00:15  loss: 0.9997 (0.9537)  MAE: 0.2928 (0.2841)  MSE: 0.1644 (0.1640)  lr: 0.000100  iter-time: 0.4295\n",
            "[13:05:54.200885] Epoch: [5]  [20/45]  eta: 0:00:10  loss: 0.9895 (0.9867)  MAE: 0.2801 (0.2807)  MSE: 0.1693 (0.1690)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:05:58.244914] Epoch: [5]  [30/45]  eta: 0:00:06  loss: 0.8765 (0.9534)  MAE: 0.2746 (0.2807)  MSE: 0.1736 (0.1717)  lr: 0.000100  iter-time: 0.4022\n",
            "[13:06:02.285882] Epoch: [5]  [40/45]  eta: 0:00:02  loss: 0.8799 (0.9761)  MAE: 0.2840 (0.2818)  MSE: 0.1775 (0.1751)  lr: 0.000100  iter-time: 0.4040\n",
            "[13:06:03.715705] Epoch: [5]  [44/45]  eta: 0:00:00  loss: 0.8799 (0.9776)  MAE: 0.2831 (0.2814)  MSE: 0.1795 (0.1753)  lr: 0.000100  iter-time: 0.3947\n",
            "[13:06:03.808404] Epoch: [5] Total time: 0:00:18 (0.4076 s / it)\n",
            "[13:06:03.809346] [Train] averaged stats: loss: 0.8799 (0.9776)  MAE: 0.2831 (0.2814)  MSE: 0.1795 (0.1753)  lr: 0.000100\n",
            "[13:06:04.172553] Epoch: [5]  [0/5]  eta: 0:00:01  loss: 1.2766 (1.2766)  MAE: 0.2467 (0.2467)  MSE: 0.1169 (0.1169)  iter-time: 0.3593\n",
            "[13:06:04.670038] Epoch: [5]  [4/5]  eta: 0:00:00  loss: 1.2720 (1.2068)  MAE: 0.2683 (0.2672)  MSE: 0.1559 (0.1528)  iter-time: 0.1712\n",
            "[13:06:04.745640] Epoch: [5] Total time: 0:00:00 (0.1866 s / it)\n",
            "[13:06:04.745776] [Val] averaged stats: loss: 1.2720 (1.2068)  MAE: 0.2683 (0.2672)  MSE: 0.1559 (0.1528)\n",
            "[13:06:04.748439] Val loss improved from 1.217516040802002 to 1.2068413138389587, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:06:04.796396] [Val] best loss: 1.2068 best  MAE: 0.2672 MSE: 0.1528 \n",
            "[13:06:04.797478] Creating training plots . . .\n",
            "[13:06:05.294664] [Time] 19.8s 3.1m/34.8m\n",
            "\n",
            "[13:06:05.294791] ~~~ Epoch 6/100 ~~~\n",
            "\n",
            "[13:06:06.005875] Epoch: [6]  [ 0/45]  eta: 0:00:31  loss: 0.6646 (0.6646)  MAE: 0.2335 (0.2335)  MSE: 0.1671 (0.1671)  lr: 0.000100  iter-time: 0.7084\n",
            "[13:06:10.038102] Epoch: [6]  [10/45]  eta: 0:00:15  loss: 0.9694 (0.9921)  MAE: 0.2672 (0.2670)  MSE: 0.1610 (0.1576)  lr: 0.000100  iter-time: 0.4308\n",
            "[13:06:14.092451] Epoch: [6]  [20/45]  eta: 0:00:10  loss: 0.9694 (0.9848)  MAE: 0.2529 (0.2565)  MSE: 0.1391 (0.1427)  lr: 0.000100  iter-time: 0.4041\n",
            "[13:06:18.135937] Epoch: [6]  [30/45]  eta: 0:00:06  loss: 0.9472 (1.0154)  MAE: 0.2459 (0.2565)  MSE: 0.1292 (0.1418)  lr: 0.000100  iter-time: 0.4046\n",
            "[13:06:22.180626] Epoch: [6]  [40/45]  eta: 0:00:02  loss: 0.9711 (0.9884)  MAE: 0.2651 (0.2584)  MSE: 0.1474 (0.1459)  lr: 0.000100  iter-time: 0.4042\n",
            "[13:06:23.599405] Epoch: [6]  [44/45]  eta: 0:00:00  loss: 0.9403 (0.9803)  MAE: 0.2651 (0.2591)  MSE: 0.1527 (0.1484)  lr: 0.000100  iter-time: 0.3943\n",
            "[13:06:23.690613] Epoch: [6] Total time: 0:00:18 (0.4088 s / it)\n",
            "[13:06:23.692304] [Train] averaged stats: loss: 0.9403 (0.9803)  MAE: 0.2651 (0.2591)  MSE: 0.1527 (0.1484)  lr: 0.000100\n",
            "[13:06:23.982790] Epoch: [6]  [0/5]  eta: 0:00:01  loss: 1.1248 (1.1248)  MAE: 0.2415 (0.2415)  MSE: 0.1334 (0.1334)  iter-time: 0.2864\n",
            "[13:06:24.481859] Epoch: [6]  [4/5]  eta: 0:00:00  loss: 1.2781 (1.2402)  MAE: 0.2718 (0.2698)  MSE: 0.2021 (0.1942)  iter-time: 0.1570\n",
            "[13:06:24.556582] Epoch: [6] Total time: 0:00:00 (0.1722 s / it)\n",
            "[13:06:24.556714] [Val] averaged stats: loss: 1.2781 (1.2402)  MAE: 0.2718 (0.2698)  MSE: 0.2021 (0.1942)\n",
            "[13:06:24.559170] [Val] best loss: 1.2068 best  MAE: 0.2672 MSE: 0.1528 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:06:24.561526] [Time] 19.3s 3.4m/33.9m\n",
            "\n",
            "[13:06:24.561583] ~~~ Epoch 7/100 ~~~\n",
            "\n",
            "[13:06:25.182815] Epoch: [7]  [ 0/45]  eta: 0:00:27  loss: 0.7333 (0.7333)  MAE: 0.2217 (0.2217)  MSE: 0.1696 (0.1696)  lr: 0.000100  iter-time: 0.6192\n",
            "[13:06:29.232530] Epoch: [7]  [10/45]  eta: 0:00:14  loss: 0.8886 (0.9175)  MAE: 0.2756 (0.2721)  MSE: 0.1953 (0.1975)  lr: 0.000100  iter-time: 0.4243\n",
            "[13:06:33.277371] Epoch: [7]  [20/45]  eta: 0:00:10  loss: 0.8886 (0.9054)  MAE: 0.2686 (0.2674)  MSE: 0.2048 (0.2043)  lr: 0.000100  iter-time: 0.4046\n",
            "[13:06:37.287517] Epoch: [7]  [30/45]  eta: 0:00:06  loss: 0.9144 (0.9481)  MAE: 0.2577 (0.2648)  MSE: 0.2072 (0.2037)  lr: 0.000100  iter-time: 0.4026\n",
            "[13:06:41.289679] Epoch: [7]  [40/45]  eta: 0:00:02  loss: 0.9654 (0.9371)  MAE: 0.2544 (0.2621)  MSE: 0.1936 (0.1990)  lr: 0.000100  iter-time: 0.4004\n",
            "[13:06:42.705966] Epoch: [7]  [44/45]  eta: 0:00:00  loss: 0.9177 (0.9373)  MAE: 0.2529 (0.2612)  MSE: 0.1810 (0.1968)  lr: 0.000100  iter-time: 0.3911\n",
            "[13:06:42.831769] Epoch: [7] Total time: 0:00:18 (0.4060 s / it)\n",
            "[13:06:42.831957] [Train] averaged stats: loss: 0.9177 (0.9373)  MAE: 0.2529 (0.2612)  MSE: 0.1810 (0.1968)  lr: 0.000100\n",
            "[13:06:43.336220] Epoch: [7]  [0/5]  eta: 0:00:02  loss: 1.0909 (1.0909)  MAE: 0.2144 (0.2144)  MSE: 0.1003 (0.1003)  iter-time: 0.5018\n",
            "[13:06:43.833438] Epoch: [7]  [4/5]  eta: 0:00:00  loss: 1.2329 (1.1876)  MAE: 0.2447 (0.2419)  MSE: 0.1560 (0.1492)  iter-time: 0.1993\n",
            "[13:06:43.978390] Epoch: [7] Total time: 0:00:01 (0.2289 s / it)\n",
            "[13:06:43.979105] [Val] averaged stats: loss: 1.2329 (1.1876)  MAE: 0.2447 (0.2419)  MSE: 0.1560 (0.1492)\n",
            "[13:06:43.979694] Val loss improved from 1.2068413138389587 to 1.1876120567321777, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:06:44.060162] [Val] best loss: 1.1876 best  MAE: 0.2419 MSE: 0.1492 \n",
            "[13:06:44.063747] [Time] 19.5s 3.7m/34.3m\n",
            "\n",
            "[13:06:44.064517] ~~~ Epoch 8/100 ~~~\n",
            "\n",
            "[13:06:44.912534] Epoch: [8]  [ 0/45]  eta: 0:00:38  loss: 0.5610 (0.5610)  MAE: 0.2043 (0.2043)  MSE: 0.1618 (0.1618)  lr: 0.000100  iter-time: 0.8448\n",
            "[13:06:48.956004] Epoch: [8]  [10/45]  eta: 0:00:15  loss: 0.8572 (0.8683)  MAE: 0.2533 (0.2458)  MSE: 0.1618 (0.1633)  lr: 0.000100  iter-time: 0.4441\n",
            "[13:06:52.953872] Epoch: [8]  [20/45]  eta: 0:00:10  loss: 0.8325 (0.8537)  MAE: 0.2359 (0.2381)  MSE: 0.1535 (0.1590)  lr: 0.000100  iter-time: 0.4018\n",
            "[13:06:56.940618] Epoch: [8]  [30/45]  eta: 0:00:06  loss: 0.8672 (0.8732)  MAE: 0.2250 (0.2351)  MSE: 0.1497 (0.1534)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:07:00.926536] Epoch: [8]  [40/45]  eta: 0:00:02  loss: 0.9694 (0.9222)  MAE: 0.2341 (0.2342)  MSE: 0.1456 (0.1519)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:07:02.340463] Epoch: [8]  [44/45]  eta: 0:00:00  loss: 0.9865 (0.9316)  MAE: 0.2337 (0.2341)  MSE: 0.1437 (0.1518)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:07:02.490982] Epoch: [8] Total time: 0:00:18 (0.4094 s / it)\n",
            "[13:07:02.492814] [Train] averaged stats: loss: 0.9865 (0.9316)  MAE: 0.2337 (0.2341)  MSE: 0.1437 (0.1518)  lr: 0.000100\n",
            "[13:07:02.955464] Epoch: [8]  [0/5]  eta: 0:00:02  loss: 1.0927 (1.0927)  MAE: 0.1892 (0.1892)  MSE: 0.0786 (0.0786)  iter-time: 0.4593\n",
            "[13:07:03.449488] Epoch: [8]  [4/5]  eta: 0:00:00  loss: 1.2060 (1.1738)  MAE: 0.2142 (0.2116)  MSE: 0.1187 (0.1135)  iter-time: 0.1905\n",
            "[13:07:03.524673] Epoch: [8] Total time: 0:00:01 (0.2058 s / it)\n",
            "[13:07:03.524795] [Val] averaged stats: loss: 1.2060 (1.1738)  MAE: 0.2142 (0.2116)  MSE: 0.1187 (0.1135)\n",
            "[13:07:03.527274] Val loss improved from 1.1876120567321777 to 1.1737968444824218, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:07:03.577816] [Val] best loss: 1.1738 best  MAE: 0.2116 MSE: 0.1135 \n",
            "[13:07:03.580640] [Time] 19.5s 4.0m/34.3m\n",
            "\n",
            "[13:07:03.581166] ~~~ Epoch 9/100 ~~~\n",
            "\n",
            "[13:07:04.181451] Epoch: [9]  [ 0/45]  eta: 0:00:26  loss: 0.8596 (0.8596)  MAE: 0.1896 (0.1896)  MSE: 0.1350 (0.1350)  lr: 0.000100  iter-time: 0.5980\n",
            "[13:07:08.165779] Epoch: [9]  [10/45]  eta: 0:00:14  loss: 1.0352 (0.9692)  MAE: 0.2342 (0.2314)  MSE: 0.1502 (0.1499)  lr: 0.000100  iter-time: 0.4162\n",
            "[13:07:12.143627] Epoch: [9]  [20/45]  eta: 0:00:10  loss: 0.8129 (0.8831)  MAE: 0.2302 (0.2297)  MSE: 0.1557 (0.1602)  lr: 0.000100  iter-time: 0.3978\n",
            "[13:07:16.153344] Epoch: [9]  [30/45]  eta: 0:00:06  loss: 0.8583 (0.9167)  MAE: 0.2295 (0.2309)  MSE: 0.1699 (0.1637)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:07:20.145337] Epoch: [9]  [40/45]  eta: 0:00:02  loss: 0.9171 (0.9159)  MAE: 0.2346 (0.2313)  MSE: 0.1697 (0.1615)  lr: 0.000100  iter-time: 0.3999\n",
            "[13:07:21.552381] Epoch: [9]  [44/45]  eta: 0:00:00  loss: 0.9815 (0.9347)  MAE: 0.2312 (0.2320)  MSE: 0.1505 (0.1619)  lr: 0.000100  iter-time: 0.3903\n",
            "[13:07:21.642655] Epoch: [9] Total time: 0:00:18 (0.4014 s / it)\n",
            "[13:07:21.644601] [Train] averaged stats: loss: 0.9815 (0.9347)  MAE: 0.2312 (0.2320)  MSE: 0.1505 (0.1619)  lr: 0.000100\n",
            "[13:07:21.933370] Epoch: [9]  [0/5]  eta: 0:00:01  loss: 1.1018 (1.1018)  MAE: 0.1920 (0.1920)  MSE: 0.0861 (0.0861)  iter-time: 0.2849\n",
            "[13:07:22.428998] Epoch: [9]  [4/5]  eta: 0:00:00  loss: 1.2260 (1.1748)  MAE: 0.2285 (0.2244)  MSE: 0.1406 (0.1337)  iter-time: 0.1556\n",
            "[13:07:22.511322] Epoch: [9] Total time: 0:00:00 (0.1729 s / it)\n",
            "[13:07:22.511449] [Val] averaged stats: loss: 1.2260 (1.1748)  MAE: 0.2285 (0.2244)  MSE: 0.1406 (0.1337)\n",
            "[13:07:22.512058] [Val] best loss: 1.1738 best  MAE: 0.2116 MSE: 0.1135 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:07:22.513002] [Time] 18.9s 4.3m/33.4m\n",
            "\n",
            "[13:07:22.513206] ~~~ Epoch 10/100 ~~~\n",
            "\n",
            "[13:07:23.110952] Epoch: [10]  [ 0/45]  eta: 0:00:26  loss: 0.6584 (0.6584)  MAE: 0.1985 (0.1985)  MSE: 0.1617 (0.1617)  lr: 0.000100  iter-time: 0.5955\n",
            "[13:07:27.094442] Epoch: [10]  [10/45]  eta: 0:00:14  loss: 0.8283 (0.9076)  MAE: 0.2419 (0.2405)  MSE: 0.1630 (0.1606)  lr: 0.000100  iter-time: 0.4160\n",
            "[13:07:31.080681] Epoch: [10]  [20/45]  eta: 0:00:10  loss: 0.8283 (0.8268)  MAE: 0.2341 (0.2350)  MSE: 0.1630 (0.1640)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:07:35.091369] Epoch: [10]  [30/45]  eta: 0:00:06  loss: 0.8103 (0.8519)  MAE: 0.2264 (0.2348)  MSE: 0.1671 (0.1661)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:07:39.080243] Epoch: [10]  [40/45]  eta: 0:00:02  loss: 0.9178 (0.8728)  MAE: 0.2311 (0.2328)  MSE: 0.1572 (0.1594)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:07:40.485335] Epoch: [10]  [44/45]  eta: 0:00:00  loss: 0.8476 (0.8859)  MAE: 0.2278 (0.2317)  MSE: 0.1298 (0.1562)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:07:40.576247] Epoch: [10] Total time: 0:00:18 (0.4014 s / it)\n",
            "[13:07:40.576409] [Train] averaged stats: loss: 0.8476 (0.8859)  MAE: 0.2278 (0.2317)  MSE: 0.1298 (0.1562)  lr: 0.000100\n",
            "[13:07:40.857326] Epoch: [10]  [0/5]  eta: 0:00:01  loss: 1.1839 (1.1839)  MAE: 0.1728 (0.1728)  MSE: 0.0601 (0.0601)  iter-time: 0.2783\n",
            "[13:07:41.353943] Epoch: [10]  [4/5]  eta: 0:00:00  loss: 1.1888 (1.1686)  MAE: 0.1985 (0.1964)  MSE: 0.0887 (0.0866)  iter-time: 0.1548\n",
            "[13:07:41.429025] Epoch: [10] Total time: 0:00:00 (0.1703 s / it)\n",
            "[13:07:41.429187] [Val] averaged stats: loss: 1.1888 (1.1686)  MAE: 0.1985 (0.1964)  MSE: 0.0887 (0.0866)\n",
            "[13:07:41.431934] Val loss improved from 1.1737968444824218 to 1.1686215162277223, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:07:41.483930] [Val] best loss: 1.1686 best  MAE: 0.1964 MSE: 0.0866 \n",
            "[13:07:41.486076] Creating training plots . . .\n",
            "[13:07:41.890480] [Time] 19.4s 4.7m/34.0m\n",
            "\n",
            "[13:07:41.891174] ~~~ Epoch 11/100 ~~~\n",
            "\n",
            "[13:07:42.523650] Epoch: [11]  [ 0/45]  eta: 0:00:28  loss: 0.9632 (0.9632)  MAE: 0.1789 (0.1789)  MSE: 0.1120 (0.1120)  lr: 0.000100  iter-time: 0.6302\n",
            "[13:07:46.517189] Epoch: [11]  [10/45]  eta: 0:00:14  loss: 0.9371 (0.9359)  MAE: 0.2212 (0.2179)  MSE: 0.1190 (0.1199)  lr: 0.000100  iter-time: 0.4202\n",
            "[13:07:50.563496] Epoch: [11]  [20/45]  eta: 0:00:10  loss: 0.9286 (0.9341)  MAE: 0.2119 (0.2131)  MSE: 0.1217 (0.1256)  lr: 0.000100  iter-time: 0.4018\n",
            "[13:07:54.564451] Epoch: [11]  [30/45]  eta: 0:00:06  loss: 0.9857 (0.9399)  MAE: 0.2077 (0.2132)  MSE: 0.1316 (0.1298)  lr: 0.000100  iter-time: 0.4021\n",
            "[13:07:58.561992] Epoch: [11]  [40/45]  eta: 0:00:02  loss: 0.9857 (0.9399)  MAE: 0.2092 (0.2113)  MSE: 0.1316 (0.1272)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:07:59.976441] Epoch: [11]  [44/45]  eta: 0:00:00  loss: 0.9215 (0.9394)  MAE: 0.2039 (0.2105)  MSE: 0.1082 (0.1263)  lr: 0.000100  iter-time: 0.3902\n",
            "[13:08:00.067559] Epoch: [11] Total time: 0:00:18 (0.4039 s / it)\n",
            "[13:08:00.068584] [Train] averaged stats: loss: 0.9215 (0.9394)  MAE: 0.2039 (0.2105)  MSE: 0.1082 (0.1263)  lr: 0.000100\n",
            "[13:08:00.351969] Epoch: [11]  [0/5]  eta: 0:00:01  loss: 1.1614 (1.1614)  MAE: 0.1644 (0.1644)  MSE: 0.0646 (0.0646)  iter-time: 0.2795\n",
            "[13:08:00.849153] Epoch: [11]  [4/5]  eta: 0:00:00  loss: 1.2028 (1.1660)  MAE: 0.1942 (0.1912)  MSE: 0.1082 (0.1024)  iter-time: 0.1549\n",
            "[13:08:00.925813] Epoch: [11] Total time: 0:00:00 (0.1708 s / it)\n",
            "[13:08:00.925940] [Val] averaged stats: loss: 1.2028 (1.1660)  MAE: 0.1942 (0.1912)  MSE: 0.1082 (0.1024)\n",
            "[13:08:00.928419] Val loss improved from 1.1686215162277223 to 1.166049075126648, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:08:00.976637] [Val] best loss: 1.1660 best  MAE: 0.1912 MSE: 0.1024 \n",
            "[13:08:00.979215] [Time] 19.1s 5.0m/33.6m\n",
            "\n",
            "[13:08:00.979288] ~~~ Epoch 12/100 ~~~\n",
            "\n",
            "[13:08:01.587343] Epoch: [12]  [ 0/45]  eta: 0:00:27  loss: 0.8949 (0.8949)  MAE: 0.1662 (0.1662)  MSE: 0.1220 (0.1220)  lr: 0.000100  iter-time: 0.6059\n",
            "[13:08:05.637708] Epoch: [12]  [10/45]  eta: 0:00:14  loss: 0.8893 (0.8886)  MAE: 0.2093 (0.2057)  MSE: 0.1250 (0.1282)  lr: 0.000100  iter-time: 0.4232\n",
            "[13:08:09.665826] Epoch: [12]  [20/45]  eta: 0:00:10  loss: 0.8068 (0.8405)  MAE: 0.2016 (0.2024)  MSE: 0.1339 (0.1371)  lr: 0.000100  iter-time: 0.4037\n",
            "[13:08:13.682237] Epoch: [12]  [30/45]  eta: 0:00:06  loss: 0.7838 (0.8214)  MAE: 0.1976 (0.2017)  MSE: 0.1430 (0.1382)  lr: 0.000100  iter-time: 0.4020\n",
            "[13:08:17.688805] Epoch: [12]  [40/45]  eta: 0:00:02  loss: 0.7905 (0.8335)  MAE: 0.1998 (0.2005)  MSE: 0.1328 (0.1348)  lr: 0.000100  iter-time: 0.4010\n",
            "[13:08:19.107400] Epoch: [12]  [44/45]  eta: 0:00:00  loss: 0.8553 (0.8502)  MAE: 0.1965 (0.2004)  MSE: 0.1148 (0.1339)  lr: 0.000100  iter-time: 0.3914\n",
            "[13:08:19.254577] Epoch: [12] Total time: 0:00:18 (0.4061 s / it)\n",
            "[13:08:19.255596] [Train] averaged stats: loss: 0.8553 (0.8502)  MAE: 0.1965 (0.2004)  MSE: 0.1148 (0.1339)  lr: 0.000100\n",
            "[13:08:19.678075] Epoch: [12]  [0/5]  eta: 0:00:02  loss: 1.1728 (1.1728)  MAE: 0.1562 (0.1562)  MSE: 0.0601 (0.0601)  iter-time: 0.4189\n",
            "[13:08:20.174651] Epoch: [12]  [4/5]  eta: 0:00:00  loss: 1.2127 (1.1679)  MAE: 0.1841 (0.1810)  MSE: 0.1017 (0.0964)  iter-time: 0.1826\n",
            "[13:08:20.320377] Epoch: [12] Total time: 0:00:01 (0.2124 s / it)\n",
            "[13:08:20.320510] [Val] averaged stats: loss: 1.2127 (1.1679)  MAE: 0.1841 (0.1810)  MSE: 0.1017 (0.0964)\n",
            "[13:08:20.321161] [Val] best loss: 1.1660 best  MAE: 0.1912 MSE: 0.1024 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:08:20.328890] [Time] 19.3s 5.3m/34.0m\n",
            "\n",
            "[13:08:20.328937] ~~~ Epoch 13/100 ~~~\n",
            "\n",
            "[13:08:21.073691] Epoch: [13]  [ 0/45]  eta: 0:00:33  loss: 0.8359 (0.8359)  MAE: 0.1646 (0.1646)  MSE: 0.1372 (0.1372)  lr: 0.000100  iter-time: 0.7425\n",
            "[13:08:25.072662] Epoch: [13]  [10/45]  eta: 0:00:15  loss: 0.8351 (0.7942)  MAE: 0.2064 (0.2048)  MSE: 0.1391 (0.1435)  lr: 0.000100  iter-time: 0.4309\n",
            "[13:08:29.071503] Epoch: [13]  [20/45]  eta: 0:00:10  loss: 0.8351 (0.8598)  MAE: 0.1995 (0.2005)  MSE: 0.1391 (0.1461)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:08:33.090370] Epoch: [13]  [30/45]  eta: 0:00:06  loss: 0.9303 (0.9245)  MAE: 0.1920 (0.1988)  MSE: 0.1380 (0.1429)  lr: 0.000100  iter-time: 0.4007\n",
            "[13:08:37.107636] Epoch: [13]  [40/45]  eta: 0:00:02  loss: 0.9549 (0.9215)  MAE: 0.1924 (0.1975)  MSE: 0.1218 (0.1362)  lr: 0.000100  iter-time: 0.4016\n",
            "[13:08:38.516786] Epoch: [13]  [44/45]  eta: 0:00:00  loss: 0.9549 (0.9175)  MAE: 0.1924 (0.1979)  MSE: 0.1096 (0.1351)  lr: 0.000100  iter-time: 0.3922\n",
            "[13:08:38.607662] Epoch: [13] Total time: 0:00:18 (0.4062 s / it)\n",
            "[13:08:38.610094] [Train] averaged stats: loss: 0.9549 (0.9175)  MAE: 0.1924 (0.1979)  MSE: 0.1096 (0.1351)  lr: 0.000100\n",
            "[13:08:38.903530] Epoch: [13]  [0/5]  eta: 0:00:01  loss: 1.1073 (1.1073)  MAE: 0.1551 (0.1551)  MSE: 0.0578 (0.0578)  iter-time: 0.2907\n",
            "[13:08:39.399515] Epoch: [13]  [4/5]  eta: 0:00:00  loss: 1.1531 (1.1404)  MAE: 0.1891 (0.1845)  MSE: 0.1044 (0.0957)  iter-time: 0.1569\n",
            "[13:08:39.486613] Epoch: [13] Total time: 0:00:00 (0.1749 s / it)\n",
            "[13:08:39.486738] [Val] averaged stats: loss: 1.1531 (1.1404)  MAE: 0.1891 (0.1845)  MSE: 0.1044 (0.0957)\n",
            "[13:08:39.489292] Val loss improved from 1.166049075126648 to 1.1404284954071044, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:08:39.537685] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "[13:08:39.538998] [Time] 19.2s 5.6m/33.8m\n",
            "\n",
            "[13:08:39.539104] ~~~ Epoch 14/100 ~~~\n",
            "\n",
            "[13:08:40.211887] Epoch: [14]  [ 0/45]  eta: 0:00:30  loss: 0.8501 (0.8501)  MAE: 0.1674 (0.1674)  MSE: 0.1353 (0.1353)  lr: 0.000100  iter-time: 0.6707\n",
            "[13:08:44.196875] Epoch: [14]  [10/45]  eta: 0:00:14  loss: 0.7163 (0.7967)  MAE: 0.2053 (0.2046)  MSE: 0.1261 (0.1230)  lr: 0.000100  iter-time: 0.4231\n",
            "[13:08:48.178276] Epoch: [14]  [20/45]  eta: 0:00:10  loss: 0.7119 (0.7875)  MAE: 0.2002 (0.1998)  MSE: 0.1191 (0.1249)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:08:52.189788] Epoch: [14]  [30/45]  eta: 0:00:06  loss: 0.7620 (0.7889)  MAE: 0.1922 (0.1989)  MSE: 0.1238 (0.1252)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:08:56.195274] Epoch: [14]  [40/45]  eta: 0:00:02  loss: 0.8171 (0.8024)  MAE: 0.1989 (0.1983)  MSE: 0.1174 (0.1233)  lr: 0.000100  iter-time: 0.4007\n",
            "[13:08:57.609294] Epoch: [14]  [44/45]  eta: 0:00:00  loss: 0.8171 (0.8143)  MAE: 0.1980 (0.1989)  MSE: 0.1174 (0.1239)  lr: 0.000100  iter-time: 0.3913\n",
            "[13:08:57.727900] Epoch: [14] Total time: 0:00:18 (0.4042 s / it)\n",
            "[13:08:57.730545] [Train] averaged stats: loss: 0.8171 (0.8143)  MAE: 0.1980 (0.1989)  MSE: 0.1174 (0.1239)  lr: 0.000100\n",
            "[13:08:58.092895] Epoch: [14]  [0/5]  eta: 0:00:01  loss: 1.0729 (1.0729)  MAE: 0.1612 (0.1612)  MSE: 0.0714 (0.0714)  iter-time: 0.3587\n",
            "[13:08:58.589670] Epoch: [14]  [4/5]  eta: 0:00:00  loss: 1.2023 (1.1494)  MAE: 0.1973 (0.1924)  MSE: 0.1286 (0.1196)  iter-time: 0.1710\n",
            "[13:08:58.665780] Epoch: [14] Total time: 0:00:00 (0.1864 s / it)\n",
            "[13:08:58.665928] [Val] averaged stats: loss: 1.2023 (1.1494)  MAE: 0.1973 (0.1924)  MSE: 0.1286 (0.1196)\n",
            "[13:08:58.668774] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:08:58.671486] [Time] 19.1s 5.9m/33.7m\n",
            "\n",
            "[13:08:58.672798] ~~~ Epoch 15/100 ~~~\n",
            "\n",
            "[13:08:59.372879] Epoch: [15]  [ 0/45]  eta: 0:00:31  loss: 0.7084 (0.7084)  MAE: 0.1735 (0.1735)  MSE: 0.1632 (0.1632)  lr: 0.000100  iter-time: 0.6977\n",
            "[13:09:03.358963] Epoch: [15]  [10/45]  eta: 0:00:14  loss: 0.8941 (0.9334)  MAE: 0.2157 (0.2172)  MSE: 0.1633 (0.1641)  lr: 0.000100  iter-time: 0.4257\n",
            "[13:09:07.372310] Epoch: [15]  [20/45]  eta: 0:00:10  loss: 0.8836 (0.8886)  MAE: 0.2100 (0.2135)  MSE: 0.1590 (0.1634)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:09:11.414099] Epoch: [15]  [30/45]  eta: 0:00:06  loss: 0.8573 (0.8724)  MAE: 0.2030 (0.2115)  MSE: 0.1502 (0.1571)  lr: 0.000100  iter-time: 0.4026\n",
            "[13:09:15.420343] Epoch: [15]  [40/45]  eta: 0:00:02  loss: 0.8531 (0.8811)  MAE: 0.2027 (0.2087)  MSE: 0.1395 (0.1486)  lr: 0.000100  iter-time: 0.4022\n",
            "[13:09:16.833287] Epoch: [15]  [44/45]  eta: 0:00:00  loss: 0.8783 (0.9019)  MAE: 0.2001 (0.2075)  MSE: 0.1135 (0.1453)  lr: 0.000100  iter-time: 0.3920\n",
            "[13:09:16.923928] Epoch: [15] Total time: 0:00:18 (0.4056 s / it)\n",
            "[13:09:16.924900] [Train] averaged stats: loss: 0.8783 (0.9019)  MAE: 0.2001 (0.2075)  MSE: 0.1135 (0.1453)  lr: 0.000100\n",
            "[13:09:17.263936] Epoch: [15]  [0/5]  eta: 0:00:01  loss: 1.2046 (1.2046)  MAE: 0.1536 (0.1536)  MSE: 0.0540 (0.0540)  iter-time: 0.3353\n",
            "[13:09:17.756986] Epoch: [15]  [4/5]  eta: 0:00:00  loss: 1.2046 (1.1640)  MAE: 0.1869 (0.1814)  MSE: 0.0953 (0.0871)  iter-time: 0.1655\n",
            "[13:09:17.837783] Epoch: [15] Total time: 0:00:00 (0.1819 s / it)\n",
            "[13:09:17.838686] [Val] averaged stats: loss: 1.2046 (1.1640)  MAE: 0.1869 (0.1814)  MSE: 0.0953 (0.0871)\n",
            "[13:09:17.841006] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "[13:09:17.843289] Creating training plots . . .\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:09:18.278413] [Time] 19.6s 6.3m/34.4m\n",
            "\n",
            "[13:09:18.278469] ~~~ Epoch 16/100 ~~~\n",
            "\n",
            "[13:09:18.944912] Epoch: [16]  [ 0/45]  eta: 0:00:29  loss: 1.0223 (1.0223)  MAE: 0.1658 (0.1658)  MSE: 0.1152 (0.1152)  lr: 0.000100  iter-time: 0.6641\n",
            "[13:09:22.935857] Epoch: [16]  [10/45]  eta: 0:00:14  loss: 0.8306 (0.8829)  MAE: 0.2051 (0.2023)  MSE: 0.1240 (0.1212)  lr: 0.000100  iter-time: 0.4230\n",
            "[13:09:26.939830] Epoch: [16]  [20/45]  eta: 0:00:10  loss: 0.8201 (0.8639)  MAE: 0.1993 (0.1987)  MSE: 0.1244 (0.1283)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:09:30.944502] Epoch: [16]  [30/45]  eta: 0:00:06  loss: 0.8576 (0.8882)  MAE: 0.1973 (0.2003)  MSE: 0.1408 (0.1354)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:09:34.937094] Epoch: [16]  [40/45]  eta: 0:00:02  loss: 0.9224 (0.8945)  MAE: 0.2109 (0.2024)  MSE: 0.1577 (0.1429)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:09:36.345741] Epoch: [16]  [44/45]  eta: 0:00:00  loss: 0.9224 (0.8933)  MAE: 0.2109 (0.2038)  MSE: 0.1674 (0.1478)  lr: 0.000100  iter-time: 0.3901\n",
            "[13:09:36.438409] Epoch: [16] Total time: 0:00:18 (0.4035 s / it)\n",
            "[13:09:36.439380] [Train] averaged stats: loss: 0.9224 (0.8933)  MAE: 0.2109 (0.2038)  MSE: 0.1674 (0.1478)  lr: 0.000100\n",
            "[13:09:36.787452] Epoch: [16]  [0/5]  eta: 0:00:01  loss: 1.0461 (1.0461)  MAE: 0.1646 (0.1646)  MSE: 0.0982 (0.0982)  iter-time: 0.3454\n",
            "[13:09:37.284504] Epoch: [16]  [4/5]  eta: 0:00:00  loss: 1.2244 (1.1747)  MAE: 0.2098 (0.2046)  MSE: 0.1906 (0.1778)  iter-time: 0.1684\n",
            "[13:09:37.358686] Epoch: [16] Total time: 0:00:00 (0.1834 s / it)\n",
            "[13:09:37.358802] [Val] averaged stats: loss: 1.2244 (1.1747)  MAE: 0.2098 (0.2046)  MSE: 0.1906 (0.1778)\n",
            "[13:09:37.361094] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:09:37.363496] [Time] 19.1s 6.6m/33.6m\n",
            "\n",
            "[13:09:37.363557] ~~~ Epoch 17/100 ~~~\n",
            "\n",
            "[13:09:37.957385] Epoch: [17]  [ 0/45]  eta: 0:00:26  loss: 0.9382 (0.9382)  MAE: 0.1800 (0.1800)  MSE: 0.2195 (0.2195)  lr: 0.000100  iter-time: 0.5918\n",
            "[13:09:41.974239] Epoch: [17]  [10/45]  eta: 0:00:14  loss: 0.8699 (0.9074)  MAE: 0.2150 (0.2188)  MSE: 0.2099 (0.1987)  lr: 0.000100  iter-time: 0.4188\n",
            "[13:09:46.014704] Epoch: [17]  [20/45]  eta: 0:00:10  loss: 0.8657 (0.9126)  MAE: 0.2048 (0.2107)  MSE: 0.1778 (0.1910)  lr: 0.000100  iter-time: 0.4026\n",
            "[13:09:50.001133] Epoch: [17]  [30/45]  eta: 0:00:06  loss: 0.8659 (0.9029)  MAE: 0.1927 (0.2061)  MSE: 0.1616 (0.1774)  lr: 0.000100  iter-time: 0.4011\n",
            "[13:09:53.996772] Epoch: [17]  [40/45]  eta: 0:00:02  loss: 0.8659 (0.9011)  MAE: 0.1915 (0.2020)  MSE: 0.1420 (0.1635)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:09:55.411552] Epoch: [17]  [44/45]  eta: 0:00:00  loss: 0.8551 (0.8965)  MAE: 0.1898 (0.2008)  MSE: 0.1089 (0.1600)  lr: 0.000100  iter-time: 0.3901\n",
            "[13:09:55.506712] Epoch: [17] Total time: 0:00:18 (0.4032 s / it)\n",
            "[13:09:55.508164] [Train] averaged stats: loss: 0.8551 (0.8965)  MAE: 0.1898 (0.2008)  MSE: 0.1089 (0.1600)  lr: 0.000100\n",
            "[13:09:55.870282] Epoch: [17]  [0/5]  eta: 0:00:01  loss: 1.1671 (1.1671)  MAE: 0.1493 (0.1493)  MSE: 0.0580 (0.0580)  iter-time: 0.3591\n",
            "[13:09:56.365153] Epoch: [17]  [4/5]  eta: 0:00:00  loss: 1.1677 (1.1419)  MAE: 0.1837 (0.1786)  MSE: 0.1053 (0.0974)  iter-time: 0.1706\n",
            "[13:09:56.487241] Epoch: [17] Total time: 0:00:00 (0.1953 s / it)\n",
            "[13:09:56.487393] [Val] averaged stats: loss: 1.1677 (1.1419)  MAE: 0.1837 (0.1786)  MSE: 0.1053 (0.0974)\n",
            "[13:09:56.488017] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:09:56.493388] [Time] 19.1s 6.9m/33.7m\n",
            "\n",
            "[13:09:56.493436] ~~~ Epoch 18/100 ~~~\n",
            "\n",
            "[13:09:57.289566] Epoch: [18]  [ 0/45]  eta: 0:00:35  loss: 0.9898 (0.9898)  MAE: 0.1616 (0.1616)  MSE: 0.1422 (0.1422)  lr: 0.000100  iter-time: 0.7937\n",
            "[13:10:01.325531] Epoch: [18]  [10/45]  eta: 0:00:15  loss: 0.8468 (0.8194)  MAE: 0.1903 (0.1962)  MSE: 0.1350 (0.1354)  lr: 0.000100  iter-time: 0.4388\n",
            "[13:10:05.331995] Epoch: [18]  [20/45]  eta: 0:00:10  loss: 0.8343 (0.8205)  MAE: 0.1892 (0.1917)  MSE: 0.1349 (0.1364)  lr: 0.000100  iter-time: 0.4018\n",
            "[13:10:09.331871] Epoch: [18]  [30/45]  eta: 0:00:06  loss: 0.8343 (0.8473)  MAE: 0.1818 (0.1899)  MSE: 0.1289 (0.1324)  lr: 0.000100  iter-time: 0.4001\n",
            "[13:10:13.321766] Epoch: [18]  [40/45]  eta: 0:00:02  loss: 0.8890 (0.8703)  MAE: 0.1830 (0.1885)  MSE: 0.1205 (0.1266)  lr: 0.000100  iter-time: 0.3994\n",
            "[13:10:14.739232] Epoch: [18]  [44/45]  eta: 0:00:00  loss: 0.8268 (0.8788)  MAE: 0.1830 (0.1884)  MSE: 0.1016 (0.1257)  lr: 0.000100  iter-time: 0.3900\n",
            "[13:10:14.875659] Epoch: [18] Total time: 0:00:18 (0.4085 s / it)\n",
            "[13:10:14.877325] [Train] averaged stats: loss: 0.8268 (0.8788)  MAE: 0.1830 (0.1884)  MSE: 0.1016 (0.1257)  lr: 0.000100\n",
            "[13:10:15.371925] Epoch: [18]  [0/5]  eta: 0:00:02  loss: 1.0948 (1.0948)  MAE: 0.1435 (0.1435)  MSE: 0.0574 (0.0574)  iter-time: 0.4908\n",
            "[13:10:15.863548] Epoch: [18]  [4/5]  eta: 0:00:00  loss: 1.1892 (1.1485)  MAE: 0.1784 (0.1736)  MSE: 0.1065 (0.0988)  iter-time: 0.1963\n",
            "[13:10:15.940452] Epoch: [18] Total time: 0:00:01 (0.2120 s / it)\n",
            "[13:10:15.940583] [Val] averaged stats: loss: 1.1892 (1.1485)  MAE: 0.1784 (0.1736)  MSE: 0.1065 (0.0988)\n",
            "[13:10:15.942988] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:10:15.945311] [Time] 19.5s 7.2m/34.1m\n",
            "\n",
            "[13:10:15.946220] ~~~ Epoch 19/100 ~~~\n",
            "\n",
            "[13:10:16.612391] Epoch: [19]  [ 0/45]  eta: 0:00:29  loss: 0.8457 (0.8457)  MAE: 0.1595 (0.1595)  MSE: 0.1299 (0.1299)  lr: 0.000100  iter-time: 0.6640\n",
            "[13:10:20.598641] Epoch: [19]  [10/45]  eta: 0:00:14  loss: 0.9410 (0.9211)  MAE: 0.1915 (0.1951)  MSE: 0.1264 (0.1251)  lr: 0.000100  iter-time: 0.4226\n",
            "[13:10:24.598999] Epoch: [19]  [20/45]  eta: 0:00:10  loss: 0.9010 (0.9052)  MAE: 0.1834 (0.1872)  MSE: 0.1153 (0.1178)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:10:28.622363] Epoch: [19]  [30/45]  eta: 0:00:06  loss: 0.8393 (0.8768)  MAE: 0.1695 (0.1833)  MSE: 0.0978 (0.1096)  lr: 0.000100  iter-time: 0.4010\n",
            "[13:10:32.633401] Epoch: [19]  [40/45]  eta: 0:00:02  loss: 0.8393 (0.8981)  MAE: 0.1779 (0.1818)  MSE: 0.0889 (0.1045)  lr: 0.000100  iter-time: 0.4016\n",
            "[13:10:34.048774] Epoch: [19]  [44/45]  eta: 0:00:00  loss: 0.8847 (0.9031)  MAE: 0.1750 (0.1817)  MSE: 0.0869 (0.1038)  lr: 0.000100  iter-time: 0.3923\n",
            "[13:10:34.135915] Epoch: [19] Total time: 0:00:18 (0.4042 s / it)\n",
            "[13:10:34.136121] [Train] averaged stats: loss: 0.8847 (0.9031)  MAE: 0.1750 (0.1817)  MSE: 0.0869 (0.1038)  lr: 0.000100\n",
            "[13:10:34.497990] Epoch: [19]  [0/5]  eta: 0:00:01  loss: 1.0421 (1.0421)  MAE: 0.1421 (0.1421)  MSE: 0.0520 (0.0520)  iter-time: 0.3600\n",
            "[13:10:34.991886] Epoch: [19]  [4/5]  eta: 0:00:00  loss: 1.1811 (1.1435)  MAE: 0.1799 (0.1741)  MSE: 0.0969 (0.0891)  iter-time: 0.1706\n",
            "[13:10:35.069441] Epoch: [19] Total time: 0:00:00 (0.1864 s / it)\n",
            "[13:10:35.070299] [Val] averaged stats: loss: 1.1811 (1.1435)  MAE: 0.1799 (0.1741)  MSE: 0.0969 (0.0891)\n",
            "[13:10:35.072315] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:10:35.074720] [Time] 19.1s 7.5m/33.7m\n",
            "\n",
            "[13:10:35.074780] ~~~ Epoch 20/100 ~~~\n",
            "\n",
            "[13:10:35.729241] Epoch: [20]  [ 0/45]  eta: 0:00:29  loss: 1.0278 (1.0278)  MAE: 0.1557 (0.1557)  MSE: 0.1018 (0.1018)  lr: 0.000100  iter-time: 0.6521\n",
            "[13:10:39.730377] Epoch: [20]  [10/45]  eta: 0:00:14  loss: 0.7729 (0.7953)  MAE: 0.1901 (0.1936)  MSE: 0.1138 (0.1113)  lr: 0.000100  iter-time: 0.4228\n",
            "[13:10:43.735161] Epoch: [20]  [20/45]  eta: 0:00:10  loss: 0.7358 (0.7811)  MAE: 0.1901 (0.1895)  MSE: 0.1138 (0.1152)  lr: 0.000100  iter-time: 0.4001\n",
            "[13:10:47.768297] Epoch: [20]  [30/45]  eta: 0:00:06  loss: 0.7886 (0.8330)  MAE: 0.1822 (0.1892)  MSE: 0.1193 (0.1174)  lr: 0.000100  iter-time: 0.4017\n",
            "[13:10:51.764270] Epoch: [20]  [40/45]  eta: 0:00:02  loss: 0.9033 (0.8638)  MAE: 0.1964 (0.1917)  MSE: 0.1328 (0.1235)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:10:53.179726] Epoch: [20]  [44/45]  eta: 0:00:00  loss: 0.9057 (0.8647)  MAE: 0.1980 (0.1938)  MSE: 0.1366 (0.1294)  lr: 0.000100  iter-time: 0.3913\n",
            "[13:10:53.271689] Epoch: [20] Total time: 0:00:18 (0.4044 s / it)\n",
            "[13:10:53.272941] [Train] averaged stats: loss: 0.9057 (0.8647)  MAE: 0.1980 (0.1938)  MSE: 0.1366 (0.1294)  lr: 0.000100\n",
            "[13:10:53.613390] Epoch: [20]  [0/5]  eta: 0:00:01  loss: 1.0339 (1.0339)  MAE: 0.1521 (0.1521)  MSE: 0.0866 (0.0866)  iter-time: 0.3366\n",
            "[13:10:54.104212] Epoch: [20]  [4/5]  eta: 0:00:00  loss: 1.2089 (1.1525)  MAE: 0.2010 (0.1946)  MSE: 0.1800 (0.1637)  iter-time: 0.1652\n",
            "[13:10:54.182515] Epoch: [20] Total time: 0:00:00 (0.1813 s / it)\n",
            "[13:10:54.183341] [Val] averaged stats: loss: 1.2089 (1.1525)  MAE: 0.2010 (0.1946)  MSE: 0.1800 (0.1637)\n",
            "[13:10:54.185922] [Val] best loss: 1.1404 best  MAE: 0.1845 MSE: 0.0957 \n",
            "[13:10:54.188205] Creating training plots . . .\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[13:10:54.632729] [Time] 19.6s 7.9m/34.3m\n",
            "\n",
            "[13:10:54.633552] ~~~ Epoch 21/100 ~~~\n",
            "\n",
            "[13:10:55.260084] Epoch: [21]  [ 0/45]  eta: 0:00:28  loss: 0.7456 (0.7456)  MAE: 0.1810 (0.1810)  MSE: 0.2177 (0.2177)  lr: 0.000100  iter-time: 0.6240\n",
            "[13:10:59.263926] Epoch: [21]  [10/45]  eta: 0:00:14  loss: 0.8921 (0.8950)  MAE: 0.2281 (0.2281)  MSE: 0.2198 (0.2191)  lr: 0.000100  iter-time: 0.4206\n",
            "[13:11:03.281372] Epoch: [21]  [20/45]  eta: 0:00:10  loss: 0.8613 (0.8863)  MAE: 0.2141 (0.2206)  MSE: 0.2214 (0.2240)  lr: 0.000100  iter-time: 0.4009\n",
            "[13:11:07.292285] Epoch: [21]  [30/45]  eta: 0:00:06  loss: 0.8819 (0.8964)  MAE: 0.2037 (0.2138)  MSE: 0.1935 (0.2070)  lr: 0.000100  iter-time: 0.4013\n",
            "[13:11:11.283833] Epoch: [21]  [40/45]  eta: 0:00:02  loss: 0.9207 (0.8967)  MAE: 0.1854 (0.2059)  MSE: 0.1474 (0.1867)  lr: 0.000100  iter-time: 0.4000\n",
            "[13:11:12.694520] Epoch: [21]  [44/45]  eta: 0:00:00  loss: 0.9207 (0.8934)  MAE: 0.1834 (0.2037)  MSE: 0.1233 (0.1810)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:11:12.786293] Epoch: [21] Total time: 0:00:18 (0.4034 s / it)\n",
            "[13:11:12.787815] [Train] averaged stats: loss: 0.9207 (0.8934)  MAE: 0.1834 (0.2037)  MSE: 0.1233 (0.1810)  lr: 0.000100\n",
            "[13:11:13.147875] Epoch: [21]  [0/5]  eta: 0:00:01  loss: 1.0315 (1.0315)  MAE: 0.1346 (0.1346)  MSE: 0.0535 (0.0535)  iter-time: 0.3563\n",
            "[13:11:13.640770] Epoch: [21]  [4/5]  eta: 0:00:00  loss: 1.1401 (1.1216)  MAE: 0.1755 (0.1707)  MSE: 0.1061 (0.0986)  iter-time: 0.1697\n",
            "[13:11:13.719574] Epoch: [21] Total time: 0:00:00 (0.1857 s / it)\n",
            "[13:11:13.719709] [Val] averaged stats: loss: 1.1401 (1.1216)  MAE: 0.1755 (0.1707)  MSE: 0.1061 (0.0986)\n",
            "[13:11:13.722278] Val loss improved from 1.1404284954071044 to 1.1215887546539307, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:11:13.773215] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "[13:11:13.776480] [Time] 19.1s 8.2m/33.7m\n",
            "\n",
            "[13:11:13.777402] ~~~ Epoch 22/100 ~~~\n",
            "\n",
            "[13:11:14.431074] Epoch: [22]  [ 0/45]  eta: 0:00:29  loss: 0.7115 (0.7115)  MAE: 0.1511 (0.1511)  MSE: 0.1355 (0.1355)  lr: 0.000100  iter-time: 0.6511\n",
            "[13:11:18.456305] Epoch: [22]  [10/45]  eta: 0:00:14  loss: 0.7920 (0.8224)  MAE: 0.1871 (0.1881)  MSE: 0.1281 (0.1267)  lr: 0.000100  iter-time: 0.4250\n",
            "[13:11:22.488318] Epoch: [22]  [20/45]  eta: 0:00:10  loss: 0.8391 (0.8465)  MAE: 0.1790 (0.1823)  MSE: 0.1201 (0.1237)  lr: 0.000100  iter-time: 0.4027\n",
            "[13:11:26.473660] Epoch: [22]  [30/45]  eta: 0:00:06  loss: 0.8391 (0.8464)  MAE: 0.1708 (0.1792)  MSE: 0.1104 (0.1165)  lr: 0.000100  iter-time: 0.4007\n",
            "[13:11:30.459600] Epoch: [22]  [40/45]  eta: 0:00:02  loss: 0.8737 (0.8886)  MAE: 0.1698 (0.1769)  MSE: 0.0992 (0.1099)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:11:31.868075] Epoch: [22]  [44/45]  eta: 0:00:00  loss: 0.9035 (0.8793)  MAE: 0.1698 (0.1769)  MSE: 0.0885 (0.1094)  lr: 0.000100  iter-time: 0.3891\n",
            "[13:11:32.013726] Epoch: [22] Total time: 0:00:18 (0.4052 s / it)\n",
            "[13:11:32.016514] [Train] averaged stats: loss: 0.9035 (0.8793)  MAE: 0.1698 (0.1769)  MSE: 0.0885 (0.1094)  lr: 0.000100\n",
            "[13:11:32.502212] Epoch: [22]  [0/5]  eta: 0:00:02  loss: 1.0499 (1.0499)  MAE: 0.1313 (0.1313)  MSE: 0.0489 (0.0489)  iter-time: 0.4822\n",
            "[13:11:32.997698] Epoch: [22]  [4/5]  eta: 0:00:00  loss: 1.1607 (1.1344)  MAE: 0.1693 (0.1654)  MSE: 0.0941 (0.0882)  iter-time: 0.1951\n",
            "[13:11:33.103737] Epoch: [22] Total time: 0:00:01 (0.2169 s / it)\n",
            "[13:11:33.103875] [Val] averaged stats: loss: 1.1607 (1.1344)  MAE: 0.1693 (0.1654)  MSE: 0.0941 (0.0882)\n",
            "[13:11:33.104561] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:11:33.106943] [Time] 19.3s 8.5m/34.0m\n",
            "\n",
            "[13:11:33.106988] ~~~ Epoch 23/100 ~~~\n",
            "\n",
            "[13:11:33.943733] Epoch: [23]  [ 0/45]  eta: 0:00:37  loss: 1.0808 (1.0808)  MAE: 0.1516 (0.1516)  MSE: 0.1109 (0.1109)  lr: 0.000100  iter-time: 0.8342\n",
            "[13:11:37.950636] Epoch: [23]  [10/45]  eta: 0:00:15  loss: 0.8821 (0.8680)  MAE: 0.1921 (0.1914)  MSE: 0.1281 (0.1263)  lr: 0.000100  iter-time: 0.4399\n",
            "[13:11:41.937186] Epoch: [23]  [20/45]  eta: 0:00:10  loss: 0.8441 (0.8597)  MAE: 0.1885 (0.1896)  MSE: 0.1327 (0.1329)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:11:45.922634] Epoch: [23]  [30/45]  eta: 0:00:06  loss: 0.8441 (0.8754)  MAE: 0.1835 (0.1881)  MSE: 0.1332 (0.1321)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:11:49.923970] Epoch: [23]  [40/45]  eta: 0:00:02  loss: 0.9465 (0.9491)  MAE: 0.1750 (0.1840)  MSE: 0.1274 (0.1280)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:11:51.329309] Epoch: [23]  [44/45]  eta: 0:00:00  loss: 0.9163 (0.9389)  MAE: 0.1748 (0.1832)  MSE: 0.1197 (0.1286)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:11:51.495900] Epoch: [23] Total time: 0:00:18 (0.4086 s / it)\n",
            "[13:11:51.496131] [Train] averaged stats: loss: 0.9163 (0.9389)  MAE: 0.1748 (0.1832)  MSE: 0.1197 (0.1286)  lr: 0.000100\n",
            "[13:11:51.959149] Epoch: [23]  [0/5]  eta: 0:00:02  loss: 1.0764 (1.0764)  MAE: 0.1276 (0.1276)  MSE: 0.0581 (0.0581)  iter-time: 0.4583\n",
            "[13:11:52.452848] Epoch: [23]  [4/5]  eta: 0:00:00  loss: 1.2169 (1.1537)  MAE: 0.1639 (0.1603)  MSE: 0.1148 (0.1079)  iter-time: 0.1903\n",
            "[13:11:52.535412] Epoch: [23] Total time: 0:00:01 (0.2070 s / it)\n",
            "[13:11:52.535550] [Val] averaged stats: loss: 1.2169 (1.1537)  MAE: 0.1639 (0.1603)  MSE: 0.1148 (0.1079)\n",
            "[13:11:52.537910] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:11:52.540290] [Time] 19.4s 8.8m/34.1m\n",
            "\n",
            "[13:11:52.540372] ~~~ Epoch 24/100 ~~~\n",
            "\n",
            "[13:11:53.219283] Epoch: [24]  [ 0/45]  eta: 0:00:30  loss: 1.1172 (1.1172)  MAE: 0.1468 (0.1468)  MSE: 0.1570 (0.1570)  lr: 0.000100  iter-time: 0.6767\n",
            "[13:11:57.209261] Epoch: [24]  [10/45]  eta: 0:00:14  loss: 0.9631 (0.8820)  MAE: 0.1803 (0.1822)  MSE: 0.1619 (0.1563)  lr: 0.000100  iter-time: 0.4241\n",
            "[13:12:01.199071] Epoch: [24]  [20/45]  eta: 0:00:10  loss: 0.7914 (0.8418)  MAE: 0.1745 (0.1778)  MSE: 0.1589 (0.1584)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:12:05.205692] Epoch: [24]  [30/45]  eta: 0:00:06  loss: 0.8036 (0.8893)  MAE: 0.1698 (0.1764)  MSE: 0.1529 (0.1552)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:12:09.219684] Epoch: [24]  [40/45]  eta: 0:00:02  loss: 0.8153 (0.8702)  MAE: 0.1698 (0.1744)  MSE: 0.1366 (0.1457)  lr: 0.000100  iter-time: 0.4008\n",
            "[13:12:10.633565] Epoch: [24]  [44/45]  eta: 0:00:00  loss: 0.8725 (0.8845)  MAE: 0.1698 (0.1745)  MSE: 0.1134 (0.1438)  lr: 0.000100  iter-time: 0.3915\n",
            "[13:12:10.734250] Epoch: [24] Total time: 0:00:18 (0.4043 s / it)\n",
            "[13:12:10.735731] [Train] averaged stats: loss: 0.8725 (0.8845)  MAE: 0.1698 (0.1745)  MSE: 0.1134 (0.1438)  lr: 0.000100\n",
            "[13:12:11.109381] Epoch: [24]  [0/5]  eta: 0:00:01  loss: 1.1797 (1.1797)  MAE: 0.1247 (0.1247)  MSE: 0.0489 (0.0489)  iter-time: 0.3683\n",
            "[13:12:11.605483] Epoch: [24]  [4/5]  eta: 0:00:00  loss: 1.1797 (1.1579)  MAE: 0.1571 (0.1531)  MSE: 0.0988 (0.0891)  iter-time: 0.1727\n",
            "[13:12:11.682360] Epoch: [24] Total time: 0:00:00 (0.1884 s / it)\n",
            "[13:12:11.682493] [Val] averaged stats: loss: 1.1797 (1.1579)  MAE: 0.1571 (0.1531)  MSE: 0.0988 (0.0891)\n",
            "[13:12:11.684888] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:12:11.687152] [Time] 19.1s 9.2m/33.7m\n",
            "\n",
            "[13:12:11.688167] ~~~ Epoch 25/100 ~~~\n",
            "\n",
            "[13:12:12.290917] Epoch: [25]  [ 0/45]  eta: 0:00:27  loss: 0.7097 (0.7097)  MAE: 0.1431 (0.1431)  MSE: 0.1425 (0.1425)  lr: 0.000100  iter-time: 0.6006\n",
            "[13:12:16.278655] Epoch: [25]  [10/45]  eta: 0:00:14  loss: 0.9087 (0.9187)  MAE: 0.1797 (0.1805)  MSE: 0.1384 (0.1371)  lr: 0.000100  iter-time: 0.4168\n",
            "[13:12:20.280594] Epoch: [25]  [20/45]  eta: 0:00:10  loss: 0.8250 (0.8403)  MAE: 0.1754 (0.1784)  MSE: 0.1384 (0.1448)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:12:24.330140] Epoch: [25]  [30/45]  eta: 0:00:06  loss: 0.7830 (0.8355)  MAE: 0.1739 (0.1784)  MSE: 0.1516 (0.1460)  lr: 0.000100  iter-time: 0.4024\n",
            "[13:12:28.352271] Epoch: [25]  [40/45]  eta: 0:00:02  loss: 0.8500 (0.8590)  MAE: 0.1762 (0.1771)  MSE: 0.1370 (0.1404)  lr: 0.000100  iter-time: 0.4033\n",
            "[13:12:29.768681] Epoch: [25]  [44/45]  eta: 0:00:00  loss: 0.8512 (0.8695)  MAE: 0.1739 (0.1773)  MSE: 0.1212 (0.1399)  lr: 0.000100  iter-time: 0.3930\n",
            "[13:12:29.859893] Epoch: [25] Total time: 0:00:18 (0.4038 s / it)\n",
            "[13:12:29.862079] [Train] averaged stats: loss: 0.8512 (0.8695)  MAE: 0.1739 (0.1773)  MSE: 0.1212 (0.1399)  lr: 0.000100\n",
            "[13:12:30.239700] Epoch: [25]  [0/5]  eta: 0:00:01  loss: 1.0209 (1.0209)  MAE: 0.1310 (0.1310)  MSE: 0.0605 (0.0605)  iter-time: 0.3743\n",
            "[13:12:30.735160] Epoch: [25]  [4/5]  eta: 0:00:00  loss: 1.1963 (1.1376)  MAE: 0.1726 (0.1693)  MSE: 0.1221 (0.1148)  iter-time: 0.1734\n",
            "[13:12:30.812969] Epoch: [25] Total time: 0:00:00 (0.1897 s / it)\n",
            "[13:12:30.813947] [Val] averaged stats: loss: 1.1963 (1.1376)  MAE: 0.1726 (0.1693)  MSE: 0.1221 (0.1148)\n",
            "[13:12:30.815733] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "[13:12:30.818021] Creating training plots . . .\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:12:31.243202] [Time] 19.6s 9.5m/34.3m\n",
            "\n",
            "[13:12:31.243264] ~~~ Epoch 26/100 ~~~\n",
            "\n",
            "[13:12:31.858748] Epoch: [26]  [ 0/45]  eta: 0:00:27  loss: 0.7221 (0.7221)  MAE: 0.1509 (0.1509)  MSE: 0.1507 (0.1507)  lr: 0.000100  iter-time: 0.6130\n",
            "[13:12:35.848292] Epoch: [26]  [10/45]  eta: 0:00:14  loss: 0.8016 (1.0936)  MAE: 0.2056 (0.2020)  MSE: 0.1665 (0.1673)  lr: 0.000100  iter-time: 0.4183\n",
            "[13:12:39.838866] Epoch: [26]  [20/45]  eta: 0:00:10  loss: 0.9727 (1.0274)  MAE: 0.2076 (0.2073)  MSE: 0.1835 (0.1879)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:12:43.840421] Epoch: [26]  [30/45]  eta: 0:00:06  loss: 0.9727 (0.9831)  MAE: 0.2140 (0.2109)  MSE: 0.2073 (0.1909)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:12:47.829557] Epoch: [26]  [40/45]  eta: 0:00:02  loss: 0.8394 (0.9445)  MAE: 0.1998 (0.2074)  MSE: 0.1884 (0.1796)  lr: 0.000100  iter-time: 0.3994\n",
            "[13:12:49.243910] Epoch: [26]  [44/45]  eta: 0:00:00  loss: 0.8253 (0.9351)  MAE: 0.1991 (0.2064)  MSE: 0.1415 (0.1768)  lr: 0.000100  iter-time: 0.3902\n",
            "[13:12:49.335257] Epoch: [26] Total time: 0:00:18 (0.4020 s / it)\n",
            "[13:12:49.336238] [Train] averaged stats: loss: 0.8253 (0.9351)  MAE: 0.1991 (0.2064)  MSE: 0.1415 (0.1768)  lr: 0.000100\n",
            "[13:12:49.639535] Epoch: [26]  [0/5]  eta: 0:00:01  loss: 1.0578 (1.0578)  MAE: 0.1417 (0.1417)  MSE: 0.0626 (0.0626)  iter-time: 0.3003\n",
            "[13:12:50.132684] Epoch: [26]  [4/5]  eta: 0:00:00  loss: 1.2011 (1.1400)  MAE: 0.1828 (0.1786)  MSE: 0.1180 (0.1110)  iter-time: 0.1586\n",
            "[13:12:50.212443] Epoch: [26] Total time: 0:00:00 (0.1748 s / it)\n",
            "[13:12:50.212584] [Val] averaged stats: loss: 1.2011 (1.1400)  MAE: 0.1828 (0.1786)  MSE: 0.1180 (0.1110)\n",
            "[13:12:50.215094] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:12:50.217528] [Time] 19.0s 9.8m/33.5m\n",
            "\n",
            "[13:12:50.217586] ~~~ Epoch 27/100 ~~~\n",
            "\n",
            "[13:12:50.893709] Epoch: [27]  [ 0/45]  eta: 0:00:30  loss: 0.6656 (0.6656)  MAE: 0.1722 (0.1722)  MSE: 0.1716 (0.1716)  lr: 0.000100  iter-time: 0.6739\n",
            "[13:12:54.926366] Epoch: [27]  [10/45]  eta: 0:00:14  loss: 0.8897 (0.9358)  MAE: 0.2019 (0.2072)  MSE: 0.1638 (0.1640)  lr: 0.000100  iter-time: 0.4277\n",
            "[13:12:58.966890] Epoch: [27]  [20/45]  eta: 0:00:10  loss: 0.7735 (0.8544)  MAE: 0.2003 (0.2031)  MSE: 0.1638 (0.1707)  lr: 0.000100  iter-time: 0.4035\n",
            "[13:13:02.958388] Epoch: [27]  [30/45]  eta: 0:00:06  loss: 0.7735 (0.8470)  MAE: 0.1969 (0.2027)  MSE: 0.1766 (0.1724)  lr: 0.000100  iter-time: 0.4014\n",
            "[13:13:06.949988] Epoch: [27]  [40/45]  eta: 0:00:02  loss: 0.8138 (0.8701)  MAE: 0.1980 (0.2008)  MSE: 0.1621 (0.1666)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:13:08.364255] Epoch: [27]  [44/45]  eta: 0:00:00  loss: 0.8138 (0.8727)  MAE: 0.1966 (0.2000)  MSE: 0.1410 (0.1647)  lr: 0.000100  iter-time: 0.3897\n",
            "[13:13:08.459656] Epoch: [27] Total time: 0:00:18 (0.4054 s / it)\n",
            "[13:13:08.461662] [Train] averaged stats: loss: 0.8138 (0.8727)  MAE: 0.1966 (0.2000)  MSE: 0.1410 (0.1647)  lr: 0.000100\n",
            "[13:13:08.909759] Epoch: [27]  [0/5]  eta: 0:00:02  loss: 0.9752 (0.9752)  MAE: 0.1352 (0.1352)  MSE: 0.0600 (0.0600)  iter-time: 0.4444\n",
            "[13:13:09.407768] Epoch: [27]  [4/5]  eta: 0:00:00  loss: 1.2053 (1.1327)  MAE: 0.1748 (0.1710)  MSE: 0.1164 (0.1089)  iter-time: 0.1883\n",
            "[13:13:09.544672] Epoch: [27] Total time: 0:00:01 (0.2160 s / it)\n",
            "[13:13:09.544801] [Val] averaged stats: loss: 1.2053 (1.1327)  MAE: 0.1748 (0.1710)  MSE: 0.1164 (0.1089)\n",
            "[13:13:09.545384] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:13:09.552579] [Time] 19.3s 10.1m/34.0m\n",
            "\n",
            "[13:13:09.552622] ~~~ Epoch 28/100 ~~~\n",
            "\n",
            "[13:13:10.423018] Epoch: [28]  [ 0/45]  eta: 0:00:39  loss: 1.2337 (1.2337)  MAE: 0.1592 (0.1592)  MSE: 0.1529 (0.1529)  lr: 0.000100  iter-time: 0.8676\n",
            "[13:13:14.473947] Epoch: [28]  [10/45]  eta: 0:00:15  loss: 0.9382 (0.9540)  MAE: 0.1911 (0.1928)  MSE: 0.1437 (0.1433)  lr: 0.000100  iter-time: 0.4468\n",
            "[13:13:18.486801] Epoch: [28]  [20/45]  eta: 0:00:10  loss: 0.8706 (0.9139)  MAE: 0.1798 (0.1849)  MSE: 0.1319 (0.1372)  lr: 0.000100  iter-time: 0.4029\n",
            "[13:13:22.479681] Epoch: [28]  [30/45]  eta: 0:00:06  loss: 0.9449 (0.9402)  MAE: 0.1730 (0.1821)  MSE: 0.1265 (0.1328)  lr: 0.000100  iter-time: 0.4001\n",
            "[13:13:26.475985] Epoch: [28]  [40/45]  eta: 0:00:02  loss: 0.9533 (0.9361)  MAE: 0.1700 (0.1782)  MSE: 0.1148 (0.1249)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:13:27.885899] Epoch: [28]  [44/45]  eta: 0:00:00  loss: 0.8321 (0.9230)  MAE: 0.1680 (0.1772)  MSE: 0.0934 (0.1230)  lr: 0.000100  iter-time: 0.3899\n",
            "[13:13:28.032514] Epoch: [28] Total time: 0:00:18 (0.4106 s / it)\n",
            "[13:13:28.036357] [Train] averaged stats: loss: 0.8321 (0.9230)  MAE: 0.1680 (0.1772)  MSE: 0.0934 (0.1230)  lr: 0.000100\n",
            "[13:13:28.544759] Epoch: [28]  [0/5]  eta: 0:00:02  loss: 1.0193 (1.0193)  MAE: 0.1219 (0.1219)  MSE: 0.0451 (0.0451)  iter-time: 0.5061\n",
            "[13:13:29.041351] Epoch: [28]  [4/5]  eta: 0:00:00  loss: 1.1813 (1.1239)  MAE: 0.1540 (0.1511)  MSE: 0.0849 (0.0794)  iter-time: 0.2000\n",
            "[13:13:29.164542] Epoch: [28] Total time: 0:00:01 (0.2253 s / it)\n",
            "[13:13:29.164704] [Val] averaged stats: loss: 1.1813 (1.1239)  MAE: 0.1540 (0.1511)  MSE: 0.0849 (0.0794)\n",
            "[13:13:29.165510] [Val] best loss: 1.1216 best  MAE: 0.1707 MSE: 0.0986 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[13:13:29.171661] [Time] 19.6s 10.4m/34.3m\n",
            "\n",
            "[13:13:29.171719] ~~~ Epoch 29/100 ~~~\n",
            "\n",
            "[13:13:29.962550] Epoch: [29]  [ 0/45]  eta: 0:00:35  loss: 0.9937 (0.9937)  MAE: 0.1472 (0.1472)  MSE: 0.1229 (0.1229)  lr: 0.000100  iter-time: 0.7883\n",
            "[13:13:33.949967] Epoch: [29]  [10/45]  eta: 0:00:15  loss: 0.9424 (0.8921)  MAE: 0.1710 (0.1780)  MSE: 0.1242 (0.1242)  lr: 0.000100  iter-time: 0.4340\n",
            "[13:13:37.939407] Epoch: [29]  [20/45]  eta: 0:00:10  loss: 0.9424 (0.9268)  MAE: 0.1750 (0.1789)  MSE: 0.1287 (0.1387)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:13:41.944000] Epoch: [29]  [30/45]  eta: 0:00:06  loss: 0.8951 (0.9196)  MAE: 0.1847 (0.1827)  MSE: 0.1604 (0.1466)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:13:45.936143] Epoch: [29]  [40/45]  eta: 0:00:02  loss: 0.8705 (0.9113)  MAE: 0.1847 (0.1820)  MSE: 0.1462 (0.1434)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:13:47.351536] Epoch: [29]  [44/45]  eta: 0:00:00  loss: 0.9164 (0.9211)  MAE: 0.1835 (0.1825)  MSE: 0.1308 (0.1436)  lr: 0.000100  iter-time: 0.3906\n",
            "[13:13:47.447662] Epoch: [29] Total time: 0:00:18 (0.4061 s / it)\n",
            "[13:13:47.448782] [Train] averaged stats: loss: 0.9164 (0.9211)  MAE: 0.1835 (0.1825)  MSE: 0.1308 (0.1436)  lr: 0.000100\n",
            "[13:13:47.836937] Epoch: [29]  [0/5]  eta: 0:00:01  loss: 0.9900 (0.9900)  MAE: 0.1313 (0.1313)  MSE: 0.0636 (0.0636)  iter-time: 0.3853\n",
            "[13:13:48.330300] Epoch: [29]  [4/5]  eta: 0:00:00  loss: 1.1948 (1.1213)  MAE: 0.1740 (0.1697)  MSE: 0.1304 (0.1205)  iter-time: 0.1756\n",
            "[13:13:48.410020] Epoch: [29] Total time: 0:00:00 (0.1918 s / it)\n",
            "[13:13:48.410190] [Val] averaged stats: loss: 1.1948 (1.1213)  MAE: 0.1740 (0.1697)  MSE: 0.1304 (0.1205)\n",
            "[13:13:48.412670] Val loss improved from 1.1215887546539307 to 1.1212890505790711, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:13:48.462883] [Val] best loss: 1.1213 best  MAE: 0.1697 MSE: 0.1205 \n",
            "[13:13:48.465568] [Time] 19.3s 10.8m/33.9m\n",
            "\n",
            "[13:13:48.466373] ~~~ Epoch 30/100 ~~~\n",
            "\n",
            "[13:13:49.087374] Epoch: [30]  [ 0/45]  eta: 0:00:27  loss: 1.0413 (1.0413)  MAE: 0.1611 (0.1611)  MSE: 0.1556 (0.1556)  lr: 0.000100  iter-time: 0.6187\n",
            "[13:13:53.092188] Epoch: [30]  [10/45]  eta: 0:00:14  loss: 0.8935 (0.8812)  MAE: 0.1919 (0.1987)  MSE: 0.1607 (0.1629)  lr: 0.000100  iter-time: 0.4202\n",
            "[13:13:57.081261] Epoch: [30]  [20/45]  eta: 0:00:10  loss: 0.8294 (0.8755)  MAE: 0.1900 (0.1944)  MSE: 0.1610 (0.1666)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:14:01.122587] Epoch: [30]  [30/45]  eta: 0:00:06  loss: 0.8294 (0.8661)  MAE: 0.1810 (0.1901)  MSE: 0.1471 (0.1592)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:14:05.141892] Epoch: [30]  [40/45]  eta: 0:00:02  loss: 0.8451 (0.8829)  MAE: 0.1716 (0.1844)  MSE: 0.1264 (0.1460)  lr: 0.000100  iter-time: 0.4026\n",
            "[13:14:06.554804] Epoch: [30]  [44/45]  eta: 0:00:00  loss: 0.8451 (0.8744)  MAE: 0.1679 (0.1829)  MSE: 0.0977 (0.1422)  lr: 0.000100  iter-time: 0.3924\n",
            "[13:14:06.647648] Epoch: [30] Total time: 0:00:18 (0.4040 s / it)\n",
            "[13:14:06.648987] [Train] averaged stats: loss: 0.8451 (0.8744)  MAE: 0.1679 (0.1829)  MSE: 0.0977 (0.1422)  lr: 0.000100\n",
            "[13:14:06.980104] Epoch: [30]  [0/5]  eta: 0:00:01  loss: 1.0168 (1.0168)  MAE: 0.1208 (0.1208)  MSE: 0.0443 (0.0443)  iter-time: 0.3291\n",
            "[13:14:07.478108] Epoch: [30]  [4/5]  eta: 0:00:00  loss: 1.1316 (1.1108)  MAE: 0.1576 (0.1536)  MSE: 0.0879 (0.0815)  iter-time: 0.1650\n",
            "[13:14:07.554935] Epoch: [30] Total time: 0:00:00 (0.1809 s / it)\n",
            "[13:14:07.555085] [Val] averaged stats: loss: 1.1316 (1.1108)  MAE: 0.1576 (0.1536)  MSE: 0.0879 (0.0815)\n",
            "[13:14:07.557848] Val loss improved from 1.1212890505790711 to 1.1107548236846925, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:14:07.609414] [Val] best loss: 1.1108 best  MAE: 0.1536 MSE: 0.0815 \n",
            "[13:14:07.612090] Creating training plots . . .\n",
            "[13:14:08.027894] [Time] 19.6s 11.1m/34.2m\n",
            "\n",
            "[13:14:08.028017] ~~~ Epoch 31/100 ~~~\n",
            "\n",
            "[13:14:08.636174] Epoch: [31]  [ 0/45]  eta: 0:00:27  loss: 0.6204 (0.6204)  MAE: 0.1460 (0.1460)  MSE: 0.1147 (0.1147)  lr: 0.000100  iter-time: 0.6050\n",
            "[13:14:12.627813] Epoch: [31]  [10/45]  eta: 0:00:14  loss: 0.8473 (0.8347)  MAE: 0.1799 (0.1831)  MSE: 0.1218 (0.1197)  lr: 0.000100  iter-time: 0.4176\n",
            "[13:14:16.640988] Epoch: [31]  [20/45]  eta: 0:00:10  loss: 0.8565 (0.8411)  MAE: 0.1761 (0.1803)  MSE: 0.1216 (0.1212)  lr: 0.000100  iter-time: 0.4000\n",
            "[13:14:20.647703] Epoch: [31]  [30/45]  eta: 0:00:06  loss: 0.8726 (0.8611)  MAE: 0.1711 (0.1771)  MSE: 0.1055 (0.1143)  lr: 0.000100  iter-time: 0.4008\n",
            "[13:14:24.643357] Epoch: [31]  [40/45]  eta: 0:00:02  loss: 0.8516 (0.8568)  MAE: 0.1654 (0.1733)  MSE: 0.0920 (0.1054)  lr: 0.000100  iter-time: 0.3999\n",
            "[13:14:26.053680] Epoch: [31]  [44/45]  eta: 0:00:00  loss: 0.8399 (0.8599)  MAE: 0.1632 (0.1726)  MSE: 0.0797 (0.1035)  lr: 0.000100  iter-time: 0.3904\n",
            "[13:14:26.147545] Epoch: [31] Total time: 0:00:18 (0.4026 s / it)\n",
            "[13:14:26.149469] [Train] averaged stats: loss: 0.8399 (0.8599)  MAE: 0.1632 (0.1726)  MSE: 0.0797 (0.1035)  lr: 0.000100\n",
            "[13:14:26.526063] Epoch: [31]  [0/5]  eta: 0:00:01  loss: 1.0136 (1.0136)  MAE: 0.1238 (0.1238)  MSE: 0.0417 (0.0417)  iter-time: 0.3717\n",
            "[13:14:27.021609] Epoch: [31]  [4/5]  eta: 0:00:00  loss: 1.1228 (1.1055)  MAE: 0.1621 (0.1572)  MSE: 0.0808 (0.0750)  iter-time: 0.1733\n",
            "[13:14:27.102477] Epoch: [31] Total time: 0:00:00 (0.1897 s / it)\n",
            "[13:14:27.102728] [Val] averaged stats: loss: 1.1228 (1.1055)  MAE: 0.1621 (0.1572)  MSE: 0.0808 (0.0750)\n",
            "[13:14:27.105309] Val loss improved from 1.1107548236846925 to 1.105494236946106, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:14:27.154720] [Val] best loss: 1.1055 best  MAE: 0.1572 MSE: 0.0750 \n",
            "[13:14:27.157388] [Time] 19.1s 11.4m/33.7m\n",
            "\n",
            "[13:14:27.157479] ~~~ Epoch 32/100 ~~~\n",
            "\n",
            "[13:14:27.834378] Epoch: [32]  [ 0/45]  eta: 0:00:30  loss: 0.9615 (0.9615)  MAE: 0.1485 (0.1485)  MSE: 0.0981 (0.0981)  lr: 0.000100  iter-time: 0.6737\n",
            "[13:14:31.857306] Epoch: [32]  [10/45]  eta: 0:00:14  loss: 0.9199 (0.8706)  MAE: 0.1751 (0.1797)  MSE: 0.1015 (0.1031)  lr: 0.000100  iter-time: 0.4268\n",
            "[13:14:35.900977] Epoch: [32]  [20/45]  eta: 0:00:10  loss: 0.7947 (0.8315)  MAE: 0.1751 (0.1781)  MSE: 0.1100 (0.1142)  lr: 0.000100  iter-time: 0.4031\n",
            "[13:14:39.906437] Epoch: [32]  [30/45]  eta: 0:00:06  loss: 0.8600 (0.8722)  MAE: 0.1765 (0.1788)  MSE: 0.1265 (0.1190)  lr: 0.000100  iter-time: 0.4022\n",
            "[13:14:43.908511] Epoch: [32]  [40/45]  eta: 0:00:02  loss: 0.9619 (0.8830)  MAE: 0.1764 (0.1772)  MSE: 0.1189 (0.1167)  lr: 0.000100  iter-time: 0.4002\n",
            "[13:14:45.319077] Epoch: [32]  [44/45]  eta: 0:00:00  loss: 0.9698 (0.8878)  MAE: 0.1729 (0.1764)  MSE: 0.1072 (0.1156)  lr: 0.000100  iter-time: 0.3900\n",
            "[13:14:45.439430] Epoch: [32] Total time: 0:00:18 (0.4062 s / it)\n",
            "[13:14:45.441770] [Train] averaged stats: loss: 0.9698 (0.8878)  MAE: 0.1729 (0.1764)  MSE: 0.1072 (0.1156)  lr: 0.000100\n",
            "[13:14:45.769476] Epoch: [32]  [0/5]  eta: 0:00:01  loss: 1.0220 (1.0220)  MAE: 0.1208 (0.1208)  MSE: 0.0425 (0.0425)  iter-time: 0.3248\n",
            "[13:14:46.267784] Epoch: [32]  [4/5]  eta: 0:00:00  loss: 1.1150 (1.1000)  MAE: 0.1569 (0.1534)  MSE: 0.0806 (0.0769)  iter-time: 0.1640\n",
            "[13:14:46.344824] Epoch: [32] Total time: 0:00:00 (0.1802 s / it)\n",
            "[13:14:46.344960] [Val] averaged stats: loss: 1.1150 (1.1000)  MAE: 0.1569 (0.1534)  MSE: 0.0806 (0.0769)\n",
            "[13:14:46.347449] Val loss improved from 1.105494236946106 to 1.0999525308609008, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:14:46.397599] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "[13:14:46.400473] [Time] 19.2s 11.7m/33.9m\n",
            "\n",
            "[13:14:46.400560] ~~~ Epoch 33/100 ~~~\n",
            "\n",
            "[13:14:47.093437] Epoch: [33]  [ 0/45]  eta: 0:00:31  loss: 0.9228 (0.9228)  MAE: 0.1465 (0.1465)  MSE: 0.1157 (0.1157)  lr: 0.000100  iter-time: 0.6905\n",
            "[13:14:51.111617] Epoch: [33]  [10/45]  eta: 0:00:14  loss: 0.9228 (0.9007)  MAE: 0.1714 (0.1772)  MSE: 0.1157 (0.1119)  lr: 0.000100  iter-time: 0.4278\n",
            "[13:14:55.139262] Epoch: [33]  [20/45]  eta: 0:00:10  loss: 0.8131 (0.8575)  MAE: 0.1714 (0.1736)  MSE: 0.1139 (0.1137)  lr: 0.000100  iter-time: 0.4021\n",
            "[13:14:59.140378] Epoch: [33]  [30/45]  eta: 0:00:06  loss: 0.8131 (0.8701)  MAE: 0.1686 (0.1733)  MSE: 0.1116 (0.1122)  lr: 0.000100  iter-time: 0.4013\n",
            "[13:15:03.141505] Epoch: [33]  [40/45]  eta: 0:00:02  loss: 0.9759 (0.8996)  MAE: 0.1668 (0.1703)  MSE: 0.1052 (0.1053)  lr: 0.000100  iter-time: 0.3999\n",
            "[13:15:04.551203] Epoch: [33]  [44/45]  eta: 0:00:00  loss: 1.0163 (0.9242)  MAE: 0.1625 (0.1689)  MSE: 0.0798 (0.1032)  lr: 0.000100  iter-time: 0.3906\n",
            "[13:15:04.703738] Epoch: [33] Total time: 0:00:18 (0.4067 s / it)\n",
            "[13:15:04.705821] [Train] averaged stats: loss: 1.0163 (0.9242)  MAE: 0.1625 (0.1689)  MSE: 0.0798 (0.1032)  lr: 0.000100\n",
            "[13:15:05.229282] Epoch: [33]  [0/5]  eta: 0:00:02  loss: 1.0106 (1.0106)  MAE: 0.1157 (0.1157)  MSE: 0.0387 (0.0387)  iter-time: 0.5194\n",
            "[13:15:05.727281] Epoch: [33]  [4/5]  eta: 0:00:00  loss: 1.1104 (1.1016)  MAE: 0.1492 (0.1458)  MSE: 0.0740 (0.0695)  iter-time: 0.2029\n",
            "[13:15:05.880955] Epoch: [33] Total time: 0:00:01 (0.2344 s / it)\n",
            "[13:15:05.881114] [Val] averaged stats: loss: 1.1104 (1.1016)  MAE: 0.1492 (0.1458)  MSE: 0.0740 (0.0695)\n",
            "[13:15:05.881759] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:15:05.887617] [Time] 19.5s 12.1m/34.1m\n",
            "\n",
            "[13:15:05.887666] ~~~ Epoch 34/100 ~~~\n",
            "\n",
            "[13:15:06.690393] Epoch: [34]  [ 0/45]  eta: 0:00:36  loss: 0.9891 (0.9891)  MAE: 0.1412 (0.1412)  MSE: 0.0933 (0.0933)  lr: 0.000100  iter-time: 0.8003\n",
            "[13:15:10.674997] Epoch: [34]  [10/45]  eta: 0:00:15  loss: 0.8915 (0.9036)  MAE: 0.1767 (0.1785)  MSE: 0.1015 (0.1017)  lr: 0.000100  iter-time: 0.4347\n",
            "[13:15:14.665071] Epoch: [34]  [20/45]  eta: 0:00:10  loss: 0.8915 (0.8923)  MAE: 0.1833 (0.1840)  MSE: 0.1114 (0.1144)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:15:18.657377] Epoch: [34]  [30/45]  eta: 0:00:06  loss: 0.8484 (0.8639)  MAE: 0.1938 (0.1884)  MSE: 0.1285 (0.1199)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:15:22.676147] Epoch: [34]  [40/45]  eta: 0:00:02  loss: 0.7876 (0.8527)  MAE: 0.1938 (0.1891)  MSE: 0.1241 (0.1187)  lr: 0.000100  iter-time: 0.4004\n",
            "[13:15:24.086734] Epoch: [34]  [44/45]  eta: 0:00:00  loss: 0.7766 (0.8368)  MAE: 0.1914 (0.1893)  MSE: 0.1084 (0.1191)  lr: 0.000100  iter-time: 0.3910\n",
            "[13:15:24.193205] Epoch: [34] Total time: 0:00:18 (0.4068 s / it)\n",
            "[13:15:24.195476] [Train] averaged stats: loss: 0.7766 (0.8368)  MAE: 0.1914 (0.1893)  MSE: 0.1084 (0.1191)  lr: 0.000100\n",
            "[13:15:24.534327] Epoch: [34]  [0/5]  eta: 0:00:01  loss: 1.0201 (1.0201)  MAE: 0.1345 (0.1345)  MSE: 0.0540 (0.0540)  iter-time: 0.3359\n",
            "[13:15:25.028995] Epoch: [34]  [4/5]  eta: 0:00:00  loss: 1.1653 (1.1041)  MAE: 0.1797 (0.1737)  MSE: 0.1053 (0.0985)  iter-time: 0.1656\n",
            "[13:15:25.114923] Epoch: [34] Total time: 0:00:00 (0.1834 s / it)\n",
            "[13:15:25.115083] [Val] averaged stats: loss: 1.1653 (1.1041)  MAE: 0.1797 (0.1737)  MSE: 0.1053 (0.0985)\n",
            "[13:15:25.117582] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:15:25.119917] [Time] 19.2s 12.4m/33.9m\n",
            "\n",
            "[13:15:25.120830] ~~~ Epoch 35/100 ~~~\n",
            "\n",
            "[13:15:25.835429] Epoch: [35]  [ 0/45]  eta: 0:00:32  loss: 0.7545 (0.7545)  MAE: 0.1725 (0.1725)  MSE: 0.1411 (0.1411)  lr: 0.000100  iter-time: 0.7123\n",
            "[13:15:29.816906] Epoch: [35]  [10/45]  eta: 0:00:14  loss: 0.7545 (0.7729)  MAE: 0.1996 (0.2068)  MSE: 0.1540 (0.1490)  lr: 0.000100  iter-time: 0.4266\n",
            "[13:15:33.801771] Epoch: [35]  [20/45]  eta: 0:00:10  loss: 0.7471 (0.7727)  MAE: 0.1929 (0.1997)  MSE: 0.1490 (0.1501)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:15:37.813306] Epoch: [35]  [30/45]  eta: 0:00:06  loss: 0.7778 (0.8123)  MAE: 0.1879 (0.1957)  MSE: 0.1456 (0.1473)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:15:41.822121] Epoch: [35]  [40/45]  eta: 0:00:02  loss: 0.8543 (0.8346)  MAE: 0.1797 (0.1904)  MSE: 0.1335 (0.1397)  lr: 0.000100  iter-time: 0.4008\n",
            "[13:15:43.233378] Epoch: [35]  [44/45]  eta: 0:00:00  loss: 0.8138 (0.8259)  MAE: 0.1763 (0.1885)  MSE: 0.1135 (0.1375)  lr: 0.000100  iter-time: 0.3912\n",
            "[13:15:43.324587] Epoch: [35] Total time: 0:00:18 (0.4045 s / it)\n",
            "[13:15:43.326667] [Train] averaged stats: loss: 0.8138 (0.8259)  MAE: 0.1763 (0.1885)  MSE: 0.1135 (0.1375)  lr: 0.000100\n",
            "[13:15:43.632915] Epoch: [35]  [0/5]  eta: 0:00:01  loss: 1.0057 (1.0057)  MAE: 0.1195 (0.1195)  MSE: 0.0420 (0.0420)  iter-time: 0.3016\n",
            "[13:15:44.128006] Epoch: [35]  [4/5]  eta: 0:00:00  loss: 1.1720 (1.1132)  MAE: 0.1520 (0.1489)  MSE: 0.0790 (0.0752)  iter-time: 0.1588\n",
            "[13:15:44.211924] Epoch: [35] Total time: 0:00:00 (0.1763 s / it)\n",
            "[13:15:44.212106] [Val] averaged stats: loss: 1.1720 (1.1132)  MAE: 0.1520 (0.1489)  MSE: 0.0790 (0.0752)\n",
            "[13:15:44.214149] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "[13:15:44.216724] Creating training plots . . .\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:15:44.645609] [Time] 19.5s 12.7m/34.2m\n",
            "\n",
            "[13:15:44.645664] ~~~ Epoch 36/100 ~~~\n",
            "\n",
            "[13:15:45.303805] Epoch: [36]  [ 0/45]  eta: 0:00:29  loss: 0.6960 (0.6960)  MAE: 0.1416 (0.1416)  MSE: 0.1139 (0.1139)  lr: 0.000100  iter-time: 0.6558\n",
            "[13:15:49.307575] Epoch: [36]  [10/45]  eta: 0:00:14  loss: 0.9400 (0.8971)  MAE: 0.1673 (0.1679)  MSE: 0.1139 (0.1122)  lr: 0.000100  iter-time: 0.4234\n",
            "[13:15:53.335624] Epoch: [36]  [20/45]  eta: 0:00:10  loss: 0.9400 (0.9236)  MAE: 0.1673 (0.1672)  MSE: 0.1167 (0.1160)  lr: 0.000100  iter-time: 0.4014\n",
            "[13:15:57.353833] Epoch: [36]  [30/45]  eta: 0:00:06  loss: 0.8772 (0.9126)  MAE: 0.1626 (0.1675)  MSE: 0.1158 (0.1140)  lr: 0.000100  iter-time: 0.4021\n",
            "[13:16:01.344812] Epoch: [36]  [40/45]  eta: 0:00:02  loss: 0.7768 (0.8954)  MAE: 0.1626 (0.1663)  MSE: 0.1072 (0.1088)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:16:02.754791] Epoch: [36]  [44/45]  eta: 0:00:00  loss: 0.7585 (0.8820)  MAE: 0.1625 (0.1662)  MSE: 0.0929 (0.1079)  lr: 0.000100  iter-time: 0.3901\n",
            "[13:16:02.850986] Epoch: [36] Total time: 0:00:18 (0.4045 s / it)\n",
            "[13:16:02.851182] [Train] averaged stats: loss: 0.7585 (0.8820)  MAE: 0.1625 (0.1662)  MSE: 0.0929 (0.1079)  lr: 0.000100\n",
            "[13:16:03.160288] Epoch: [36]  [0/5]  eta: 0:00:01  loss: 0.9624 (0.9624)  MAE: 0.1208 (0.1208)  MSE: 0.0456 (0.0456)  iter-time: 0.3070\n",
            "[13:16:03.654822] Epoch: [36]  [4/5]  eta: 0:00:00  loss: 1.1938 (1.1175)  MAE: 0.1581 (0.1544)  MSE: 0.0891 (0.0849)  iter-time: 0.1602\n",
            "[13:16:03.729705] Epoch: [36] Total time: 0:00:00 (0.1754 s / it)\n",
            "[13:16:03.729973] [Val] averaged stats: loss: 1.1938 (1.1175)  MAE: 0.1581 (0.1544)  MSE: 0.0891 (0.0849)\n",
            "[13:16:03.732477] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:16:03.734681] [Time] 19.1s 13.0m/33.7m\n",
            "\n",
            "[13:16:03.734739] ~~~ Epoch 37/100 ~~~\n",
            "\n",
            "[13:16:04.400820] Epoch: [37]  [ 0/45]  eta: 0:00:29  loss: 1.0088 (1.0088)  MAE: 0.1460 (0.1460)  MSE: 0.1105 (0.1105)  lr: 0.000100  iter-time: 0.6638\n",
            "[13:16:08.399925] Epoch: [37]  [10/45]  eta: 0:00:14  loss: 0.9608 (0.9867)  MAE: 0.1805 (0.1821)  MSE: 0.1124 (0.1131)  lr: 0.000100  iter-time: 0.4238\n",
            "[13:16:12.420305] Epoch: [37]  [20/45]  eta: 0:00:10  loss: 0.8549 (0.8814)  MAE: 0.1805 (0.1823)  MSE: 0.1156 (0.1168)  lr: 0.000100  iter-time: 0.4008\n",
            "[13:16:16.410889] Epoch: [37]  [30/45]  eta: 0:00:06  loss: 0.8060 (0.8719)  MAE: 0.1827 (0.1843)  MSE: 0.1186 (0.1166)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:16:20.411780] Epoch: [37]  [40/45]  eta: 0:00:02  loss: 0.8873 (0.8907)  MAE: 0.1827 (0.1839)  MSE: 0.1113 (0.1119)  lr: 0.000100  iter-time: 0.3994\n",
            "[13:16:21.825690] Epoch: [37]  [44/45]  eta: 0:00:00  loss: 0.8304 (0.8912)  MAE: 0.1826 (0.1840)  MSE: 0.0983 (0.1114)  lr: 0.000100  iter-time: 0.3901\n",
            "[13:16:21.915582] Epoch: [37] Total time: 0:00:18 (0.4040 s / it)\n",
            "[13:16:21.916539] [Train] averaged stats: loss: 0.8304 (0.8912)  MAE: 0.1826 (0.1840)  MSE: 0.0983 (0.1114)  lr: 0.000100\n",
            "[13:16:22.319252] Epoch: [37]  [0/5]  eta: 0:00:01  loss: 1.0032 (1.0032)  MAE: 0.1300 (0.1300)  MSE: 0.0482 (0.0482)  iter-time: 0.3968\n",
            "[13:16:22.814790] Epoch: [37]  [4/5]  eta: 0:00:00  loss: 1.1770 (1.1130)  MAE: 0.1710 (0.1666)  MSE: 0.0926 (0.0880)  iter-time: 0.1780\n",
            "[13:16:22.942328] Epoch: [37] Total time: 0:00:01 (0.2041 s / it)\n",
            "[13:16:22.942451] [Val] averaged stats: loss: 1.1770 (1.1130)  MAE: 0.1710 (0.1666)  MSE: 0.0926 (0.0880)\n",
            "[13:16:22.942984] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:16:22.947844] [Time] 19.2s 13.3m/33.8m\n",
            "\n",
            "[13:16:22.947887] ~~~ Epoch 38/100 ~~~\n",
            "\n",
            "[13:16:23.846251] Epoch: [38]  [ 0/45]  eta: 0:00:40  loss: 0.6501 (0.6501)  MAE: 0.1618 (0.1618)  MSE: 0.1101 (0.1101)  lr: 0.000100  iter-time: 0.8942\n",
            "[13:16:27.883954] Epoch: [38]  [10/45]  eta: 0:00:15  loss: 0.7906 (0.8040)  MAE: 0.1888 (0.1959)  MSE: 0.1184 (0.1172)  lr: 0.000100  iter-time: 0.4482\n",
            "[13:16:31.881242] Epoch: [38]  [20/45]  eta: 0:00:10  loss: 0.7906 (0.8134)  MAE: 0.1888 (0.1924)  MSE: 0.1189 (0.1220)  lr: 0.000100  iter-time: 0.4015\n",
            "[13:16:35.871042] Epoch: [38]  [30/45]  eta: 0:00:06  loss: 0.7799 (0.8109)  MAE: 0.1923 (0.1936)  MSE: 0.1331 (0.1288)  lr: 0.000100  iter-time: 0.3991\n",
            "[13:16:39.860516] Epoch: [38]  [40/45]  eta: 0:00:02  loss: 0.8395 (0.8493)  MAE: 0.1937 (0.1931)  MSE: 0.1363 (0.1293)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:16:41.275838] Epoch: [38]  [44/45]  eta: 0:00:00  loss: 0.8395 (0.8355)  MAE: 0.1936 (0.1935)  MSE: 0.1348 (0.1306)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:16:41.447852] Epoch: [38] Total time: 0:00:18 (0.4110 s / it)\n",
            "[13:16:41.449650] [Train] averaged stats: loss: 0.8395 (0.8355)  MAE: 0.1936 (0.1935)  MSE: 0.1348 (0.1306)  lr: 0.000100\n",
            "[13:16:41.950671] Epoch: [38]  [0/5]  eta: 0:00:02  loss: 1.0051 (1.0051)  MAE: 0.1344 (0.1344)  MSE: 0.0585 (0.0585)  iter-time: 0.4972\n",
            "[13:16:42.441448] Epoch: [38]  [4/5]  eta: 0:00:00  loss: 1.1737 (1.1108)  MAE: 0.1779 (0.1739)  MSE: 0.1138 (0.1077)  iter-time: 0.1973\n",
            "[13:16:42.522143] Epoch: [38] Total time: 0:00:01 (0.2138 s / it)\n",
            "[13:16:42.522272] [Val] averaged stats: loss: 1.1737 (1.1108)  MAE: 0.1779 (0.1739)  MSE: 0.1138 (0.1077)\n",
            "[13:16:42.522838] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:16:42.523757] [Time] 19.6s 13.7m/34.2m\n",
            "\n",
            "[13:16:42.523798] ~~~ Epoch 39/100 ~~~\n",
            "\n",
            "[13:16:43.120323] Epoch: [39]  [ 0/45]  eta: 0:00:26  loss: 0.6874 (0.6874)  MAE: 0.1731 (0.1731)  MSE: 0.1596 (0.1596)  lr: 0.000100  iter-time: 0.5941\n",
            "[13:16:47.124268] Epoch: [39]  [10/45]  eta: 0:00:14  loss: 0.9244 (0.8916)  MAE: 0.1918 (0.1974)  MSE: 0.1416 (0.1420)  lr: 0.000100  iter-time: 0.4178\n",
            "[13:16:51.109470] Epoch: [39]  [20/45]  eta: 0:00:10  loss: 0.8746 (0.8540)  MAE: 0.1829 (0.1895)  MSE: 0.1352 (0.1387)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:16:55.115830] Epoch: [39]  [30/45]  eta: 0:00:06  loss: 0.8144 (0.8565)  MAE: 0.1764 (0.1855)  MSE: 0.1239 (0.1329)  lr: 0.000100  iter-time: 0.3994\n",
            "[13:16:59.116739] Epoch: [39]  [40/45]  eta: 0:00:02  loss: 0.8300 (0.8541)  MAE: 0.1688 (0.1811)  MSE: 0.1147 (0.1235)  lr: 0.000100  iter-time: 0.4002\n",
            "[13:17:00.523151] Epoch: [39]  [44/45]  eta: 0:00:00  loss: 0.8144 (0.8532)  MAE: 0.1663 (0.1806)  MSE: 0.0883 (0.1218)  lr: 0.000100  iter-time: 0.3906\n",
            "[13:17:00.621851] Epoch: [39] Total time: 0:00:18 (0.4022 s / it)\n",
            "[13:17:00.623014] [Train] averaged stats: loss: 0.8144 (0.8532)  MAE: 0.1663 (0.1806)  MSE: 0.0883 (0.1218)  lr: 0.000100\n",
            "[13:17:00.993484] Epoch: [39]  [0/5]  eta: 0:00:01  loss: 1.0293 (1.0293)  MAE: 0.1288 (0.1288)  MSE: 0.0500 (0.0500)  iter-time: 0.3663\n",
            "[13:17:01.490690] Epoch: [39]  [4/5]  eta: 0:00:00  loss: 1.1702 (1.1098)  MAE: 0.1656 (0.1628)  MSE: 0.0923 (0.0880)  iter-time: 0.1723\n",
            "[13:17:01.570060] Epoch: [39] Total time: 0:00:00 (0.1887 s / it)\n",
            "[13:17:01.570205] [Val] averaged stats: loss: 1.1702 (1.1098)  MAE: 0.1656 (0.1628)  MSE: 0.0923 (0.0880)\n",
            "[13:17:01.572597] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 7 out of 20\n",
            "[13:17:01.575273] [Time] 19.1s 14.0m/33.7m\n",
            "\n",
            "[13:17:01.575332] ~~~ Epoch 40/100 ~~~\n",
            "\n",
            "[13:17:02.155970] Epoch: [40]  [ 0/45]  eta: 0:00:25  loss: 0.9831 (0.9831)  MAE: 0.1546 (0.1546)  MSE: 0.1208 (0.1208)  lr: 0.000100  iter-time: 0.5769\n",
            "[13:17:06.143999] Epoch: [40]  [10/45]  eta: 0:00:14  loss: 0.7431 (0.7967)  MAE: 0.1819 (0.1896)  MSE: 0.1219 (0.1248)  lr: 0.000100  iter-time: 0.4149\n",
            "[13:17:10.140695] Epoch: [40]  [20/45]  eta: 0:00:10  loss: 0.7306 (0.7771)  MAE: 0.1819 (0.1879)  MSE: 0.1269 (0.1306)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:17:14.162213] Epoch: [40]  [30/45]  eta: 0:00:06  loss: 0.7822 (0.7960)  MAE: 0.1849 (0.1875)  MSE: 0.1277 (0.1287)  lr: 0.000100  iter-time: 0.4007\n",
            "[13:17:18.150536] Epoch: [40]  [40/45]  eta: 0:00:02  loss: 0.8101 (0.8061)  MAE: 0.1842 (0.1856)  MSE: 0.1148 (0.1238)  lr: 0.000100  iter-time: 0.4004\n",
            "[13:17:19.556354] Epoch: [40]  [44/45]  eta: 0:00:00  loss: 0.8160 (0.8048)  MAE: 0.1833 (0.1862)  MSE: 0.0977 (0.1246)  lr: 0.000100  iter-time: 0.3906\n",
            "[13:17:19.648825] Epoch: [40] Total time: 0:00:18 (0.4016 s / it)\n",
            "[13:17:19.649778] [Train] averaged stats: loss: 0.8160 (0.8048)  MAE: 0.1833 (0.1862)  MSE: 0.0977 (0.1246)  lr: 0.000100\n",
            "[13:17:19.943772] Epoch: [40]  [0/5]  eta: 0:00:01  loss: 1.0180 (1.0180)  MAE: 0.1409 (0.1409)  MSE: 0.0684 (0.0684)  iter-time: 0.2891\n",
            "[13:17:20.436960] Epoch: [40]  [4/5]  eta: 0:00:00  loss: 1.1573 (1.1316)  MAE: 0.1852 (0.1807)  MSE: 0.1337 (0.1246)  iter-time: 0.1560\n",
            "[13:17:20.514375] Epoch: [40] Total time: 0:00:00 (0.1721 s / it)\n",
            "[13:17:20.514500] [Val] averaged stats: loss: 1.1573 (1.1316)  MAE: 0.1852 (0.1807)  MSE: 0.1337 (0.1246)\n",
            "[13:17:20.516824] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "[13:17:20.518992] Creating training plots . . .\n",
            "EarlyStopping counter: 8 out of 20\n",
            "[13:17:20.942814] [Time] 19.4s 14.3m/34.0m\n",
            "\n",
            "[13:17:20.944070] ~~~ Epoch 41/100 ~~~\n",
            "\n",
            "[13:17:21.661928] Epoch: [41]  [ 0/45]  eta: 0:00:32  loss: 1.0060 (1.0060)  MAE: 0.1738 (0.1738)  MSE: 0.1553 (0.1553)  lr: 0.000100  iter-time: 0.7155\n",
            "[13:17:25.667163] Epoch: [41]  [10/45]  eta: 0:00:15  loss: 0.9543 (0.9506)  MAE: 0.2153 (0.2174)  MSE: 0.1794 (0.1768)  lr: 0.000100  iter-time: 0.4289\n",
            "[13:17:29.694259] Epoch: [41]  [20/45]  eta: 0:00:10  loss: 0.9174 (0.9108)  MAE: 0.2153 (0.2218)  MSE: 0.1900 (0.2039)  lr: 0.000100  iter-time: 0.4014\n",
            "[13:17:33.680454] Epoch: [41]  [30/45]  eta: 0:00:06  loss: 0.8481 (0.8971)  MAE: 0.2236 (0.2234)  MSE: 0.2169 (0.2049)  lr: 0.000100  iter-time: 0.4005\n",
            "[13:17:37.671442] Epoch: [41]  [40/45]  eta: 0:00:02  loss: 0.8481 (0.8840)  MAE: 0.2098 (0.2171)  MSE: 0.1626 (0.1868)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:17:39.085624] Epoch: [41]  [44/45]  eta: 0:00:00  loss: 0.7874 (0.8961)  MAE: 0.2024 (0.2146)  MSE: 0.1156 (0.1799)  lr: 0.000100  iter-time: 0.3896\n",
            "[13:17:39.175020] Epoch: [41] Total time: 0:00:18 (0.4051 s / it)\n",
            "[13:17:39.175987] [Train] averaged stats: loss: 0.7874 (0.8961)  MAE: 0.2024 (0.2146)  MSE: 0.1156 (0.1799)  lr: 0.000100\n",
            "[13:17:39.475331] Epoch: [41]  [0/5]  eta: 0:00:01  loss: 1.0316 (1.0316)  MAE: 0.1390 (0.1390)  MSE: 0.0510 (0.0510)  iter-time: 0.2956\n",
            "[13:17:39.970390] Epoch: [41]  [4/5]  eta: 0:00:00  loss: 1.1553 (1.1022)  MAE: 0.1782 (0.1740)  MSE: 0.0947 (0.0885)  iter-time: 0.1576\n",
            "[13:17:40.048361] Epoch: [41] Total time: 0:00:00 (0.1740 s / it)\n",
            "[13:17:40.048480] [Val] averaged stats: loss: 1.1553 (1.1022)  MAE: 0.1782 (0.1740)  MSE: 0.0947 (0.0885)\n",
            "[13:17:40.050847] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[13:17:40.053303] [Time] 19.1s 14.6m/33.7m\n",
            "\n",
            "[13:17:40.053365] ~~~ Epoch 42/100 ~~~\n",
            "\n",
            "[13:17:40.645509] Epoch: [42]  [ 0/45]  eta: 0:00:26  loss: 0.9314 (0.9314)  MAE: 0.1563 (0.1563)  MSE: 0.1164 (0.1164)  lr: 0.000100  iter-time: 0.5901\n",
            "[13:17:44.677247] Epoch: [42]  [10/45]  eta: 0:00:14  loss: 0.8962 (0.9047)  MAE: 0.1881 (0.1922)  MSE: 0.1164 (0.1179)  lr: 0.000100  iter-time: 0.4200\n",
            "[13:17:48.701733] Epoch: [42]  [20/45]  eta: 0:00:10  loss: 0.8216 (0.8628)  MAE: 0.1847 (0.1876)  MSE: 0.1150 (0.1193)  lr: 0.000100  iter-time: 0.4027\n",
            "[13:17:52.685892] Epoch: [42]  [30/45]  eta: 0:00:06  loss: 0.7533 (0.8523)  MAE: 0.1833 (0.1872)  MSE: 0.1165 (0.1193)  lr: 0.000100  iter-time: 0.4002\n",
            "[13:17:56.672956] Epoch: [42]  [40/45]  eta: 0:00:02  loss: 0.8345 (0.8686)  MAE: 0.1833 (0.1853)  MSE: 0.1077 (0.1151)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:17:58.083418] Epoch: [42]  [44/45]  eta: 0:00:00  loss: 0.8243 (0.8581)  MAE: 0.1814 (0.1855)  MSE: 0.1007 (0.1151)  lr: 0.000100  iter-time: 0.3892\n",
            "[13:17:58.235828] Epoch: [42] Total time: 0:00:18 (0.4040 s / it)\n",
            "[13:17:58.236932] [Train] averaged stats: loss: 0.8243 (0.8581)  MAE: 0.1814 (0.1855)  MSE: 0.1007 (0.1151)  lr: 0.000100\n",
            "[13:17:58.775076] Epoch: [42]  [0/5]  eta: 0:00:02  loss: 1.0249 (1.0249)  MAE: 0.1303 (0.1303)  MSE: 0.0504 (0.0504)  iter-time: 0.5348\n",
            "[13:17:59.264268] Epoch: [42]  [4/5]  eta: 0:00:00  loss: 1.1630 (1.1103)  MAE: 0.1709 (0.1661)  MSE: 0.0983 (0.0915)  iter-time: 0.2043\n",
            "[13:17:59.367683] Epoch: [42] Total time: 0:00:01 (0.2256 s / it)\n",
            "[13:17:59.367814] [Val] averaged stats: loss: 1.1630 (1.1103)  MAE: 0.1709 (0.1661)  MSE: 0.0983 (0.0915)\n",
            "[13:17:59.368384] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[13:17:59.372518] [Time] 19.3s 15.0m/33.9m\n",
            "\n",
            "[13:17:59.372563] ~~~ Epoch 43/100 ~~~\n",
            "\n",
            "[13:18:00.279501] Epoch: [43]  [ 0/45]  eta: 0:00:40  loss: 1.1796 (1.1796)  MAE: 0.1627 (0.1627)  MSE: 0.1236 (0.1236)  lr: 0.000100  iter-time: 0.9042\n",
            "[13:18:04.307755] Epoch: [43]  [10/45]  eta: 0:00:15  loss: 0.8330 (0.8670)  MAE: 0.1941 (0.1969)  MSE: 0.1340 (0.1329)  lr: 0.000100  iter-time: 0.4481\n",
            "[13:18:08.297774] Epoch: [43]  [20/45]  eta: 0:00:10  loss: 0.7611 (0.8257)  MAE: 0.1919 (0.1946)  MSE: 0.1345 (0.1395)  lr: 0.000100  iter-time: 0.4006\n",
            "[13:18:12.276951] Epoch: [43]  [30/45]  eta: 0:00:06  loss: 0.8032 (0.8524)  MAE: 0.1919 (0.1942)  MSE: 0.1354 (0.1390)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:18:16.270497] Epoch: [43]  [40/45]  eta: 0:00:02  loss: 0.9301 (0.8807)  MAE: 0.1947 (0.1946)  MSE: 0.1261 (0.1356)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:18:17.683045] Epoch: [43]  [44/45]  eta: 0:00:00  loss: 0.9086 (0.8707)  MAE: 0.1947 (0.1954)  MSE: 0.1227 (0.1359)  lr: 0.000100  iter-time: 0.3896\n",
            "[13:18:17.846507] Epoch: [43] Total time: 0:00:18 (0.4105 s / it)\n",
            "[13:18:17.847527] [Train] averaged stats: loss: 0.9086 (0.8707)  MAE: 0.1947 (0.1954)  MSE: 0.1227 (0.1359)  lr: 0.000100\n",
            "[13:18:18.315722] Epoch: [43]  [0/5]  eta: 0:00:02  loss: 1.0388 (1.0388)  MAE: 0.1433 (0.1433)  MSE: 0.0599 (0.0599)  iter-time: 0.4645\n",
            "[13:18:18.810767] Epoch: [43]  [4/5]  eta: 0:00:00  loss: 1.1559 (1.1165)  MAE: 0.1905 (0.1851)  MSE: 0.1171 (0.1092)  iter-time: 0.1915\n",
            "[13:18:18.890299] Epoch: [43] Total time: 0:00:01 (0.2079 s / it)\n",
            "[13:18:18.890430] [Val] averaged stats: loss: 1.1559 (1.1165)  MAE: 0.1905 (0.1851)  MSE: 0.1171 (0.1092)\n",
            "[13:18:18.892938] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 11 out of 20\n",
            "[13:18:18.895320] [Time] 19.5s 15.3m/34.1m\n",
            "\n",
            "[13:18:18.895382] ~~~ Epoch 44/100 ~~~\n",
            "\n",
            "[13:18:19.509097] Epoch: [44]  [ 0/45]  eta: 0:00:27  loss: 0.8772 (0.8772)  MAE: 0.1767 (0.1767)  MSE: 0.1458 (0.1458)  lr: 0.000100  iter-time: 0.6116\n",
            "[13:18:23.494921] Epoch: [44]  [10/45]  eta: 0:00:14  loss: 0.8421 (0.8223)  MAE: 0.2135 (0.2200)  MSE: 0.1662 (0.1646)  lr: 0.000100  iter-time: 0.4178\n",
            "[13:18:27.480902] Epoch: [44]  [20/45]  eta: 0:00:10  loss: 0.7579 (0.8002)  MAE: 0.2110 (0.2163)  MSE: 0.1662 (0.1684)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:18:31.487612] Epoch: [44]  [30/45]  eta: 0:00:06  loss: 0.8094 (0.8497)  MAE: 0.2054 (0.2132)  MSE: 0.1539 (0.1611)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:18:35.481272] Epoch: [44]  [40/45]  eta: 0:00:02  loss: 0.9659 (0.8799)  MAE: 0.2021 (0.2118)  MSE: 0.1445 (0.1574)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:18:36.888638] Epoch: [44]  [44/45]  eta: 0:00:00  loss: 0.9868 (0.8943)  MAE: 0.2021 (0.2119)  MSE: 0.1445 (0.1589)  lr: 0.000100  iter-time: 0.3902\n",
            "[13:18:36.981393] Epoch: [44] Total time: 0:00:18 (0.4019 s / it)\n",
            "[13:18:36.983019] [Train] averaged stats: loss: 0.9868 (0.8943)  MAE: 0.2021 (0.2119)  MSE: 0.1445 (0.1589)  lr: 0.000100\n",
            "[13:18:37.279538] Epoch: [44]  [0/5]  eta: 0:00:01  loss: 0.9784 (0.9784)  MAE: 0.1496 (0.1496)  MSE: 0.0826 (0.0826)  iter-time: 0.2934\n",
            "[13:18:37.769369] Epoch: [44]  [4/5]  eta: 0:00:00  loss: 1.1661 (1.1632)  MAE: 0.2048 (0.1995)  MSE: 0.1662 (0.1562)  iter-time: 0.1562\n",
            "[13:18:37.851385] Epoch: [44] Total time: 0:00:00 (0.1732 s / it)\n",
            "[13:18:37.851517] [Val] averaged stats: loss: 1.1661 (1.1632)  MAE: 0.2048 (0.1995)  MSE: 0.1662 (0.1562)\n",
            "[13:18:37.854113] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 12 out of 20\n",
            "[13:18:37.856525] [Time] 19.0s 15.6m/33.6m\n",
            "\n",
            "[13:18:37.856576] ~~~ Epoch 45/100 ~~~\n",
            "\n",
            "[13:18:38.460684] Epoch: [45]  [ 0/45]  eta: 0:00:27  loss: 0.8256 (0.8256)  MAE: 0.1894 (0.1894)  MSE: 0.2107 (0.2107)  lr: 0.000100  iter-time: 0.6020\n",
            "[13:18:42.451426] Epoch: [45]  [10/45]  eta: 0:00:14  loss: 0.8122 (0.8540)  MAE: 0.2169 (0.2219)  MSE: 0.1962 (0.2001)  lr: 0.000100  iter-time: 0.4174\n",
            "[13:18:46.441962] Epoch: [45]  [20/45]  eta: 0:00:10  loss: 0.8122 (0.8557)  MAE: 0.2091 (0.2110)  MSE: 0.1876 (0.1952)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:18:50.431268] Epoch: [45]  [30/45]  eta: 0:00:06  loss: 0.8972 (0.8650)  MAE: 0.1931 (0.2047)  MSE: 0.1678 (0.1837)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:18:54.428810] Epoch: [45]  [40/45]  eta: 0:00:02  loss: 0.8805 (0.8649)  MAE: 0.1845 (0.1991)  MSE: 0.1536 (0.1682)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:18:55.838578] Epoch: [45]  [44/45]  eta: 0:00:00  loss: 0.8851 (0.8656)  MAE: 0.1844 (0.1977)  MSE: 0.1109 (0.1643)  lr: 0.000100  iter-time: 0.3902\n",
            "[13:18:55.935267] Epoch: [45] Total time: 0:00:18 (0.4017 s / it)\n",
            "[13:18:55.936697] [Train] averaged stats: loss: 0.8851 (0.8656)  MAE: 0.1844 (0.1977)  MSE: 0.1109 (0.1643)  lr: 0.000100\n",
            "[13:18:56.242744] Epoch: [45]  [0/5]  eta: 0:00:01  loss: 1.0452 (1.0452)  MAE: 0.1286 (0.1286)  MSE: 0.0514 (0.0514)  iter-time: 0.3026\n",
            "[13:18:56.738897] Epoch: [45]  [4/5]  eta: 0:00:00  loss: 1.1710 (1.1296)  MAE: 0.1724 (0.1666)  MSE: 0.1024 (0.0948)  iter-time: 0.1592\n",
            "[13:18:56.818557] Epoch: [45] Total time: 0:00:00 (0.1759 s / it)\n",
            "[13:18:56.818687] [Val] averaged stats: loss: 1.1710 (1.1296)  MAE: 0.1724 (0.1666)  MSE: 0.1024 (0.0948)\n",
            "[13:18:56.821320] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "[13:18:56.823703] Creating training plots . . .\n",
            "EarlyStopping counter: 13 out of 20\n",
            "[13:18:57.220964] [Time] 19.4s 15.9m/34.0m\n",
            "\n",
            "[13:18:57.221619] ~~~ Epoch 46/100 ~~~\n",
            "\n",
            "[13:18:57.836217] Epoch: [46]  [ 0/45]  eta: 0:00:27  loss: 0.6687 (0.6687)  MAE: 0.1643 (0.1643)  MSE: 0.1431 (0.1431)  lr: 0.000100  iter-time: 0.6120\n",
            "[13:19:01.825613] Epoch: [46]  [10/45]  eta: 0:00:14  loss: 0.9984 (0.9305)  MAE: 0.1925 (0.2009)  MSE: 0.1431 (0.1432)  lr: 0.000100  iter-time: 0.4182\n",
            "[13:19:05.830687] Epoch: [46]  [20/45]  eta: 0:00:10  loss: 0.8605 (0.8459)  MAE: 0.1957 (0.2005)  MSE: 0.1471 (0.1503)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:19:09.821617] Epoch: [46]  [30/45]  eta: 0:00:06  loss: 0.8605 (0.8650)  MAE: 0.1957 (0.1997)  MSE: 0.1522 (0.1501)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:19:13.812933] Epoch: [46]  [40/45]  eta: 0:00:02  loss: 0.9061 (0.8794)  MAE: 0.1946 (0.1979)  MSE: 0.1373 (0.1433)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:19:15.219637] Epoch: [46]  [44/45]  eta: 0:00:00  loss: 0.9061 (0.8874)  MAE: 0.1934 (0.1976)  MSE: 0.1217 (0.1420)  lr: 0.000100  iter-time: 0.3896\n",
            "[13:19:15.315996] Epoch: [46] Total time: 0:00:18 (0.4021 s / it)\n",
            "[13:19:15.319049] [Train] averaged stats: loss: 0.9061 (0.8874)  MAE: 0.1934 (0.1976)  MSE: 0.1217 (0.1420)  lr: 0.000100\n",
            "[13:19:15.676553] Epoch: [46]  [0/5]  eta: 0:00:01  loss: 1.0351 (1.0351)  MAE: 0.1378 (0.1378)  MSE: 0.0540 (0.0540)  iter-time: 0.3546\n",
            "[13:19:16.173475] Epoch: [46]  [4/5]  eta: 0:00:00  loss: 1.1645 (1.1151)  MAE: 0.1834 (0.1780)  MSE: 0.1043 (0.0979)  iter-time: 0.1702\n",
            "[13:19:16.251172] Epoch: [46] Total time: 0:00:00 (0.1860 s / it)\n",
            "[13:19:16.251956] [Val] averaged stats: loss: 1.1645 (1.1151)  MAE: 0.1834 (0.1780)  MSE: 0.1043 (0.0979)\n",
            "[13:19:16.253892] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 14 out of 20\n",
            "[13:19:16.256246] [Time] 19.0s 16.2m/33.7m\n",
            "\n",
            "[13:19:16.256300] ~~~ Epoch 47/100 ~~~\n",
            "\n",
            "[13:19:16.857628] Epoch: [47]  [ 0/45]  eta: 0:00:26  loss: 0.6320 (0.6320)  MAE: 0.1699 (0.1699)  MSE: 0.1389 (0.1389)  lr: 0.000100  iter-time: 0.5992\n",
            "[13:19:20.902396] Epoch: [47]  [10/45]  eta: 0:00:14  loss: 0.6565 (0.7693)  MAE: 0.1989 (0.2016)  MSE: 0.1343 (0.1372)  lr: 0.000100  iter-time: 0.4220\n",
            "[13:19:24.943786] Epoch: [47]  [20/45]  eta: 0:00:10  loss: 0.8326 (0.8197)  MAE: 0.1907 (0.1947)  MSE: 0.1302 (0.1356)  lr: 0.000100  iter-time: 0.4041\n",
            "[13:19:28.933280] Epoch: [47]  [30/45]  eta: 0:00:06  loss: 0.7961 (0.8123)  MAE: 0.1807 (0.1914)  MSE: 0.1268 (0.1319)  lr: 0.000100  iter-time: 0.4013\n",
            "[13:19:32.919010] Epoch: [47]  [40/45]  eta: 0:00:02  loss: 0.8336 (0.8308)  MAE: 0.1781 (0.1863)  MSE: 0.1202 (0.1245)  lr: 0.000100  iter-time: 0.3986\n",
            "[13:19:34.329347] Epoch: [47]  [44/45]  eta: 0:00:00  loss: 0.8336 (0.8295)  MAE: 0.1722 (0.1845)  MSE: 0.0979 (0.1231)  lr: 0.000100  iter-time: 0.3894\n",
            "[13:19:34.431649] Epoch: [47] Total time: 0:00:18 (0.4039 s / it)\n",
            "[13:19:34.433219] [Train] averaged stats: loss: 0.8336 (0.8295)  MAE: 0.1722 (0.1845)  MSE: 0.0979 (0.1231)  lr: 0.000100\n",
            "[13:19:34.809512] Epoch: [47]  [0/5]  eta: 0:00:01  loss: 1.0429 (1.0429)  MAE: 0.1197 (0.1197)  MSE: 0.0467 (0.0467)  iter-time: 0.3730\n",
            "[13:19:35.306020] Epoch: [47]  [4/5]  eta: 0:00:00  loss: 1.1625 (1.1112)  MAE: 0.1562 (0.1521)  MSE: 0.0925 (0.0866)  iter-time: 0.1738\n",
            "[13:19:35.428587] Epoch: [47] Total time: 0:00:00 (0.1986 s / it)\n",
            "[13:19:35.428710] [Val] averaged stats: loss: 1.1625 (1.1112)  MAE: 0.1562 (0.1521)  MSE: 0.0925 (0.0866)\n",
            "[13:19:35.429265] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 15 out of 20\n",
            "[13:19:35.430140] [Time] 19.2s 16.6m/33.8m\n",
            "\n",
            "[13:19:35.430182] ~~~ Epoch 48/100 ~~~\n",
            "\n",
            "[13:19:36.260738] Epoch: [48]  [ 0/45]  eta: 0:00:37  loss: 0.7339 (0.7339)  MAE: 0.1423 (0.1423)  MSE: 0.1155 (0.1155)  lr: 0.000100  iter-time: 0.8282\n",
            "[13:19:40.300993] Epoch: [48]  [10/45]  eta: 0:00:15  loss: 0.9613 (0.9118)  MAE: 0.1794 (0.1808)  MSE: 0.1302 (0.1261)  lr: 0.000100  iter-time: 0.4423\n",
            "[13:19:44.299066] Epoch: [48]  [20/45]  eta: 0:00:10  loss: 0.8219 (0.8419)  MAE: 0.1821 (0.1844)  MSE: 0.1367 (0.1422)  lr: 0.000100  iter-time: 0.4016\n",
            "[13:19:48.281640] Epoch: [48]  [30/45]  eta: 0:00:06  loss: 0.8003 (0.8637)  MAE: 0.1858 (0.1864)  MSE: 0.1514 (0.1446)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:19:52.265051] Epoch: [48]  [40/45]  eta: 0:00:02  loss: 0.8453 (0.8705)  MAE: 0.1858 (0.1851)  MSE: 0.1472 (0.1376)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:19:53.679794] Epoch: [48]  [44/45]  eta: 0:00:00  loss: 0.8453 (0.8664)  MAE: 0.1846 (0.1854)  MSE: 0.1138 (0.1375)  lr: 0.000100  iter-time: 0.3893\n",
            "[13:19:53.831255] Epoch: [48] Total time: 0:00:18 (0.4089 s / it)\n",
            "[13:19:53.833121] [Train] averaged stats: loss: 0.8453 (0.8664)  MAE: 0.1846 (0.1854)  MSE: 0.1138 (0.1375)  lr: 0.000100\n",
            "[13:19:54.311825] Epoch: [48]  [0/5]  eta: 0:00:02  loss: 1.0583 (1.0583)  MAE: 0.1313 (0.1313)  MSE: 0.0559 (0.0559)  iter-time: 0.4749\n",
            "[13:19:54.805626] Epoch: [48]  [4/5]  eta: 0:00:00  loss: 1.1662 (1.1101)  MAE: 0.1758 (0.1702)  MSE: 0.1136 (0.1051)  iter-time: 0.1931\n",
            "[13:19:54.890633] Epoch: [48] Total time: 0:00:01 (0.2109 s / it)\n",
            "[13:19:54.891694] [Val] averaged stats: loss: 1.1662 (1.1101)  MAE: 0.1758 (0.1702)  MSE: 0.1136 (0.1051)\n",
            "[13:19:54.893547] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 16 out of 20\n",
            "[13:19:54.895984] [Time] 19.5s 16.9m/34.1m\n",
            "\n",
            "[13:19:54.896064] ~~~ Epoch 49/100 ~~~\n",
            "\n",
            "[13:19:55.488895] Epoch: [49]  [ 0/45]  eta: 0:00:26  loss: 0.8660 (0.8660)  MAE: 0.1663 (0.1663)  MSE: 0.1589 (0.1589)  lr: 0.000100  iter-time: 0.5905\n",
            "[13:19:59.467569] Epoch: [49]  [10/45]  eta: 0:00:14  loss: 0.8265 (0.8486)  MAE: 0.1958 (0.2046)  MSE: 0.1660 (0.1644)  lr: 0.000100  iter-time: 0.4151\n",
            "[13:20:03.436866] Epoch: [49]  [20/45]  eta: 0:00:10  loss: 0.7683 (0.7965)  MAE: 0.1958 (0.2010)  MSE: 0.1672 (0.1702)  lr: 0.000100  iter-time: 0.3972\n",
            "[13:20:07.424902] Epoch: [49]  [30/45]  eta: 0:00:06  loss: 0.7552 (0.7966)  MAE: 0.1956 (0.2003)  MSE: 0.1670 (0.1680)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:20:11.396326] Epoch: [49]  [40/45]  eta: 0:00:02  loss: 0.8413 (0.8168)  MAE: 0.1956 (0.1982)  MSE: 0.1501 (0.1584)  lr: 0.000100  iter-time: 0.3978\n",
            "[13:20:12.803500] Epoch: [49]  [44/45]  eta: 0:00:00  loss: 0.8431 (0.8304)  MAE: 0.1935 (0.1980)  MSE: 0.1259 (0.1570)  lr: 0.000100  iter-time: 0.3889\n",
            "[13:20:12.897134] Epoch: [49] Total time: 0:00:18 (0.4000 s / it)\n",
            "[13:20:12.899573] [Train] averaged stats: loss: 0.8431 (0.8304)  MAE: 0.1935 (0.1980)  MSE: 0.1259 (0.1570)  lr: 0.000100\n",
            "[13:20:13.208179] Epoch: [49]  [0/5]  eta: 0:00:01  loss: 1.0626 (1.0626)  MAE: 0.1333 (0.1333)  MSE: 0.0577 (0.0577)  iter-time: 0.3056\n",
            "[13:20:13.700748] Epoch: [49]  [4/5]  eta: 0:00:00  loss: 1.1362 (1.1013)  MAE: 0.1802 (0.1770)  MSE: 0.1166 (0.1105)  iter-time: 0.1595\n",
            "[13:20:13.778557] Epoch: [49] Total time: 0:00:00 (0.1753 s / it)\n",
            "[13:20:13.778684] [Val] averaged stats: loss: 1.1362 (1.1013)  MAE: 0.1802 (0.1770)  MSE: 0.1166 (0.1105)\n",
            "[13:20:13.781080] [Val] best loss: 1.1000 best  MAE: 0.1534 MSE: 0.0769 \n",
            "EarlyStopping counter: 17 out of 20\n",
            "[13:20:13.783455] [Time] 18.9s 17.2m/33.6m\n",
            "\n",
            "[13:20:13.783520] ~~~ Epoch 50/100 ~~~\n",
            "\n",
            "[13:20:14.371715] Epoch: [50]  [ 0/45]  eta: 0:00:26  loss: 1.2824 (1.2824)  MAE: 0.1672 (0.1672)  MSE: 0.1539 (0.1539)  lr: 0.000100  iter-time: 0.5845\n",
            "[13:20:18.351526] Epoch: [50]  [10/45]  eta: 0:00:14  loss: 0.7795 (0.8626)  MAE: 0.1995 (0.2059)  MSE: 0.1539 (0.1550)  lr: 0.000100  iter-time: 0.4148\n",
            "[13:20:22.331508] Epoch: [50]  [20/45]  eta: 0:00:10  loss: 0.7797 (0.8522)  MAE: 0.1938 (0.1979)  MSE: 0.1501 (0.1530)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:20:26.339523] Epoch: [50]  [30/45]  eta: 0:00:06  loss: 0.7797 (0.8238)  MAE: 0.1827 (0.1928)  MSE: 0.1368 (0.1456)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:20:30.328915] Epoch: [50]  [40/45]  eta: 0:00:02  loss: 0.7524 (0.8377)  MAE: 0.1767 (0.1885)  MSE: 0.1169 (0.1365)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:20:31.737560] Epoch: [50]  [44/45]  eta: 0:00:00  loss: 0.7524 (0.8290)  MAE: 0.1767 (0.1884)  MSE: 0.1011 (0.1358)  lr: 0.000100  iter-time: 0.3900\n",
            "[13:20:31.845203] Epoch: [50] Total time: 0:00:18 (0.4013 s / it)\n",
            "[13:20:31.846205] [Train] averaged stats: loss: 0.7524 (0.8290)  MAE: 0.1767 (0.1884)  MSE: 0.1011 (0.1358)  lr: 0.000100\n",
            "[13:20:32.197966] Epoch: [50]  [0/5]  eta: 0:00:01  loss: 1.0783 (1.0783)  MAE: 0.1292 (0.1292)  MSE: 0.0516 (0.0516)  iter-time: 0.3488\n",
            "[13:20:32.695445] Epoch: [50]  [4/5]  eta: 0:00:00  loss: 1.1174 (1.0959)  MAE: 0.1735 (0.1683)  MSE: 0.1053 (0.0963)  iter-time: 0.1691\n",
            "[13:20:32.778646] Epoch: [50] Total time: 0:00:00 (0.1860 s / it)\n",
            "[13:20:32.778781] [Val] averaged stats: loss: 1.1174 (1.0959)  MAE: 0.1735 (0.1683)  MSE: 0.1053 (0.0963)\n",
            "[13:20:32.781260] Val loss improved from 1.0999525308609008 to 1.0958963274955749, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:20:32.842440] [Val] best loss: 1.0959 best  MAE: 0.1683 MSE: 0.0963 \n",
            "[13:20:32.845242] Creating training plots . . .\n",
            "[13:20:33.565948] [Time] 19.8s 17.5m/34.3m\n",
            "\n",
            "[13:20:33.566093] ~~~ Epoch 51/100 ~~~\n",
            "\n",
            "[13:20:34.182564] Epoch: [51]  [ 0/45]  eta: 0:00:27  loss: 1.0482 (1.0482)  MAE: 0.1623 (0.1623)  MSE: 0.1499 (0.1499)  lr: 0.000100  iter-time: 0.6126\n",
            "[13:20:38.160283] Epoch: [51]  [10/45]  eta: 0:00:14  loss: 0.9340 (0.9254)  MAE: 0.1941 (0.2038)  MSE: 0.1516 (0.1518)  lr: 0.000100  iter-time: 0.4172\n",
            "[13:20:42.164863] Epoch: [51]  [20/45]  eta: 0:00:10  loss: 0.9098 (0.8941)  MAE: 0.1910 (0.1966)  MSE: 0.1452 (0.1507)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:20:46.136356] Epoch: [51]  [30/45]  eta: 0:00:06  loss: 0.8196 (0.8528)  MAE: 0.1815 (0.1901)  MSE: 0.1207 (0.1406)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:20:50.121722] Epoch: [51]  [40/45]  eta: 0:00:02  loss: 0.8558 (0.8729)  MAE: 0.1736 (0.1847)  MSE: 0.1144 (0.1291)  lr: 0.000100  iter-time: 0.3976\n",
            "[13:20:51.527468] Epoch: [51]  [44/45]  eta: 0:00:00  loss: 0.8987 (0.8753)  MAE: 0.1682 (0.1833)  MSE: 0.0871 (0.1267)  lr: 0.000100  iter-time: 0.3886\n",
            "[13:20:51.624294] Epoch: [51] Total time: 0:00:18 (0.4012 s / it)\n",
            "[13:20:51.626642] [Train] averaged stats: loss: 0.8987 (0.8753)  MAE: 0.1682 (0.1833)  MSE: 0.0871 (0.1267)  lr: 0.000100\n",
            "[13:20:51.957232] Epoch: [51]  [0/5]  eta: 0:00:01  loss: 1.0615 (1.0615)  MAE: 0.1164 (0.1164)  MSE: 0.0405 (0.0405)  iter-time: 0.3274\n",
            "[13:20:52.452681] Epoch: [51]  [4/5]  eta: 0:00:00  loss: 1.0876 (1.0962)  MAE: 0.1570 (0.1525)  MSE: 0.0826 (0.0766)  iter-time: 0.1644\n",
            "[13:20:52.533279] Epoch: [51] Total time: 0:00:00 (0.1808 s / it)\n",
            "[13:20:52.533448] [Val] averaged stats: loss: 1.0876 (1.0962)  MAE: 0.1570 (0.1525)  MSE: 0.0826 (0.0766)\n",
            "[13:20:52.535959] [Val] best loss: 1.0959 best  MAE: 0.1683 MSE: 0.0963 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:20:52.538301] [Time] 19.0s 17.8m/33.6m\n",
            "\n",
            "[13:20:52.538360] ~~~ Epoch 52/100 ~~~\n",
            "\n",
            "[13:20:53.190328] Epoch: [52]  [ 0/45]  eta: 0:00:29  loss: 0.8670 (0.8670)  MAE: 0.1469 (0.1469)  MSE: 0.1099 (0.1099)  lr: 0.000100  iter-time: 0.6498\n",
            "[13:20:57.214053] Epoch: [52]  [10/45]  eta: 0:00:14  loss: 0.8429 (0.8098)  MAE: 0.1691 (0.1757)  MSE: 0.1098 (0.1067)  lr: 0.000100  iter-time: 0.4247\n",
            "[13:21:01.221484] Epoch: [52]  [20/45]  eta: 0:00:10  loss: 0.8315 (0.8470)  MAE: 0.1708 (0.1761)  MSE: 0.1098 (0.1153)  lr: 0.000100  iter-time: 0.4014\n",
            "[13:21:05.203088] Epoch: [52]  [30/45]  eta: 0:00:06  loss: 0.8597 (0.8594)  MAE: 0.1848 (0.1822)  MSE: 0.1255 (0.1251)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:21:09.188111] Epoch: [52]  [40/45]  eta: 0:00:02  loss: 0.8446 (0.8678)  MAE: 0.1974 (0.1879)  MSE: 0.1290 (0.1289)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:21:10.601509] Epoch: [52]  [44/45]  eta: 0:00:00  loss: 0.7565 (0.8446)  MAE: 0.1989 (0.1900)  MSE: 0.1290 (0.1317)  lr: 0.000100  iter-time: 0.3892\n",
            "[13:21:10.760177] Epoch: [52] Total time: 0:00:18 (0.4049 s / it)\n",
            "[13:21:10.761158] [Train] averaged stats: loss: 0.7565 (0.8446)  MAE: 0.1989 (0.1900)  MSE: 0.1290 (0.1317)  lr: 0.000100\n",
            "[13:21:11.311219] Epoch: [52]  [0/5]  eta: 0:00:02  loss: 1.0499 (1.0499)  MAE: 0.1472 (0.1472)  MSE: 0.0667 (0.0667)  iter-time: 0.5460\n",
            "[13:21:11.807670] Epoch: [52]  [4/5]  eta: 0:00:00  loss: 1.1580 (1.1139)  MAE: 0.1979 (0.1922)  MSE: 0.1354 (0.1245)  iter-time: 0.2080\n",
            "[13:21:11.924006] Epoch: [52] Total time: 0:00:01 (0.2319 s / it)\n",
            "[13:21:11.924162] [Val] averaged stats: loss: 1.1580 (1.1139)  MAE: 0.1979 (0.1922)  MSE: 0.1354 (0.1245)\n",
            "[13:21:11.924755] [Val] best loss: 1.0959 best  MAE: 0.1683 MSE: 0.0963 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:21:11.929726] [Time] 19.4s 18.2m/34.0m\n",
            "\n",
            "[13:21:11.929774] ~~~ Epoch 53/100 ~~~\n",
            "\n",
            "[13:21:12.756900] Epoch: [53]  [ 0/45]  eta: 0:00:37  loss: 1.0354 (1.0354)  MAE: 0.1869 (0.1869)  MSE: 0.1858 (0.1858)  lr: 0.000100  iter-time: 0.8247\n",
            "[13:21:16.726683] Epoch: [53]  [10/45]  eta: 0:00:15  loss: 0.7571 (0.7930)  MAE: 0.2194 (0.2276)  MSE: 0.1888 (0.1859)  lr: 0.000100  iter-time: 0.4357\n",
            "[13:21:20.712513] Epoch: [53]  [20/45]  eta: 0:00:10  loss: 0.7992 (0.8339)  MAE: 0.2179 (0.2243)  MSE: 0.1924 (0.1980)  lr: 0.000100  iter-time: 0.3976\n",
            "[13:21:24.709369] Epoch: [53]  [30/45]  eta: 0:00:06  loss: 0.8767 (0.8573)  MAE: 0.2139 (0.2191)  MSE: 0.1772 (0.1877)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:21:28.718201] Epoch: [53]  [40/45]  eta: 0:00:02  loss: 0.8553 (0.8701)  MAE: 0.1938 (0.2111)  MSE: 0.1445 (0.1697)  lr: 0.000100  iter-time: 0.4001\n",
            "[13:21:30.129112] Epoch: [53]  [44/45]  eta: 0:00:00  loss: 0.8640 (0.8679)  MAE: 0.1894 (0.2083)  MSE: 0.1053 (0.1639)  lr: 0.000100  iter-time: 0.3908\n",
            "[13:21:30.274797] Epoch: [53] Total time: 0:00:18 (0.4076 s / it)\n",
            "[13:21:30.276019] [Train] averaged stats: loss: 0.8640 (0.8679)  MAE: 0.1894 (0.2083)  MSE: 0.1053 (0.1639)  lr: 0.000100\n",
            "[13:21:30.777643] Epoch: [53]  [0/5]  eta: 0:00:02  loss: 1.0384 (1.0384)  MAE: 0.1253 (0.1253)  MSE: 0.0431 (0.0431)  iter-time: 0.4980\n",
            "[13:21:31.274563] Epoch: [53]  [4/5]  eta: 0:00:00  loss: 1.1173 (1.0957)  MAE: 0.1686 (0.1633)  MSE: 0.0882 (0.0816)  iter-time: 0.1988\n",
            "[13:21:31.357196] Epoch: [53] Total time: 0:00:01 (0.2157 s / it)\n",
            "[13:21:31.357317] [Val] averaged stats: loss: 1.1173 (1.0957)  MAE: 0.1686 (0.1633)  MSE: 0.0882 (0.0816)\n",
            "[13:21:31.359757] Val loss improved from 1.0958963274955749 to 1.0956735491752625, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:21:31.411907] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "[13:21:31.414614] [Time] 19.5s 18.5m/34.1m\n",
            "\n",
            "[13:21:31.414690] ~~~ Epoch 54/100 ~~~\n",
            "\n",
            "[13:21:32.095288] Epoch: [54]  [ 0/45]  eta: 0:00:30  loss: 0.8456 (0.8456)  MAE: 0.1564 (0.1564)  MSE: 0.1135 (0.1135)  lr: 0.000100  iter-time: 0.6772\n",
            "[13:21:36.081774] Epoch: [54]  [10/45]  eta: 0:00:14  loss: 0.9100 (0.8857)  MAE: 0.1782 (0.1844)  MSE: 0.1128 (0.1095)  lr: 0.000100  iter-time: 0.4238\n",
            "[13:21:40.064252] Epoch: [54]  [20/45]  eta: 0:00:10  loss: 0.8250 (0.8762)  MAE: 0.1778 (0.1798)  MSE: 0.1065 (0.1114)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:21:44.070671] Epoch: [54]  [30/45]  eta: 0:00:06  loss: 0.8250 (0.8802)  MAE: 0.1782 (0.1802)  MSE: 0.1118 (0.1144)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:21:48.062867] Epoch: [54]  [40/45]  eta: 0:00:02  loss: 0.8213 (0.8600)  MAE: 0.1806 (0.1810)  MSE: 0.1067 (0.1136)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:21:49.472890] Epoch: [54]  [44/45]  eta: 0:00:00  loss: 0.8046 (0.8663)  MAE: 0.1806 (0.1818)  MSE: 0.1036 (0.1148)  lr: 0.000100  iter-time: 0.3903\n",
            "[13:21:49.567414] Epoch: [54] Total time: 0:00:18 (0.4033 s / it)\n",
            "[13:21:49.569897] [Train] averaged stats: loss: 0.8046 (0.8663)  MAE: 0.1806 (0.1818)  MSE: 0.1036 (0.1148)  lr: 0.000100\n",
            "[13:21:49.878722] Epoch: [54]  [0/5]  eta: 0:00:01  loss: 1.0580 (1.0580)  MAE: 0.1330 (0.1330)  MSE: 0.0528 (0.0528)  iter-time: 0.3058\n",
            "[13:21:50.371132] Epoch: [54]  [4/5]  eta: 0:00:00  loss: 1.1551 (1.1111)  MAE: 0.1766 (0.1710)  MSE: 0.1068 (0.0970)  iter-time: 0.1592\n",
            "[13:21:50.463319] Epoch: [54] Total time: 0:00:00 (0.1782 s / it)\n",
            "[13:21:50.463460] [Val] averaged stats: loss: 1.1551 (1.1111)  MAE: 0.1766 (0.1710)  MSE: 0.1068 (0.0970)\n",
            "[13:21:50.466368] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:21:50.468781] [Time] 19.1s 18.8m/33.7m\n",
            "\n",
            "[13:21:50.469863] ~~~ Epoch 55/100 ~~~\n",
            "\n",
            "[13:21:51.212513] Epoch: [55]  [ 0/45]  eta: 0:00:33  loss: 0.8340 (0.8340)  MAE: 0.1757 (0.1757)  MSE: 0.1547 (0.1547)  lr: 0.000100  iter-time: 0.7403\n",
            "[13:21:55.197841] Epoch: [55]  [10/45]  eta: 0:00:15  loss: 0.8871 (0.8627)  MAE: 0.2106 (0.2150)  MSE: 0.1701 (0.1644)  lr: 0.000100  iter-time: 0.4294\n",
            "[13:21:59.210417] Epoch: [55]  [20/45]  eta: 0:00:10  loss: 0.8764 (0.8535)  MAE: 0.2187 (0.2205)  MSE: 0.1872 (0.1963)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:22:03.237908] Epoch: [55]  [30/45]  eta: 0:00:06  loss: 0.8468 (0.8745)  MAE: 0.2187 (0.2148)  MSE: 0.1876 (0.1843)  lr: 0.000100  iter-time: 0.4017\n",
            "[13:22:07.229611] Epoch: [55]  [40/45]  eta: 0:00:02  loss: 0.8468 (0.8683)  MAE: 0.1849 (0.2044)  MSE: 0.1141 (0.1619)  lr: 0.000100  iter-time: 0.4006\n",
            "[13:22:08.645112] Epoch: [55]  [44/45]  eta: 0:00:00  loss: 0.8124 (0.8573)  MAE: 0.1775 (0.2019)  MSE: 0.0909 (0.1558)  lr: 0.000100  iter-time: 0.3905\n",
            "[13:22:08.739576] Epoch: [55] Total time: 0:00:18 (0.4060 s / it)\n",
            "[13:22:08.740084] [Train] averaged stats: loss: 0.8124 (0.8573)  MAE: 0.1775 (0.2019)  MSE: 0.0909 (0.1558)  lr: 0.000100\n",
            "[13:22:09.082558] Epoch: [55]  [0/5]  eta: 0:00:01  loss: 1.0128 (1.0128)  MAE: 0.1225 (0.1225)  MSE: 0.0402 (0.0402)  iter-time: 0.3405\n",
            "[13:22:09.575652] Epoch: [55]  [4/5]  eta: 0:00:00  loss: 1.1201 (1.0995)  MAE: 0.1639 (0.1596)  MSE: 0.0793 (0.0745)  iter-time: 0.1666\n",
            "[13:22:09.653128] Epoch: [55] Total time: 0:00:00 (0.1823 s / it)\n",
            "[13:22:09.653259] [Val] averaged stats: loss: 1.1201 (1.0995)  MAE: 0.1639 (0.1596)  MSE: 0.0793 (0.0745)\n",
            "[13:22:09.655577] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "[13:22:09.657763] Creating training plots . . .\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:22:10.079517] [Time] 19.6s 19.1m/34.2m\n",
            "\n",
            "[13:22:10.079574] ~~~ Epoch 56/100 ~~~\n",
            "\n",
            "[13:22:10.807904] Epoch: [56]  [ 0/45]  eta: 0:00:32  loss: 0.9387 (0.9387)  MAE: 0.1555 (0.1555)  MSE: 0.1008 (0.1008)  lr: 0.000100  iter-time: 0.7242\n",
            "[13:22:14.799451] Epoch: [56]  [10/45]  eta: 0:00:14  loss: 0.9387 (0.8996)  MAE: 0.1797 (0.1846)  MSE: 0.1109 (0.1080)  lr: 0.000100  iter-time: 0.4286\n",
            "[13:22:18.816432] Epoch: [56]  [20/45]  eta: 0:00:10  loss: 0.8322 (0.8578)  MAE: 0.1797 (0.1832)  MSE: 0.1151 (0.1185)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:22:22.807436] Epoch: [56]  [30/45]  eta: 0:00:06  loss: 0.7695 (0.8543)  MAE: 0.1857 (0.1845)  MSE: 0.1301 (0.1233)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:22:26.794753] Epoch: [56]  [40/45]  eta: 0:00:02  loss: 0.7695 (0.8421)  MAE: 0.1834 (0.1834)  MSE: 0.1234 (0.1200)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:22:28.202921] Epoch: [56]  [44/45]  eta: 0:00:00  loss: 0.7717 (0.8583)  MAE: 0.1802 (0.1836)  MSE: 0.1083 (0.1203)  lr: 0.000100  iter-time: 0.3892\n",
            "[13:22:28.297982] Epoch: [56] Total time: 0:00:18 (0.4048 s / it)\n",
            "[13:22:28.298312] [Train] averaged stats: loss: 0.7717 (0.8583)  MAE: 0.1802 (0.1836)  MSE: 0.1083 (0.1203)  lr: 0.000100\n",
            "[13:22:28.711879] Epoch: [56]  [0/5]  eta: 0:00:02  loss: 1.0167 (1.0167)  MAE: 0.1275 (0.1275)  MSE: 0.0508 (0.0508)  iter-time: 0.4101\n",
            "[13:22:29.203761] Epoch: [56]  [4/5]  eta: 0:00:00  loss: 1.1549 (1.1153)  MAE: 0.1677 (0.1651)  MSE: 0.1000 (0.0944)  iter-time: 0.1800\n",
            "[13:22:29.284703] Epoch: [56] Total time: 0:00:00 (0.1967 s / it)\n",
            "[13:22:29.285629] [Val] averaged stats: loss: 1.1549 (1.1153)  MAE: 0.1677 (0.1651)  MSE: 0.1000 (0.0944)\n",
            "[13:22:29.287550] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:22:29.289826] [Time] 19.2s 19.5m/33.9m\n",
            "\n",
            "[13:22:29.289885] ~~~ Epoch 57/100 ~~~\n",
            "\n",
            "[13:22:29.997597] Epoch: [57]  [ 0/45]  eta: 0:00:31  loss: 0.5359 (0.5359)  MAE: 0.1645 (0.1645)  MSE: 0.1290 (0.1290)  lr: 0.000100  iter-time: 0.7054\n",
            "[13:22:34.022360] Epoch: [57]  [10/45]  eta: 0:00:15  loss: 0.8834 (0.8171)  MAE: 0.1866 (0.1923)  MSE: 0.1324 (0.1345)  lr: 0.000100  iter-time: 0.4299\n",
            "[13:22:38.064193] Epoch: [57]  [20/45]  eta: 0:00:10  loss: 0.8907 (0.8842)  MAE: 0.1936 (0.1961)  MSE: 0.1586 (0.1553)  lr: 0.000100  iter-time: 0.4031\n",
            "[13:22:42.048130] Epoch: [57]  [30/45]  eta: 0:00:06  loss: 0.8745 (0.8733)  MAE: 0.2002 (0.2001)  MSE: 0.1816 (0.1709)  lr: 0.000100  iter-time: 0.4011\n",
            "[13:22:46.033774] Epoch: [57]  [40/45]  eta: 0:00:02  loss: 0.8616 (0.8818)  MAE: 0.1962 (0.1982)  MSE: 0.1794 (0.1688)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:22:47.446723] Epoch: [57]  [44/45]  eta: 0:00:00  loss: 0.7928 (0.8836)  MAE: 0.1946 (0.1983)  MSE: 0.1501 (0.1696)  lr: 0.000100  iter-time: 0.3891\n",
            "[13:22:47.556543] Epoch: [57] Total time: 0:00:18 (0.4059 s / it)\n",
            "[13:22:47.557766] [Train] averaged stats: loss: 0.7928 (0.8836)  MAE: 0.1946 (0.1983)  MSE: 0.1501 (0.1696)  lr: 0.000100\n",
            "[13:22:47.920713] Epoch: [57]  [0/5]  eta: 0:00:01  loss: 0.9979 (0.9979)  MAE: 0.1357 (0.1357)  MSE: 0.0708 (0.0708)  iter-time: 0.3590\n",
            "[13:22:48.410096] Epoch: [57]  [4/5]  eta: 0:00:00  loss: 1.1593 (1.1459)  MAE: 0.1801 (0.1770)  MSE: 0.1426 (0.1334)  iter-time: 0.1695\n",
            "[13:22:48.544963] Epoch: [57] Total time: 0:00:00 (0.1968 s / it)\n",
            "[13:22:48.545112] [Val] averaged stats: loss: 1.1593 (1.1459)  MAE: 0.1801 (0.1770)  MSE: 0.1426 (0.1334)\n",
            "[13:22:48.545660] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:22:48.550314] [Time] 19.3s 19.8m/33.9m\n",
            "\n",
            "[13:22:48.550360] ~~~ Epoch 58/100 ~~~\n",
            "\n",
            "[13:22:49.450679] Epoch: [58]  [ 0/45]  eta: 0:00:40  loss: 0.8046 (0.8046)  MAE: 0.1750 (0.1750)  MSE: 0.2148 (0.2148)  lr: 0.000100  iter-time: 0.8948\n",
            "[13:22:53.462898] Epoch: [58]  [10/45]  eta: 0:00:15  loss: 0.8046 (0.8188)  MAE: 0.2015 (0.2039)  MSE: 0.1978 (0.1882)  lr: 0.000100  iter-time: 0.4460\n",
            "[13:22:57.443831] Epoch: [58]  [20/45]  eta: 0:00:10  loss: 0.7868 (0.8495)  MAE: 0.1918 (0.1980)  MSE: 0.1819 (0.1930)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:23:01.427473] Epoch: [58]  [30/45]  eta: 0:00:06  loss: 0.8373 (0.8772)  MAE: 0.1876 (0.1941)  MSE: 0.1695 (0.1819)  lr: 0.000100  iter-time: 0.3980\n",
            "[13:23:05.406460] Epoch: [58]  [40/45]  eta: 0:00:02  loss: 0.8701 (0.9068)  MAE: 0.1838 (0.1900)  MSE: 0.1342 (0.1653)  lr: 0.000100  iter-time: 0.3980\n",
            "[13:23:06.820386] Epoch: [58]  [44/45]  eta: 0:00:00  loss: 0.8701 (0.9022)  MAE: 0.1765 (0.1889)  MSE: 0.1040 (0.1602)  lr: 0.000100  iter-time: 0.3891\n",
            "[13:23:06.986636] Epoch: [58] Total time: 0:00:18 (0.4097 s / it)\n",
            "[13:23:06.988198] [Train] averaged stats: loss: 0.8701 (0.9022)  MAE: 0.1765 (0.1889)  MSE: 0.1040 (0.1602)  lr: 0.000100\n",
            "[13:23:07.477861] Epoch: [58]  [0/5]  eta: 0:00:02  loss: 1.0560 (1.0560)  MAE: 0.1272 (0.1272)  MSE: 0.0431 (0.0431)  iter-time: 0.4851\n",
            "[13:23:07.971562] Epoch: [58]  [4/5]  eta: 0:00:00  loss: 1.1477 (1.1040)  MAE: 0.1662 (0.1613)  MSE: 0.0840 (0.0768)  iter-time: 0.1952\n",
            "[13:23:08.051017] Epoch: [58] Total time: 0:00:01 (0.2118 s / it)\n",
            "[13:23:08.051185] [Val] averaged stats: loss: 1.1477 (1.1040)  MAE: 0.1662 (0.1613)  MSE: 0.0840 (0.0768)\n",
            "[13:23:08.053810] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:23:08.056407] [Time] 19.5s 20.1m/34.1m\n",
            "\n",
            "[13:23:08.056476] ~~~ Epoch 59/100 ~~~\n",
            "\n",
            "[13:23:08.740793] Epoch: [59]  [ 0/45]  eta: 0:00:30  loss: 0.7737 (0.7737)  MAE: 0.1576 (0.1576)  MSE: 0.1212 (0.1212)  lr: 0.000100  iter-time: 0.6823\n",
            "[13:23:12.725417] Epoch: [59]  [10/45]  eta: 0:00:14  loss: 0.8189 (0.8715)  MAE: 0.1828 (0.1837)  MSE: 0.1146 (0.1111)  lr: 0.000100  iter-time: 0.4240\n",
            "[13:23:16.708942] Epoch: [59]  [20/45]  eta: 0:00:10  loss: 0.8274 (0.8726)  MAE: 0.1733 (0.1777)  MSE: 0.1089 (0.1140)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:23:20.704668] Epoch: [59]  [30/45]  eta: 0:00:06  loss: 0.8274 (0.8550)  MAE: 0.1724 (0.1765)  MSE: 0.1121 (0.1128)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:23:24.707914] Epoch: [59]  [40/45]  eta: 0:00:02  loss: 0.8723 (0.8580)  MAE: 0.1715 (0.1739)  MSE: 0.0955 (0.1074)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:23:26.119383] Epoch: [59]  [44/45]  eta: 0:00:00  loss: 0.9219 (0.8589)  MAE: 0.1715 (0.1742)  MSE: 0.0815 (0.1073)  lr: 0.000100  iter-time: 0.3903\n",
            "[13:23:26.213330] Epoch: [59] Total time: 0:00:18 (0.4035 s / it)\n",
            "[13:23:26.214556] [Train] averaged stats: loss: 0.9219 (0.8589)  MAE: 0.1715 (0.1742)  MSE: 0.0815 (0.1073)  lr: 0.000100\n",
            "[13:23:26.548640] Epoch: [59]  [0/5]  eta: 0:00:01  loss: 1.0405 (1.0405)  MAE: 0.1297 (0.1297)  MSE: 0.0486 (0.0486)  iter-time: 0.3297\n",
            "[13:23:27.045130] Epoch: [59]  [4/5]  eta: 0:00:00  loss: 1.1485 (1.1061)  MAE: 0.1679 (0.1644)  MSE: 0.0921 (0.0860)  iter-time: 0.1651\n",
            "[13:23:27.124156] Epoch: [59] Total time: 0:00:00 (0.1812 s / it)\n",
            "[13:23:27.124432] [Val] averaged stats: loss: 1.1485 (1.1061)  MAE: 0.1679 (0.1644)  MSE: 0.0921 (0.0860)\n",
            "[13:23:27.126901] [Val] best loss: 1.0957 best  MAE: 0.1633 MSE: 0.0816 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:23:27.129358] [Time] 19.1s 20.4m/33.8m\n",
            "\n",
            "[13:23:27.130321] ~~~ Epoch 60/100 ~~~\n",
            "\n",
            "[13:23:27.785885] Epoch: [60]  [ 0/45]  eta: 0:00:29  loss: 0.7531 (0.7531)  MAE: 0.1639 (0.1639)  MSE: 0.1358 (0.1358)  lr: 0.000100  iter-time: 0.6535\n",
            "[13:23:31.787997] Epoch: [60]  [10/45]  eta: 0:00:14  loss: 0.9028 (0.8892)  MAE: 0.1899 (0.1947)  MSE: 0.1323 (0.1289)  lr: 0.000100  iter-time: 0.4231\n",
            "[13:23:35.778210] Epoch: [60]  [20/45]  eta: 0:00:10  loss: 0.8402 (0.8132)  MAE: 0.1973 (0.1994)  MSE: 0.1479 (0.1501)  lr: 0.000100  iter-time: 0.3994\n",
            "[13:23:39.803428] Epoch: [60]  [30/45]  eta: 0:00:06  loss: 0.7563 (0.8172)  MAE: 0.1973 (0.1984)  MSE: 0.1628 (0.1504)  lr: 0.000100  iter-time: 0.4006\n",
            "[13:23:43.808853] Epoch: [60]  [40/45]  eta: 0:00:02  loss: 0.8335 (0.8478)  MAE: 0.1813 (0.1912)  MSE: 0.1280 (0.1381)  lr: 0.000100  iter-time: 0.4013\n",
            "[13:23:45.219799] Epoch: [60]  [44/45]  eta: 0:00:00  loss: 0.8048 (0.8549)  MAE: 0.1719 (0.1893)  MSE: 0.1014 (0.1352)  lr: 0.000100  iter-time: 0.3918\n",
            "[13:23:45.310791] Epoch: [60] Total time: 0:00:18 (0.4040 s / it)\n",
            "[13:23:45.312739] [Train] averaged stats: loss: 0.8048 (0.8549)  MAE: 0.1719 (0.1893)  MSE: 0.1014 (0.1352)  lr: 0.000100\n",
            "[13:23:45.712165] Epoch: [60]  [0/5]  eta: 0:00:01  loss: 1.0314 (1.0314)  MAE: 0.1222 (0.1222)  MSE: 0.0439 (0.0439)  iter-time: 0.3966\n",
            "[13:23:46.204788] Epoch: [60]  [4/5]  eta: 0:00:00  loss: 1.1258 (1.0930)  MAE: 0.1583 (0.1549)  MSE: 0.0849 (0.0793)  iter-time: 0.1777\n",
            "[13:23:46.283407] Epoch: [60] Total time: 0:00:00 (0.1937 s / it)\n",
            "[13:23:46.283526] [Val] averaged stats: loss: 1.1258 (1.0930)  MAE: 0.1583 (0.1549)  MSE: 0.0849 (0.0793)\n",
            "[13:23:46.286054] Val loss improved from 1.0956735491752625 to 1.0929643273353578, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:23:46.338564] [Val] best loss: 1.0930 best  MAE: 0.1549 MSE: 0.0793 \n",
            "[13:23:46.341276] Creating training plots . . .\n",
            "[13:23:46.767591] [Time] 19.6s 20.7m/34.2m\n",
            "\n",
            "[13:23:46.768504] ~~~ Epoch 61/100 ~~~\n",
            "\n",
            "[13:23:47.442909] Epoch: [61]  [ 0/45]  eta: 0:00:30  loss: 1.1475 (1.1475)  MAE: 0.1494 (0.1494)  MSE: 0.1138 (0.1138)  lr: 0.000100  iter-time: 0.6710\n",
            "[13:23:51.435774] Epoch: [61]  [10/45]  eta: 0:00:14  loss: 0.7824 (0.8392)  MAE: 0.1730 (0.1767)  MSE: 0.1114 (0.1110)  lr: 0.000100  iter-time: 0.4239\n",
            "[13:23:55.440685] Epoch: [61]  [20/45]  eta: 0:00:10  loss: 0.8037 (0.8414)  MAE: 0.1730 (0.1758)  MSE: 0.1114 (0.1175)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:23:59.476626] Epoch: [61]  [30/45]  eta: 0:00:06  loss: 0.8093 (0.8411)  MAE: 0.1702 (0.1746)  MSE: 0.1149 (0.1125)  lr: 0.000100  iter-time: 0.4019\n",
            "[13:24:03.467825] Epoch: [61]  [40/45]  eta: 0:00:02  loss: 0.8339 (0.8531)  MAE: 0.1652 (0.1707)  MSE: 0.0901 (0.1028)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:24:04.875224] Epoch: [61]  [44/45]  eta: 0:00:00  loss: 0.8491 (0.8662)  MAE: 0.1631 (0.1705)  MSE: 0.0739 (0.1013)  lr: 0.000100  iter-time: 0.3909\n",
            "[13:24:04.974936] Epoch: [61] Total time: 0:00:18 (0.4045 s / it)\n",
            "[13:24:04.976691] [Train] averaged stats: loss: 0.8491 (0.8662)  MAE: 0.1631 (0.1705)  MSE: 0.0739 (0.1013)  lr: 0.000100\n",
            "[13:24:05.387012] Epoch: [61]  [0/5]  eta: 0:00:02  loss: 0.9702 (0.9702)  MAE: 0.1216 (0.1216)  MSE: 0.0396 (0.0396)  iter-time: 0.4041\n",
            "[13:24:05.876596] Epoch: [61]  [4/5]  eta: 0:00:00  loss: 1.1332 (1.0928)  MAE: 0.1621 (0.1584)  MSE: 0.0774 (0.0732)  iter-time: 0.1786\n",
            "[13:24:05.956293] Epoch: [61] Total time: 0:00:00 (0.1948 s / it)\n",
            "[13:24:05.957325] [Val] averaged stats: loss: 1.1332 (1.0928)  MAE: 0.1621 (0.1584)  MSE: 0.0774 (0.0732)\n",
            "[13:24:05.959226] Val loss improved from 1.0929643273353578 to 1.0927632689476012, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:24:06.010841] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "[13:24:06.012069] [Time] 19.2s 21.1m/33.9m\n",
            "\n",
            "[13:24:06.012173] ~~~ Epoch 62/100 ~~~\n",
            "\n",
            "[13:24:06.750915] Epoch: [62]  [ 0/45]  eta: 0:00:33  loss: 0.7663 (0.7663)  MAE: 0.1539 (0.1539)  MSE: 0.0941 (0.0941)  lr: 0.000100  iter-time: 0.7364\n",
            "[13:24:10.751693] Epoch: [62]  [10/45]  eta: 0:00:15  loss: 0.7663 (0.8330)  MAE: 0.1755 (0.1796)  MSE: 0.0990 (0.1003)  lr: 0.000100  iter-time: 0.4305\n",
            "[13:24:14.759561] Epoch: [62]  [20/45]  eta: 0:00:10  loss: 0.8041 (0.8344)  MAE: 0.1750 (0.1760)  MSE: 0.1009 (0.1026)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:24:18.747219] Epoch: [62]  [30/45]  eta: 0:00:06  loss: 0.9226 (0.8651)  MAE: 0.1685 (0.1742)  MSE: 0.1009 (0.1016)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:24:22.733596] Epoch: [62]  [40/45]  eta: 0:00:02  loss: 0.9328 (0.8833)  MAE: 0.1628 (0.1700)  MSE: 0.0967 (0.0960)  lr: 0.000100  iter-time: 0.3986\n",
            "[13:24:24.136317] Epoch: [62]  [44/45]  eta: 0:00:00  loss: 0.9390 (0.9164)  MAE: 0.1606 (0.1688)  MSE: 0.0754 (0.0950)  lr: 0.000100  iter-time: 0.3885\n",
            "[13:24:24.230073] Epoch: [62] Total time: 0:00:18 (0.4048 s / it)\n",
            "[13:24:24.230256] [Train] averaged stats: loss: 0.9390 (0.9164)  MAE: 0.1606 (0.1688)  MSE: 0.0754 (0.0950)  lr: 0.000100\n",
            "[13:24:24.621525] Epoch: [62]  [0/5]  eta: 0:00:01  loss: 1.0419 (1.0419)  MAE: 0.1132 (0.1132)  MSE: 0.0353 (0.0353)  iter-time: 0.3894\n",
            "[13:24:25.114842] Epoch: [62]  [4/5]  eta: 0:00:00  loss: 1.1236 (1.1023)  MAE: 0.1482 (0.1440)  MSE: 0.0682 (0.0630)  iter-time: 0.1764\n",
            "[13:24:25.190723] Epoch: [62] Total time: 0:00:00 (0.1918 s / it)\n",
            "[13:24:25.190860] [Val] averaged stats: loss: 1.1236 (1.1023)  MAE: 0.1482 (0.1440)  MSE: 0.0682 (0.0630)\n",
            "[13:24:25.193319] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:24:25.195430] [Time] 19.2s 21.4m/33.9m\n",
            "\n",
            "[13:24:25.195492] ~~~ Epoch 63/100 ~~~\n",
            "\n",
            "[13:24:25.822258] Epoch: [63]  [ 0/45]  eta: 0:00:28  loss: 0.8857 (0.8857)  MAE: 0.1431 (0.1431)  MSE: 0.0923 (0.0923)  lr: 0.000100  iter-time: 0.6244\n",
            "[13:24:29.830745] Epoch: [63]  [10/45]  eta: 0:00:14  loss: 0.8016 (0.7999)  MAE: 0.1638 (0.1653)  MSE: 0.0923 (0.0931)  lr: 0.000100  iter-time: 0.4210\n",
            "[13:24:33.819351] Epoch: [63]  [20/45]  eta: 0:00:10  loss: 0.7410 (0.7707)  MAE: 0.1597 (0.1620)  MSE: 0.0930 (0.0971)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:24:37.801769] Epoch: [63]  [30/45]  eta: 0:00:06  loss: 0.7802 (0.8001)  MAE: 0.1585 (0.1609)  MSE: 0.0989 (0.0961)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:24:41.798926] Epoch: [63]  [40/45]  eta: 0:00:02  loss: 0.8666 (0.8374)  MAE: 0.1567 (0.1597)  MSE: 0.0896 (0.0943)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:24:43.209204] Epoch: [63]  [44/45]  eta: 0:00:00  loss: 0.8514 (0.8439)  MAE: 0.1567 (0.1607)  MSE: 0.0906 (0.0979)  lr: 0.000100  iter-time: 0.3897\n",
            "[13:24:43.398833] Epoch: [63] Total time: 0:00:18 (0.4045 s / it)\n",
            "[13:24:43.399834] [Train] averaged stats: loss: 0.8514 (0.8439)  MAE: 0.1567 (0.1607)  MSE: 0.0906 (0.0979)  lr: 0.000100\n",
            "[13:24:43.965541] Epoch: [63]  [0/5]  eta: 0:00:02  loss: 1.0141 (1.0141)  MAE: 0.1194 (0.1194)  MSE: 0.0513 (0.0513)  iter-time: 0.5574\n",
            "[13:24:44.460365] Epoch: [63]  [4/5]  eta: 0:00:00  loss: 1.1723 (1.1132)  MAE: 0.1569 (0.1533)  MSE: 0.1037 (0.0964)  iter-time: 0.2098\n",
            "[13:24:44.582392] Epoch: [63] Total time: 0:00:01 (0.2350 s / it)\n",
            "[13:24:44.582534] [Val] averaged stats: loss: 1.1723 (1.1132)  MAE: 0.1569 (0.1533)  MSE: 0.1037 (0.0964)\n",
            "[13:24:44.585383] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:24:44.587170] [Time] 19.4s 21.7m/34.0m\n",
            "\n",
            "[13:24:44.587217] ~~~ Epoch 64/100 ~~~\n",
            "\n",
            "[13:24:45.536577] Epoch: [64]  [ 0/45]  eta: 0:00:42  loss: 0.7169 (0.7169)  MAE: 0.1525 (0.1525)  MSE: 0.1571 (0.1571)  lr: 0.000100  iter-time: 0.9469\n",
            "[13:24:49.520439] Epoch: [64]  [10/45]  eta: 0:00:15  loss: 0.7637 (0.7981)  MAE: 0.1724 (0.1773)  MSE: 0.1458 (0.1432)  lr: 0.000100  iter-time: 0.4481\n",
            "[13:24:53.494379] Epoch: [64]  [20/45]  eta: 0:00:10  loss: 0.7637 (0.7869)  MAE: 0.1772 (0.1801)  MSE: 0.1485 (0.1554)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:24:57.504856] Epoch: [64]  [30/45]  eta: 0:00:06  loss: 0.8282 (0.8310)  MAE: 0.1888 (0.1837)  MSE: 0.1701 (0.1580)  lr: 0.000100  iter-time: 0.3991\n",
            "[13:25:01.500190] Epoch: [64]  [40/45]  eta: 0:00:02  loss: 0.9381 (0.8500)  MAE: 0.1802 (0.1814)  MSE: 0.1528 (0.1496)  lr: 0.000100  iter-time: 0.4001\n",
            "[13:25:02.912508] Epoch: [64]  [44/45]  eta: 0:00:00  loss: 0.8613 (0.8446)  MAE: 0.1783 (0.1811)  MSE: 0.1241 (0.1488)  lr: 0.000100  iter-time: 0.3906\n",
            "[13:25:03.007486] Epoch: [64] Total time: 0:00:18 (0.4093 s / it)\n",
            "[13:25:03.009054] [Train] averaged stats: loss: 0.8613 (0.8446)  MAE: 0.1783 (0.1811)  MSE: 0.1241 (0.1488)  lr: 0.000100\n",
            "[13:25:03.408083] Epoch: [64]  [0/5]  eta: 0:00:01  loss: 1.0010 (1.0010)  MAE: 0.1231 (0.1231)  MSE: 0.0573 (0.0573)  iter-time: 0.3963\n",
            "[13:25:03.898705] Epoch: [64]  [4/5]  eta: 0:00:00  loss: 1.1712 (1.1129)  MAE: 0.1638 (0.1595)  MSE: 0.1197 (0.1099)  iter-time: 0.1772\n",
            "[13:25:03.980182] Epoch: [64] Total time: 0:00:00 (0.1938 s / it)\n",
            "[13:25:03.980317] [Val] averaged stats: loss: 1.1712 (1.1129)  MAE: 0.1638 (0.1595)  MSE: 0.1197 (0.1099)\n",
            "[13:25:03.982847] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:25:03.985450] [Time] 19.4s 22.0m/34.0m\n",
            "\n",
            "[13:25:03.985508] ~~~ Epoch 65/100 ~~~\n",
            "\n",
            "[13:25:04.652357] Epoch: [65]  [ 0/45]  eta: 0:00:29  loss: 0.9466 (0.9466)  MAE: 0.1536 (0.1536)  MSE: 0.1578 (0.1578)  lr: 0.000100  iter-time: 0.6646\n",
            "[13:25:08.637259] Epoch: [65]  [10/45]  eta: 0:00:14  loss: 0.6938 (0.7043)  MAE: 0.1774 (0.1831)  MSE: 0.1519 (0.1474)  lr: 0.000100  iter-time: 0.4225\n",
            "[13:25:12.619078] Epoch: [65]  [20/45]  eta: 0:00:10  loss: 0.7300 (0.7756)  MAE: 0.1774 (0.1801)  MSE: 0.1466 (0.1489)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:25:16.615244] Epoch: [65]  [30/45]  eta: 0:00:06  loss: 0.9378 (0.8458)  MAE: 0.1743 (0.1796)  MSE: 0.1379 (0.1441)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:25:20.609202] Epoch: [65]  [40/45]  eta: 0:00:02  loss: 0.9603 (0.8596)  MAE: 0.1728 (0.1778)  MSE: 0.1237 (0.1359)  lr: 0.000100  iter-time: 0.3994\n",
            "[13:25:22.019156] Epoch: [65]  [44/45]  eta: 0:00:00  loss: 0.9361 (0.8536)  MAE: 0.1723 (0.1775)  MSE: 0.1014 (0.1340)  lr: 0.000100  iter-time: 0.3899\n",
            "[13:25:22.114808] Epoch: [65] Total time: 0:00:18 (0.4029 s / it)\n",
            "[13:25:22.115776] [Train] averaged stats: loss: 0.9361 (0.8536)  MAE: 0.1723 (0.1775)  MSE: 0.1014 (0.1340)  lr: 0.000100\n",
            "[13:25:22.457159] Epoch: [65]  [0/5]  eta: 0:00:01  loss: 0.9919 (0.9919)  MAE: 0.1228 (0.1228)  MSE: 0.0440 (0.0440)  iter-time: 0.3387\n",
            "[13:25:22.948461] Epoch: [65]  [4/5]  eta: 0:00:00  loss: 1.1374 (1.0957)  MAE: 0.1603 (0.1570)  MSE: 0.0859 (0.0809)  iter-time: 0.1656\n",
            "[13:25:23.025084] Epoch: [65] Total time: 0:00:00 (0.1814 s / it)\n",
            "[13:25:23.025890] [Val] averaged stats: loss: 1.1374 (1.0957)  MAE: 0.1603 (0.1570)  MSE: 0.0859 (0.0809)\n",
            "[13:25:23.027810] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "[13:25:23.030046] Creating training plots . . .\n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:25:23.456271] [Time] 19.5s 22.4m/34.0m\n",
            "\n",
            "[13:25:23.456343] ~~~ Epoch 66/100 ~~~\n",
            "\n",
            "[13:25:24.163605] Epoch: [66]  [ 0/45]  eta: 0:00:31  loss: 1.0082 (1.0082)  MAE: 0.1517 (0.1517)  MSE: 0.1221 (0.1221)  lr: 0.000100  iter-time: 0.7045\n",
            "[13:25:28.152911] Epoch: [66]  [10/45]  eta: 0:00:14  loss: 0.8254 (0.8077)  MAE: 0.1774 (0.1840)  MSE: 0.1221 (0.1211)  lr: 0.000100  iter-time: 0.4266\n",
            "[13:25:32.163704] Epoch: [66]  [20/45]  eta: 0:00:10  loss: 0.8157 (0.7988)  MAE: 0.1774 (0.1822)  MSE: 0.1222 (0.1277)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:25:36.171000] Epoch: [66]  [30/45]  eta: 0:00:06  loss: 0.8167 (0.8223)  MAE: 0.1810 (0.1823)  MSE: 0.1325 (0.1302)  lr: 0.000100  iter-time: 0.4007\n",
            "[13:25:40.160013] Epoch: [66]  [40/45]  eta: 0:00:02  loss: 0.8706 (0.8226)  MAE: 0.1835 (0.1821)  MSE: 0.1188 (0.1288)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:25:41.567266] Epoch: [66]  [44/45]  eta: 0:00:00  loss: 0.8502 (0.8200)  MAE: 0.1835 (0.1828)  MSE: 0.1194 (0.1307)  lr: 0.000100  iter-time: 0.3897\n",
            "[13:25:41.661176] Epoch: [66] Total time: 0:00:18 (0.4045 s / it)\n",
            "[13:25:41.663620] [Train] averaged stats: loss: 0.8502 (0.8200)  MAE: 0.1835 (0.1828)  MSE: 0.1194 (0.1307)  lr: 0.000100\n",
            "[13:25:41.972175] Epoch: [66]  [0/5]  eta: 0:00:01  loss: 1.0711 (1.0711)  MAE: 0.1285 (0.1285)  MSE: 0.0555 (0.0555)  iter-time: 0.3051\n",
            "[13:25:42.463917] Epoch: [66]  [4/5]  eta: 0:00:00  loss: 1.1711 (1.1120)  MAE: 0.1691 (0.1645)  MSE: 0.1086 (0.1011)  iter-time: 0.1592\n",
            "[13:25:42.559263] Epoch: [66] Total time: 0:00:00 (0.1786 s / it)\n",
            "[13:25:42.559409] [Val] averaged stats: loss: 1.1711 (1.1120)  MAE: 0.1691 (0.1645)  MSE: 0.1086 (0.1011)\n",
            "[13:25:42.561875] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:25:42.564427] [Time] 19.1s 22.7m/33.8m\n",
            "\n",
            "[13:25:42.564492] ~~~ Epoch 67/100 ~~~\n",
            "\n",
            "[13:25:43.307825] Epoch: [67]  [ 0/45]  eta: 0:00:33  loss: 0.8229 (0.8229)  MAE: 0.1705 (0.1705)  MSE: 0.1810 (0.1810)  lr: 0.000100  iter-time: 0.7411\n",
            "[13:25:47.309506] Epoch: [67]  [10/45]  eta: 0:00:15  loss: 0.8229 (0.8480)  MAE: 0.2035 (0.2043)  MSE: 0.1754 (0.1698)  lr: 0.000100  iter-time: 0.4310\n",
            "[13:25:51.335699] Epoch: [67]  [20/45]  eta: 0:00:10  loss: 0.8185 (0.8295)  MAE: 0.1988 (0.2016)  MSE: 0.1606 (0.1700)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:25:55.336401] Epoch: [67]  [30/45]  eta: 0:00:06  loss: 0.8238 (0.8172)  MAE: 0.1918 (0.1954)  MSE: 0.1234 (0.1496)  lr: 0.000100  iter-time: 0.4011\n",
            "[13:25:59.322748] Epoch: [67]  [40/45]  eta: 0:00:02  loss: 0.8238 (0.8311)  MAE: 0.1692 (0.1885)  MSE: 0.0934 (0.1310)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:26:00.736678] Epoch: [67]  [44/45]  eta: 0:00:00  loss: 0.8445 (0.8483)  MAE: 0.1685 (0.1866)  MSE: 0.0665 (0.1259)  lr: 0.000100  iter-time: 0.3901\n",
            "[13:26:00.833430] Epoch: [67] Total time: 0:00:18 (0.4060 s / it)\n",
            "[13:26:00.836083] [Train] averaged stats: loss: 0.8445 (0.8483)  MAE: 0.1685 (0.1866)  MSE: 0.0665 (0.1259)  lr: 0.000100\n",
            "[13:26:01.223271] Epoch: [67]  [0/5]  eta: 0:00:01  loss: 1.0442 (1.0442)  MAE: 0.1238 (0.1238)  MSE: 0.0366 (0.0366)  iter-time: 0.3842\n",
            "[13:26:01.720901] Epoch: [67]  [4/5]  eta: 0:00:00  loss: 1.1338 (1.1041)  MAE: 0.1585 (0.1543)  MSE: 0.0655 (0.0615)  iter-time: 0.1762\n",
            "[13:26:01.867011] Epoch: [67] Total time: 0:00:01 (0.2057 s / it)\n",
            "[13:26:01.867159] [Val] averaged stats: loss: 1.1338 (1.1041)  MAE: 0.1585 (0.1543)  MSE: 0.0655 (0.0615)\n",
            "[13:26:01.867780] [Val] best loss: 1.0928 best  MAE: 0.1584 MSE: 0.0732 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:26:01.871781] [Time] 19.3s 23.0m/33.9m\n",
            "\n",
            "[13:26:01.871824] ~~~ Epoch 68/100 ~~~\n",
            "\n",
            "[13:26:02.725017] Epoch: [68]  [ 0/45]  eta: 0:00:38  loss: 0.8984 (0.8984)  MAE: 0.1504 (0.1504)  MSE: 0.0845 (0.0845)  lr: 0.000100  iter-time: 0.8505\n",
            "[13:26:06.763998] Epoch: [68]  [10/45]  eta: 0:00:15  loss: 0.8892 (0.8414)  MAE: 0.1736 (0.1776)  MSE: 0.0883 (0.0906)  lr: 0.000100  iter-time: 0.4442\n",
            "[13:26:10.772756] Epoch: [68]  [20/45]  eta: 0:00:10  loss: 0.8434 (0.8633)  MAE: 0.1738 (0.1777)  MSE: 0.0942 (0.0993)  lr: 0.000100  iter-time: 0.4021\n",
            "[13:26:14.757615] Epoch: [68]  [30/45]  eta: 0:00:06  loss: 0.8350 (0.8544)  MAE: 0.1763 (0.1775)  MSE: 0.0990 (0.0989)  lr: 0.000100  iter-time: 0.3995\n",
            "[13:26:18.740818] Epoch: [68]  [40/45]  eta: 0:00:02  loss: 0.8449 (0.8746)  MAE: 0.1779 (0.1766)  MSE: 0.0909 (0.0946)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:26:20.152339] Epoch: [68]  [44/45]  eta: 0:00:00  loss: 0.8449 (0.8648)  MAE: 0.1779 (0.1775)  MSE: 0.0759 (0.0949)  lr: 0.000100  iter-time: 0.3891\n",
            "[13:26:20.305653] Epoch: [68] Total time: 0:00:18 (0.4096 s / it)\n",
            "[13:26:20.305835] [Train] averaged stats: loss: 0.8449 (0.8648)  MAE: 0.1779 (0.1775)  MSE: 0.0759 (0.0949)  lr: 0.000100\n",
            "[13:26:20.810379] Epoch: [68]  [0/5]  eta: 0:00:02  loss: 1.0304 (1.0304)  MAE: 0.1356 (0.1356)  MSE: 0.0455 (0.0455)  iter-time: 0.5023\n",
            "[13:26:21.300279] Epoch: [68]  [4/5]  eta: 0:00:00  loss: 1.1460 (1.0924)  MAE: 0.1764 (0.1720)  MSE: 0.0836 (0.0788)  iter-time: 0.1979\n",
            "[13:26:21.377889] Epoch: [68] Total time: 0:00:01 (0.2141 s / it)\n",
            "[13:26:21.378039] [Val] averaged stats: loss: 1.1460 (1.0924)  MAE: 0.1764 (0.1720)  MSE: 0.0836 (0.0788)\n",
            "[13:26:21.380159] Val loss improved from 1.0927632689476012 to 1.0924322009086609, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:26:21.437267] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "[13:26:21.439880] [Time] 19.6s 23.3m/34.1m\n",
            "\n",
            "[13:26:21.439962] ~~~ Epoch 69/100 ~~~\n",
            "\n",
            "[13:26:22.134596] Epoch: [69]  [ 0/45]  eta: 0:00:31  loss: 0.6659 (0.6659)  MAE: 0.1716 (0.1716)  MSE: 0.1131 (0.1131)  lr: 0.000100  iter-time: 0.6924\n",
            "[13:26:26.118879] Epoch: [69]  [10/45]  eta: 0:00:14  loss: 0.7316 (0.7649)  MAE: 0.2123 (0.2103)  MSE: 0.1202 (0.1235)  lr: 0.000100  iter-time: 0.4250\n",
            "[13:26:30.099130] Epoch: [69]  [20/45]  eta: 0:00:10  loss: 0.7911 (0.8183)  MAE: 0.2019 (0.2075)  MSE: 0.1220 (0.1283)  lr: 0.000100  iter-time: 0.3980\n",
            "[13:26:34.114958] Epoch: [69]  [30/45]  eta: 0:00:06  loss: 0.7258 (0.7884)  MAE: 0.2019 (0.2048)  MSE: 0.1244 (0.1288)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:26:38.118942] Epoch: [69]  [40/45]  eta: 0:00:02  loss: 0.7425 (0.8103)  MAE: 0.1886 (0.1995)  MSE: 0.1122 (0.1241)  lr: 0.000100  iter-time: 0.4008\n",
            "[13:26:39.531475] Epoch: [69]  [44/45]  eta: 0:00:00  loss: 0.7982 (0.8119)  MAE: 0.1860 (0.1984)  MSE: 0.1053 (0.1244)  lr: 0.000100  iter-time: 0.3915\n",
            "[13:26:39.627416] Epoch: [69] Total time: 0:00:18 (0.4041 s / it)\n",
            "[13:26:39.628472] [Train] averaged stats: loss: 0.7982 (0.8119)  MAE: 0.1860 (0.1984)  MSE: 0.1053 (0.1244)  lr: 0.000100\n",
            "[13:26:40.018183] Epoch: [69]  [0/5]  eta: 0:00:01  loss: 1.0277 (1.0277)  MAE: 0.1324 (0.1324)  MSE: 0.0531 (0.0531)  iter-time: 0.3852\n",
            "[13:26:40.515758] Epoch: [69]  [4/5]  eta: 0:00:00  loss: 1.1564 (1.0964)  MAE: 0.1716 (0.1675)  MSE: 0.1013 (0.0942)  iter-time: 0.1764\n",
            "[13:26:40.594679] Epoch: [69] Total time: 0:00:00 (0.1924 s / it)\n",
            "[13:26:40.594817] [Val] averaged stats: loss: 1.1564 (1.0964)  MAE: 0.1716 (0.1675)  MSE: 0.1013 (0.0942)\n",
            "[13:26:40.597316] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:26:40.599635] [Time] 19.2s 23.6m/33.9m\n",
            "\n",
            "[13:26:40.599689] ~~~ Epoch 70/100 ~~~\n",
            "\n",
            "[13:26:41.255554] Epoch: [70]  [ 0/45]  eta: 0:00:29  loss: 0.6359 (0.6359)  MAE: 0.1686 (0.1686)  MSE: 0.1484 (0.1484)  lr: 0.000100  iter-time: 0.6537\n",
            "[13:26:45.243294] Epoch: [70]  [10/45]  eta: 0:00:14  loss: 0.8354 (0.8030)  MAE: 0.1993 (0.2010)  MSE: 0.1513 (0.1488)  lr: 0.000100  iter-time: 0.4218\n",
            "[13:26:49.236493] Epoch: [70]  [20/45]  eta: 0:00:10  loss: 0.8215 (0.8114)  MAE: 0.1993 (0.2021)  MSE: 0.1528 (0.1685)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:26:53.251748] Epoch: [70]  [30/45]  eta: 0:00:06  loss: 0.7457 (0.8079)  MAE: 0.2037 (0.2028)  MSE: 0.1826 (0.1709)  lr: 0.000100  iter-time: 0.4002\n",
            "[13:26:57.231941] Epoch: [70]  [40/45]  eta: 0:00:02  loss: 0.8444 (0.8385)  MAE: 0.1919 (0.1982)  MSE: 0.1536 (0.1579)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:26:58.638247] Epoch: [70]  [44/45]  eta: 0:00:00  loss: 0.8863 (0.8468)  MAE: 0.1882 (0.1964)  MSE: 0.1023 (0.1535)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:26:58.743944] Epoch: [70] Total time: 0:00:18 (0.4032 s / it)\n",
            "[13:26:58.745001] [Train] averaged stats: loss: 0.8863 (0.8468)  MAE: 0.1882 (0.1964)  MSE: 0.1023 (0.1535)  lr: 0.000100\n",
            "[13:26:59.066268] Epoch: [70]  [0/5]  eta: 0:00:01  loss: 1.0301 (1.0301)  MAE: 0.1337 (0.1337)  MSE: 0.0465 (0.0465)  iter-time: 0.3171\n",
            "[13:26:59.562467] Epoch: [70]  [4/5]  eta: 0:00:00  loss: 1.1595 (1.0968)  MAE: 0.1718 (0.1668)  MSE: 0.0852 (0.0796)  iter-time: 0.1625\n",
            "[13:26:59.639895] Epoch: [70] Total time: 0:00:00 (0.1783 s / it)\n",
            "[13:26:59.640215] [Val] averaged stats: loss: 1.1595 (1.0968)  MAE: 0.1718 (0.1668)  MSE: 0.0852 (0.0796)\n",
            "[13:26:59.643363] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "[13:26:59.645591] Creating training plots . . .\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:27:00.096826] [Time] 19.5s 24.0m/34.0m\n",
            "\n",
            "[13:27:00.098153] ~~~ Epoch 71/100 ~~~\n",
            "\n",
            "[13:27:00.723714] Epoch: [71]  [ 0/45]  eta: 0:00:28  loss: 0.7363 (0.7363)  MAE: 0.1552 (0.1552)  MSE: 0.1157 (0.1157)  lr: 0.000100  iter-time: 0.6230\n",
            "[13:27:04.725417] Epoch: [71]  [10/45]  eta: 0:00:14  loss: 0.8011 (0.8695)  MAE: 0.1750 (0.1810)  MSE: 0.1113 (0.1096)  lr: 0.000100  iter-time: 0.4203\n",
            "[13:27:08.712236] Epoch: [71]  [20/45]  eta: 0:00:10  loss: 0.8011 (0.8566)  MAE: 0.1744 (0.1776)  MSE: 0.1089 (0.1125)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:27:12.694625] Epoch: [71]  [30/45]  eta: 0:00:06  loss: 0.8530 (0.8637)  MAE: 0.1711 (0.1757)  MSE: 0.1018 (0.1079)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:27:16.677912] Epoch: [71]  [40/45]  eta: 0:00:02  loss: 0.8833 (0.8714)  MAE: 0.1661 (0.1722)  MSE: 0.0904 (0.1009)  lr: 0.000100  iter-time: 0.3981\n",
            "[13:27:18.092784] Epoch: [71]  [44/45]  eta: 0:00:00  loss: 0.8302 (0.8654)  MAE: 0.1628 (0.1713)  MSE: 0.0752 (0.0997)  lr: 0.000100  iter-time: 0.3890\n",
            "[13:27:18.189153] Epoch: [71] Total time: 0:00:18 (0.4020 s / it)\n",
            "[13:27:18.189337] [Train] averaged stats: loss: 0.8302 (0.8654)  MAE: 0.1628 (0.1713)  MSE: 0.0752 (0.0997)  lr: 0.000100\n",
            "[13:27:18.560185] Epoch: [71]  [0/5]  eta: 0:00:01  loss: 1.0326 (1.0326)  MAE: 0.1232 (0.1232)  MSE: 0.0406 (0.0406)  iter-time: 0.3689\n",
            "[13:27:19.055440] Epoch: [71]  [4/5]  eta: 0:00:00  loss: 1.1384 (1.0981)  MAE: 0.1565 (0.1527)  MSE: 0.0740 (0.0694)  iter-time: 0.1723\n",
            "[13:27:19.138246] Epoch: [71] Total time: 0:00:00 (0.1895 s / it)\n",
            "[13:27:19.138380] [Val] averaged stats: loss: 1.1384 (1.0981)  MAE: 0.1565 (0.1527)  MSE: 0.0740 (0.0694)\n",
            "[13:27:19.140911] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:27:19.143711] [Time] 19.0s 24.3m/33.8m\n",
            "\n",
            "[13:27:19.143780] ~~~ Epoch 72/100 ~~~\n",
            "\n",
            "[13:27:19.769171] Epoch: [72]  [ 0/45]  eta: 0:00:28  loss: 1.1598 (1.1598)  MAE: 0.1459 (0.1459)  MSE: 0.1030 (0.1030)  lr: 0.000100  iter-time: 0.6239\n",
            "[13:27:23.815562] Epoch: [72]  [10/45]  eta: 0:00:14  loss: 0.8577 (0.9252)  MAE: 0.1680 (0.1726)  MSE: 0.1031 (0.1037)  lr: 0.000100  iter-time: 0.4244\n",
            "[13:27:27.842421] Epoch: [72]  [20/45]  eta: 0:00:10  loss: 0.8385 (0.8778)  MAE: 0.1659 (0.1705)  MSE: 0.1040 (0.1109)  lr: 0.000100  iter-time: 0.4035\n",
            "[13:27:31.829447] Epoch: [72]  [30/45]  eta: 0:00:06  loss: 0.8598 (0.8753)  MAE: 0.1646 (0.1679)  MSE: 0.1096 (0.1091)  lr: 0.000100  iter-time: 0.4005\n",
            "[13:27:35.819182] Epoch: [72]  [40/45]  eta: 0:00:02  loss: 0.9131 (0.8822)  MAE: 0.1618 (0.1662)  MSE: 0.0977 (0.1052)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:27:37.230246] Epoch: [72]  [44/45]  eta: 0:00:00  loss: 0.9351 (0.8949)  MAE: 0.1618 (0.1669)  MSE: 0.0967 (0.1061)  lr: 0.000100  iter-time: 0.3894\n",
            "[13:27:37.385254] Epoch: [72] Total time: 0:00:18 (0.4053 s / it)\n",
            "[13:27:37.386368] [Train] averaged stats: loss: 0.9351 (0.8949)  MAE: 0.1618 (0.1669)  MSE: 0.0967 (0.1061)  lr: 0.000100\n",
            "[13:27:37.925611] Epoch: [72]  [0/5]  eta: 0:00:02  loss: 1.0038 (1.0038)  MAE: 0.1227 (0.1227)  MSE: 0.0485 (0.0485)  iter-time: 0.5346\n",
            "[13:27:38.427860] Epoch: [72]  [4/5]  eta: 0:00:00  loss: 1.1488 (1.1010)  MAE: 0.1604 (0.1579)  MSE: 0.0953 (0.0901)  iter-time: 0.2069\n",
            "[13:27:38.569900] Epoch: [72] Total time: 0:00:01 (0.2359 s / it)\n",
            "[13:27:38.570061] [Val] averaged stats: loss: 1.1488 (1.1010)  MAE: 0.1604 (0.1579)  MSE: 0.0953 (0.0901)\n",
            "[13:27:38.570718] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:27:38.574787] [Time] 19.4s 24.6m/34.0m\n",
            "\n",
            "[13:27:38.574838] ~~~ Epoch 73/100 ~~~\n",
            "\n",
            "[13:27:39.490686] Epoch: [73]  [ 0/45]  eta: 0:00:40  loss: 0.7684 (0.7684)  MAE: 0.1586 (0.1586)  MSE: 0.1359 (0.1359)  lr: 0.000100  iter-time: 0.9094\n",
            "[13:27:43.494659] Epoch: [73]  [10/45]  eta: 0:00:15  loss: 0.7471 (0.8382)  MAE: 0.1868 (0.1903)  MSE: 0.1320 (0.1305)  lr: 0.000100  iter-time: 0.4464\n",
            "[13:27:47.471813] Epoch: [73]  [20/45]  eta: 0:00:10  loss: 0.7631 (0.8451)  MAE: 0.1886 (0.1902)  MSE: 0.1320 (0.1372)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:27:51.456402] Epoch: [73]  [30/45]  eta: 0:00:06  loss: 0.7724 (0.8586)  MAE: 0.1894 (0.1896)  MSE: 0.1317 (0.1348)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:27:55.445347] Epoch: [73]  [40/45]  eta: 0:00:02  loss: 0.7780 (0.8566)  MAE: 0.1892 (0.1885)  MSE: 0.1156 (0.1290)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:27:56.875495] Epoch: [73]  [44/45]  eta: 0:00:00  loss: 0.7955 (0.8612)  MAE: 0.1892 (0.1891)  MSE: 0.1108 (0.1285)  lr: 0.000100  iter-time: 0.3903\n",
            "[13:27:57.030492] Epoch: [73] Total time: 0:00:18 (0.4100 s / it)\n",
            "[13:27:57.031970] [Train] averaged stats: loss: 0.7955 (0.8612)  MAE: 0.1892 (0.1891)  MSE: 0.1108 (0.1285)  lr: 0.000100\n",
            "[13:27:57.514686] Epoch: [73]  [0/5]  eta: 0:00:02  loss: 1.0492 (1.0492)  MAE: 0.1345 (0.1345)  MSE: 0.0523 (0.0523)  iter-time: 0.4785\n",
            "[13:27:58.007535] Epoch: [73]  [4/5]  eta: 0:00:00  loss: 1.1554 (1.0973)  MAE: 0.1795 (0.1743)  MSE: 0.1015 (0.0947)  iter-time: 0.1941\n",
            "[13:27:58.086870] Epoch: [73] Total time: 0:00:01 (0.2103 s / it)\n",
            "[13:27:58.087003] [Val] averaged stats: loss: 1.1554 (1.0973)  MAE: 0.1795 (0.1743)  MSE: 0.1015 (0.0947)\n",
            "[13:27:58.089455] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:27:58.091930] [Time] 19.5s 24.9m/34.0m\n",
            "\n",
            "[13:27:58.091987] ~~~ Epoch 74/100 ~~~\n",
            "\n",
            "[13:27:58.753585] Epoch: [74]  [ 0/45]  eta: 0:00:29  loss: 0.9247 (0.9247)  MAE: 0.1807 (0.1807)  MSE: 0.1407 (0.1407)  lr: 0.000100  iter-time: 0.6578\n",
            "[13:28:02.742051] Epoch: [74]  [10/45]  eta: 0:00:14  loss: 0.8885 (0.8302)  MAE: 0.2160 (0.2165)  MSE: 0.1428 (0.1470)  lr: 0.000100  iter-time: 0.4221\n",
            "[13:28:06.730244] Epoch: [74]  [20/45]  eta: 0:00:10  loss: 0.7615 (0.8109)  MAE: 0.2064 (0.2125)  MSE: 0.1460 (0.1515)  lr: 0.000100  iter-time: 0.3986\n",
            "[13:28:10.738010] Epoch: [74]  [30/45]  eta: 0:00:06  loss: 0.7917 (0.8314)  MAE: 0.2028 (0.2081)  MSE: 0.1450 (0.1471)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:28:14.740468] Epoch: [74]  [40/45]  eta: 0:00:02  loss: 0.8514 (0.8380)  MAE: 0.1853 (0.1985)  MSE: 0.1260 (0.1340)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:28:16.149674] Epoch: [74]  [44/45]  eta: 0:00:00  loss: 0.8514 (0.8484)  MAE: 0.1744 (0.1955)  MSE: 0.0933 (0.1307)  lr: 0.000100  iter-time: 0.3907\n",
            "[13:28:16.248303] Epoch: [74] Total time: 0:00:18 (0.4034 s / it)\n",
            "[13:28:16.250413] [Train] averaged stats: loss: 0.8514 (0.8484)  MAE: 0.1744 (0.1955)  MSE: 0.0933 (0.1307)  lr: 0.000100\n",
            "[13:28:16.603204] Epoch: [74]  [0/5]  eta: 0:00:01  loss: 1.0157 (1.0157)  MAE: 0.1214 (0.1214)  MSE: 0.0465 (0.0465)  iter-time: 0.3488\n",
            "[13:28:17.098408] Epoch: [74]  [4/5]  eta: 0:00:00  loss: 1.1441 (1.0945)  MAE: 0.1603 (0.1564)  MSE: 0.0907 (0.0851)  iter-time: 0.1684\n",
            "[13:28:17.181474] Epoch: [74] Total time: 0:00:00 (0.1855 s / it)\n",
            "[13:28:17.181756] [Val] averaged stats: loss: 1.1441 (1.0945)  MAE: 0.1603 (0.1564)  MSE: 0.0907 (0.0851)\n",
            "[13:28:17.184453] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:28:17.187181] [Time] 19.1s 25.2m/33.8m\n",
            "\n",
            "[13:28:17.187235] ~~~ Epoch 75/100 ~~~\n",
            "\n",
            "[13:28:17.950380] Epoch: [75]  [ 0/45]  eta: 0:00:34  loss: 1.1248 (1.1248)  MAE: 0.1530 (0.1530)  MSE: 0.1226 (0.1226)  lr: 0.000100  iter-time: 0.7606\n",
            "[13:28:21.942810] Epoch: [75]  [10/45]  eta: 0:00:15  loss: 0.9753 (0.9879)  MAE: 0.1830 (0.1895)  MSE: 0.1262 (0.1331)  lr: 0.000100  iter-time: 0.4318\n",
            "[13:28:25.933092] Epoch: [75]  [20/45]  eta: 0:00:10  loss: 0.9014 (0.8917)  MAE: 0.1995 (0.1995)  MSE: 0.1600 (0.1646)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:28:29.964209] Epoch: [75]  [30/45]  eta: 0:00:06  loss: 0.8498 (0.9036)  MAE: 0.2045 (0.2036)  MSE: 0.1845 (0.1683)  lr: 0.000100  iter-time: 0.4008\n",
            "[13:28:33.971239] Epoch: [75]  [40/45]  eta: 0:00:02  loss: 0.8738 (0.8957)  MAE: 0.2045 (0.2017)  MSE: 0.1673 (0.1597)  lr: 0.000100  iter-time: 0.4017\n",
            "[13:28:35.383371] Epoch: [75]  [44/45]  eta: 0:00:00  loss: 0.8498 (0.8975)  MAE: 0.2019 (0.2004)  MSE: 0.1280 (0.1573)  lr: 0.000100  iter-time: 0.3919\n",
            "[13:28:35.479181] Epoch: [75] Total time: 0:00:18 (0.4065 s / it)\n",
            "[13:28:35.479410] [Train] averaged stats: loss: 0.8498 (0.8975)  MAE: 0.2019 (0.2004)  MSE: 0.1280 (0.1573)  lr: 0.000100\n",
            "[13:28:35.880574] Epoch: [75]  [0/5]  eta: 0:00:01  loss: 0.9855 (0.9855)  MAE: 0.1283 (0.1283)  MSE: 0.0519 (0.0519)  iter-time: 0.3991\n",
            "[13:28:36.368245] Epoch: [75]  [4/5]  eta: 0:00:00  loss: 1.1581 (1.0968)  MAE: 0.1739 (0.1692)  MSE: 0.1050 (0.0986)  iter-time: 0.1772\n",
            "[13:28:36.449209] Epoch: [75] Total time: 0:00:00 (0.1937 s / it)\n",
            "[13:28:36.449362] [Val] averaged stats: loss: 1.1581 (1.0968)  MAE: 0.1739 (0.1692)  MSE: 0.1050 (0.0986)\n",
            "[13:28:36.452215] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "[13:28:36.454372] Creating training plots . . .\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[13:28:36.895900] [Time] 19.7s 25.6m/34.1m\n",
            "\n",
            "[13:28:36.895960] ~~~ Epoch 76/100 ~~~\n",
            "\n",
            "[13:28:37.562557] Epoch: [76]  [ 0/45]  eta: 0:00:29  loss: 1.0491 (1.0491)  MAE: 0.1633 (0.1633)  MSE: 0.1466 (0.1466)  lr: 0.000100  iter-time: 0.6626\n",
            "[13:28:41.548450] Epoch: [76]  [10/45]  eta: 0:00:14  loss: 0.8905 (0.8679)  MAE: 0.1824 (0.1848)  MSE: 0.1355 (0.1354)  lr: 0.000100  iter-time: 0.4225\n",
            "[13:28:45.565703] Epoch: [76]  [20/45]  eta: 0:00:10  loss: 0.8110 (0.8617)  MAE: 0.1705 (0.1772)  MSE: 0.1322 (0.1373)  lr: 0.000100  iter-time: 0.4000\n",
            "[13:28:49.577631] Epoch: [76]  [30/45]  eta: 0:00:06  loss: 0.8129 (0.8645)  MAE: 0.1677 (0.1746)  MSE: 0.1323 (0.1364)  lr: 0.000100  iter-time: 0.4013\n",
            "[13:28:53.560741] Epoch: [76]  [40/45]  eta: 0:00:02  loss: 0.7657 (0.8380)  MAE: 0.1685 (0.1725)  MSE: 0.1224 (0.1297)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:28:54.966183] Epoch: [76]  [44/45]  eta: 0:00:00  loss: 0.7657 (0.8516)  MAE: 0.1685 (0.1726)  MSE: 0.1109 (0.1300)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:28:55.062210] Epoch: [76] Total time: 0:00:18 (0.4036 s / it)\n",
            "[13:28:55.063726] [Train] averaged stats: loss: 0.7657 (0.8516)  MAE: 0.1685 (0.1726)  MSE: 0.1109 (0.1300)  lr: 0.000100\n",
            "[13:28:55.383374] Epoch: [76]  [0/5]  eta: 0:00:01  loss: 1.0075 (1.0075)  MAE: 0.1262 (0.1262)  MSE: 0.0578 (0.0578)  iter-time: 0.3161\n",
            "[13:28:55.871206] Epoch: [76]  [4/5]  eta: 0:00:00  loss: 1.1775 (1.1076)  MAE: 0.1656 (0.1607)  MSE: 0.1144 (0.1058)  iter-time: 0.1603\n",
            "[13:28:55.952469] Epoch: [76] Total time: 0:00:00 (0.1772 s / it)\n",
            "[13:28:55.952613] [Val] averaged stats: loss: 1.1775 (1.1076)  MAE: 0.1656 (0.1607)  MSE: 0.1144 (0.1058)\n",
            "[13:28:55.955099] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[13:28:55.957445] [Time] 19.1s 25.9m/33.8m\n",
            "\n",
            "[13:28:55.957500] ~~~ Epoch 77/100 ~~~\n",
            "\n",
            "[13:28:56.617311] Epoch: [77]  [ 0/45]  eta: 0:00:29  loss: 0.8590 (0.8590)  MAE: 0.1605 (0.1605)  MSE: 0.1662 (0.1662)  lr: 0.000100  iter-time: 0.6560\n",
            "[13:29:00.616362] Epoch: [77]  [10/45]  eta: 0:00:14  loss: 0.8590 (0.8813)  MAE: 0.1877 (0.1928)  MSE: 0.1617 (0.1568)  lr: 0.000100  iter-time: 0.4230\n",
            "[13:29:04.607221] Epoch: [77]  [20/45]  eta: 0:00:10  loss: 0.8338 (0.8493)  MAE: 0.1880 (0.1916)  MSE: 0.1601 (0.1617)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:29:08.589128] Epoch: [77]  [30/45]  eta: 0:00:06  loss: 0.8219 (0.8460)  MAE: 0.1855 (0.1882)  MSE: 0.1397 (0.1519)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:29:12.565620] Epoch: [77]  [40/45]  eta: 0:00:02  loss: 0.8847 (0.8650)  MAE: 0.1734 (0.1834)  MSE: 0.1250 (0.1396)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:29:13.971678] Epoch: [77]  [44/45]  eta: 0:00:00  loss: 0.8620 (0.8497)  MAE: 0.1715 (0.1828)  MSE: 0.0988 (0.1375)  lr: 0.000100  iter-time: 0.3883\n",
            "[13:29:14.066613] Epoch: [77] Total time: 0:00:18 (0.4024 s / it)\n",
            "[13:29:14.067609] [Train] averaged stats: loss: 0.8620 (0.8497)  MAE: 0.1715 (0.1828)  MSE: 0.0988 (0.1375)  lr: 0.000100\n",
            "[13:29:14.453279] Epoch: [77]  [0/5]  eta: 0:00:01  loss: 1.0013 (1.0013)  MAE: 0.1252 (0.1252)  MSE: 0.0480 (0.0480)  iter-time: 0.3802\n",
            "[13:29:14.949872] Epoch: [77]  [4/5]  eta: 0:00:00  loss: 1.1441 (1.0962)  MAE: 0.1669 (0.1627)  MSE: 0.0937 (0.0882)  iter-time: 0.1749\n",
            "[13:29:15.041202] Epoch: [77] Total time: 0:00:00 (0.1937 s / it)\n",
            "[13:29:15.041332] [Val] averaged stats: loss: 1.1441 (1.0962)  MAE: 0.1669 (0.1627)  MSE: 0.0937 (0.0882)\n",
            "[13:29:15.043833] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[13:29:15.046549] [Time] 19.1s 26.2m/33.8m\n",
            "\n",
            "[13:29:15.047764] ~~~ Epoch 78/100 ~~~\n",
            "\n",
            "[13:29:15.719188] Epoch: [78]  [ 0/45]  eta: 0:00:30  loss: 0.8787 (0.8787)  MAE: 0.1602 (0.1602)  MSE: 0.1407 (0.1407)  lr: 0.000100  iter-time: 0.6693\n",
            "[13:29:19.731333] Epoch: [78]  [10/45]  eta: 0:00:14  loss: 0.8070 (0.7701)  MAE: 0.1807 (0.1853)  MSE: 0.1301 (0.1281)  lr: 0.000100  iter-time: 0.4254\n",
            "[13:29:23.733698] Epoch: [78]  [20/45]  eta: 0:00:10  loss: 0.7902 (0.8077)  MAE: 0.1750 (0.1796)  MSE: 0.1277 (0.1306)  lr: 0.000100  iter-time: 0.4006\n",
            "[13:29:27.712914] Epoch: [78]  [30/45]  eta: 0:00:06  loss: 0.8081 (0.8146)  MAE: 0.1742 (0.1783)  MSE: 0.1266 (0.1278)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:29:31.690261] Epoch: [78]  [40/45]  eta: 0:00:02  loss: 0.8685 (0.8329)  MAE: 0.1720 (0.1759)  MSE: 0.1094 (0.1204)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:29:33.098412] Epoch: [78]  [44/45]  eta: 0:00:00  loss: 0.8929 (0.8464)  MAE: 0.1720 (0.1758)  MSE: 0.0943 (0.1195)  lr: 0.000100  iter-time: 0.3883\n",
            "[13:29:33.286219] Epoch: [78] Total time: 0:00:18 (0.4053 s / it)\n",
            "[13:29:33.286393] [Train] averaged stats: loss: 0.8929 (0.8464)  MAE: 0.1720 (0.1758)  MSE: 0.0943 (0.1195)  lr: 0.000100\n",
            "[13:29:33.797158] Epoch: [78]  [0/5]  eta: 0:00:02  loss: 1.0071 (1.0071)  MAE: 0.1229 (0.1229)  MSE: 0.0481 (0.0481)  iter-time: 0.5085\n",
            "[13:29:34.295660] Epoch: [78]  [4/5]  eta: 0:00:00  loss: 1.1619 (1.0996)  MAE: 0.1644 (0.1603)  MSE: 0.0952 (0.0889)  iter-time: 0.2009\n",
            "[13:29:34.426565] Epoch: [78] Total time: 0:00:01 (0.2277 s / it)\n",
            "[13:29:34.426713] [Val] averaged stats: loss: 1.1619 (1.0996)  MAE: 0.1644 (0.1603)  MSE: 0.0952 (0.0889)\n",
            "[13:29:34.427414] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[13:29:34.428413] [Time] 19.4s 26.5m/34.0m\n",
            "\n",
            "[13:29:34.428464] ~~~ Epoch 79/100 ~~~\n",
            "\n",
            "[13:29:35.334435] Epoch: [79]  [ 0/45]  eta: 0:00:40  loss: 0.8289 (0.8289)  MAE: 0.1566 (0.1566)  MSE: 0.1272 (0.1272)  lr: 0.000100  iter-time: 0.9034\n",
            "[13:29:39.318209] Epoch: [79]  [10/45]  eta: 0:00:15  loss: 0.7153 (0.7720)  MAE: 0.1750 (0.1799)  MSE: 0.1229 (0.1214)  lr: 0.000100  iter-time: 0.4440\n",
            "[13:29:43.293540] Epoch: [79]  [20/45]  eta: 0:00:10  loss: 0.7228 (0.7955)  MAE: 0.1750 (0.1779)  MSE: 0.1229 (0.1289)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:29:47.279932] Epoch: [79]  [30/45]  eta: 0:00:06  loss: 0.7919 (0.8253)  MAE: 0.1762 (0.1783)  MSE: 0.1322 (0.1286)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:29:51.268623] Epoch: [79]  [40/45]  eta: 0:00:02  loss: 0.9026 (0.8402)  MAE: 0.1702 (0.1754)  MSE: 0.1172 (0.1195)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:29:52.672008] Epoch: [79]  [44/45]  eta: 0:00:00  loss: 0.7935 (0.8380)  MAE: 0.1696 (0.1749)  MSE: 0.0851 (0.1179)  lr: 0.000100  iter-time: 0.3890\n",
            "[13:29:52.830280] Epoch: [79] Total time: 0:00:18 (0.4089 s / it)\n",
            "[13:29:52.831444] [Train] averaged stats: loss: 0.7935 (0.8380)  MAE: 0.1696 (0.1749)  MSE: 0.0851 (0.1179)  lr: 0.000100\n",
            "[13:29:53.282294] Epoch: [79]  [0/5]  eta: 0:00:02  loss: 1.0254 (1.0254)  MAE: 0.1215 (0.1215)  MSE: 0.0433 (0.0433)  iter-time: 0.4474\n",
            "[13:29:53.773581] Epoch: [79]  [4/5]  eta: 0:00:00  loss: 1.1194 (1.0932)  MAE: 0.1598 (0.1550)  MSE: 0.0835 (0.0779)  iter-time: 0.1873\n",
            "[13:29:53.852790] Epoch: [79] Total time: 0:00:01 (0.2037 s / it)\n",
            "[13:29:53.853791] [Val] averaged stats: loss: 1.1194 (1.0932)  MAE: 0.1598 (0.1550)  MSE: 0.0835 (0.0779)\n",
            "[13:29:53.855721] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "EarlyStopping counter: 11 out of 20\n",
            "[13:29:53.858009] [Time] 19.4s 26.9m/34.0m\n",
            "\n",
            "[13:29:53.858083] ~~~ Epoch 80/100 ~~~\n",
            "\n",
            "[13:29:54.526694] Epoch: [80]  [ 0/45]  eta: 0:00:29  loss: 0.8837 (0.8837)  MAE: 0.1511 (0.1511)  MSE: 0.1134 (0.1134)  lr: 0.000100  iter-time: 0.6651\n",
            "[13:29:58.512656] Epoch: [80]  [10/45]  eta: 0:00:14  loss: 0.7716 (0.8331)  MAE: 0.1666 (0.1716)  MSE: 0.1098 (0.1050)  lr: 0.000100  iter-time: 0.4226\n",
            "[13:30:02.485442] Epoch: [80]  [20/45]  eta: 0:00:10  loss: 0.7401 (0.8026)  MAE: 0.1577 (0.1644)  MSE: 0.0973 (0.1052)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:30:06.469675] Epoch: [80]  [30/45]  eta: 0:00:06  loss: 0.7520 (0.8022)  MAE: 0.1564 (0.1635)  MSE: 0.0999 (0.1033)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:30:10.446223] Epoch: [80]  [40/45]  eta: 0:00:02  loss: 0.7965 (0.8310)  MAE: 0.1634 (0.1656)  MSE: 0.0906 (0.1018)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:30:11.853947] Epoch: [80]  [44/45]  eta: 0:00:00  loss: 0.8128 (0.8352)  MAE: 0.1656 (0.1674)  MSE: 0.0920 (0.1037)  lr: 0.000100  iter-time: 0.3887\n",
            "[13:30:11.959538] Epoch: [80] Total time: 0:00:18 (0.4022 s / it)\n",
            "[13:30:11.961284] [Train] averaged stats: loss: 0.8128 (0.8352)  MAE: 0.1656 (0.1674)  MSE: 0.0920 (0.1037)  lr: 0.000100\n",
            "[13:30:12.323258] Epoch: [80]  [0/5]  eta: 0:00:01  loss: 1.0413 (1.0413)  MAE: 0.1316 (0.1316)  MSE: 0.0535 (0.0535)  iter-time: 0.3589\n",
            "[13:30:12.816722] Epoch: [80]  [4/5]  eta: 0:00:00  loss: 1.1406 (1.0950)  MAE: 0.1755 (0.1707)  MSE: 0.1040 (0.0978)  iter-time: 0.1703\n",
            "[13:30:12.896050] Epoch: [80] Total time: 0:00:00 (0.1864 s / it)\n",
            "[13:30:12.896878] [Val] averaged stats: loss: 1.1406 (1.0950)  MAE: 0.1755 (0.1707)  MSE: 0.1040 (0.0978)\n",
            "[13:30:12.898758] [Val] best loss: 1.0924 best  MAE: 0.1720 MSE: 0.0788 \n",
            "[13:30:12.901122] Creating training plots . . .\n",
            "EarlyStopping counter: 12 out of 20\n",
            "[13:30:13.354229] [Time] 19.5s 27.2m/34.0m\n",
            "\n",
            "[13:30:13.354286] ~~~ Epoch 81/100 ~~~\n",
            "\n",
            "[13:30:14.095250] Epoch: [81]  [ 0/45]  eta: 0:00:33  loss: 0.7708 (0.7708)  MAE: 0.1675 (0.1675)  MSE: 0.1386 (0.1386)  lr: 0.000100  iter-time: 0.7385\n",
            "[13:30:18.077752] Epoch: [81]  [10/45]  eta: 0:00:15  loss: 0.7987 (0.8121)  MAE: 0.2046 (0.2078)  MSE: 0.1567 (0.1532)  lr: 0.000100  iter-time: 0.4290\n",
            "[13:30:22.064480] Epoch: [81]  [20/45]  eta: 0:00:10  loss: 0.7712 (0.7863)  MAE: 0.2090 (0.2109)  MSE: 0.1638 (0.1748)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:30:26.057216] Epoch: [81]  [30/45]  eta: 0:00:06  loss: 0.8205 (0.8350)  MAE: 0.2117 (0.2115)  MSE: 0.1906 (0.1763)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:30:30.036393] Epoch: [81]  [40/45]  eta: 0:00:02  loss: 0.8739 (0.8380)  MAE: 0.2012 (0.2070)  MSE: 0.1623 (0.1636)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:30:31.447636] Epoch: [81]  [44/45]  eta: 0:00:00  loss: 0.8739 (0.8411)  MAE: 0.1989 (0.2054)  MSE: 0.1129 (0.1605)  lr: 0.000100  iter-time: 0.3892\n",
            "[13:30:31.542824] Epoch: [81] Total time: 0:00:18 (0.4042 s / it)\n",
            "[13:30:31.543769] [Train] averaged stats: loss: 0.8739 (0.8411)  MAE: 0.1989 (0.2054)  MSE: 0.1129 (0.1605)  lr: 0.000100\n",
            "[13:30:31.912994] Epoch: [81]  [0/5]  eta: 0:00:01  loss: 1.0789 (1.0789)  MAE: 0.1322 (0.1322)  MSE: 0.0522 (0.0522)  iter-time: 0.3653\n",
            "[13:30:32.408797] Epoch: [81]  [4/5]  eta: 0:00:00  loss: 1.1098 (1.0897)  MAE: 0.1738 (0.1693)  MSE: 0.0995 (0.0934)  iter-time: 0.1718\n",
            "[13:30:32.490351] Epoch: [81] Total time: 0:00:00 (0.1886 s / it)\n",
            "[13:30:32.491347] [Val] averaged stats: loss: 1.1098 (1.0897)  MAE: 0.1738 (0.1693)  MSE: 0.0995 (0.0934)\n",
            "[13:30:32.493158] Val loss improved from 1.0924322009086609 to 1.0896856307983398, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:30:32.544828] [Val] best loss: 1.0897 best  MAE: 0.1693 MSE: 0.0934 \n",
            "[13:30:32.547494] [Time] 19.2s 27.5m/33.9m\n",
            "\n",
            "[13:30:32.547568] ~~~ Epoch 82/100 ~~~\n",
            "\n",
            "[13:30:33.282822] Epoch: [82]  [ 0/45]  eta: 0:00:32  loss: 0.9813 (0.9813)  MAE: 0.1606 (0.1606)  MSE: 0.1346 (0.1346)  lr: 0.000100  iter-time: 0.7317\n",
            "[13:30:37.294589] Epoch: [82]  [10/45]  eta: 0:00:15  loss: 0.9311 (0.8457)  MAE: 0.1876 (0.1936)  MSE: 0.1468 (0.1435)  lr: 0.000100  iter-time: 0.4311\n",
            "[13:30:41.336926] Epoch: [82]  [20/45]  eta: 0:00:10  loss: 0.9311 (0.8775)  MAE: 0.1876 (0.1912)  MSE: 0.1499 (0.1573)  lr: 0.000100  iter-time: 0.4025\n",
            "[13:30:45.322289] Epoch: [82]  [30/45]  eta: 0:00:06  loss: 0.8912 (0.8743)  MAE: 0.1817 (0.1871)  MSE: 0.1517 (0.1517)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:30:49.317150] Epoch: [82]  [40/45]  eta: 0:00:02  loss: 0.8990 (0.8815)  MAE: 0.1698 (0.1817)  MSE: 0.1261 (0.1393)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:30:50.728887] Epoch: [82]  [44/45]  eta: 0:00:00  loss: 0.8007 (0.8704)  MAE: 0.1681 (0.1805)  MSE: 0.0992 (0.1368)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:30:50.827184] Epoch: [82] Total time: 0:00:18 (0.4062 s / it)\n",
            "[13:30:50.828605] [Train] averaged stats: loss: 0.8007 (0.8704)  MAE: 0.1681 (0.1805)  MSE: 0.0992 (0.1368)  lr: 0.000100\n",
            "[13:30:51.139414] Epoch: [82]  [0/5]  eta: 0:00:01  loss: 1.0239 (1.0239)  MAE: 0.1220 (0.1220)  MSE: 0.0473 (0.0473)  iter-time: 0.3069\n",
            "[13:30:51.638402] Epoch: [82]  [4/5]  eta: 0:00:00  loss: 1.1169 (1.0942)  MAE: 0.1594 (0.1550)  MSE: 0.0927 (0.0859)  iter-time: 0.1602\n",
            "[13:30:51.779751] Epoch: [82] Total time: 0:00:00 (0.1896 s / it)\n",
            "[13:30:51.779886] [Val] averaged stats: loss: 1.1169 (1.0942)  MAE: 0.1594 (0.1550)  MSE: 0.0927 (0.0859)\n",
            "[13:30:51.782405] [Val] best loss: 1.0897 best  MAE: 0.1693 MSE: 0.0934 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:30:51.784964] [Time] 19.2s 27.8m/33.9m\n",
            "\n",
            "[13:30:51.785006] ~~~ Epoch 83/100 ~~~\n",
            "\n",
            "[13:30:52.673288] Epoch: [83]  [ 0/45]  eta: 0:00:39  loss: 0.7818 (0.7818)  MAE: 0.1490 (0.1490)  MSE: 0.1288 (0.1288)  lr: 0.000100  iter-time: 0.8856\n",
            "[13:30:56.720543] Epoch: [83]  [10/45]  eta: 0:00:15  loss: 0.8014 (0.7961)  MAE: 0.1749 (0.1781)  MSE: 0.1323 (0.1314)  lr: 0.000100  iter-time: 0.4481\n",
            "[13:31:00.761001] Epoch: [83]  [20/45]  eta: 0:00:10  loss: 0.8014 (0.8089)  MAE: 0.1810 (0.1795)  MSE: 0.1391 (0.1428)  lr: 0.000100  iter-time: 0.4041\n",
            "[13:31:04.750320] Epoch: [83]  [30/45]  eta: 0:00:06  loss: 0.7773 (0.7982)  MAE: 0.1821 (0.1822)  MSE: 0.1512 (0.1471)  lr: 0.000100  iter-time: 0.4013\n",
            "[13:31:08.743664] Epoch: [83]  [40/45]  eta: 0:00:02  loss: 0.8341 (0.8337)  MAE: 0.1837 (0.1812)  MSE: 0.1418 (0.1415)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:31:10.160709] Epoch: [83]  [44/45]  eta: 0:00:00  loss: 0.8171 (0.8236)  MAE: 0.1788 (0.1810)  MSE: 0.1187 (0.1413)  lr: 0.000100  iter-time: 0.3899\n",
            "[13:31:10.291502] Epoch: [83] Total time: 0:00:18 (0.4112 s / it)\n",
            "[13:31:10.291694] [Train] averaged stats: loss: 0.8171 (0.8236)  MAE: 0.1788 (0.1810)  MSE: 0.1187 (0.1413)  lr: 0.000100\n",
            "[13:31:10.847723] Epoch: [83]  [0/5]  eta: 0:00:02  loss: 1.0220 (1.0220)  MAE: 0.1242 (0.1242)  MSE: 0.0526 (0.0526)  iter-time: 0.5538\n",
            "[13:31:11.343405] Epoch: [83]  [4/5]  eta: 0:00:00  loss: 1.1160 (1.0807)  MAE: 0.1638 (0.1596)  MSE: 0.1035 (0.0964)  iter-time: 0.2094\n",
            "[13:31:11.465329] Epoch: [83] Total time: 0:00:01 (0.2344 s / it)\n",
            "[13:31:11.465474] [Val] averaged stats: loss: 1.1160 (1.0807)  MAE: 0.1638 (0.1596)  MSE: 0.1035 (0.0964)\n",
            "[13:31:11.466165] Val loss improved from 1.0896856307983398 to 1.0807088613510132, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:31:11.542185] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "[13:31:11.551617] [Time] 19.8s 28.2m/34.1m\n",
            "\n",
            "[13:31:11.552845] ~~~ Epoch 84/100 ~~~\n",
            "\n",
            "[13:31:12.464356] Epoch: [84]  [ 0/45]  eta: 0:00:40  loss: 1.5371 (1.5371)  MAE: 0.1578 (0.1578)  MSE: 0.1617 (0.1617)  lr: 0.000100  iter-time: 0.9080\n",
            "[13:31:16.488574] Epoch: [84]  [10/45]  eta: 0:00:15  loss: 0.8798 (0.9229)  MAE: 0.1810 (0.1884)  MSE: 0.1575 (0.1505)  lr: 0.000100  iter-time: 0.4482\n",
            "[13:31:20.489479] Epoch: [84]  [20/45]  eta: 0:00:10  loss: 0.8218 (0.8981)  MAE: 0.1820 (0.1863)  MSE: 0.1455 (0.1529)  lr: 0.000100  iter-time: 0.4011\n",
            "[13:31:24.476364] Epoch: [84]  [30/45]  eta: 0:00:06  loss: 0.8480 (0.8898)  MAE: 0.1788 (0.1834)  MSE: 0.1269 (0.1419)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:31:28.472768] Epoch: [84]  [40/45]  eta: 0:00:02  loss: 0.8480 (0.8718)  MAE: 0.1680 (0.1785)  MSE: 0.1133 (0.1287)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:31:29.887320] Epoch: [84]  [44/45]  eta: 0:00:00  loss: 0.9355 (0.8824)  MAE: 0.1680 (0.1781)  MSE: 0.0921 (0.1268)  lr: 0.000100  iter-time: 0.3899\n",
            "[13:31:30.062543] Epoch: [84] Total time: 0:00:18 (0.4113 s / it)\n",
            "[13:31:30.063619] [Train] averaged stats: loss: 0.9355 (0.8824)  MAE: 0.1680 (0.1781)  MSE: 0.0921 (0.1268)  lr: 0.000100\n",
            "[13:31:30.527388] Epoch: [84]  [0/5]  eta: 0:00:02  loss: 1.0135 (1.0135)  MAE: 0.1229 (0.1229)  MSE: 0.0452 (0.0452)  iter-time: 0.4603\n",
            "[13:31:31.020569] Epoch: [84]  [4/5]  eta: 0:00:00  loss: 1.1442 (1.0911)  MAE: 0.1620 (0.1578)  MSE: 0.0878 (0.0820)  iter-time: 0.1906\n",
            "[13:31:31.103073] Epoch: [84] Total time: 0:00:01 (0.2073 s / it)\n",
            "[13:31:31.103264] [Val] averaged stats: loss: 1.1442 (1.0911)  MAE: 0.1620 (0.1578)  MSE: 0.0878 (0.0820)\n",
            "[13:31:31.105826] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:31:31.108290] [Time] 19.6s 28.5m/34.0m\n",
            "\n",
            "[13:31:31.108346] ~~~ Epoch 85/100 ~~~\n",
            "\n",
            "[13:31:31.808739] Epoch: [85]  [ 0/45]  eta: 0:00:31  loss: 0.6648 (0.6648)  MAE: 0.1576 (0.1576)  MSE: 0.1261 (0.1261)  lr: 0.000100  iter-time: 0.6982\n",
            "[13:31:35.791894] Epoch: [85]  [10/45]  eta: 0:00:14  loss: 0.7254 (0.7853)  MAE: 0.1836 (0.1884)  MSE: 0.1262 (0.1259)  lr: 0.000100  iter-time: 0.4253\n",
            "[13:31:39.773847] Epoch: [85]  [20/45]  eta: 0:00:10  loss: 0.7525 (0.7983)  MAE: 0.1836 (0.1885)  MSE: 0.1303 (0.1340)  lr: 0.000100  iter-time: 0.3980\n",
            "[13:31:43.756787] Epoch: [85]  [30/45]  eta: 0:00:06  loss: 0.8600 (0.8253)  MAE: 0.1889 (0.1891)  MSE: 0.1375 (0.1336)  lr: 0.000100  iter-time: 0.3981\n",
            "[13:31:47.749960] Epoch: [85]  [40/45]  eta: 0:00:02  loss: 0.8881 (0.8422)  MAE: 0.1800 (0.1848)  MSE: 0.1204 (0.1242)  lr: 0.000100  iter-time: 0.3986\n",
            "[13:31:49.161778] Epoch: [85]  [44/45]  eta: 0:00:00  loss: 0.8905 (0.8432)  MAE: 0.1755 (0.1839)  MSE: 0.0890 (0.1226)  lr: 0.000100  iter-time: 0.3894\n",
            "[13:31:49.257737] Epoch: [85] Total time: 0:00:18 (0.4033 s / it)\n",
            "[13:31:49.258703] [Train] averaged stats: loss: 0.8905 (0.8432)  MAE: 0.1755 (0.1839)  MSE: 0.0890 (0.1226)  lr: 0.000100\n",
            "[13:31:49.636741] Epoch: [85]  [0/5]  eta: 0:00:01  loss: 1.0119 (1.0119)  MAE: 0.1227 (0.1227)  MSE: 0.0435 (0.0435)  iter-time: 0.3740\n",
            "[13:31:50.130273] Epoch: [85]  [4/5]  eta: 0:00:00  loss: 1.1331 (1.0871)  MAE: 0.1610 (0.1567)  MSE: 0.0831 (0.0777)  iter-time: 0.1731\n",
            "[13:31:50.210334] Epoch: [85] Total time: 0:00:00 (0.1896 s / it)\n",
            "[13:31:50.210587] [Val] averaged stats: loss: 1.1331 (1.0871)  MAE: 0.1610 (0.1567)  MSE: 0.0831 (0.0777)\n",
            "[13:31:50.213013] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "[13:31:50.215559] Creating training plots . . .\n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:31:50.637557] [Time] 19.5s 28.8m/34.0m\n",
            "\n",
            "[13:31:50.637644] ~~~ Epoch 86/100 ~~~\n",
            "\n",
            "[13:31:51.331959] Epoch: [86]  [ 0/45]  eta: 0:00:31  loss: 0.8201 (0.8201)  MAE: 0.1512 (0.1512)  MSE: 0.1168 (0.1168)  lr: 0.000100  iter-time: 0.6916\n",
            "[13:31:55.310115] Epoch: [86]  [10/45]  eta: 0:00:14  loss: 0.9598 (0.8887)  MAE: 0.1794 (0.1851)  MSE: 0.1186 (0.1213)  lr: 0.000100  iter-time: 0.4243\n",
            "[13:31:59.312077] Epoch: [86]  [20/45]  eta: 0:00:10  loss: 0.7966 (0.8675)  MAE: 0.1794 (0.1832)  MSE: 0.1239 (0.1266)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:32:03.336740] Epoch: [86]  [30/45]  eta: 0:00:06  loss: 0.7606 (0.8380)  MAE: 0.1761 (0.1809)  MSE: 0.1175 (0.1224)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:32:07.324300] Epoch: [86]  [40/45]  eta: 0:00:02  loss: 0.7753 (0.8577)  MAE: 0.1707 (0.1771)  MSE: 0.1024 (0.1140)  lr: 0.000100  iter-time: 0.4005\n",
            "[13:32:08.736114] Epoch: [86]  [44/45]  eta: 0:00:00  loss: 0.7901 (0.8634)  MAE: 0.1707 (0.1767)  MSE: 0.0876 (0.1132)  lr: 0.000100  iter-time: 0.3907\n",
            "[13:32:08.829188] Epoch: [86] Total time: 0:00:18 (0.4042 s / it)\n",
            "[13:32:08.832137] [Train] averaged stats: loss: 0.7901 (0.8634)  MAE: 0.1707 (0.1767)  MSE: 0.0876 (0.1132)  lr: 0.000100\n",
            "[13:32:09.209014] Epoch: [86]  [0/5]  eta: 0:00:01  loss: 1.0150 (1.0150)  MAE: 0.1203 (0.1203)  MSE: 0.0415 (0.0415)  iter-time: 0.3740\n",
            "[13:32:09.701947] Epoch: [86]  [4/5]  eta: 0:00:00  loss: 1.1212 (1.0830)  MAE: 0.1583 (0.1552)  MSE: 0.0792 (0.0748)  iter-time: 0.1732\n",
            "[13:32:09.782390] Epoch: [86] Total time: 0:00:00 (0.1896 s / it)\n",
            "[13:32:09.782515] [Val] averaged stats: loss: 1.1212 (1.0830)  MAE: 0.1583 (0.1552)  MSE: 0.0792 (0.0748)\n",
            "[13:32:09.784837] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:32:09.787235] [Time] 19.1s 29.1m/33.9m\n",
            "\n",
            "[13:32:09.787291] ~~~ Epoch 87/100 ~~~\n",
            "\n",
            "[13:32:10.472819] Epoch: [87]  [ 0/45]  eta: 0:00:30  loss: 0.8910 (0.8910)  MAE: 0.1502 (0.1502)  MSE: 0.1142 (0.1142)  lr: 0.000100  iter-time: 0.6834\n",
            "[13:32:14.465818] Epoch: [87]  [10/45]  eta: 0:00:14  loss: 0.9857 (0.9798)  MAE: 0.1742 (0.1817)  MSE: 0.1087 (0.1078)  lr: 0.000100  iter-time: 0.4249\n",
            "[13:32:18.511262] Epoch: [87]  [20/45]  eta: 0:00:10  loss: 0.7762 (0.8861)  MAE: 0.1819 (0.1828)  MSE: 0.1086 (0.1117)  lr: 0.000100  iter-time: 0.4017\n",
            "[13:32:22.529149] Epoch: [87]  [30/45]  eta: 0:00:06  loss: 0.7762 (0.8649)  MAE: 0.1876 (0.1856)  MSE: 0.1162 (0.1135)  lr: 0.000100  iter-time: 0.4030\n",
            "[13:32:26.511588] Epoch: [87]  [40/45]  eta: 0:00:02  loss: 0.8631 (0.8863)  MAE: 0.1836 (0.1828)  MSE: 0.1073 (0.1080)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:32:27.925711] Epoch: [87]  [44/45]  eta: 0:00:00  loss: 0.8622 (0.8906)  MAE: 0.1782 (0.1818)  MSE: 0.0825 (0.1070)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:32:28.021923] Epoch: [87] Total time: 0:00:18 (0.4052 s / it)\n",
            "[13:32:28.022120] [Train] averaged stats: loss: 0.8622 (0.8906)  MAE: 0.1782 (0.1818)  MSE: 0.0825 (0.1070)  lr: 0.000100\n",
            "[13:32:28.370213] Epoch: [87]  [0/5]  eta: 0:00:01  loss: 1.0009 (1.0009)  MAE: 0.1201 (0.1201)  MSE: 0.0396 (0.0396)  iter-time: 0.3463\n",
            "[13:32:28.866197] Epoch: [87]  [4/5]  eta: 0:00:00  loss: 1.1174 (1.0886)  MAE: 0.1546 (0.1517)  MSE: 0.0753 (0.0708)  iter-time: 0.1683\n",
            "[13:32:28.954149] Epoch: [87] Total time: 0:00:00 (0.1862 s / it)\n",
            "[13:32:28.954920] [Val] averaged stats: loss: 1.1174 (1.0886)  MAE: 0.1546 (0.1517)  MSE: 0.0753 (0.0708)\n",
            "[13:32:28.956898] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 4 out of 20\n",
            "[13:32:28.959187] [Time] 19.2s 29.4m/33.9m\n",
            "\n",
            "[13:32:28.959245] ~~~ Epoch 88/100 ~~~\n",
            "\n",
            "[13:32:29.623912] Epoch: [88]  [ 0/45]  eta: 0:00:29  loss: 1.0529 (1.0529)  MAE: 0.1482 (0.1482)  MSE: 0.1021 (0.1021)  lr: 0.000100  iter-time: 0.6627\n",
            "[13:32:33.666628] Epoch: [88]  [10/45]  eta: 0:00:14  loss: 0.7978 (0.8531)  MAE: 0.1754 (0.1827)  MSE: 0.1139 (0.1124)  lr: 0.000100  iter-time: 0.4276\n",
            "[13:32:37.687344] Epoch: [88]  [20/45]  eta: 0:00:10  loss: 0.8065 (0.8842)  MAE: 0.1864 (0.1877)  MSE: 0.1197 (0.1280)  lr: 0.000100  iter-time: 0.4029\n",
            "[13:32:41.670924] Epoch: [88]  [30/45]  eta: 0:00:06  loss: 0.8361 (0.8872)  MAE: 0.2012 (0.1926)  MSE: 0.1455 (0.1334)  lr: 0.000100  iter-time: 0.4000\n",
            "[13:32:45.658532] Epoch: [88]  [40/45]  eta: 0:00:02  loss: 0.8602 (0.9008)  MAE: 0.1955 (0.1922)  MSE: 0.1392 (0.1301)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:32:47.064515] Epoch: [88]  [44/45]  eta: 0:00:00  loss: 0.8602 (0.8973)  MAE: 0.1935 (0.1926)  MSE: 0.1259 (0.1316)  lr: 0.000100  iter-time: 0.3889\n",
            "[13:32:47.224909] Epoch: [88] Total time: 0:00:18 (0.4059 s / it)\n",
            "[13:32:47.226626] [Train] averaged stats: loss: 0.8602 (0.8973)  MAE: 0.1935 (0.1926)  MSE: 0.1259 (0.1316)  lr: 0.000100\n",
            "[13:32:47.781998] Epoch: [88]  [0/5]  eta: 0:00:02  loss: 1.0078 (1.0078)  MAE: 0.1380 (0.1380)  MSE: 0.0571 (0.0571)  iter-time: 0.5513\n",
            "[13:32:48.278207] Epoch: [88]  [4/5]  eta: 0:00:00  loss: 1.1370 (1.0889)  MAE: 0.1828 (0.1771)  MSE: 0.1120 (0.1036)  iter-time: 0.2090\n",
            "[13:32:48.400011] Epoch: [88] Total time: 0:00:01 (0.2340 s / it)\n",
            "[13:32:48.400183] [Val] averaged stats: loss: 1.1370 (1.0889)  MAE: 0.1828 (0.1771)  MSE: 0.1120 (0.1036)\n",
            "[13:32:48.400773] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 5 out of 20\n",
            "[13:32:48.405540] [Time] 19.4s 29.8m/34.0m\n",
            "\n",
            "[13:32:48.405594] ~~~ Epoch 89/100 ~~~\n",
            "\n",
            "[13:32:49.172816] Epoch: [89]  [ 0/45]  eta: 0:00:34  loss: 0.6996 (0.6996)  MAE: 0.1798 (0.1798)  MSE: 0.1772 (0.1772)  lr: 0.000100  iter-time: 0.7649\n",
            "[13:32:53.158356] Epoch: [89]  [10/45]  eta: 0:00:15  loss: 0.9205 (1.0117)  MAE: 0.2074 (0.2112)  MSE: 0.1772 (0.1740)  lr: 0.000100  iter-time: 0.4316\n",
            "[13:32:57.136158] Epoch: [89]  [20/45]  eta: 0:00:10  loss: 0.8332 (0.9019)  MAE: 0.2035 (0.2079)  MSE: 0.1824 (0.1860)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:33:01.126693] Epoch: [89]  [30/45]  eta: 0:00:06  loss: 0.7958 (0.8974)  MAE: 0.1981 (0.2018)  MSE: 0.1712 (0.1766)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:33:05.120598] Epoch: [89]  [40/45]  eta: 0:00:02  loss: 0.8865 (0.9009)  MAE: 0.1742 (0.1929)  MSE: 0.1327 (0.1575)  lr: 0.000100  iter-time: 0.3991\n",
            "[13:33:06.531658] Epoch: [89]  [44/45]  eta: 0:00:00  loss: 0.8103 (0.8876)  MAE: 0.1705 (0.1911)  MSE: 0.0911 (0.1532)  lr: 0.000100  iter-time: 0.3902\n",
            "[13:33:06.672620] Epoch: [89] Total time: 0:00:18 (0.4059 s / it)\n",
            "[13:33:06.675407] [Train] averaged stats: loss: 0.8103 (0.8876)  MAE: 0.1705 (0.1911)  MSE: 0.0911 (0.1532)  lr: 0.000100\n",
            "[13:33:07.126649] Epoch: [89]  [0/5]  eta: 0:00:02  loss: 1.0344 (1.0344)  MAE: 0.1270 (0.1270)  MSE: 0.0445 (0.0445)  iter-time: 0.4481\n",
            "[13:33:07.619264] Epoch: [89]  [4/5]  eta: 0:00:00  loss: 1.1149 (1.0893)  MAE: 0.1644 (0.1608)  MSE: 0.0852 (0.0807)  iter-time: 0.1880\n",
            "[13:33:07.708793] Epoch: [89] Total time: 0:00:01 (0.2061 s / it)\n",
            "[13:33:07.708943] [Val] averaged stats: loss: 1.1149 (1.0893)  MAE: 0.1644 (0.1608)  MSE: 0.0852 (0.0807)\n",
            "[13:33:07.711639] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 6 out of 20\n",
            "[13:33:07.714255] [Time] 19.3s 30.1m/34.0m\n",
            "\n",
            "[13:33:07.714317] ~~~ Epoch 90/100 ~~~\n",
            "\n",
            "[13:33:08.465125] Epoch: [90]  [ 0/45]  eta: 0:00:33  loss: 0.5837 (0.5837)  MAE: 0.1600 (0.1600)  MSE: 0.1351 (0.1351)  lr: 0.000100  iter-time: 0.7485\n",
            "[13:33:12.446363] Epoch: [90]  [10/45]  eta: 0:00:15  loss: 0.7552 (0.8246)  MAE: 0.1830 (0.1885)  MSE: 0.1267 (0.1239)  lr: 0.000100  iter-time: 0.4298\n",
            "[13:33:16.415763] Epoch: [90]  [20/45]  eta: 0:00:10  loss: 0.7209 (0.7941)  MAE: 0.1931 (0.1933)  MSE: 0.1320 (0.1408)  lr: 0.000100  iter-time: 0.3974\n",
            "[13:33:20.416647] Epoch: [90]  [30/45]  eta: 0:00:06  loss: 0.7686 (0.8122)  MAE: 0.1938 (0.1953)  MSE: 0.1466 (0.1421)  lr: 0.000100  iter-time: 0.3984\n",
            "[13:33:24.401493] Epoch: [90]  [40/45]  eta: 0:00:02  loss: 0.8895 (0.8515)  MAE: 0.1942 (0.1948)  MSE: 0.1404 (0.1366)  lr: 0.000100  iter-time: 0.3991\n",
            "[13:33:25.807794] Epoch: [90]  [44/45]  eta: 0:00:00  loss: 0.8804 (0.8486)  MAE: 0.1942 (0.1962)  MSE: 0.1253 (0.1373)  lr: 0.000100  iter-time: 0.3895\n",
            "[13:33:25.902730] Epoch: [90] Total time: 0:00:18 (0.4042 s / it)\n",
            "[13:33:25.902902] [Train] averaged stats: loss: 0.8804 (0.8486)  MAE: 0.1942 (0.1962)  MSE: 0.1253 (0.1373)  lr: 0.000100\n",
            "[13:33:26.289322] Epoch: [90]  [0/5]  eta: 0:00:01  loss: 0.9887 (0.9887)  MAE: 0.1441 (0.1441)  MSE: 0.0590 (0.0590)  iter-time: 0.3844\n",
            "[13:33:26.781101] Epoch: [90]  [4/5]  eta: 0:00:00  loss: 1.1485 (1.0951)  MAE: 0.1955 (0.1882)  MSE: 0.1190 (0.1096)  iter-time: 0.1751\n",
            "[13:33:26.856544] Epoch: [90] Total time: 0:00:00 (0.1904 s / it)\n",
            "[13:33:26.856672] [Val] averaged stats: loss: 1.1485 (1.0951)  MAE: 0.1955 (0.1882)  MSE: 0.1190 (0.1096)\n",
            "[13:33:26.859130] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "[13:33:26.861483] Creating training plots . . .\n",
            "EarlyStopping counter: 7 out of 20\n",
            "[13:33:27.267786] [Time] 19.6s 30.4m/34.0m\n",
            "\n",
            "[13:33:27.269064] ~~~ Epoch 91/100 ~~~\n",
            "\n",
            "[13:33:27.889730] Epoch: [91]  [ 0/45]  eta: 0:00:27  loss: 0.6645 (0.6645)  MAE: 0.1897 (0.1897)  MSE: 0.1554 (0.1554)  lr: 0.000100  iter-time: 0.6183\n",
            "[13:33:31.853388] Epoch: [91]  [10/45]  eta: 0:00:14  loss: 0.7076 (0.7952)  MAE: 0.2177 (0.2212)  MSE: 0.1554 (0.1561)  lr: 0.000100  iter-time: 0.4164\n",
            "[13:33:35.841763] Epoch: [91]  [20/45]  eta: 0:00:10  loss: 0.7115 (0.7777)  MAE: 0.2094 (0.2110)  MSE: 0.1456 (0.1528)  lr: 0.000100  iter-time: 0.3974\n",
            "[13:33:39.841417] Epoch: [91]  [30/45]  eta: 0:00:06  loss: 0.7686 (0.7969)  MAE: 0.1924 (0.2023)  MSE: 0.1218 (0.1411)  lr: 0.000100  iter-time: 0.3992\n",
            "[13:33:43.808328] Epoch: [91]  [40/45]  eta: 0:00:02  loss: 0.8299 (0.8227)  MAE: 0.1771 (0.1948)  MSE: 0.1058 (0.1278)  lr: 0.000100  iter-time: 0.3982\n",
            "[13:33:45.219523] Epoch: [91]  [44/45]  eta: 0:00:00  loss: 0.9254 (0.8288)  MAE: 0.1737 (0.1928)  MSE: 0.0795 (0.1245)  lr: 0.000100  iter-time: 0.3887\n",
            "[13:33:45.316722] Epoch: [91] Total time: 0:00:18 (0.4010 s / it)\n",
            "[13:33:45.317956] [Train] averaged stats: loss: 0.9254 (0.8288)  MAE: 0.1737 (0.1928)  MSE: 0.0795 (0.1245)  lr: 0.000100\n",
            "[13:33:45.718653] Epoch: [91]  [0/5]  eta: 0:00:01  loss: 1.0196 (1.0196)  MAE: 0.1193 (0.1193)  MSE: 0.0373 (0.0373)  iter-time: 0.3973\n",
            "[13:33:46.213250] Epoch: [91]  [4/5]  eta: 0:00:00  loss: 1.1016 (1.0931)  MAE: 0.1604 (0.1571)  MSE: 0.0744 (0.0704)  iter-time: 0.1782\n",
            "[13:33:46.304414] Epoch: [91] Total time: 0:00:00 (0.1968 s / it)\n",
            "[13:33:46.304547] [Val] averaged stats: loss: 1.1016 (1.0931)  MAE: 0.1604 (0.1571)  MSE: 0.0744 (0.0704)\n",
            "[13:33:46.307573] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 8 out of 20\n",
            "[13:33:46.310207] [Time] 19.0s 30.7m/33.9m\n",
            "\n",
            "[13:33:46.310300] ~~~ Epoch 92/100 ~~~\n",
            "\n",
            "[13:33:47.058722] Epoch: [92]  [ 0/45]  eta: 0:00:33  loss: 0.6997 (0.6997)  MAE: 0.1609 (0.1609)  MSE: 0.1023 (0.1023)  lr: 0.000100  iter-time: 0.7461\n",
            "[13:33:51.037937] Epoch: [92]  [10/45]  eta: 0:00:15  loss: 0.8786 (0.8823)  MAE: 0.1834 (0.1859)  MSE: 0.1056 (0.1072)  lr: 0.000100  iter-time: 0.4294\n",
            "[13:33:55.032869] Epoch: [92]  [20/45]  eta: 0:00:10  loss: 0.8533 (0.8721)  MAE: 0.1834 (0.1857)  MSE: 0.1103 (0.1184)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:33:59.018804] Epoch: [92]  [30/45]  eta: 0:00:06  loss: 0.7692 (0.8533)  MAE: 0.1819 (0.1842)  MSE: 0.1268 (0.1209)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:34:02.995476] Epoch: [92]  [40/45]  eta: 0:00:02  loss: 0.8783 (0.8752)  MAE: 0.1819 (0.1830)  MSE: 0.1132 (0.1186)  lr: 0.000100  iter-time: 0.3980\n",
            "[13:34:04.405446] Epoch: [92]  [44/45]  eta: 0:00:00  loss: 0.8832 (0.8782)  MAE: 0.1822 (0.1839)  MSE: 0.1147 (0.1208)  lr: 0.000100  iter-time: 0.3885\n",
            "[13:34:04.498957] Epoch: [92] Total time: 0:00:18 (0.4042 s / it)\n",
            "[13:34:04.499918] [Train] averaged stats: loss: 0.8832 (0.8782)  MAE: 0.1822 (0.1839)  MSE: 0.1147 (0.1208)  lr: 0.000100\n",
            "[13:34:04.905540] Epoch: [92]  [0/5]  eta: 0:00:02  loss: 1.0552 (1.0552)  MAE: 0.1265 (0.1265)  MSE: 0.0525 (0.0525)  iter-time: 0.4016\n",
            "[13:34:05.396619] Epoch: [92]  [4/5]  eta: 0:00:00  loss: 1.1428 (1.1053)  MAE: 0.1714 (0.1667)  MSE: 0.1061 (0.0989)  iter-time: 0.1784\n",
            "[13:34:05.477657] Epoch: [92] Total time: 0:00:00 (0.1949 s / it)\n",
            "[13:34:05.477780] [Val] averaged stats: loss: 1.1428 (1.1053)  MAE: 0.1714 (0.1667)  MSE: 0.1061 (0.0989)\n",
            "[13:34:05.481627] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 9 out of 20\n",
            "[13:34:05.484963] [Time] 19.2s 31.1m/33.9m\n",
            "\n",
            "[13:34:05.485661] ~~~ Epoch 93/100 ~~~\n",
            "\n",
            "[13:34:06.083550] Epoch: [93]  [ 0/45]  eta: 0:00:26  loss: 0.5904 (0.5904)  MAE: 0.1686 (0.1686)  MSE: 0.1461 (0.1461)  lr: 0.000100  iter-time: 0.5957\n",
            "[13:34:10.074148] Epoch: [93]  [10/45]  eta: 0:00:14  loss: 0.7908 (0.8448)  MAE: 0.1909 (0.1966)  MSE: 0.1461 (0.1456)  lr: 0.000100  iter-time: 0.4168\n",
            "[13:34:14.093657] Epoch: [93]  [20/45]  eta: 0:00:10  loss: 0.7590 (0.8279)  MAE: 0.1880 (0.1915)  MSE: 0.1387 (0.1455)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:34:18.072154] Epoch: [93]  [30/45]  eta: 0:00:06  loss: 0.7590 (0.8313)  MAE: 0.1815 (0.1878)  MSE: 0.1166 (0.1348)  lr: 0.000100  iter-time: 0.3996\n",
            "[13:34:22.056416] Epoch: [93]  [40/45]  eta: 0:00:02  loss: 0.8145 (0.8497)  MAE: 0.1826 (0.1883)  MSE: 0.1111 (0.1319)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:34:23.464061] Epoch: [93]  [44/45]  eta: 0:00:00  loss: 0.8836 (0.8589)  MAE: 0.1839 (0.1903)  MSE: 0.1190 (0.1379)  lr: 0.000100  iter-time: 0.3888\n",
            "[13:34:23.595935] Epoch: [93] Total time: 0:00:18 (0.4024 s / it)\n",
            "[13:34:23.597359] [Train] averaged stats: loss: 0.8836 (0.8589)  MAE: 0.1839 (0.1903)  MSE: 0.1190 (0.1379)  lr: 0.000100\n",
            "[13:34:24.182137] Epoch: [93]  [0/5]  eta: 0:00:02  loss: 1.0340 (1.0340)  MAE: 0.1392 (0.1392)  MSE: 0.0734 (0.0734)  iter-time: 0.5813\n",
            "[13:34:24.680087] Epoch: [93]  [4/5]  eta: 0:00:00  loss: 1.1188 (1.0960)  MAE: 0.1889 (0.1840)  MSE: 0.1490 (0.1390)  iter-time: 0.2153\n",
            "[13:34:24.819749] Epoch: [93] Total time: 0:00:01 (0.2439 s / it)\n",
            "[13:34:24.819871] [Val] averaged stats: loss: 1.1188 (1.0960)  MAE: 0.1889 (0.1840)  MSE: 0.1490 (0.1390)\n",
            "[13:34:24.820449] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 10 out of 20\n",
            "[13:34:24.824835] [Time] 19.3s 31.4m/34.0m\n",
            "\n",
            "[13:34:24.824876] ~~~ Epoch 94/100 ~~~\n",
            "\n",
            "[13:34:25.724004] Epoch: [94]  [ 0/45]  eta: 0:00:40  loss: 0.9982 (0.9982)  MAE: 0.1974 (0.1974)  MSE: 0.2486 (0.2486)  lr: 0.000100  iter-time: 0.8947\n",
            "[13:34:29.729922] Epoch: [94]  [10/45]  eta: 0:00:15  loss: 0.8378 (0.8166)  MAE: 0.2118 (0.2194)  MSE: 0.2133 (0.2078)  lr: 0.000100  iter-time: 0.4453\n",
            "[13:34:33.723152] Epoch: [94]  [20/45]  eta: 0:00:10  loss: 0.7819 (0.7681)  MAE: 0.2054 (0.2074)  MSE: 0.1778 (0.1944)  lr: 0.000100  iter-time: 0.3997\n",
            "[13:34:37.708668] Epoch: [94]  [30/45]  eta: 0:00:06  loss: 0.7819 (0.7947)  MAE: 0.1857 (0.1975)  MSE: 0.1406 (0.1720)  lr: 0.000100  iter-time: 0.3987\n",
            "[13:34:41.696515] Epoch: [94]  [40/45]  eta: 0:00:02  loss: 0.8562 (0.8207)  MAE: 0.1709 (0.1905)  MSE: 0.1076 (0.1541)  lr: 0.000100  iter-time: 0.3985\n",
            "[13:34:43.105279] Epoch: [94]  [44/45]  eta: 0:00:00  loss: 0.8111 (0.8260)  MAE: 0.1709 (0.1898)  MSE: 0.1076 (0.1517)  lr: 0.000100  iter-time: 0.3892\n",
            "[13:34:43.260406] Epoch: [94] Total time: 0:00:18 (0.4097 s / it)\n",
            "[13:34:43.261532] [Train] averaged stats: loss: 0.8111 (0.8260)  MAE: 0.1709 (0.1898)  MSE: 0.1076 (0.1517)  lr: 0.000100\n",
            "[13:34:43.733874] Epoch: [94]  [0/5]  eta: 0:00:02  loss: 0.9850 (0.9850)  MAE: 0.1311 (0.1311)  MSE: 0.0525 (0.0525)  iter-time: 0.4683\n",
            "[13:34:44.225007] Epoch: [94]  [4/5]  eta: 0:00:00  loss: 1.0999 (1.0833)  MAE: 0.1784 (0.1732)  MSE: 0.1066 (0.0999)  iter-time: 0.1915\n",
            "[13:34:44.307157] Epoch: [94] Total time: 0:00:01 (0.2084 s / it)\n",
            "[13:34:44.308139] [Val] averaged stats: loss: 1.0999 (1.0833)  MAE: 0.1784 (0.1732)  MSE: 0.1066 (0.0999)\n",
            "[13:34:44.309828] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 11 out of 20\n",
            "[13:34:44.312285] [Time] 19.5s 31.7m/34.0m\n",
            "\n",
            "[13:34:44.312347] ~~~ Epoch 95/100 ~~~\n",
            "\n",
            "[13:34:44.994694] Epoch: [95]  [ 0/45]  eta: 0:00:30  loss: 0.8090 (0.8090)  MAE: 0.1737 (0.1737)  MSE: 0.1545 (0.1545)  lr: 0.000100  iter-time: 0.6801\n",
            "[13:34:48.967460] Epoch: [95]  [10/45]  eta: 0:00:14  loss: 0.8090 (0.8230)  MAE: 0.1989 (0.2042)  MSE: 0.1517 (0.1515)  lr: 0.000100  iter-time: 0.4229\n",
            "[13:34:52.953264] Epoch: [95]  [20/45]  eta: 0:00:10  loss: 0.8295 (0.8186)  MAE: 0.1989 (0.2031)  MSE: 0.1517 (0.1609)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:34:56.952261] Epoch: [95]  [30/45]  eta: 0:00:06  loss: 0.8449 (0.8288)  MAE: 0.2042 (0.2053)  MSE: 0.1678 (0.1611)  lr: 0.000100  iter-time: 0.3990\n",
            "[13:35:00.954509] Epoch: [95]  [40/45]  eta: 0:00:02  loss: 0.8607 (0.8396)  MAE: 0.2033 (0.2033)  MSE: 0.1551 (0.1521)  lr: 0.000100  iter-time: 0.3999\n",
            "[13:35:02.367993] Epoch: [95]  [44/45]  eta: 0:00:00  loss: 0.8522 (0.8381)  MAE: 0.2031 (0.2029)  MSE: 0.1150 (0.1504)  lr: 0.000100  iter-time: 0.3909\n",
            "[13:35:02.463939] Epoch: [95] Total time: 0:00:18 (0.4033 s / it)\n",
            "[13:35:02.464953] [Train] averaged stats: loss: 0.8522 (0.8381)  MAE: 0.2031 (0.2029)  MSE: 0.1150 (0.1504)  lr: 0.000100\n",
            "[13:35:02.827262] Epoch: [95]  [0/5]  eta: 0:00:01  loss: 1.0190 (1.0190)  MAE: 0.1382 (0.1382)  MSE: 0.0519 (0.0519)  iter-time: 0.3582\n",
            "[13:35:03.319692] Epoch: [95]  [4/5]  eta: 0:00:00  loss: 1.1032 (1.0814)  MAE: 0.1781 (0.1731)  MSE: 0.0974 (0.0905)  iter-time: 0.1700\n",
            "[13:35:03.399001] Epoch: [95] Total time: 0:00:00 (0.1861 s / it)\n",
            "[13:35:03.399194] [Val] averaged stats: loss: 1.1032 (1.0814)  MAE: 0.1781 (0.1731)  MSE: 0.0974 (0.0905)\n",
            "[13:35:03.401572] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "[13:35:03.403924] Creating training plots . . .\n",
            "EarlyStopping counter: 12 out of 20\n",
            "[13:35:03.811633] [Time] 19.5s 32.0m/34.0m\n",
            "\n",
            "[13:35:03.812980] ~~~ Epoch 96/100 ~~~\n",
            "\n",
            "[13:35:04.431846] Epoch: [96]  [ 0/45]  eta: 0:00:27  loss: 1.0439 (1.0439)  MAE: 0.1842 (0.1842)  MSE: 0.1508 (0.1508)  lr: 0.000100  iter-time: 0.6162\n",
            "[13:35:08.420493] Epoch: [96]  [10/45]  eta: 0:00:14  loss: 0.9246 (0.8788)  MAE: 0.2046 (0.2051)  MSE: 0.1433 (0.1405)  lr: 0.000100  iter-time: 0.4185\n",
            "[13:35:12.421146] Epoch: [96]  [20/45]  eta: 0:00:10  loss: 0.8128 (0.8620)  MAE: 0.1902 (0.1953)  MSE: 0.1373 (0.1429)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:35:16.447359] Epoch: [96]  [30/45]  eta: 0:00:06  loss: 0.8061 (0.8617)  MAE: 0.1804 (0.1888)  MSE: 0.1339 (0.1372)  lr: 0.000100  iter-time: 0.4012\n",
            "[13:35:20.437537] Epoch: [96]  [40/45]  eta: 0:00:02  loss: 0.8344 (0.8611)  MAE: 0.1702 (0.1838)  MSE: 0.1138 (0.1273)  lr: 0.000100  iter-time: 0.4006\n",
            "[13:35:21.844105] Epoch: [96]  [44/45]  eta: 0:00:00  loss: 0.8344 (0.8608)  MAE: 0.1702 (0.1836)  MSE: 0.0978 (0.1265)  lr: 0.000100  iter-time: 0.3904\n",
            "[13:35:21.950008] Epoch: [96] Total time: 0:00:18 (0.4030 s / it)\n",
            "[13:35:21.952678] [Train] averaged stats: loss: 0.8344 (0.8608)  MAE: 0.1702 (0.1836)  MSE: 0.0978 (0.1265)  lr: 0.000100\n",
            "[13:35:22.322282] Epoch: [96]  [0/5]  eta: 0:00:01  loss: 1.0142 (1.0142)  MAE: 0.1268 (0.1268)  MSE: 0.0461 (0.0461)  iter-time: 0.3639\n",
            "[13:35:22.814818] Epoch: [96]  [4/5]  eta: 0:00:00  loss: 1.1073 (1.0810)  MAE: 0.1660 (0.1613)  MSE: 0.0895 (0.0830)  iter-time: 0.1712\n",
            "[13:35:22.896543] Epoch: [96] Total time: 0:00:00 (0.1877 s / it)\n",
            "[13:35:22.896672] [Val] averaged stats: loss: 1.1073 (1.0810)  MAE: 0.1660 (0.1613)  MSE: 0.0895 (0.0830)\n",
            "[13:35:22.897320] [Val] best loss: 1.0807 best  MAE: 0.1596 MSE: 0.0964 \n",
            "EarlyStopping counter: 13 out of 20\n",
            "[13:35:22.899091] [Time] 19.1s 32.3m/33.9m\n",
            "\n",
            "[13:35:22.899140] ~~~ Epoch 97/100 ~~~\n",
            "\n",
            "[13:35:23.515149] Epoch: [97]  [ 0/45]  eta: 0:00:27  loss: 0.8210 (0.8210)  MAE: 0.1736 (0.1736)  MSE: 0.1399 (0.1399)  lr: 0.000100  iter-time: 0.6137\n",
            "[13:35:27.494738] Epoch: [97]  [10/45]  eta: 0:00:14  loss: 0.8441 (0.8966)  MAE: 0.1970 (0.2035)  MSE: 0.1372 (0.1375)  lr: 0.000100  iter-time: 0.4174\n",
            "[13:35:31.493149] Epoch: [97]  [20/45]  eta: 0:00:10  loss: 0.8118 (0.8563)  MAE: 0.2035 (0.2063)  MSE: 0.1372 (0.1474)  lr: 0.000100  iter-time: 0.3988\n",
            "[13:35:35.494477] Epoch: [97]  [30/45]  eta: 0:00:06  loss: 0.7902 (0.8271)  MAE: 0.2096 (0.2075)  MSE: 0.1518 (0.1475)  lr: 0.000100  iter-time: 0.3999\n",
            "[13:35:39.473436] Epoch: [97]  [40/45]  eta: 0:00:02  loss: 0.8432 (0.8573)  MAE: 0.2074 (0.2055)  MSE: 0.1338 (0.1410)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:35:40.882309] Epoch: [97]  [44/45]  eta: 0:00:00  loss: 0.8963 (0.8708)  MAE: 0.2004 (0.2046)  MSE: 0.1097 (0.1401)  lr: 0.000100  iter-time: 0.3889\n",
            "[13:35:40.978005] Epoch: [97] Total time: 0:00:18 (0.4017 s / it)\n",
            "[13:35:40.978958] [Train] averaged stats: loss: 0.8963 (0.8708)  MAE: 0.2004 (0.2046)  MSE: 0.1097 (0.1401)  lr: 0.000100\n",
            "[13:35:41.301382] Epoch: [97]  [0/5]  eta: 0:00:01  loss: 1.0038 (1.0038)  MAE: 0.1345 (0.1345)  MSE: 0.0500 (0.0500)  iter-time: 0.3190\n",
            "[13:35:41.790164] Epoch: [97]  [4/5]  eta: 0:00:00  loss: 1.1045 (1.0728)  MAE: 0.1747 (0.1704)  MSE: 0.0956 (0.0894)  iter-time: 0.1614\n",
            "[13:35:41.866782] Epoch: [97] Total time: 0:00:00 (0.1770 s / it)\n",
            "[13:35:41.866916] [Val] averaged stats: loss: 1.1045 (1.0728)  MAE: 0.1747 (0.1704)  MSE: 0.0956 (0.0894)\n",
            "[13:35:41.869561] Val loss improved from 1.0807088613510132 to 1.072841477394104, saving model to /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:35:41.919473] [Val] best loss: 1.0728 best  MAE: 0.1704 MSE: 0.0894 \n",
            "[13:35:41.921954] [Time] 19.0s 32.7m/33.9m\n",
            "\n",
            "[13:35:41.922023] ~~~ Epoch 98/100 ~~~\n",
            "\n",
            "[13:35:42.618520] Epoch: [98]  [ 0/45]  eta: 0:00:31  loss: 0.8130 (0.8130)  MAE: 0.1778 (0.1778)  MSE: 0.1534 (0.1534)  lr: 0.000100  iter-time: 0.6945\n",
            "[13:35:46.618626] Epoch: [98]  [10/45]  eta: 0:00:14  loss: 0.8130 (0.8517)  MAE: 0.1950 (0.2021)  MSE: 0.1425 (0.1410)  lr: 0.000100  iter-time: 0.4266\n",
            "[13:35:50.627725] Epoch: [98]  [20/45]  eta: 0:00:10  loss: 0.8283 (0.8692)  MAE: 0.1963 (0.2007)  MSE: 0.1425 (0.1521)  lr: 0.000100  iter-time: 0.4003\n",
            "[13:35:54.607242] Epoch: [98]  [30/45]  eta: 0:00:06  loss: 0.8272 (0.8535)  MAE: 0.1917 (0.1956)  MSE: 0.1468 (0.1475)  lr: 0.000100  iter-time: 0.3993\n",
            "[13:35:58.581324] Epoch: [98]  [40/45]  eta: 0:00:02  loss: 0.8774 (0.8814)  MAE: 0.1742 (0.1871)  MSE: 0.1271 (0.1355)  lr: 0.000100  iter-time: 0.3975\n",
            "[13:35:59.989283] Epoch: [98]  [44/45]  eta: 0:00:00  loss: 0.8774 (0.8655)  MAE: 0.1639 (0.1850)  MSE: 0.0991 (0.1333)  lr: 0.000100  iter-time: 0.3882\n",
            "[13:36:00.091535] Epoch: [98] Total time: 0:00:18 (0.4038 s / it)\n",
            "[13:36:00.092485] [Train] averaged stats: loss: 0.8774 (0.8655)  MAE: 0.1639 (0.1850)  MSE: 0.0991 (0.1333)  lr: 0.000100\n",
            "[13:36:00.401524] Epoch: [98]  [0/5]  eta: 0:00:01  loss: 0.9849 (0.9849)  MAE: 0.1179 (0.1179)  MSE: 0.0424 (0.0424)  iter-time: 0.3063\n",
            "[13:36:00.893014] Epoch: [98]  [4/5]  eta: 0:00:00  loss: 1.1019 (1.0883)  MAE: 0.1530 (0.1490)  MSE: 0.0847 (0.0785)  iter-time: 0.1586\n",
            "[13:36:01.001557] Epoch: [98] Total time: 0:00:00 (0.1814 s / it)\n",
            "[13:36:01.001683] [Val] averaged stats: loss: 1.1019 (1.0883)  MAE: 0.1530 (0.1490)  MSE: 0.0847 (0.0785)\n",
            "[13:36:01.002236] [Val] best loss: 1.0728 best  MAE: 0.1704 MSE: 0.0894 \n",
            "EarlyStopping counter: 1 out of 20\n",
            "[13:36:01.004098] [Time] 19.1s 33.0m/33.9m\n",
            "\n",
            "[13:36:01.004152] ~~~ Epoch 99/100 ~~~\n",
            "\n",
            "[13:36:01.862506] Epoch: [99]  [ 0/45]  eta: 0:00:38  loss: 0.9187 (0.9187)  MAE: 0.1523 (0.1523)  MSE: 0.1293 (0.1293)  lr: 0.000100  iter-time: 0.8561\n",
            "[13:36:05.896202] Epoch: [99]  [10/45]  eta: 0:00:15  loss: 0.8963 (0.8627)  MAE: 0.1722 (0.1731)  MSE: 0.1198 (0.1182)  lr: 0.000100  iter-time: 0.4443\n",
            "[13:36:09.916121] Epoch: [99]  [20/45]  eta: 0:00:10  loss: 0.8963 (0.9093)  MAE: 0.1687 (0.1719)  MSE: 0.1198 (0.1233)  lr: 0.000100  iter-time: 0.4024\n",
            "[13:36:13.896415] Epoch: [99]  [30/45]  eta: 0:00:06  loss: 0.8121 (0.8738)  MAE: 0.1683 (0.1703)  MSE: 0.1220 (0.1200)  lr: 0.000100  iter-time: 0.3998\n",
            "[13:36:17.874239] Epoch: [99]  [40/45]  eta: 0:00:02  loss: 0.8121 (0.8756)  MAE: 0.1624 (0.1674)  MSE: 0.0951 (0.1130)  lr: 0.000100  iter-time: 0.3977\n",
            "[13:36:19.282124] Epoch: [99]  [44/45]  eta: 0:00:00  loss: 0.8903 (0.8745)  MAE: 0.1624 (0.1672)  MSE: 0.0933 (0.1131)  lr: 0.000100  iter-time: 0.3884\n",
            "[13:36:19.415975] Epoch: [99] Total time: 0:00:18 (0.4091 s / it)\n",
            "[13:36:19.416184] [Train] averaged stats: loss: 0.8903 (0.8745)  MAE: 0.1624 (0.1672)  MSE: 0.0933 (0.1131)  lr: 0.000100\n",
            "[13:36:19.916252] Epoch: [99]  [0/5]  eta: 0:00:02  loss: 1.0363 (1.0363)  MAE: 0.1159 (0.1159)  MSE: 0.0436 (0.0436)  iter-time: 0.4978\n",
            "[13:36:20.406347] Epoch: [99]  [4/5]  eta: 0:00:00  loss: 1.0863 (1.0872)  MAE: 0.1510 (0.1465)  MSE: 0.0865 (0.0794)  iter-time: 0.1971\n",
            "[13:36:20.524981] Epoch: [99] Total time: 0:00:01 (0.2215 s / it)\n",
            "[13:36:20.525177] [Val] averaged stats: loss: 1.0863 (1.0872)  MAE: 0.1510 (0.1465)  MSE: 0.0865 (0.0794)\n",
            "[13:36:20.525781] [Val] best loss: 1.0728 best  MAE: 0.1704 MSE: 0.0894 \n",
            "EarlyStopping counter: 2 out of 20\n",
            "[13:36:20.533768] [Time] 19.5s 33.3m/34.0m\n",
            "\n",
            "[13:36:20.533820] ~~~ Epoch 100/100 ~~~\n",
            "\n",
            "[13:36:21.476892] Epoch: [100]  [ 0/45]  eta: 0:00:42  loss: 0.8689 (0.8689)  MAE: 0.1525 (0.1525)  MSE: 0.1373 (0.1373)  lr: 0.000100  iter-time: 0.9404\n",
            "[13:36:25.482074] Epoch: [100]  [10/45]  eta: 0:00:15  loss: 0.8689 (0.8355)  MAE: 0.1751 (0.1798)  MSE: 0.1283 (0.1279)  lr: 0.000100  iter-time: 0.4493\n",
            "[13:36:29.458650] Epoch: [100]  [20/45]  eta: 0:00:10  loss: 0.7352 (0.8080)  MAE: 0.1813 (0.1825)  MSE: 0.1283 (0.1339)  lr: 0.000100  iter-time: 0.3989\n",
            "[13:36:33.443610] Epoch: [100]  [30/45]  eta: 0:00:06  loss: 0.7526 (0.8040)  MAE: 0.1915 (0.1859)  MSE: 0.1289 (0.1313)  lr: 0.000100  iter-time: 0.3979\n",
            "[13:36:37.429722] Epoch: [100]  [40/45]  eta: 0:00:02  loss: 0.8329 (0.8293)  MAE: 0.1958 (0.1880)  MSE: 0.1180 (0.1270)  lr: 0.000100  iter-time: 0.3983\n",
            "[13:36:38.838128] Epoch: [100]  [44/45]  eta: 0:00:00  loss: 0.8296 (0.8199)  MAE: 0.1958 (0.1887)  MSE: 0.1046 (0.1270)  lr: 0.000100  iter-time: 0.3892\n",
            "[13:36:38.978510] Epoch: [100] Total time: 0:00:18 (0.4099 s / it)\n",
            "[13:36:38.979622] [Train] averaged stats: loss: 0.8296 (0.8199)  MAE: 0.1958 (0.1887)  MSE: 0.1046 (0.1270)  lr: 0.000100\n",
            "[13:36:39.418514] Epoch: [100]  [0/5]  eta: 0:00:02  loss: 0.9980 (0.9980)  MAE: 0.1313 (0.1313)  MSE: 0.0466 (0.0466)  iter-time: 0.4356\n",
            "[13:36:39.915239] Epoch: [100]  [4/5]  eta: 0:00:00  loss: 1.1274 (1.0859)  MAE: 0.1754 (0.1720)  MSE: 0.0912 (0.0864)  iter-time: 0.1860\n",
            "[13:36:39.992618] Epoch: [100] Total time: 0:00:01 (0.2020 s / it)\n",
            "[13:36:39.993584] [Val] averaged stats: loss: 1.1274 (1.0859)  MAE: 0.1754 (0.1720)  MSE: 0.0912 (0.0864)\n",
            "[13:36:39.995458] [Val] best loss: 1.0728 best  MAE: 0.1704 MSE: 0.0894 \n",
            "[13:36:39.997687] Creating training plots . . .\n",
            "EarlyStopping counter: 3 out of 20\n",
            "[13:36:40.401335] [Time] 19.9s 33.6m/34.0m\n",
            "\n",
            "[13:36:40.401410] Training time: 0:33:38\n",
            "[13:36:40.401454] Train loss: 0.8199064566029443\n",
            "[13:36:40.401497] Train MAE: 0.18868250019020505\n",
            "[13:36:40.404434] Train MSE: 0.12703374524911246\n",
            "[13:36:40.404493] Validation loss: 1.072841477394104\n",
            "[13:36:40.405925] Validation MAE: 0.17036060988903046\n",
            "[13:36:40.406664] Validation MSE: 0.08941168338060379\n",
            "[13:36:40.406718] Finished Training\n",
            "[13:36:40.791618] Releasing memory . . .\n",
            "[13:36:40.791924] ######################\n",
            "[13:36:40.793665] #   LOAD TEST DATA   #\n",
            "[13:36:40.793722] ######################\n",
            "[13:36:40.793803] 2) Loading test images . . .\n",
            "[13:36:40.793893] Loading data from /content/data/test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00<00:00,  2.84it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/biapy/utils/misc.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(resume, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:36:41.198503] *** Loaded data shape is (1, 35, 520, 692, 1)\n",
            "[13:36:41.199901] ############################\n",
            "[13:36:41.199971] #  PREPARE TEST GENERATOR  #\n",
            "[13:36:41.201158] ############################\n",
            "[13:36:41.348654] Loading checkpoint from file /content/output/my_3d_denoising/checkpoints/my_3d_denoising_1-checkpoint-best.pth\n",
            "[13:36:41.420541] Model weights loaded!\n",
            "[13:36:41.421896] ###############\n",
            "[13:36:41.421972] #  INFERENCE  #\n",
            "[13:36:41.422012] ###############\n",
            "[13:36:41.423591] Making predictions on test data . . .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:36:41.579664] Processing image: flywing.tif\n",
            "[13:36:41.579848] ### 3D-OV-CROP ###\n",
            "[13:36:41.579901] Cropping (35, 520, 692, 1) images into (32, 64, 64, 1) with overlapping . . .\n",
            "[13:36:41.581918] Minimum overlap selected: (0, 0, 0)\n",
            "[13:36:41.581965] Padding: (4, 8, 8)\n",
            "[13:36:41.604606] Real overlapping (%): (0.5416666666666666, 0.0, 0.041666666666666664)\n",
            "[13:36:41.604732] Real overlapping (pixels): (13.0, 0.0, 2.0)\n",
            "[13:36:41.606075] (2, 15, 11) patches per (z,y,x) axis\n",
            "[13:36:41.728795] **** New data shape is: (330, 32, 64, 64, 1)\n",
            "[13:36:41.728937] ### END 3D-OV-CROP ###\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/83 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/biapy/engine/denoising.py:255: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "\n",
            "  1%|          | 1/83 [00:00<01:04,  1.26it/s]\u001b[A\n",
            "  5%|\u258d         | 4/83 [00:00<00:14,  5.36it/s]\u001b[A\n",
            "  8%|\u258a         | 7/83 [00:01<00:08,  9.03it/s]\u001b[A\n",
            " 12%|\u2588\u258f        | 10/83 [00:01<00:06, 12.15it/s]\u001b[A\n",
            " 16%|\u2588\u258c        | 13/83 [00:01<00:04, 14.59it/s]\u001b[A\n",
            " 19%|\u2588\u2589        | 16/83 [00:01<00:04, 16.53it/s]\u001b[A\n",
            " 23%|\u2588\u2588\u258e       | 19/83 [00:01<00:03, 17.98it/s]\u001b[A\n",
            " 27%|\u2588\u2588\u258b       | 22/83 [00:01<00:03, 18.77it/s]\u001b[A\n",
            " 30%|\u2588\u2588\u2588       | 25/83 [00:01<00:02, 19.73it/s]\u001b[A\n",
            " 34%|\u2588\u2588\u2588\u258e      | 28/83 [00:02<00:02, 20.44it/s]\u001b[A\n",
            " 37%|\u2588\u2588\u2588\u258b      | 31/83 [00:02<00:02, 20.88it/s]\u001b[A\n",
            " 41%|\u2588\u2588\u2588\u2588      | 34/83 [00:02<00:02, 21.16it/s]\u001b[A\n",
            " 45%|\u2588\u2588\u2588\u2588\u258d     | 37/83 [00:02<00:02, 21.38it/s]\u001b[A\n",
            " 48%|\u2588\u2588\u2588\u2588\u258a     | 40/83 [00:02<00:01, 21.61it/s]\u001b[A\n",
            " 52%|\u2588\u2588\u2588\u2588\u2588\u258f    | 43/83 [00:02<00:01, 21.47it/s]\u001b[A\n",
            " 55%|\u2588\u2588\u2588\u2588\u2588\u258c    | 46/83 [00:02<00:01, 21.51it/s]\u001b[A\n",
            " 59%|\u2588\u2588\u2588\u2588\u2588\u2589    | 49/83 [00:02<00:01, 21.57it/s]\u001b[A\n",
            " 63%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 52/83 [00:03<00:01, 21.71it/s]\u001b[A\n",
            " 66%|\u2588\u2588\u2588\u2588\u2588\u2588\u258b   | 55/83 [00:03<00:01, 21.75it/s]\u001b[A\n",
            " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2589   | 58/83 [00:03<00:01, 21.83it/s]\u001b[A\n",
            " 73%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e  | 61/83 [00:03<00:01, 21.77it/s]\u001b[A\n",
            " 77%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b  | 64/83 [00:03<00:00, 21.69it/s]\u001b[A\n",
            " 81%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588  | 67/83 [00:03<00:00, 21.72it/s]\u001b[A\n",
            " 84%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258d | 70/83 [00:03<00:00, 21.72it/s]\u001b[A\n",
            " 88%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a | 73/83 [00:04<00:00, 21.64it/s]\u001b[A\n",
            " 92%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f| 76/83 [00:04<00:00, 21.74it/s]\u001b[A\n",
            " 95%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c| 79/83 [00:04<00:00, 21.78it/s]\u001b[A\n",
            " 99%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2589| 82/83 [00:04<00:00, 21.84it/s]\u001b[A\n",
            "                                               \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:36:46.563915] ### MERGE-3D-OV-CROP ###\n",
            "[13:36:46.564018] Merging (330, 32, 64, 64, 1) images into (35, 520, 692, 1) with overlapping . . .\n",
            "[13:36:46.564066] Minimum overlap selected: (0, 0, 0)\n",
            "[13:36:46.564103] Padding: (4, 8, 8)\n",
            "[13:36:46.564198] Real overlapping (%): (0.5416666666666666, 0.0, 0.041666666666666664)\n",
            "[13:36:46.564232] Real overlapping (pixels): (13.0, 0.0, 2.0)\n",
            "[13:36:46.564262] (2, 15, 11) patches per (z,y,x) axis\n",
            "[13:36:46.746586] **** New data shape is: (35, 520, 692, 1)\n",
            "[13:36:46.746721] ### END MERGE-3D-OV-CROP ###\n",
            "[13:36:46.814263] Saving (1, 35, 520, 692, 1) data as .tif in folder: /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:01<00:00,  1.52s/it]\u001b[A\n",
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:06<00:00,  6.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:36:48.376216] Releasing memory . . .\n",
            "[13:36:48.376906] #############\n",
            "[13:36:48.376943] #  RESULTS  #\n",
            "[13:36:48.376970] #############\n",
            "[13:36:48.377007] Epoch number: 100\n",
            "[13:36:48.377058] Train time (s): 0:33:38\n",
            "[13:36:48.377246] Train loss: 0.8047901650269826\n",
            "[13:36:48.377369] Train MAE: 0.16071298254860772\n",
            "[13:36:48.377471] Train MSE: 0.09491034895181656\n",
            "[13:36:48.377520] Validation loss: 1.072841477394104\n",
            "[13:36:48.377575] Validation MAE: 0.17036060988903046\n",
            "[13:36:48.377621] Validation MSE: 0.08941168338060379\n",
            "[13:36:48.377717] FINISHED JOB my_3d_denoising_1 !!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play to train the model\n",
        "import os\n",
        "import errno\n",
        "\n",
        "os.chdir('/content/')\n",
        "\n",
        "job_name = model_name\n",
        "yaml_file = \"/content/\"+str(job_name)+\".yaml\"\n",
        "\n",
        "# remove previous configuration file if it exists with the same name\n",
        "if os.path.exists( yaml_file ):\n",
        "    os.remove( yaml_file )\n",
        "\n",
        "# remove template file it is exists\n",
        "template_file = '3d_denoising.yaml'\n",
        "if os.path.exists( template_file ):\n",
        "    os.remove( template_file )\n",
        "\n",
        "# Download template file\n",
        "!wget https://raw.githubusercontent.com/BiaPyX/BiaPy/master/templates/denoising/3d_denoising.yaml &> /dev/null\n",
        "\n",
        "# Check files before modifying the .yaml file\n",
        "if not os.path.exists(train_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), train_data_path)\n",
        "ids = sorted(next(os.walk(train_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No files found in dir {}\".format(train_data_path))\n",
        "\n",
        "if not os.path.exists(test_data_path):\n",
        "    raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), test_data_path)\n",
        "ids = sorted(next(os.walk(test_data_path))[2])\n",
        "if len(ids) == 0:\n",
        "    raise ValueError(\"No files found in dir {}\".format(test_data_path))\n",
        "\n",
        "\n",
        "# open template configuration file\n",
        "import yaml\n",
        "with open( template_file, 'r') as stream:\n",
        "    try:\n",
        "        biapy_config = yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "        print(exc)\n",
        "\n",
        "# update paths to data\n",
        "biapy_config['DATA']['TRAIN']['PATH'] = train_data_path\n",
        "biapy_config['DATA']['TEST']['PATH'] = test_data_path\n",
        "\n",
        "# update data patch size\n",
        "biapy_config['DATA']['PATCH_SIZE'] = '('+str(patch_size_z)+', '+str(patch_size_xy)+', '+ str(patch_size_xy)+', ' + str(input_channels)+')'\n",
        "# adjust test padding accordingly\n",
        "padding_xy = patch_size_xy // 8\n",
        "padding_z = patch_size_z // 8\n",
        "biapy_config['DATA']['TEST']['PADDING'] = '('+str(padding_z)+', '+str(padding_xy)+', '+ str(padding_xy)+')'\n",
        "\n",
        "# update training parameters\n",
        "biapy_config['DATA']['VAL']['FROM_TRAIN'] = True\n",
        "biapy_config['DATA']['VAL']['SPLIT_TRAIN'] = percentage_validation/100.0\n",
        "biapy_config['TRAIN']['EPOCHS'] = number_of_epochs\n",
        "if number_of_epochs < 10:\n",
        "    biapy_config['LOG'] = {}\n",
        "    biapy_config['LOG']['CHART_CREATION_FREQ'] = 1\n",
        "biapy_config['TRAIN']['PATIENCE'] = patience\n",
        "biapy_config['TRAIN']['BATCH_SIZE'] = batch_size\n",
        "biapy_config['TRAIN']['OPTIMIZER'] = optimizer\n",
        "biapy_config['TRAIN']['LR'] = initial_learning_rate\n",
        "\n",
        "# update N2V parameters\n",
        "biapy_config['PROBLEM']['DENOISING']['N2V_PERC_PIX'] = n2v_perc_pix\n",
        "biapy_config['PROBLEM']['DENOISING']['N2V_MANIPULATOR'] = pixel_manipulator\n",
        "biapy_config['PROBLEM']['DENOISING']['N2V_NEIGHBORHOOD_RADIUS'] = neighborhood_radius\n",
        "biapy_config['PROBLEM']['DENOISING']['N2V_STRUCTMASK'] = apply_structmask\n",
        "\n",
        "# change source to build model - biapy, torchvision or bmz\n",
        "if changed_source:\n",
        "    if source.value == \"BiaPy\":\n",
        "        biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "    elif source.value == 'BioImage Model Zoo':\n",
        "        biapy_config['MODEL']['SOURCE'] = \"bmz\"\n",
        "        biapy_config['MODEL']['BMZ'] = {}\n",
        "        biapy_config['MODEL']['BMZ']['SOURCE_MODEL_ID'] = str(bmz.value).strip()\n",
        "else:\n",
        "    biapy_config['MODEL']['SOURCE'] = \"biapy\"\n",
        "\n",
        "\n",
        "# Transcribe model architecture\n",
        "architecture = 'unet'\n",
        "if model_architecture == \"U-Net\":\n",
        "    architecture = 'unet'\n",
        "elif model_architecture == \"Residual U-Net\":\n",
        "    architecture = 'resunet'\n",
        "elif model_architecture == 'ResUNet++':\n",
        "    architecture = 'resunet++'\n",
        "elif model_architecture == \"Attention U-Net\":\n",
        "    architecture = 'attention_unet'\n",
        "elif model_architecture == \"SEUNet\":\n",
        "    architecture = 'seunet'\n",
        "biapy_config['MODEL']['ARCHITECTURE'] = architecture\n",
        "\n",
        "if anisotropic_data == True:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [1 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "else:\n",
        "    biapy_config['MODEL']['Z_DOWN'] = [2 for i in range(len(biapy_config['MODEL']['FEATURE_MAPS'])-1)]\n",
        "\n",
        "# update test parameters\n",
        "biapy_config['TEST']['AUGMENTATION'] = test_time_augmentation\n",
        "\n",
        "# model weights\n",
        "if checkpoint_path != '':\n",
        "    biapy_config['PATHS'] = {}\n",
        "    biapy_config['PATHS']['CHECKPOINT_FILE'] = checkpoint_path\n",
        "    biapy_config['MODEL'] = {}\n",
        "    biapy_config['MODEL']['LOAD_CHECKPOINT'] = True\n",
        "\n",
        "\n",
        "# save file\n",
        "with open( yaml_file, 'w') as outfile:\n",
        "    yaml.dump(biapy_config, outfile, default_flow_style=False)\n",
        "\n",
        "print( \"Training configuration finished.\")\n",
        "\n",
        "# Run the code\n",
        "biapy = BiaPy(f'/content/{job_name}.yaml', result_dir=output_path, name=job_name, run_id=1, gpu=0)\n",
        "biapy.run_job()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4i0N2vOWUes"
      },
      "source": [
        "## **Inspection of the Loss Function and Mean Squared Error (MSE)**\n",
        "---\n",
        "\n",
        "Before proceeding with interpretations, it's pivotal to gauge the training evolution by juxtaposing the training loss against the validation loss. The validation loss casts light on the model's efficacy over a reserved subset of data unseen during training. A deeper understanding can be garnered from [this review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6381354/) by Nichols *et al.*\n",
        "\n",
        "- **Training Loss**: This captures the discrepancy between the model's predictions and the actual ground-truth after each epoch.\n",
        "\n",
        "- **Validation Loss**: This signifies the error between the model's estimates on validation images and their actual counterparts.\n",
        "\n",
        "As training unfurls, these metrics are expected to wane, eventually plateauing at an optimal, minimal value. Contrasting the trajectories of these losses can yield vital information about the model's adaptability.\n",
        "\n",
        "- **Decreasing Training and Validation Losses**: This trend is indicative of potential model improvements with further training. Elevating the `number_of_epochs` is advised in such scenarios. Notably, even if the loss curves seem to stabilize towards the tail end, it might be a mere visual effect due to y-axis scaling. The model is considered convergent once the curves genuinely flatten, marking the end of required training.\n",
        "\n",
        "- **Divergent Losses**: An upward tick in validation loss while training loss gravitates towards zero hints at overfitting. It suggests that the model is intricately memorizing training patterns at the cost of broader applicability. A more substantial training dataset can alleviate this.\n",
        "\n",
        "\n",
        "The **MSE** serves as a general yardstick to evaluate the model\u2019s prowess by contrasting the target with its prediction output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "ur21krhZVwX2",
        "outputId": "d73b2aa4-a7ea-4904-ea02-4b5a5ef43a4a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x1000 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ##Play the cell to show a plot of training error vs. epoch number and MSE vs epoch number\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_loss.png' )\n",
        "\n",
        "iou_plot = imread( output_path + '/'+job_name+'/results/'+job_name+'_1/charts/'+job_name+'_1_MSE.png' )\n",
        "\n",
        "fig = plt.figure( figsize = (20,10))\n",
        "ax1 = plt.subplot( 1, 2, 1 )\n",
        "_ = plt.imshow( loss_plot )\n",
        "_ = plt.axis('off')\n",
        "ax1.set_title( 'Training error vs epoch number', fontdict = {'fontsize':22})\n",
        "\n",
        "ax2 = plt.subplot( 1, 2, 2 )\n",
        "_ = plt.imshow( iou_plot )\n",
        "_ = plt.axis('off')\n",
        "_= ax2.set_title( 'MSE vs epoch number', fontdict = {'fontsize':22})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWl1LtdrNoYf"
      },
      "source": [
        "## **Visualize denoising results (from the test set)**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593,
          "referenced_widgets": [
            "46cd5f043c01451c9970abb00d44b15f",
            "22123db8ad7e4823bab0f94421a711dd",
            "0849cacc8fd84216bfce920a92be2df9",
            "fd038ebdab214e79b30646caed4ea60e",
            "fedc7e479f9c47458ac5e699fd47b90a",
            "7786a01a54714ac28ba7a9cc8b83e24a",
            "184e46466f42470a982aff724e5016c2"
          ]
        },
        "id": "7ogyiWIMNofh",
        "outputId": "2e3e83c0-e4ba-4ef3-9115-8db9ffaf9208",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(IntSlider(value=1, description='z', max=35, min=1), Output()), _dom_classes=('widget-int\u2026"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46cd5f043c01451c9970abb00d44b15f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "denoising_results = os.path.join(final_results, \"per_image\")\n",
        "\n",
        "#@markdown ###Play to visualize some results\n",
        "#@markdown The current model will be applied to some test images and results will be shown as browsable 2D stacks displaying:\n",
        "#@markdown 1. The original **Source** (input) image.\n",
        "#@markdown 2. The model **Prediction** (without noise) image.\n",
        "\n",
        "from IPython.display import Markdown as md\n",
        "md(\"After this last step, the resulting images should be placed in {}\".format(final_results))\n",
        "# Show a few examples to check that they have been stored correctly\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "from numpy.random import randint, seed\n",
        "from matplotlib import pyplot as plt\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "\n",
        "ids_pred = sorted(next(os.walk(denoising_results))[2])\n",
        "ids_input = sorted(next(os.walk(test_data_path))[2])\n",
        "\n",
        "samples_to_show = min(len(ids_input), 3)\n",
        "chosen_images = np.random.choice(len(ids_input), samples_to_show, replace=False)\n",
        "seed(1)\n",
        "\n",
        "test_samples = []\n",
        "test_sample_preds = []\n",
        "\n",
        "for i in range(len(chosen_images)):\n",
        "    aux = imread(os.path.join(test_data_path, ids_input[chosen_images[i]]))\n",
        "    test_samples.append(aux)\n",
        "\n",
        "    aux = imread(os.path.join(denoising_results, ids_pred[chosen_images[i]])).astype(np.uint16)\n",
        "    test_sample_preds.append(aux)\n",
        "\n",
        "# function to show results in 3D within a widget\n",
        "def scroll_in_z(z):\n",
        "\n",
        "    plt.figure(figsize=(25,10))\n",
        "    # Source\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_source[z-1], cmap='magma',vmin=np.percentile(test_source[z-1],0.1),vmax=np.percentile(test_source[z-1],99.9))\n",
        "    plt.title('Source (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(test_prediction[z-1], cmap='magma',vmin=np.percentile(test_prediction[z-1],0.1),vmax=np.percentile(test_prediction[z-1],99.9))\n",
        "    plt.title('Prediction (z = ' + str(z) + ')', fontsize=15)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for j in range(samples_to_show):\n",
        "    test_source = test_samples[j]\n",
        "    test_prediction = test_sample_preds[j]\n",
        "\n",
        "    interact(scroll_in_z, z=widgets.IntSlider(min=1, max=test_source.shape[0], step=1, value=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlQnAH6uAawl",
        "outputId": "ed2c1bdc-3b9a-4450-c81f-691f50d8bebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13:36:50.417340] Output paths:\n",
            "[13:36:50.418405]     Predicted test denoised images are in /content/output/my_3d_denoising/results/my_3d_denoising_1/per_image\n"
          ]
        }
      ],
      "source": [
        "#@markdown ###Play to display the path to the output denoised files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "\n",
        "denoising_results = os.path.join(final_results, \"per_image\")\n",
        "\n",
        "print(\"Output paths:\")\n",
        "print(\"    Predicted test denoised images are in {}\".format(denoising_results))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdCIYo4ohcAw"
      },
      "source": [
        "## **Download denoising results**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 16
        },
        "id": "gnRa9DOUP0FM",
        "outputId": "310ad34b-3781-4c55-d9f3-a190068c2de1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f76e1277-b741-4d53-845b-990eaae53643\", \"denoising.zip\", 35993656)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@markdown ###Play to download all denoising results in test.\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "!zip -q -j /content/denoising.zip $denoising_results/*.tif\n",
        "\n",
        "files.download(\"/content/denoising.zip\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kwt72WYddVgl"
      },
      "source": [
        "## **Download train model (weights and configuration file)**\n",
        "---\n",
        "If you want to **reuse the train model in the future**, you can download both the model weights and its configuration file (.YAML) by running the following cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "XoFclBfEduZC",
        "outputId": "e5898710-2258-4628-da8d-60c89e1e89d4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_c8b92b85-0cb2-49ea-bd3f-678428fc0ef1\", \"my_3d_denoising_1-checkpoint-best.pth\", 15523706)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "#@markdown ###Play to download the model weights\n",
        "\n",
        "checkpoints_path = os.path.join(output_path, job_name, 'checkpoints')\n",
        "\n",
        "weights_filename = str( job_name ) + '_1-checkpoint-best.pth'\n",
        "\n",
        "files.download( os.path.join( checkpoints_path, weights_filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "raDdSsz1dujE",
        "outputId": "596b570f-29ea-4e7c-bee4-2791631a44c1"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_64e1f516-cb10-41f6-b4e6-c6e1c017bcd6\", \"my_3d_denoising.yaml\", 980)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@markdown ###Play to download the model configuration file (.YAML)\n",
        "\n",
        "config_path = os.path.join(output_path, job_name, 'config_files')\n",
        "\n",
        "files.download( os.path.join( config_path, yaml_file))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b21qkJWuoFNF"
      },
      "source": [
        "## **Export your model to BioImage Model Zoo format**\n",
        "---\n",
        "If you want to export the model into the [BioImage Model Zoo](https://bioimage.io/#/) format, fill the metadata and run the following cell. After the cell is run a `trained_model_name.bmz.zip` file will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LWHr_sQK_-qs"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@markdown ##Construct model's metadata to export it to the BioImage Model Zoo format. Choose just one option:\n",
        "\n",
        "#@markdown **Option 1: Reuse previous BioImage Model Zoo model configuration**\n",
        "\n",
        "#@markdown With this option, if you were using a model from BioImage Model Zoo you can select this option to reuse its configuration instead of provide all fields manually. If that's not the case and you try to use this option an error will be thrown.\n",
        "reuse_previous_BMZ_model_config = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ---\n",
        "\n",
        "#@markdown **Option 2: Manual export fields**\n",
        "\n",
        "#@markdown With this option you need to introduce manually the metadata of the model.\n",
        "\n",
        "# ------------- User input ------------\n",
        "# information about the model\n",
        "trained_model_name    = \"\" #@param {type:\"string\"}\n",
        "trained_model_authors =  \"[First Author, Second Author, Third Author]\" #@param {type:\"string\"}\n",
        "trained_model_authors_github_user =  \"[First Author Github User, Second Author Github User, Third Author Github User]\" #@param {type:\"string\"}\n",
        "trained_model_description = \"\" #@param {type:\"string\"}\n",
        "trained_model_license = 'CC-BY-4.0'#@param {type:\"string\"}\n",
        "trained_model_references = [\"Ronneberger et al. arXiv in 2015\", \"Franco-Barranco, Daniel, et al. ISBI in 2023\"] #@param {type:\"string\"}\n",
        "trained_model_references_DOI = [\"10.1007/978-3-319-24574-4_28\",\"10.1109/ISBI53787.2023.10230593\"] #@param {type:\"string\"}\n",
        "trained_model_tags = \"[\\\"tag-1\\\", \\\"tag-2\\\"]\" #@param {type:\"string\"}\n",
        "trained_model_documentation = \"/content/README.md\" #@param {type:\"string\"}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KH8UuC_CgpH2"
      },
      "outputs": [],
      "source": [
        "# @markdown ###Play to download a zip file with your [BioImage Model Zoo](https://bioimage.io/#/) exported model\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "final_results = os.path.join(output_path, job_name, 'results', job_name+\"_1\")\n",
        "bmz_results = os.path.join(final_results, \"bmz_model\")\n",
        "\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "\n",
        "    # create the author spec input\n",
        "    auth_names = trained_model_authors[1:-1].split(\",\")\n",
        "    auth_githubusers = trained_model_authors_github_user[1:-1].split(\",\")\n",
        "    assert len(auth_names) == len(auth_githubusers)\n",
        "    authors = [{\"name\": auth_name, \"github_user\": auth_guser} for auth_name, auth_guser in zip(auth_names, auth_githubusers)]\n",
        "\n",
        "    # create the citation input spec\n",
        "    assert len(trained_model_references_DOI) == len(trained_model_references)\n",
        "    citations = [{'text': text, 'doi': doi} for text, doi in zip(trained_model_references, trained_model_references_DOI)]\n",
        "\n",
        "    tags = [t for t in trained_model_tags.split(\",\")]\n",
        "\n",
        "    with open(trained_model_documentation, \"w\") as f:\n",
        "        f.write(\"### **Description**\\n\")\n",
        "        f.write(f\"{trained_model_description}\\n\\n\")\n",
        "        f.write(\"This model was created using the [BiaPy library](https://biapyx.github.io/).\\n\")\n",
        "\n",
        "    bmz_cfg = {}\n",
        "    # Description of the model\n",
        "    bmz_cfg['description'] = trained_model_description\n",
        "    # Authors of the model. Need to be a list of dicts, e.g. authors=[{\"name\": \"Daniel\", \"github_user\": \"danifranco\"}]\n",
        "    bmz_cfg['authors'] = authors\n",
        "    # License of the model. E.g. \"CC-BY-4.0\"\n",
        "    bmz_cfg['license'] = trained_model_license\n",
        "    # List of dictionaries of citations associated, e.g. [{\"text\": \"Gizmo et al.\", \"doi\": \"doi:10.1002/xyzacab123\"}]\n",
        "    bmz_cfg['tags'] = tags\n",
        "    # Tags to make models more findable on the website, e.g. tags=[\"electron-microscopy\", \"mitochondria\"]\n",
        "    bmz_cfg['cite'] = citations\n",
        "    # Path to a file with a documentation of the model in markdown, e.g. \"my-model/doc.md\"\n",
        "    bmz_cfg['doc'] = trained_model_documentation\n",
        "    # Name of the model\n",
        "    bmz_cfg[\"model_name\"] = trained_model_name\n",
        "    biapy.export_model_to_bmz(bmz_results, bmz_cfg)\n",
        "else:\n",
        "    try:\n",
        "        biapy.export_model_to_bmz(bmz_results, reuse_original_bmz_config=True)\n",
        "    except:\n",
        "        print(\"Seems that the was a problem reusing BMZ model specs. Please uncheck 'reuse_previous_BMZ_model_config' and do it manually\")\n",
        "\n",
        "download = True\n",
        "if not reuse_previous_BMZ_model_config:\n",
        "    bmz_zip_path = f\"/{bmz_results}/{trained_model_name}.zip\"\n",
        "else:\n",
        "    ids = sorted(next(os.walk(bmz_results))[2])\n",
        "    ids = [x for x in ids if x.endswith(\".zip\")]\n",
        "    if len(ids) > 1:\n",
        "        print(f\"There are more than one ZIP files in {bmz_results} folder. Please check which one you want you want to download and do it manually.\")\n",
        "        download = False\n",
        "    elif len(ids) == 0:\n",
        "        print(f\"BMZ zip file could not be found.\")\n",
        "        download = False\n",
        "    else: # only one zip\n",
        "        ids = ids[0]\n",
        "    bmz_zip_path = f\"/{bmz_results}/{ids}\"\n",
        "\n",
        "if download and os.path.exists(bmz_zip_path):\n",
        "    files.download(bmz_zip_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **How to use the trained model with new data**\n",
        "---\n",
        "To directly infer new data to the trained model, you can use [this notebook](https://github.com/BiaPyX/BiaPy/blob/master/notebooks/BiaPy_Inference.ipynb). It will be necessary to upload the downloaded YAML configuration file and model weights to that notebook."
      ],
      "metadata": {
        "id": "PFVjWbF8GZ2z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjSgLwe0x-P0"
      },
      "source": [
        "## **Acknowledgments**\n",
        "---\n",
        "We extend our gratitude to the [ZeroCostDL4Mic notebooks](https://github.com/HenriquesLab/ZeroCostDL4Mic/wiki) for their invaluable inspiration. Notably, we have adopted some of their descriptions concerning metrics and parameters."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}